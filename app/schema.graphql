directive @oneOf on INPUT_OBJECT

input AddExamplesToDatasetInput {
  datasetId: GlobalID!
  examples: [DatasetExampleInput!]!
  datasetVersionDescription: String
  datasetVersionMetadata: JSON
}

input AddSpansToDatasetInput {
  datasetId: GlobalID!
  spanIds: [GlobalID!]!
  datasetVersionDescription: String
  datasetVersionMetadata: JSON
}

interface Annotation {
  """Name of the annotation, e.g. 'helpfulness' or 'relevance'."""
  name: String!

  """Value of the annotation in the form of a numeric score."""
  score: Float

  """
  Value of the annotation in the form of a string, e.g. 'helpful' or 'not helpful'. Note that the label is not necessarily binary.
  """
  label: String

  """
  The annotator's explanation for the annotation result (i.e. score or label, or both) given to the subject.
  """
  explanation: String
}

type AnnotationSummary {
  count: Int!
  labels: [String!]!
  labelFractions: [LabelFraction!]!
  meanScore: Float
  scoreCount: Int!
  labelCount: Int!
}

enum AnnotatorKind {
  LLM
  HUMAN
}

interface ApiKey {
  """Name of the API key."""
  name: String!

  """Description of the API key."""
  description: String

  """The date and time the API key was created."""
  createdAt: DateTime!

  """The date and time the API key will expire."""
  expiresAt: DateTime
}

enum AuthMethod {
  LOCAL
  OAUTH2
}

union Bin = NominalBin | IntervalBin | MissingValueBin

type BooleanInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: Boolean
}

type BoundedFloatInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: Float
  minValue: Float!
  maxValue: Float!
}

enum CanonicalParameterName {
  TEMPERATURE
  MAX_COMPLETION_TOKENS
  STOP_SEQUENCES
  TOP_P
  RANDOM_SEED
  TOOL_CHOICE
  RESPONSE_FORMAT
  REASONING_EFFORT
  ANTHROPIC_EXTENDED_THINKING
}

type ChatCompletionFunctionCall {
  name: String!
  arguments: String!
}

input ChatCompletionInput {
  messages: [ChatCompletionMessageInput!]!
  model: GenerativeModelInput!
  invocationParameters: [InvocationParameterInput!]! = []
  tools: [JSON!]
  apiKey: String = null
  template: PromptTemplateOptions
  promptName: Identifier = null
}

input ChatCompletionMessageInput {
  role: ChatCompletionMessageRole!

  """The content of the message as JSON to support various kinds of text"""
  content: JSON! = ""

  """The tool calls that were made in the message"""
  toolCalls: [JSON!]

  """
  The ID that corresponds to a prior tool call. Used to link a tool message to a pre-existing tool call.
  """
  toolCallId: String
}

enum ChatCompletionMessageRole {
  USER
  SYSTEM
  TOOL
  AI
}

type ChatCompletionMutationError {
  message: String!
}

type ChatCompletionMutationPayload {
  content: String
  toolCalls: [ChatCompletionToolCall!]!
  span: Span!
  errorMessage: String
}

union ChatCompletionMutationPayloadChatCompletionMutationError = ChatCompletionMutationPayload | ChatCompletionMutationError

input ChatCompletionOverDatasetInput {
  messages: [ChatCompletionMessageInput!]!
  model: GenerativeModelInput!
  invocationParameters: [InvocationParameterInput!]! = []
  tools: [JSON!]
  apiKey: String = null
  templateFormat: PromptTemplateFormat! = MUSTACHE
  datasetId: GlobalID!
  datasetVersionId: GlobalID = null
  experimentName: String = null
  experimentDescription: String = null
  experimentMetadata: JSON = {}
  promptName: Identifier = null
}

type ChatCompletionOverDatasetMutationExamplePayload {
  datasetExampleId: GlobalID!
  experimentRunId: GlobalID!
  result: ChatCompletionMutationPayloadChatCompletionMutationError!
}

type ChatCompletionOverDatasetMutationPayload {
  datasetId: GlobalID!
  datasetVersionId: GlobalID!
  experimentId: GlobalID!
  examples: [ChatCompletionOverDatasetMutationExamplePayload!]!
}

type ChatCompletionSubscriptionError implements ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
  message: String!
}

type ChatCompletionSubscriptionExperiment implements ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
  experiment: Experiment!
}

interface ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
}

type ChatCompletionSubscriptionResult implements ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
  span: Span
  experimentRun: ExperimentRun
}

type ChatCompletionToolCall {
  id: String!
  function: ChatCompletionFunctionCall!
}

input ChatPromptVersionInput {
  description: String = null
  templateFormat: PromptTemplateFormat!
  template: PromptChatTemplateInput!
  invocationParameters: JSON! = {}
  tools: [ToolDefinitionInput!]! = []
  responseFormat: ResponseFormatInput = null
  modelProvider: ModelProvider!
  modelName: String!
}

input ClearProjectInput {
  id: GlobalID!

  """The time up to which to purge data. Time is right-open /non-inclusive."""
  endTime: DateTime
}

input ClonePromptInput {
  name: Identifier!
  description: String = null
  promptId: GlobalID!
}

type Cluster {
  """The ID of the cluster"""
  id: ID!

  """The event IDs of the points in the cluster"""
  eventIds: [ID!]!

  """Ratio of primary points over reference points"""
  driftRatio: Float

  """Ratio of primary points over corpus points"""
  primaryToCorpusRatio: Float

  """
  Data quality metric summarized by the respective datasets of the clustered events
  """
  dataQualityMetric(metric: DataQualityMetricInput!): DatasetValues!

  """
  Performance metric summarized by the respective datasets of the clustered events
  """
  performanceMetric(metric: PerformanceMetricInput!): DatasetValues!
}

input ClusterInput {
  eventIds: [ID!]!
  id: ID
}

union ContentPart = TextContentPart | ToolCallContentPart | ToolResultContentPart

input ContentPartInput @oneOf {
  text: TextContentValueInput
  toolCall: ToolCallContentValueInput
  toolResult: ToolResultContentValueInput
}

input CreateApiKeyInput {
  name: String!
  description: String
  expiresAt: DateTime
}

input CreateChatPromptInput {
  name: Identifier!
  description: String = null
  promptVersion: ChatPromptVersionInput!
}

input CreateChatPromptVersionInput {
  promptId: GlobalID!
  promptVersion: ChatPromptVersionInput!
  tags: [SetPromptVersionTagInput!] = null
}

input CreateDatasetInput {
  name: String!
  description: String
  metadata: JSON
}

input CreatePromptLabelInput {
  name: Identifier!
  description: String = null
}

input CreateSpanAnnotationInput {
  spanId: GlobalID!
  name: String!
  annotatorKind: AnnotatorKind!
  label: String = null
  score: Float = null
  explanation: String = null
  metadata: JSON! = {}
}

type CreateSystemApiKeyMutationPayload {
  jwt: String!
  apiKey: SystemApiKey!
  query: Query!
}

input CreateTraceAnnotationInput {
  traceId: GlobalID!
  name: String!
  annotatorKind: AnnotatorKind!
  label: String = null
  score: Float = null
  explanation: String = null
  metadata: JSON! = {}
}

input CreateUserApiKeyInput {
  name: String!
  description: String
  expiresAt: DateTime
}

type CreateUserApiKeyMutationPayload {
  jwt: String!
  apiKey: UserApiKey!
  query: Query!
}

input CreateUserInput {
  email: String!
  username: String!
  password: String!
  role: UserRoleInput!
}

enum DataQualityMetric {
  cardinality
  percentEmpty
  mean
  sum
  min
  max
  count
  p01
  p25
  p50
  p75
  p99
}

input DataQualityMetricInput {
  metric: DataQualityMetric!
  columnName: String
}

type DataQualityTimeSeries implements TimeSeries {
  data: [TimeSeriesDataPoint!]!
}

type Dataset implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
  description: String
  metadata: JSON!
  createdAt: DateTime!
  updatedAt: DateTime!
  versions(first: Int = 50, last: Int, after: String, before: String, sort: DatasetVersionSort): DatasetVersionConnection!

  """
  Number of examples in a specific version if version is specified, or in the latest version if version is not specified.
  """
  exampleCount(datasetVersionId: GlobalID): Int!
  examples(datasetVersionId: GlobalID, first: Int = 50, last: Int, after: String, before: String): DatasetExampleConnection!

  """
  Number of experiments for a specific version if version is specified, or for all versions if version is not specified.
  """
  experimentCount(datasetVersionId: GlobalID): Int!
  experiments(first: Int = 50, last: Int, after: String, before: String): ExperimentConnection!
  experimentAnnotationSummaries: [ExperimentAnnotationSummary!]!
  lastUpdatedAt: DateTime
}

enum DatasetColumn {
  createdAt
  name
}

"""A connection to a list of items."""
type DatasetConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [DatasetEdge!]!
}

"""An edge in a connection."""
type DatasetEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Dataset!
}

type DatasetExample implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  createdAt: DateTime!
  revision(datasetVersionId: GlobalID): DatasetExampleRevision!
  span: Span
  experimentRuns(first: Int = 50, last: Int, after: String, before: String): ExperimentRunConnection!
}

"""A connection to a list of items."""
type DatasetExampleConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [DatasetExampleEdge!]!
}

"""An edge in a connection."""
type DatasetExampleEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: DatasetExample!
}

input DatasetExampleInput {
  input: JSON!
  output: JSON!
  metadata: JSON!
  spanId: GlobalID
}

input DatasetExamplePatch {
  exampleId: GlobalID!
  input: JSON
  output: JSON
  metadata: JSON
}

type DatasetExampleRevision implements ExampleRevision {
  input: JSON!
  output: JSON!
  metadata: JSON!
  revisionKind: RevisionKind!
  createdAt: DateTime!
}

type DatasetMutationPayload {
  dataset: Dataset!
}

"""The sort key and direction for dataset connections"""
input DatasetSort {
  col: DatasetColumn!
  dir: SortDir!
}

type DatasetValues {
  primaryValue: Float
  referenceValue: Float
}

type DatasetVersion implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  description: String
  metadata: JSON!
  createdAt: DateTime!
}

enum DatasetVersionColumn {
  createdAt
}

"""A connection to a list of items."""
type DatasetVersionConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [DatasetVersionEdge!]!
}

"""An edge in a connection."""
type DatasetVersionEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: DatasetVersion!
}

"""The sort key and direction for dataset version connections"""
input DatasetVersionSort {
  col: DatasetVersionColumn!
  dir: SortDir!
}

"""Date with time (isoformat)"""
scalar DateTime

type DbTableStats {
  tableName: String!
  numBytes: Float!
}

input DeleteAnnotationsInput {
  annotationIds: [GlobalID!]!
}

input DeleteApiKeyInput {
  id: GlobalID!
}

type DeleteApiKeyMutationPayload {
  apiKeyId: GlobalID!
  query: Query!
}

input DeleteDatasetExamplesInput {
  exampleIds: [GlobalID!]!
  datasetVersionDescription: String
  datasetVersionMetadata: JSON
}

input DeleteDatasetInput {
  datasetId: GlobalID!
}

input DeleteExperimentsInput {
  experimentIds: [GlobalID!]!
}

input DeletePromptInput {
  promptId: GlobalID!
}

input DeletePromptLabelInput {
  promptLabelId: GlobalID!
}

type DeletePromptMutationPayload {
  query: Query!
}

input DeletePromptVersionTagInput {
  promptVersionTagId: GlobalID!
}

input DeleteUsersInput {
  userIds: [GlobalID!]!
}

type Dimension implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!

  """The name of the dimension (a.k.a. the column name)"""
  name: String!

  """
  Whether the dimension represents a feature, tag, prediction, or actual.
  """
  type: DimensionType!

  """The data type of the column. Categorical or numeric."""
  dataType: DimensionDataType!

  """Whether the dimension data is continuous or discrete."""
  shape: DimensionShape!
  driftMetric(metric: ScalarDriftMetric!, timeRange: TimeRange): Float
  dataQualityMetric(
    metric: DataQualityMetric!
    timeRange: TimeRange

    """The inferences (primary or reference) to query"""
    inferencesRole: InferencesRole = primary
  ): Float

  """
  Returns the observed categories of a categorical dimension (usually a dimension of string values) as a list of unique string labels sorted in lexicographical order. Missing values are excluded. Non-categorical dimensions return an empty list.
  """
  categories: [String!]!

  """
  Returns the time series of the specified metric for data within a time range. Data points are generated starting at the end time and are separated by the sampling interval. Each data point is labeled by the end instant and contains data from their respective evaluation windows.
  """
  dataQualityTimeSeries(
    metric: DataQualityMetric!
    timeRange: TimeRange!
    granularity: Granularity!

    """The inferences (primary or reference) to query"""
    inferencesRole: InferencesRole = primary
  ): DataQualityTimeSeries!

  """
  The time series of the specified metric for data within a time range. Data points are generated starting at the end time and are separated by the sampling interval. Each data point is labeled by the end instant and contains data from their respective evaluation windows.
  """
  driftTimeSeries(metric: ScalarDriftMetric!, timeRange: TimeRange!, granularity: Granularity!): DriftTimeSeries!

  """
  The segments across both inference sets and returns the counts per segment
  """
  segmentsComparison(primaryTimeRange: TimeRange): Segments!
}

"""A connection to a list of items."""
type DimensionConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [DimensionEdge!]!
}

enum DimensionDataType {
  categorical
  numeric
}

"""An edge in a connection."""
type DimensionEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Dimension!
}

input DimensionFilter {
  types: [DimensionType!]
  shapes: [DimensionShape!]
  dataTypes: [DimensionDataType!]
}

input DimensionInput {
  name: String!
  type: DimensionType!
}

enum DimensionShape {
  continuous
  discrete
}

enum DimensionType {
  feature
  tag
  prediction
  actual
}

type DimensionWithValue {
  dimension: Dimension!

  """The string representation of the dimension's value"""
  value: String
}

type DocumentEvaluation implements Annotation {
  """Name of the annotation, e.g. 'helpfulness' or 'relevance'."""
  name: String!

  """Value of the annotation in the form of a numeric score."""
  score: Float

  """
  Value of the annotation in the form of a string, e.g. 'helpful' or 'not helpful'. Note that the label is not necessarily binary.
  """
  label: String

  """
  The annotator's explanation for the annotation result (i.e. score or label, or both) given to the subject.
  """
  explanation: String

  """
  The zero-based index among retrieved documents, which is collected as a list (even when ordering is not inherently meaningful).
  """
  documentPosition: Int!
}

"""
Summarization of retrieval metrics: Average NDCG@K, Average Precision@K, Mean Reciprocal Rank, Hit Rate, etc.
"""
type DocumentEvaluationSummary {
  evaluationName: String!
  averageNdcg(k: Int): Float
  countNdcg(k: Int): Int!
  averagePrecision(k: Int): Float
  countPrecision(k: Int): Int!
  meanReciprocalRank: Float
  countReciprocalRank: Int!
  hitRate: Float
  countHit: Int!
}

"""
A collection of retrieval metrics computed on a list of document evaluation scores: NDCG@K, Precision@K, Reciprocal Rank, etc.
"""
type DocumentRetrievalMetrics {
  evaluationName: String!

  """
  Normalized Discounted Cumulative Gain (NDCG) at `k` with log base 2 discounting. If `k` is None, it's set to the length of the scores. If `k` < 1, return 0.0.
  """
  ndcg(k: Int): Float

  """
  Precision at `k`, defined as the fraction of truthy scores among first `k` positions (1-based index). If `k` is None, then it's set to the length of the scores. If `k` < 1, return 0.0.
  """
  precision(k: Int): Float

  """
  Return `1/R` where `R` is the rank of the first hit, i.e. the 1-based index position of first truthy score, e.g. score=1. If a non-finite value (e.g. `NaN`) is encountered before the first (finite) truthy score, then return `NaN`, otherwise if no truthy score is found (or if the count of scores is zero), return 0.0.
  """
  reciprocalRank: Float

  """
  Return 1.0 if any score is truthy (i.e. is a hit), e.g. score=1. Otherwise, return `NaN` if any score is non-finite (e.g. `NaN`), or return 0.0 if all scores are falsy, e.g. all scores are 0.
  """
  hit: Float
}

type DriftTimeSeries implements TimeSeries {
  data: [TimeSeriesDataPoint!]!
}

type EmbeddingDimension implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!

  """
  Computes a drift metric between all reference data and the primary data belonging to the input time range (inclusive of the time range start and exclusive of the time range end). Returns None if no reference dataset exists, if no primary data exists in the input time range, or if the input time range is invalid.
  """
  driftMetric(metric: VectorDriftMetric!, timeRange: TimeRange): Float

  """
  Computes a retrieval metric between corpus data and the primary data belonging to the input time range (inclusive of the time range start and exclusive of the time range end). Returns None if no reference dataset exists, if no primary data exists in the input time range, or if the input time range is invalid.
  """
  retrievalMetric(metric: VectorDriftMetric!, timeRange: TimeRange): Float

  """
  Returns the time series of the specified metric for data within timeRange. Data points are generated starting at the end time, are separated by the sampling interval. Each data point is labeled by the end instant of and contains data from their respective evaluation window.
  """
  dataQualityTimeSeries(
    metric: DataQualityMetric!
    timeRange: TimeRange!
    granularity: Granularity!

    """The dataset (primary or reference) to query"""
    inferencesRole: InferencesRole = primary
  ): DataQualityTimeSeries!

  """
  Computes a drift time-series between the primary and reference datasets. The output drift time-series contains one data point for each whole hour in the input time range (inclusive of the time range start and exclusive of the time range end). Each data point contains the drift metric value between all reference data and the primary data within the evaluation window ending at the corresponding time. Returns None if no reference dataset exists or if the input time range is invalid.           
  """
  driftTimeSeries(metric: VectorDriftMetric!, timeRange: TimeRange!, granularity: Granularity!): DriftTimeSeries!

  """
  Computes a retrieval metric between the primary and corpus datasets. The output time-series contains one data point for each whole hour in the input time range (inclusive of the time range start and exclusive of the time range end). Each data point contains the metric value between all corpus data and the primary data within the evaluation window ending at the corresponding time. Returns None if no corpus dataset exists or if the input time range is invalid.           
  """
  retrievalMetricTimeSeries(metric: VectorDriftMetric!, timeRange: TimeRange!, granularity: Granularity!): DriftTimeSeries!
  UMAPPoints(
    """The time range of the primary dataset to generate the UMAP points for"""
    timeRange: TimeRange!

    """UMAP target dimension hyperparameter. Must be 2 or 3"""
    nComponents: Int = 3

    """UMAP minimum distance hyperparameter"""
    minDist: Float! = 0

    """UMAP N neighbors hyperparameter"""
    nNeighbors: Int! = 30

    """UMAP N samples"""
    nSamples: Int! = 500

    """HDBSCAN minimum cluster size"""
    minClusterSize: Int! = 10

    """HDBSCAN minimum samples"""
    clusterMinSamples: Int! = 1

    """HDBSCAN cluster selection epsilon"""
    clusterSelectionEpsilon: Float! = 0
  ): UMAPPoints!
}

"""A connection to a list of items."""
type EmbeddingDimensionConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [EmbeddingDimensionEdge!]!
}

"""An edge in a connection."""
type EmbeddingDimensionEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: EmbeddingDimension!
}

type EmbeddingMetadata {
  predictionId: String
  rawData: String
  linkToData: String
}

enum EvalAttr {
  score
  label
}

input EvalResultKey {
  name: String!
  attr: EvalAttr!
}

type Event {
  id: ID!
  eventMetadata: EventMetadata!
  dimensions: [DimensionWithValue!]!

  """The prompt and response pair associated with the event"""
  promptAndResponse: PromptResponse

  """The text of the document if the event is a retrieved document record"""
  documentText: String
}

type EventMetadata {
  predictionId: String
  predictionScore: Float
  predictionLabel: String
  actualScore: Float
  actualLabel: String
}

interface ExampleRevision {
  input: JSON!
  output: JSON!
  metadata: JSON!
}

type Experiment implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
  projectName: String
  description: String
  metadata: JSON!
  createdAt: DateTime!
  updatedAt: DateTime!

  """Sequence number (1-based) of experiments belonging to the same dataset"""
  sequenceNumber: Int!
  runs(first: Int = 50, last: Int, after: String, before: String): ExperimentRunConnection!
  runCount: Int!
  annotationSummaries: [ExperimentAnnotationSummary!]!
  errorRate: Float
  averageRunLatencyMs: Float
  project: Project
  lastUpdatedAt: DateTime
}

type ExperimentAnnotationSummary {
  annotationName: String!
  minScore: Float
  maxScore: Float
  meanScore: Float
  count: Int!
  errorCount: Int!
}

type ExperimentComparison {
  example: DatasetExample!
  runComparisonItems: [RunComparisonItem!]!
}

"""A connection to a list of items."""
type ExperimentConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [ExperimentEdge!]!
}

"""An edge in a connection."""
type ExperimentEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Experiment!
}

type ExperimentMutationPayload {
  experiments: [Experiment!]!
}

type ExperimentRun implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  experimentId: GlobalID!
  traceId: String
  output: JSON
  startTime: DateTime!
  endTime: DateTime!
  error: String
  annotations(first: Int = 50, last: Int, after: String, before: String): ExperimentRunAnnotationConnection!
  trace: Trace
  example: DatasetExample!
}

type ExperimentRunAnnotation implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
  annotatorKind: ExperimentRunAnnotatorKind!
  label: String
  score: Float
  explanation: String
  error: String
  metadata: JSON!
  startTime: DateTime!
  endTime: DateTime!
  traceId: String
  trace: Trace
}

"""A connection to a list of items."""
type ExperimentRunAnnotationConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [ExperimentRunAnnotationEdge!]!
}

"""An edge in a connection."""
type ExperimentRunAnnotationEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: ExperimentRunAnnotation!
}

enum ExperimentRunAnnotatorKind {
  LLM
  HUMAN
  CODE
}

"""A connection to a list of items."""
type ExperimentRunConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [ExperimentRunEdge!]!
}

"""An edge in a connection."""
type ExperimentRunEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: ExperimentRun!
}

type ExportedFile {
  """File name without the file extension."""
  fileName: String!
}

type FloatInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: Float
}

type FunctionCallChunk implements ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
  name: String!
  arguments: String!
}

type Functionality {
  """Model inferences are available for analysis"""
  modelInferences: Boolean!

  """Generative tracing records are available for analysis"""
  tracing: Boolean!
}

type GenerativeModel {
  name: String!
  providerKey: GenerativeProviderKey!
}

input GenerativeModelInput {
  providerKey: GenerativeProviderKey!
  name: String!
  baseUrl: String
  endpoint: String
  apiVersion: String
}

type GenerativeProvider {
  name: String!
  key: GenerativeProviderKey!
  dependencies: [String!]!
  dependenciesInstalled: Boolean!

  """The API key for the provider"""
  apiKeyEnvVar: String!

  """Whether the credentials are set on the server for the provider"""
  apiKeySet: Boolean!
}

enum GenerativeProviderKey {
  OPENAI
  ANTHROPIC
  AZURE_OPENAI
  GOOGLE
}

"""
The `ID` scalar type represents a unique identifier, often used to refetch an object or as key for a cache. The ID type appears in a JSON response as a String; however, it is not intended to be human-readable. When expected as an input type, any string (such as `"4"`) or integer (such as `4`) input value will be accepted as an ID.
"""
scalar GlobalID @specifiedBy(url: "https://relay.dev/graphql/objectidentification.htm")

"""
Granularity specifies the distance between points in a time-series and the duration of time (i.e. evaluation window) by which data is aggregated for  each data point. By convention all time intervals are right-open intervals, i.e. the end instant of the evaluation window is excluded from the interval. As a matter of standardization, each point in a time-series aggregates data  corresponding to an interval of time (i.e. the evaluation window) ending at the point's timestamp, and each time-series enumerates its points starting from the end instant of the TimeRange.
"""
input Granularity {
  """
  Specifies the length of time by which the data are grouped for aggregation. Each point in a time-series will have the same evaluation_window, but the evaluation_window for each point can overlap in real time. For example, when the points are 24 hours apart but the eval window is 72 hours, it means that each point in the time-series is aggregating 72 hours worth of data ending at the point's timestamp.
  """
  evaluationWindowMinutes: Int!

  """
  Specifies the time interval between each point in the time-series. All points in the time-series are separated by the same length of time, and are generated starting from the end time of the time range.
  """
  samplingIntervalMinutes: Int!
}

scalar Identifier

type Inferences {
  """The start bookend of the data"""
  startTime: DateTime!

  """The end bookend of the data"""
  endTime: DateTime!

  """The record count of the data"""
  recordCount: Int!

  """Returns a human friendly name for the inferences."""
  name: String!
  events(eventIds: [ID!]!, dimensions: [DimensionInput!]): [Event!]!
}

enum InferencesRole {
  primary
  reference
}

input InputCoordinate2D {
  x: Float!
  y: Float!
}

input InputCoordinate3D {
  x: Float!
  y: Float!
  z: Float!
}

type IntInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: Int
}

type IntervalBin {
  range: NumericRange!
}

enum InvocationInputField {
  value_int
  value_float
  value_bool
  value_string
  value_json
  value_string_list
  value_boolean
}

union InvocationParameter = IntInvocationParameter | FloatInvocationParameter | BoundedFloatInvocationParameter | StringInvocationParameter | JSONInvocationParameter | StringListInvocationParameter | BooleanInvocationParameter

interface InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
}

input InvocationParameterInput {
  invocationName: String!
  canonicalName: CanonicalParameterName = null
  valueInt: Int
  valueFloat: Float
  valueBool: Boolean
  valueString: String
  valueJson: JSON
  valueStringList: [String!]
  valueBoolean: Boolean
}

"""
The `JSON` scalar type represents JSON values as specified by [ECMA-404](https://ecma-international.org/wp-content/uploads/ECMA-404_2nd_edition_december_2017.pdf).
"""
scalar JSON @specifiedBy(url: "https://ecma-international.org/wp-content/uploads/ECMA-404_2nd_edition_december_2017.pdf")

type JSONInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: JSON
}

type LabelFraction {
  label: String!
  fraction: Float!
}

enum MimeType {
  text
  json
}

type MissingValueBin {
  name: String
}

type Model {
  dimensions(first: Int = 50, last: Int, after: String, before: String, include: DimensionFilter, exclude: DimensionFilter): DimensionConnection!
  primaryInferences: Inferences!
  referenceInferences: Inferences
  corpusInferences: Inferences
  embeddingDimensions(first: Int = 50, last: Int, after: String, before: String): EmbeddingDimensionConnection!

  """Returns exported file names sorted by descending modification time."""
  exportedFiles: [ExportedFile!]!
  performanceMetric(
    metric: PerformanceMetricInput!
    timeRange: TimeRange

    """The inferences (primary or reference) to query"""
    inferencesRole: InferencesRole = primary
  ): Float

  """
  Returns the time series of the specified metric for data within a time range. Data points are generated starting at the end time and are separated by the sampling interval. Each data point is labeled by the end instant and contains data from their respective evaluation windows.
  """
  performanceTimeSeries(
    metric: PerformanceMetricInput!
    timeRange: TimeRange!
    granularity: Granularity!

    """The inferences (primary or reference) to query"""
    inferencesRole: InferencesRole = primary
  ): PerformanceTimeSeries!
}

enum ModelProvider {
  OPENAI
  AZURE_OPENAI
  ANTHROPIC
  GOOGLE
}

input ModelsInput {
  providerKey: GenerativeProviderKey
  modelName: String = null
}

type Mutation {
  createSystemApiKey(input: CreateApiKeyInput!): CreateSystemApiKeyMutationPayload!
  createUserApiKey(input: CreateUserApiKeyInput!): CreateUserApiKeyMutationPayload!
  deleteSystemApiKey(input: DeleteApiKeyInput!): DeleteApiKeyMutationPayload!
  deleteUserApiKey(input: DeleteApiKeyInput!): DeleteApiKeyMutationPayload!
  chatCompletionOverDataset(input: ChatCompletionOverDatasetInput!): ChatCompletionOverDatasetMutationPayload!
  chatCompletion(input: ChatCompletionInput!): ChatCompletionMutationPayload!
  createDataset(input: CreateDatasetInput!): DatasetMutationPayload!
  patchDataset(input: PatchDatasetInput!): DatasetMutationPayload!
  addSpansToDataset(input: AddSpansToDatasetInput!): DatasetMutationPayload!
  addExamplesToDataset(input: AddExamplesToDatasetInput!): DatasetMutationPayload!
  deleteDataset(input: DeleteDatasetInput!): DatasetMutationPayload!
  patchDatasetExamples(input: PatchDatasetExamplesInput!): DatasetMutationPayload!
  deleteDatasetExamples(input: DeleteDatasetExamplesInput!): DatasetMutationPayload!
  deleteExperiments(input: DeleteExperimentsInput!): ExperimentMutationPayload!

  """
  Given a list of event ids, export the corresponding data subset in Parquet format. File name is optional, but if specified, should be without file extension. By default the exported file name is current timestamp.
  """
  exportEvents(eventIds: [ID!]!, fileName: String): ExportedFile!

  """
  Given a list of clusters, export the corresponding data subset in Parquet format. File name is optional, but if specified, should be without file extension. By default the exported file name is current timestamp.
  """
  exportClusters(clusters: [ClusterInput!]!, fileName: String): ExportedFile!
  deleteProject(id: GlobalID!): Query!
  clearProject(input: ClearProjectInput!): Query!
  createChatPrompt(input: CreateChatPromptInput!): Prompt!
  createChatPromptVersion(input: CreateChatPromptVersionInput!): Prompt!
  deletePrompt(input: DeletePromptInput!): DeletePromptMutationPayload!
  clonePrompt(input: ClonePromptInput!): Prompt!
  patchPrompt(input: PatchPromptInput!): Prompt!
  deletePromptVersionTag(input: DeletePromptVersionTagInput!): PromptVersionTagMutationPayload!
  setPromptVersionTag(input: SetPromptVersionTagInput!): PromptVersionTagMutationPayload!
  createPromptLabel(input: CreatePromptLabelInput!): PromptLabelMutationPayload!
  patchPromptLabel(input: PatchPromptLabelInput!): PromptLabelMutationPayload!
  deletePromptLabel(input: DeletePromptLabelInput!): PromptLabelMutationPayload!
  setPromptLabel(input: SetPromptLabelInput!): PromptLabelMutationPayload!
  unsetPromptLabel(input: UnsetPromptLabelInput!): PromptLabelMutationPayload!
  createSpanAnnotations(input: [CreateSpanAnnotationInput!]!): SpanAnnotationMutationPayload!
  patchSpanAnnotations(input: [PatchAnnotationInput!]!): SpanAnnotationMutationPayload!
  deleteSpanAnnotations(input: DeleteAnnotationsInput!): SpanAnnotationMutationPayload!
  createTraceAnnotations(input: [CreateTraceAnnotationInput!]!): TraceAnnotationMutationPayload!
  patchTraceAnnotations(input: [PatchAnnotationInput!]!): TraceAnnotationMutationPayload!
  deleteTraceAnnotations(input: DeleteAnnotationsInput!): TraceAnnotationMutationPayload!
  deleteTraces(traceIds: [GlobalID!]!): Query!
  createUser(input: CreateUserInput!): UserMutationPayload!
  patchUser(input: PatchUserInput!): UserMutationPayload!
  patchViewer(input: PatchViewerInput!): UserMutationPayload!
  deleteUsers(input: DeleteUsersInput!): Void
}

"""An object with a Globally Unique ID"""
interface Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
}

type NominalBin {
  name: String!
}

type NumericRange {
  start: Float!
  end: Float!
}

"""Information to aid in pagination."""
type PageInfo {
  """When paginating forwards, are there more items?"""
  hasNextPage: Boolean!

  """When paginating backwards, are there more items?"""
  hasPreviousPage: Boolean!

  """When paginating backwards, the cursor to continue."""
  startCursor: String

  """When paginating forwards, the cursor to continue."""
  endCursor: String
}

input PatchAnnotationInput {
  annotationId: GlobalID!
  name: String
  annotatorKind: AnnotatorKind
  label: String
  score: Float
  explanation: String
  metadata: JSON
}

input PatchDatasetExamplesInput {
  patches: [DatasetExamplePatch!]!
  versionDescription: String
  versionMetadata: JSON
}

input PatchDatasetInput {
  datasetId: GlobalID!
  name: String
  description: String
  metadata: JSON
}

input PatchPromptInput {
  promptId: GlobalID!
  description: String!
}

input PatchPromptLabelInput {
  promptLabelId: GlobalID!
  name: Identifier = null
  description: String = null
}

input PatchUserInput {
  userId: GlobalID!
  newRole: UserRoleInput
  newUsername: String
  newPassword: String
}

input PatchViewerInput {
  newUsername: String
  newPassword: String
  currentPassword: String
}

enum PerformanceMetric {
  accuracyScore
}

input PerformanceMetricInput {
  metric: PerformanceMetric!
}

type PerformanceTimeSeries implements TimeSeries {
  data: [TimeSeriesDataPoint!]!
}

type Point2D {
  x: Float!
  y: Float!
}

union Point2DPoint3D = Point2D | Point3D

type Point3D {
  x: Float!
  y: Float!
  z: Float!
}

type Project implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
  gradientStartColor: String!
  gradientEndColor: String!
  startTime: DateTime
  endTime: DateTime
  recordCount(timeRange: TimeRange, filterCondition: String): Int!
  traceCount(timeRange: TimeRange): Int!
  tokenCountTotal(timeRange: TimeRange, filterCondition: String): Int!
  tokenCountPrompt(timeRange: TimeRange, filterCondition: String): Int!
  tokenCountCompletion(timeRange: TimeRange, filterCondition: String): Int!
  latencyMsQuantile(probability: Float!, timeRange: TimeRange): Float
  spanLatencyMsQuantile(probability: Float!, timeRange: TimeRange, filterCondition: String): Float
  trace(traceId: ID!): Trace
  spans(timeRange: TimeRange, first: Int = 30, last: Int, after: String, before: String, sort: SpanSort, rootSpansOnly: Boolean, filterCondition: String): SpanConnection!
  sessions(timeRange: TimeRange, first: Int = 30, after: String, sort: ProjectSessionSort, filterIoSubstring: String): ProjectSessionConnection!

  """
  Names of all available annotations for traces. (The list contains no duplicates.)
  """
  traceAnnotationsNames: [String!]!

  """
  Names of all available annotations for spans. (The list contains no duplicates.)
  """
  spanAnnotationNames: [String!]!

  """Names of available document evaluations."""
  documentEvaluationNames(spanId: ID): [String!]!
  traceAnnotationSummary(annotationName: String!, timeRange: TimeRange): AnnotationSummary
  spanAnnotationSummary(annotationName: String!, timeRange: TimeRange, filterCondition: String): AnnotationSummary
  documentEvaluationSummary(evaluationName: String!, timeRange: TimeRange, filterCondition: String): DocumentEvaluationSummary
  streamingLastUpdatedAt: DateTime
  validateSpanFilterCondition(condition: String!): ValidationResult!
}

"""A connection to a list of items."""
type ProjectConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [ProjectEdge!]!
}

"""An edge in a connection."""
type ProjectEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Project!
}

type ProjectSession implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  sessionId: String!
  startTime: DateTime!
  endTime: DateTime!
  projectId: GlobalID!
  numTraces: Int!
  numTracesWithError: Int!
  firstInput: SpanIOValue
  lastOutput: SpanIOValue
  tokenUsage: TokenUsage!
  traces(first: Int = 50, last: Int, after: String, before: String): TraceConnection!
  traceLatencyMsQuantile(probability: Float!): Float
}

enum ProjectSessionColumn {
  startTime
  endTime
  tokenCountTotal
  numTraces
}

"""A connection to a list of items."""
type ProjectSessionConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [ProjectSessionEdge!]!
}

"""An edge in a connection."""
type ProjectSessionEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: ProjectSession!
}

"""The sort key and direction for ProjectSession connections."""
input ProjectSessionSort {
  col: ProjectSessionColumn!
  dir: SortDir!
}

type Prompt implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  sourcePromptId: GlobalID
  name: Identifier!
  description: String
  createdAt: DateTime!
  version(versionId: GlobalID = null): PromptVersion!
  versionTags: [PromptVersionTag!]!
  promptVersions(first: Int = 50, last: Int, after: String, before: String): PromptVersionConnection!
  sourcePrompt: Prompt
}

type PromptChatTemplate {
  messages: [PromptMessage!]!
}

input PromptChatTemplateInput {
  messages: [PromptMessageInput!]!
}

"""A connection to a list of items."""
type PromptConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [PromptEdge!]!
}

"""An edge in a connection."""
type PromptEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Prompt!
}

type PromptLabel implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: Identifier!
  description: String
  prompts: [Prompt!]!
}

"""A connection to a list of items."""
type PromptLabelConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [PromptLabelEdge!]!
}

"""An edge in a connection."""
type PromptLabelEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: PromptLabel!
}

type PromptLabelMutationPayload {
  promptLabel: PromptLabel
  query: Query!
}

type PromptMessage {
  role: PromptMessageRole!
  content: [ContentPart!]!
}

input PromptMessageInput {
  role: String!
  content: [ContentPartInput!]!
}

enum PromptMessageRole {
  USER
  SYSTEM
  AI
  TOOL
}

type PromptResponse {
  """The prompt submitted to the LLM"""
  prompt: String

  """The response generated by the LLM"""
  response: String
}

type PromptStringTemplate {
  template: String!
}

union PromptTemplate = PromptStringTemplate | PromptChatTemplate

enum PromptTemplateFormat {
  MUSTACHE
  F_STRING
  NONE
}

input PromptTemplateOptions {
  variables: JSON!
  format: PromptTemplateFormat!
}

enum PromptTemplateType {
  STRING
  CHAT
}

type PromptVersion implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  description: String
  templateType: PromptTemplateType!
  templateFormat: PromptTemplateFormat!
  template: PromptTemplate!
  invocationParameters: JSON
  tools: [ToolDefinition!]!
  responseFormat: ResponseFormat
  modelName: String!
  modelProvider: ModelProvider!
  metadata: JSON!
  createdAt: DateTime!
  tags: [PromptVersionTag!]!
  user: User
  previousVersion: PromptVersion

  """
  Sequence number (1-based) of prompt versions belonging to the same prompt
  """
  sequenceNumber: Int!
}

"""A connection to a list of items."""
type PromptVersionConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [PromptVersionEdge!]!
}

"""An edge in a connection."""
type PromptVersionEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: PromptVersion!
}

type PromptVersionTag implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  promptVersionId: GlobalID!
  name: Identifier!
  description: String
}

type PromptVersionTagMutationPayload {
  promptVersionTag: PromptVersionTag
  prompt: Prompt!
  query: Query!
}

type Query {
  modelProviders: [GenerativeProvider!]!
  models(input: ModelsInput = null): [GenerativeModel!]!
  modelInvocationParameters(input: ModelsInput = null): [InvocationParameter!]!
  users(first: Int = 50, last: Int, after: String, before: String): UserConnection!
  userRoles: [UserRole!]!
  userApiKeys: [UserApiKey!]!
  systemApiKeys: [SystemApiKey!]!
  projects(first: Int = 50, last: Int, after: String, before: String): ProjectConnection!
  projectsLastUpdatedAt: DateTime
  datasets(first: Int = 50, last: Int, after: String, before: String, sort: DatasetSort): DatasetConnection!
  datasetsLastUpdatedAt: DateTime
  compareExperiments(experimentIds: [GlobalID!]!, filterCondition: String): [ExperimentComparison!]!
  validateExperimentRunFilterCondition(condition: String!, experimentIds: [GlobalID!]!): ValidationResult!
  functionality: Functionality!
  model: Model!
  node(id: GlobalID!): Node!
  viewer: User
  prompts(first: Int = 50, last: Int, after: String, before: String): PromptConnection!
  promptLabels(first: Int = 50, last: Int, after: String, before: String): PromptLabelConnection!
  clusters(clusters: [ClusterInput!]!): [Cluster!]!
  hdbscanClustering(
    """Event ID of the coordinates"""
    eventIds: [ID!]!

    """Point coordinates. Must be either 2D or 3D."""
    coordinates2d: [InputCoordinate2D!]

    """Point coordinates. Must be either 2D or 3D."""
    coordinates3d: [InputCoordinate3D!]

    """HDBSCAN minimum cluster size"""
    minClusterSize: Int! = 10

    """HDBSCAN minimum samples"""
    clusterMinSamples: Int! = 1

    """HDBSCAN cluster selection epsilon"""
    clusterSelectionEpsilon: Float! = 0
  ): [Cluster!]!

  """
  The allocated storage capacity of the database in bytes. Return None if this information is unavailable.
  """
  dbStorageCapacityBytes: Float
  dbTableStats: [DbTableStats!]!
}

type ResponseFormat {
  definition: JSON!
}

input ResponseFormatInput {
  definition: JSON!
}

type Retrieval {
  queryId: ID!
  documentId: ID!
  relevance: Float
}

enum RevisionKind {
  CREATE
  PATCH
  DELETE
}

type RunComparisonItem {
  experimentId: GlobalID!
  runs: [ExperimentRun!]!
}

enum ScalarDriftMetric {
  psi
  klDivergence
  jsDistance
}

type Segment {
  bin: Bin!
  counts: DatasetValues!
}

type Segments {
  segments: [Segment!]!
  totalCounts: DatasetValues!
}

input SetPromptLabelInput {
  promptId: GlobalID!
  promptLabelId: GlobalID!
}

input SetPromptVersionTagInput {
  promptVersionId: GlobalID!
  name: Identifier!
  description: String = null
}

enum SortDir {
  asc
  desc
}

type Span implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
  statusCode: SpanStatusCode!
  statusMessage: String!
  startTime: DateTime!
  endTime: DateTime
  latencyMs: Float

  """the parent span ID. If null, it is a root span"""
  parentId: ID
  spanKind: SpanKind!
  spanId: ID!
  trace: Trace!
  context: SpanContext!

  """Span attributes as a JSON string"""
  attributes: String!

  """Metadata as a JSON string"""
  metadata: String
  numDocuments: Int
  tokenCountTotal: Int
  tokenCountPrompt: Int
  tokenCountCompletion: Int
  input: SpanIOValue
  output: SpanIOValue
  events: [SpanEvent!]!

  """
  Cumulative (prompt plus completion) token count from self and all descendant spans (children, grandchildren, etc.)
  """
  cumulativeTokenCountTotal: Int

  """
  Cumulative (prompt) token count from self and all descendant spans (children, grandchildren, etc.)
  """
  cumulativeTokenCountPrompt: Int

  """
  Cumulative (completion) token count from self and all descendant spans (children, grandchildren, etc.)
  """
  cumulativeTokenCountCompletion: Int

  """
  Propagated status code that percolates up error status codes from descendant spans (children, grandchildren, etc.)
  """
  propagatedStatusCode: SpanStatusCode!

  """
  Annotations associated with the span. This encompasses both LLM and human annotations.
  """
  spanAnnotations(sort: SpanAnnotationSort): [SpanAnnotation!]!

  """
  Evaluations of the documents associated with the span, e.g. if the span is a RETRIEVER with a list of documents in its RETRIEVAL_DOCUMENTS attribute, an evaluation for each document may assess its relevance respect to the input query of the span. Note that RETRIEVAL_DOCUMENTS is a list, and each evaluation is identified by its document's (zero-based) index in that list.
  """
  documentEvaluations: [DocumentEvaluation!]!

  """Retrieval metrics: NDCG@K, Precision@K, Reciprocal Rank, etc."""
  documentRetrievalMetrics(evaluationName: String): [DocumentRetrievalMetrics!]!
  numChildSpans: Int!

  """All descendant spans (children, grandchildren, etc.)"""
  descendants(
    """
    Maximum depth of breadth first search. For example, maxDepth=1 searches for only the immediate child spans (if any); maxDepth=2 searches for the immediate child spans plus their children. maxDepth=0 (or None) means no limit.
    """
    maxDepth: Int = 3
    first: Int = 50
    last: Int
    after: String
    before: String
  ): SpanConnection!

  """
  The span's attributes translated into an example revision for a dataset
  """
  asExampleRevision: SpanAsExampleRevision!

  """The project that this span belongs to."""
  project: Project!

  """Indicates if the span is contained in any dataset"""
  containedInDataset: Boolean!

  """Invocation parameters for the span"""
  invocationParameters: [InvocationParameter!]!
}

type SpanAnnotation implements Node & Annotation {
  """The Globally Unique ID of this object"""
  id: GlobalID!

  """Name of the annotation, e.g. 'helpfulness' or 'relevance'."""
  name: String!

  """Value of the annotation in the form of a numeric score."""
  score: Float

  """
  Value of the annotation in the form of a string, e.g. 'helpful' or 'not helpful'. Note that the label is not necessarily binary.
  """
  label: String

  """
  The annotator's explanation for the annotation result (i.e. score or label, or both) given to the subject.
  """
  explanation: String
  annotatorKind: AnnotatorKind!
  metadata: JSON!
  spanId: GlobalID!
}

enum SpanAnnotationColumn {
  createdAt
  name
}

type SpanAnnotationMutationPayload {
  spanAnnotations: [SpanAnnotation!]!
  query: Query!
}

"""The sort key and direction for SpanAnnotation connections"""
input SpanAnnotationSort {
  col: SpanAnnotationColumn!
  dir: SortDir!
}

type SpanAsExampleRevision implements ExampleRevision {
  input: JSON!
  output: JSON!
  metadata: JSON!
}

enum SpanColumn {
  startTime
  endTime
  latencyMs
  tokenCountTotal
  tokenCountPrompt
  tokenCountCompletion
  cumulativeTokenCountTotal
  cumulativeTokenCountPrompt
  cumulativeTokenCountCompletion
}

"""A connection to a list of items."""
type SpanConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [SpanEdge!]!
}

type SpanContext {
  traceId: ID!
  spanId: ID!
}

"""An edge in a connection."""
type SpanEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Span!
}

type SpanEvent {
  name: String!
  message: String!
  timestamp: DateTime!
}

type SpanIOValue {
  mimeType: MimeType!

  """Truncated value up to 100 characters, appending '...' if truncated."""
  truncatedValue: String!
  value: String!
}

enum SpanKind {
  chain
  tool
  llm
  retriever
  embedding
  agent
  reranker
  evaluator
  guardrail
  unknown
}

"""
The sort key and direction for span connections. Must specify one and only one of either `col` or `evalResultKey`.
"""
input SpanSort {
  col: SpanColumn
  evalResultKey: EvalResultKey
  dir: SortDir!
}

enum SpanStatusCode {
  OK
  ERROR
  UNSET
}

type StringInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: String
}

type StringListInvocationParameter implements InvocationParameterBase {
  invocationName: String!
  canonicalName: CanonicalParameterName
  label: String!
  required: Boolean!
  invocationInputField: InvocationInputField!
  defaultValue: [String!]
}

type Subscription {
  chatCompletion(input: ChatCompletionInput!): ChatCompletionSubscriptionPayload!
  chatCompletionOverDataset(input: ChatCompletionOverDatasetInput!): ChatCompletionSubscriptionPayload!
}

type SystemApiKey implements ApiKey & Node {
  """Name of the API key."""
  name: String!

  """Description of the API key."""
  description: String

  """The date and time the API key was created."""
  createdAt: DateTime!

  """The date and time the API key will expire."""
  expiresAt: DateTime

  """The Globally Unique ID of this object"""
  id: GlobalID!
}

type TextChunk implements ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
  content: String!
}

type TextContentPart {
  text: TextContentValue!
}

type TextContentValue {
  text: String!
}

input TextContentValueInput {
  text: String!
}

input TimeRange {
  """The start of the time range"""
  start: DateTime = null

  """The end of the time range. Right exclusive."""
  end: DateTime = null
}

interface TimeSeries {
  data: [TimeSeriesDataPoint!]!
}

type TimeSeriesDataPoint {
  timestamp: DateTime!
  value: Float
}

type TokenUsage {
  prompt: Int!
  completion: Int!
  total: Int!
}

type ToolCallChunk implements ChatCompletionSubscriptionPayload {
  datasetExampleId: GlobalID
  id: String!
  function: FunctionCallChunk!
}

type ToolCallContentPart {
  toolCall: ToolCallContentValue!
}

type ToolCallContentValue {
  toolCallId: String!
  toolCall: ToolCallFunction!
}

input ToolCallContentValueInput {
  toolCallId: String!
  toolCall: ToolCallFunctionInput!
}

type ToolCallFunction {
  name: String!
  arguments: String!
}

input ToolCallFunctionInput {
  type: String = "function"
  name: String!
  arguments: String!
}

type ToolDefinition {
  definition: JSON!
}

input ToolDefinitionInput {
  definition: JSON!
}

type ToolResultContentPart {
  toolResult: ToolResultContentValue!
}

type ToolResultContentValue {
  toolCallId: String!
  result: JSON!
}

input ToolResultContentValueInput {
  toolCallId: String!
  result: JSON!
}

type Trace implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  traceId: ID!
  startTime: DateTime!
  endTime: DateTime!
  latencyMs: Float
  project: Project!
  projectId: GlobalID!
  projectSessionId: GlobalID
  session: ProjectSession
  rootSpan: Span
  numSpans: Int!
  spans(first: Int = 50, last: Int, after: String, before: String): SpanConnection!

  """Annotations associated with the trace."""
  spanAnnotations(sort: TraceAnnotationSort = null): [TraceAnnotation!]!
}

type TraceAnnotation implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
  annotatorKind: AnnotatorKind!
  label: String
  score: Float
  explanation: String
  metadata: JSON!
  traceId: GlobalID!
}

enum TraceAnnotationColumn {
  createdAt
  name
}

type TraceAnnotationMutationPayload {
  traceAnnotations: [TraceAnnotation!]!
  query: Query!
}

"""The sort key and direction for TraceAnnotation connections"""
input TraceAnnotationSort {
  col: TraceAnnotationColumn!
  dir: SortDir!
}

"""A connection to a list of items."""
type TraceConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [TraceEdge!]!
}

"""An edge in a connection."""
type TraceEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: Trace!
}

type UMAPPoint {
  id: GlobalID!

  """The ID of the event that the point is a projection of"""
  eventId: ID!
  coordinates: Point2DPoint3D!
  embeddingMetadata: EmbeddingMetadata!
  eventMetadata: EventMetadata!
}

type UMAPPoints {
  data: [UMAPPoint!]!
  referenceData: [UMAPPoint!]!
  clusters: [Cluster!]!
  corpusData: [UMAPPoint!]!
  contextRetrievals: [Retrieval!]!
}

input UnsetPromptLabelInput {
  promptId: GlobalID!
  promptLabelId: GlobalID!
}

type User implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  passwordNeedsReset: Boolean!
  email: String!
  username: String!
  profilePictureUrl: String
  createdAt: DateTime!
  authMethod: AuthMethod!
  role: UserRole!
  apiKeys: [UserApiKey!]!
}

type UserApiKey implements ApiKey & Node {
  """Name of the API key."""
  name: String!

  """Description of the API key."""
  description: String

  """The date and time the API key was created."""
  createdAt: DateTime!

  """The date and time the API key will expire."""
  expiresAt: DateTime

  """The Globally Unique ID of this object"""
  id: GlobalID!
  user: User!
}

"""A connection to a list of items."""
type UserConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!

  """Contains the nodes in this connection"""
  edges: [UserEdge!]!
}

"""An edge in a connection."""
type UserEdge {
  """A cursor for use in pagination"""
  cursor: String!

  """The item at the end of the edge"""
  node: User!
}

type UserMutationPayload {
  user: User!
}

type UserRole implements Node {
  """The Globally Unique ID of this object"""
  id: GlobalID!
  name: String!
}

enum UserRoleInput {
  ADMIN
  MEMBER
}

type ValidationResult {
  isValid: Boolean!
  errorMessage: String
}

enum VectorDriftMetric {
  euclideanDistance
}

"""Represents NULL values"""
scalar Void