---
title: "More Cookbooks"
---

Iteratively improve your LLM task by building datasets, running experiments, and evaluating performance using code and LLM-as-a-Judge.

## Use Cases

* [Answer and Context Relevancy Evals](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/experiments/llama-index/answer_and_context_relevancy.ipynb)
* [RAG with Reranker](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/experiments/run_experiments_with_llama_index.ipynb)
* [Response Guideline Evals](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/experiments/llama-index/guideline_eval.ipynb)

