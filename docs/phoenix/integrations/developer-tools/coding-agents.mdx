---
title: "Coding Agents"
description: Integrate Phoenix with AI coding assistants like Claude Code, Cursor, and Windsurf for debugging LLM applications.
---

Phoenix provides tools for AI coding assistants to debug and analyze your LLM applications directly from the terminal.

## Installation

### Phoenix CLI

Install the CLI globally:

```bash
npm install -g @arizeai/phoenix-cli
```

### Phoenix Skills

Add Phoenix skills to your AI coding agent using [skills add](https://github.com/vercel-labs/skills):

```bash
npx skills add Arize-ai/phoenix
```

This installs the skill to your project's skills directory (`.cursor/skills/`, `.claude/skills/`, or `.github/skills/`).

#### Available Skills

| Skill | Description | Recommended |
|-------|-------------|-------------|
| `phoenix-cli` | Debug and analyze LLM applications using Phoenix CLI tools. Teaches agents to fetch traces, analyze performance, and review experiments. | Yes |
| `phoenix-tracing` | OpenInference semantic conventions and instrumentation. Teaches agents proper span types, attributes, and production deployment patterns. | Optional |

#### skills add Options

| Option | Description |
|--------|-------------|
| `-g, --global` | Install to user directory instead of project |
| `-a, --agent <agents...>` | Target specific agents (e.g., `claude-code`, `cursor`) |
| `-s, --skill <skills...>` | Install specific skills by name |
| `-l, --list` | List available skills without installing |
| `-y, --yes` | Skip all confirmation prompts |

**Examples:**

```bash
# Install the CLI skill globally for all projects
npx skills add Arize-ai/phoenix --skill phoenix-cli -g

# Install both skills for comprehensive Phoenix support
npx skills add Arize-ai/phoenix --skill phoenix-cli --skill phoenix-tracing

# Install to specific agents
npx skills add Arize-ai/phoenix --skill phoenix-cli -a claude-code -a cursor

# Non-interactive installation (CI/CD friendly)
npx skills add Arize-ai/phoenix --skill phoenix-cli -g -y
```

**Supported agents:** Claude Code, Cursor, Windsurf, Codex, GitHub Copilot, Cline, OpenCode, Gemini CLI, and [20+ more](https://github.com/vercel-labs/skills#supported-agents).

## Configuration

Set environment variables to connect to your Phoenix instance:

```bash
export PHOENIX_HOST=http://localhost:6006    # Your Phoenix endpoint
export PHOENIX_PROJECT=my-project            # Project name
export PHOENIX_API_KEY=your-api-key          # API key (if auth enabled)
```

## Using the Skills

### phoenix-cli

The CLI skill teaches your AI assistant how to:

- Debug failed LLM applications using trace data
- Analyze performance issues and token usage
- Review experiment results and datasets

**Example prompt:**

```
Debug my agent - it's failing on tool calls. Fetch recent traces and identify the issue.
```

### phoenix-tracing (Optional)

The tracing skill teaches your AI assistant how to:

- Instrument LLM applications with OpenInference tracing
- Create custom spans with proper attributes (LLM, RETRIEVER, TOOL, AGENT, etc.)
- Follow semantic conventions for consistent observability
- Configure production deployment patterns (batching, PII masking)

**Example prompt:**

```
Add Phoenix tracing to my RAG pipeline. Create spans for the retriever and LLM calls.
```

## Related

<CardGroup cols={2}>
  <Card title="CLI Reference" icon="terminal" href="/docs/phoenix/sdk-api-reference/typescript/arizeai-phoenix-cli">
    Full CLI command reference
  </Card>
  <Card title="Retrieve Traces via CLI" icon="download" href="/docs/phoenix/tracing/how-to-tracing/importing-and-exporting-traces/retrieve-traces-via-cli">
    Detailed guide for fetching traces
  </Card>
  <Card title="MCP Servers" icon="plug" href="/docs/phoenix/integrations/phoenix-mcp-server">
    Connect AI assistants to Phoenix via MCP
  </Card>
</CardGroup>
