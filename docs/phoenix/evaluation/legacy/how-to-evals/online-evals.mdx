---
title: "Online evals"
---

You can use cron to run evals client-side as your traces and spans are generated, augmenting your dataset with evaluations in an online manner. View the [example in Github](https://github.com/Arize-ai/phoenix/tree/main/examples/cron-evals).

<Frame caption="">
  <img src="https://storage.googleapis.com/arize-phoenix-assets/assets/images/phoenix-docs-images/7bbef1d7-image.jpeg" />
</Frame>

This example:

* Continuously queries a LangChain application to send new traces and spans to your Phoenix session

* Queries new spans once per minute and runs evals, including:

  * Hallucination

  * Q\&A Correctness

  * Relevance

* Logs evaluations back to Phoenix so they appear in the UI

The evaluation script is run as a cron job, enabling you to adjust the frequency of the evaluation job:

```ruby
* * * * * /path/to/python /path/to/run_evals.py
```

<Frame caption="Example Online Evals Script">
  <Card
    horizontal
    title="online_evals_periodic_eval_chron.py"
    icon="file-arrow-down"
    href="https://3394180728-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FShR775Rt7OzHRfy5j2Ks%2Fuploads%2Fgit-blob-f417754c4808d53836acf34742495879d759da10%2Fonline_evals_periodic_eval_chron.py?alt=media"
  >
    5KB
  </Card>
</Frame>

The above script can be run periodically to augment Evals in Phoenix.


