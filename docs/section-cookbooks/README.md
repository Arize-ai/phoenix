# Featured Tutorials

<table data-view="cards"><thead><tr><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>OpenAI Agents SDK Cookbook</strong> </td><td></td><td><a href="agent-workflow-patterns/openai-agents.md">openai-agents.md</a></td><td><a href=".gitbook/assets/image.avif">image.avif</a></td></tr><tr><td><strong>Agent Cookbook</strong></td><td></td><td><a href="datasets-and-experiments/experiment-with-a-customer-support-agent.md">experiment-with-a-customer-support-agent.md</a></td><td><a href=".gitbook/assets/Screenshot 2025-04-21 at 10.52.50 PM.png">Screenshot 2025-04-21 at 10.52.50 PM.png</a></td></tr><tr><td><strong>Creating a Custom LLM Evaluator with a Benchmark Dataset</strong></td><td></td><td><a href="human-in-the-loop-workflows-annotations/creating-a-custom-llm-evaluator-with-a-benchmark-dataset.md">creating-a-custom-llm-evaluator-with-a-benchmark-dataset.md</a></td><td><a href=".gitbook/assets/custom_llm_eval_cookbook_thumbnail.png">custom_llm_eval_cookbook_thumbnail.png</a></td></tr><tr><td><strong>Using Human Annotations for Eval-Driven Development</strong></td><td></td><td><a href="human-in-the-loop-workflows-annotations/using-human-annotations-for-eval-driven-development.md">using-human-annotations-for-eval-driven-development.md</a></td><td><a href=".gitbook/assets/annotation-cookbook-thumbnail.png">annotation-cookbook-thumbnail.png</a></td></tr><tr><td><strong>LLM Ops - Tracing, Evaluation, and Analysis</strong></td><td></td><td><a href="https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/llm_ops_overview.ipynb">https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/llm_ops_overview.ipynb</a></td><td><a href=".gitbook/assets/de2.avif">de2.avif</a></td></tr><tr><td><strong>Prompt Optimization</strong></td><td></td><td><a href="prompt-engineering/prompt-optimization.md">prompt-optimization.md</a></td><td><a href=".gitbook/assets/Screenshot 2025-04-14 at 6.11.24 PM.png">Screenshot 2025-04-14 at 6.11.24 PM.png</a></td></tr><tr><td><strong>Optimizing LLM as a Judge Prompts</strong></td><td></td><td><a href="prompt-engineering/llm-as-a-judge-prompt-optimization.md">llm-as-a-judge-prompt-optimization.md</a></td><td><a href=".gitbook/assets/Few-Shot Prompting - thumbnail.jpg">Few-Shot Prompting - thumbnail.jpg</a></td></tr><tr><td><strong>Using Ragas to Evaluate a Math Problem-Solving Agent</strong></td><td></td><td><a href="evaluation/using-ragas-to-evaluate-a-math-problem-solving-agent.md">using-ragas-to-evaluate-a-math-problem-solving-agent.md</a></td><td><a href=".gitbook/assets/Ragas.jpg">Ragas.jpg</a></td></tr><tr><td><strong>Chatbot with User Feedback</strong></td><td><a href="https://github.com/Arize-ai/phoenix/tree/main/examples/manually-instrumented-chatbot">Python</a> or <a href="https://github.com/Arize-ai/openinference/tree/main/js/examples/openai">TypeScript</a></td><td></td><td><a href=".gitbook/assets/Screenshot 2025-04-14 at 5.59.34 PM.png">Screenshot 2025-04-14 at 5.59.34 PM.png</a></td></tr></tbody></table>
