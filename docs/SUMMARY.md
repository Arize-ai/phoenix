# Table of contents

* [Phoenix: AI Observability & Evaluation](README.md)
* [Examples](notebooks.md)

## ðŸ”‘ Quickstart

* [Phoenix Traces](quickstart/llm-traces.md)
* [Phoenix Evals](quickstart/evals.md)
* [Phoenix Inferences](quickstart/phoenix-inferences/README.md)
  * [Schemas and Datasets](quickstart/phoenix-inferences/inferences.md)

## ðŸ’¡ Concepts

* [Deploying Phoenix](concepts/deploying-phoenix.md)
* [LLM Observability](concepts/llm-observability.md)
* [Traces and Spans](concepts/llm-traces.md)
* [Evaluation](concepts/evaluation.md)
* [Generating Embeddings](concepts/generating-embeddings.md)
* [Embeddings Analysis](concepts/embeddings-analysis.md)

## ðŸ§  LLM Evals

* [Phoenix LLM Evals](llm-evals/llm-evals.md)
* [Running Pre-Tested Evals](llm-evals/running-pre-tested-evals/README.md)
  * [Retrieval (RAG) Relevance](llm-evals/running-pre-tested-evals/retrieval-rag-relevance.md)
  * [Hallucinations](llm-evals/running-pre-tested-evals/hallucinations.md)
  * [Q\&A on Retrieved Data](llm-evals/running-pre-tested-evals/q-and-a-on-retrieved-data.md)
  * [Toxicity](llm-evals/running-pre-tested-evals/toxicity.md)
  * [Code Generation Eval](llm-evals/running-pre-tested-evals/code-generation-eval.md)
  * [Summarization Eval](llm-evals/running-pre-tested-evals/summarization-eval.md)
  * [Reference (citation) Link Evals](llm-evals/running-pre-tested-evals/reference-link-evals.md)
  * [AI vs Human (Groundtruth)](llm-evals/running-pre-tested-evals/ai-vs-human-groundtruth.md)
* [Evaluation Types](llm-evals/evaluation-types.md)
* [Evals With Explanations](llm-evals/evals-with-explanations.md)
* [Building Your Own Evals](llm-evals/building-your-own-evals.md)
* [Quickstart Retrieval Evals](llm-evals/quickstart-retrieval-evals/README.md)
  * [Retrieval Evals on Document Chunks](llm-evals/quickstart-retrieval-evals/retrieval-evals-on-document-chunks.md)
* [Benchmarking Retrieval (RAG)](llm-evals/benchmarking-retrieval-rag.md)

## ðŸ”® Use Cases

* [QA with Retrieval (Using Vector Stores)](use-cases/troubleshooting-llm-retrieval-with-vector-stores.md)
* [Structured Extraction](use-cases/structured-extraction.md)
* [Evaluate RAG with LLM Evals](use-cases/rag-evaluation.md)

## ðŸ”¢ How-To

* [Install and Import Phoenix](how-to/install-and-import-phoenix.md)
* [Import Your Data](how-to/define-your-schema/README.md)
  * [LLM Evaluations](how-to/define-your-schema/llm-evaluations.md)
  * [Prompt and Response (LLM)](how-to/define-your-schema/prompt-and-response-llm.md)
  * [Retrieval (RAG)](how-to/define-your-schema/retrieval-rag.md)
  * [Corpus Data](how-to/define-your-schema/corpus-data.md)
* [Manage the App](how-to/manage-the-app.md)
* [Export Your Data](how-to/export-your-data.md)
* [Extract Data from Spans](how-to/extract-data-from-spans.md)
* [Use Example Datasets](how-to/use-example-datasets.md)
* [Contribute to Phoenix](how-to/contribute-to-phoenix.md)

## âŒ¨ API

* [Dataset and Schema](api/dataset-and-schema.md)
* [Session](api/session.md)
* [Evals](api/evals.md)
* [Models](api/evaluation-models.md)

## ðŸ”Œ INTEGRATIONS

* [LlamaIndex](integrations/llamaindex.md)
* [LangChain](integrations/langchain.md)
* [OpenAI](integrations/openai.md)
* [Arize](integrations/bring-production-data-to-notebook-for-eda-or-retraining.md)
* [AutoGen](integrations/autogen-support.md)

## ðŸ“š Reference

* [Environments](reference/environments.md)
* [Architecture](reference/architecture.md)
* [Embeddings](concepts/embeddings.md)
* [OpenInference](concepts/open-inference.md)
* [Frequently Asked Questions](reference/frequently-asked-questions.md)

***

* [GitHub](https://github.com/Arize-ai/phoenix)
* [Releases](https://github.com/Arize-ai/phoenix/releases)
