# How to: Evals

## [Phoenix Evaluators](running-pre-tested-evals/)

* [Hallucinations](running-pre-tested-evals/hallucinations.md)
* [Q\&A on Retrieved Data](running-pre-tested-evals/q-and-a-on-retrieved-data.md)
* [Retrieval (RAG) Relevance](running-pre-tested-evals/retrieval-rag-relevance.md)
* [Summarization ](running-pre-tested-evals/summarization-eval.md)
* [Code Generation](running-pre-tested-evals/code-generation-eval.md)
* [Toxicity](running-pre-tested-evals/toxicity.md)&#x20;
* [AI vs Human ](running-pre-tested-evals/ai-vs-human-groundtruth.md)
* [Reference (Citation) Eval](running-pre-tested-evals/reference-link-evals.md)

## [Bring Your Own Evaluator](bring-your-own-evaluator.md)

* [Categorical evaluator](bring-your-own-evaluator.md#categorical-llm\_classify) (llm\_classify)
* [Numeric evaluator](bring-your-own-evaluator.md#score-numeric-eval-llm\_generate) (llm\_generate)

## [Online Evals](./#online-evals)

Run evaluations via a job to visualize in the UI as traces stream in.

