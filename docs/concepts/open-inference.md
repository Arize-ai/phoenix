---
description: >-
  OpenInference is an open standard that encompasses model inference and LLM
  application tracing.
---

# OpenInference

{% hint style="info" %}
For a in-depth specification of the OpenInference specification, please consult the spec [https://github.com/Arize-ai/openinference](https://github.com/Arize-ai/openinference)
{% endhint %}

<figure><img src="https://raw.githubusercontent.com/Arize-ai/phoenix-assets/main/logos/OpenInference/Full%20color/OI-full-horiz.svg" alt="" width="563"><figcaption><p>OpenInference is a set of specifications for model inferences and LLM traces</p></figcaption></figure>

OpenInference is a specification that encompass two data models:

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>Inferences</strong></td><td>designed to capture inference logs from a variety of model types and use-cases</td><td></td><td><a href="https://github.com/Arize-ai/open-infernece-spec">https://github.com/Arize-ai/open-infernece-spec</a></td></tr><tr><td><strong>Tracing</strong></td><td>capture the execution of an application that results in invocations of an LLM.<br></td><td></td><td><a href="https://github.com/Arize-ai/openinference">https://github.com/Arize-ai/openinference</a></td></tr></tbody></table>

###
