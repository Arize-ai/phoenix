{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoenix Embeddings\n",
    "\n",
    "This small tutorial goes over creating Phoenix's `Dataset` objects and using them to obtain a UMAP pointcloud using the `UMAPWidget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.datasets import Dataset, EmbeddingColumnNames, Schema\n",
    "from phoenix.pointcloud import DriftPointCloud, UMAPProjector\n",
    "from phoenix.widgets import UMAPWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_local_filename = \"NLP_sentiment_classification_language_drift\"\n",
    "test_url_filename = \"https://storage.googleapis.com/arize-assets/fixtures/open-source/datasets/unstructured/nlp/sentiment_classification_language_drift\"\n",
    "\n",
    "features = [\n",
    "    \"reviewer_age\",\n",
    "    \"reviewer_gender\",\n",
    "    \"product_category\",\n",
    "    \"language\",\n",
    "]\n",
    "\n",
    "embedding_features = {\n",
    "    \"embedding_feature\": EmbeddingColumnNames(\n",
    "        vector_column_name=\"text_vector\",  # Will be name of embedding feature in the app\n",
    "        raw_data_column_name=\"text\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
    "schema = Schema(\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"pred_label\",\n",
    "    actual_label_column_name=\"label\",\n",
    "    feature_column_names=features,\n",
    "    embedding_feature_column_names=embedding_features,\n",
    ")\n",
    "\n",
    "desired_format = \"url_hdf5\"\n",
    "\n",
    "if desired_format == \"hdf5\":\n",
    "    train_ds = Dataset.from_hdf(\n",
    "        f\"./fixtures/{test_local_filename}.hdf5\", schema=schema, key=\"training\"\n",
    "    )\n",
    "    prod_ds = Dataset.from_hdf(\n",
    "        f\"./fixtures/{test_local_filename}.hdf5\", schema=schema, key=\"production\"\n",
    "    )\n",
    "elif desired_format == \"url_hdf5\":\n",
    "    train_ds = Dataset.from_url(f\"{test_url_filename}.hdf5\", schema=schema, hdf_key=\"training\")\n",
    "    prod_ds = Dataset.from_url(f\"{test_url_filename}.hdf5\", schema=schema, hdf_key=\"production\")\n",
    "elif desired_format == \"csv\":\n",
    "    train_ds = Dataset.from_csv(f\"./fixtures/{test_local_filename}_training.csv\", schema=schema)\n",
    "    prod_ds = Dataset.from_csv(f\"./fixtures/{test_local_filename}_production.csv\", schema=schema)\n",
    "elif desired_format == \"url_csv\":\n",
    "    train_ds = Dataset.from_csv(f\"{test_url_filename}_training.csv\", schema=schema)\n",
    "    prod_ds = Dataset.from_csv(f\"{test_url_filename}_production.csv\", schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the point cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_hyperparameters = {\n",
    "    \"n_components\": 3,\n",
    "    \"min_dist\": 0,\n",
    "}\n",
    "projector = UMAPProjector(hyperparameters=UMAP_hyperparameters)\n",
    "primary_pts, reference_pts, clusters = projector.project(prod_ds, train_ds, \"embedding_feature\")\n",
    "pc = DriftPointCloud(primary_pts, reference_pts, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = UMAPWidget(pc.to_json())\n",
    "widget.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3 (main, Apr 14 2022, 13:44:37) [Clang 13.1.6 (clang-1316.0.21.2.3)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8476af36f82f278d0224c299b3c84ccca1fb7344702eda80d935d8f2c34d234"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
