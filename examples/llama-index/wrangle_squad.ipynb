{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_database import download_squad_training_data, GRANULAR_TO_BROAD_SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df, query_df = download_squad_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BROAD_TO_GRANULAR_SUBJECTS = {}\n",
    "for granular_subject, broad_subject in GRANULAR_TO_BROAD_SUBJECT.items():\n",
    "    if broad_subject not in BROAD_TO_GRANULAR_SUBJECTS:\n",
    "        BROAD_TO_GRANULAR_SUBJECTS[broad_subject] = []\n",
    "    BROAD_TO_GRANULAR_SUBJECTS[broad_subject].append(granular_subject)\n",
    "BROAD_TO_GRANULAR_SUBJECTS\n",
    "for broad_subject, granular_subjects in BROAD_TO_GRANULAR_SUBJECTS.items():\n",
    "    print(broad_subject)\n",
    "    print(granular_subjects)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granular_subjects = [\n",
    "    \"Buddhism\",\n",
    "    \"New_York_City\",\n",
    "    \"American_Idol\",\n",
    "    \"Age_of_Enlightenment\",\n",
    "    \"Beyonc√©\",\n",
    "    \"Chinese_characters\",\n",
    "    \"Computer\",\n",
    "    \"Myocardial_infarction\",\n",
    "    \"Yale_University\",\n",
    "    \"Wood\",\n",
    "    \"FC_Barcelona\",\n",
    "    \"Richard_Feynman\",\n",
    "    \"To_Kill_a_Mockingbird\",\n",
    "    \"United_States_Air_Force\",\n",
    "    \"YouTube\",\n",
    "    \"Supreme_court\",\n",
    "    \"Gothic_architecture\",\n",
    "    \"United_States_dollar\",\n",
    "    \"Humanism\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[query_df[\"granular_subject\"].isin(granular_subjects)].groupby(\n",
    "    \"paragraph_index\", as_index=False\n",
    ").head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df[database_df[\"granular_subject\"].isin(granular_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_database_df = database_df.sample(n=1000)\n",
    "paragraphs = set(\n",
    "    sample_database_df.apply(\n",
    "        lambda row: (row[\"granular_subject\"], row[\"paragraph_index\"]), axis=1\n",
    "    ).to_list()\n",
    ")\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query_df = (\n",
    "    query_df[query_df[\"is_answerable\"]][\n",
    "        query_df.apply(\n",
    "            lambda row: (row[\"granular_subject\"], row[\"paragraph_index\"]) in paragraphs, axis=1\n",
    "        )\n",
    "    ]\n",
    "    .groupby([\"granular_subject\", \"paragraph_index\"], as_index=False)\n",
    "    .first()\n",
    ")\n",
    "sample_query_df[\"is_answerable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[query_df[\"granular_subject\"].isin(granular_subjects) & query_df[\"is_answerable\"]].groupby(\n",
    "    [\"granular_subject\", \"paragraph_index\"], as_index=False\n",
    ").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df[database_df[\"granular_subject\"].isin(granular_subjects)].groupby(\n",
    "    \"granular_subject\"\n",
    ").max()[\"paragraph_index\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "granular_subjects = []\n",
    "for subjects in BROAD_TO_GRANULAR_SUBJECTS.values():\n",
    "    granular_subjects.append(random.choice(subjects))\n",
    "granular_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GRANULAR_TO_BROAD_SUBJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"text-embedding-ada-002\"\n",
    "embedding0 = np.array(\n",
    "    openai.Embedding.create(input=[\"What is the meaning of life?\"], model=model_name)[\"data\"][0][\n",
    "        \"embedding\"\n",
    "    ]\n",
    ")\n",
    "embedding1 = np.array(\n",
    "    openai.Embedding.create(input=[\"What is the meaning of life?\"], model=model_name)[\"data\"][0][\n",
    "        \"embedding\"\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
