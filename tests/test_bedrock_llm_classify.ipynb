{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root / \"packages\" / \"phoenix-evals\" / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import BedrockModel, llm_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (aws_access_key := os.getenv(\"AWS_ACCESS_KEY_ID\")):\n",
    "    aws_access_key = getpass(\"üîë Enter your AWS Access Key ID: \")\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (aws_secret_key := os.getenv(\"AWS_SECRET_ACCESS_KEY\")):\n",
    "    aws_secret_key = getpass(\"üîë Enter your AWS Secret Access Key: \")\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (aws_session_token := os.getenv(\"AWS_SESSION_TOKEN\")):\n",
    "    aws_session_token = getpass(\"üîë Enter your AWS Session Token: \")\n",
    "    os.environ[\"AWS_SESSION_TOKEN\"] = aws_session_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\")\n",
    "os.environ[\"AWS_DEFAULT_REGION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    "    aws_session_token=aws_session_token,\n",
    "    region_name=os.environ[\"AWS_DEFAULT_REGION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BedrockModel(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",  # anthropic.claude-3-haiku-20240307-v1:0\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"bunch_of_spans.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_HALLUCINATION_TEMPLATE = \"\"\"\n",
    "You are a \"EVAL assistant\" evaluating prompts and responses for\n",
    "hallucinations. The prompts ask an AI assistant to generate an answer to a\n",
    "question based on data or context.\n",
    "\n",
    "In this task, you will be evaluating an assistants response to a query,\n",
    "using reference text to generate an answer. You will be provided a\n",
    "conversation between an assistant and a user that will contain instructions\n",
    "for the AI assistant (not for you).\n",
    "\n",
    "The answer is generated to the question based on the reference text. The\n",
    "answer may contain false information, you must use the reference text to\n",
    "determine if the answer to the question contains false information, if the\n",
    "answer is a hallucination of facts. Your objective is to determine whether\n",
    "the reference text contains factual information and is not a hallucination.\n",
    "A 'hallucination' in this context refers to an answer that is not based on\n",
    "the reference text or assumes information that is not available in the\n",
    "reference text. Your response should be a single word: either \"factual\" or\n",
    "\"hallucinated\", and it should not include any other text or characters.\n",
    "\"hallucinated\" indicates that the answer provides factually inaccurate\n",
    "information to the query based on the reference text. \"factual\" indicates\n",
    "that the answer to the question is correct relative to the reference text,\n",
    "and does not contain made up information. Please read the query and\n",
    "reference text carefully before determining your response.\n",
    "\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Input Question, System message and Context to AI Assistant]:\n",
    "    {input_value}\n",
    "    ************\n",
    "    [AI Assistant Answer]:\n",
    "    {output_value}\n",
    "     ************\n",
    "    [END DATA]\n",
    "\n",
    "Example response:\n",
    "************\n",
    "LABEL: \"factual\" or \"hallucinated\"\n",
    "************\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classification\n",
    "results = llm_classify(\n",
    "    data=df,\n",
    "    model=model,\n",
    "    template=MY_HALLUCINATION_TEMPLATE,\n",
    "    rails=[\"factual\", \"hallucinated\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"us.amazon.nova-pro-v1:0\",\n",
    "    \"us.amazon.nova-lite-v1:0\",\n",
    "    \"us.amazon.nova-micro-v1:0\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    \"anthropic.claude-v2\",\n",
    "    \"anthropic.claude-instant-v1\",\n",
    "    \"anthropic.claude-v2:1\",\n",
    "    \"amazon.titan-text-express-v1\",\n",
    "    \"amazon.titan-text-lite-v1\",\n",
    "    \"amazon.titan-text-premier-v1:0\",\n",
    "]\n",
    "\n",
    "failed_models = []\n",
    "\n",
    "for model_id in models:\n",
    "    try:\n",
    "        model = BedrockModel(model_id=model_id, session=session)\n",
    "\n",
    "        results = llm_classify(\n",
    "            data=df,\n",
    "            model=model,\n",
    "            template=MY_HALLUCINATION_TEMPLATE,\n",
    "            rails=[\"factual\", \"hallucinated\"],\n",
    "        )\n",
    "\n",
    "        if not all(results[\"execution_status\"] == \"COMPLETED\"):\n",
    "            print(f\"‚ö†Ô∏è Model {model_id} has incomplete execution statuses.\")\n",
    "            failed_models.append(model_id)\n",
    "        else:\n",
    "            print(f\"‚úÖ Model {model_id} executed successfully with 'COMPLETED' statuses.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with model {model_id}: {e}\")\n",
    "        failed_models.append(model_id)\n",
    "\n",
    "if not failed_models:\n",
    "    print(\"‚úÖ All models executed successfully with 'COMPLETED' statuses.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Some models failed or had incomplete statuses: {failed_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_models  # should be empty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix-migrate-to-bedrock-convers-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
