---
title: "Prompt playground"
---

<Frame caption="">
  <img src="https://storage.googleapis.com/arize-phoenix-assets/assets/images/playground_overview.gif" />
</Frame>

Phoenix's Prompt Playground makes the process of iterating and testing prompts quick and easy. Phoenix's playground supports [various AI providers](/phoenix/prompt-engineering/how-to-prompts/configure-ai-providers) (OpenAI, Anthropic, Gemini, Azure) as well as custom model endpoints, making it the ideal prompt IDE for you to build experiment and evaluate prompts and models for your task.

* **Speed**: Rapidly test variations in the [prompt](/phoenix/prompt-engineering/concepts-prompts/prompts-concepts#prompt), model, invocation parameters, [tools](/phoenix/prompt-engineering/concepts-prompts/prompts-concepts#tools), and output format.

* **Reproducibility**: All runs of the playground are [recorded as traces and experiments](/phoenix/prompt-engineering/how-to-prompts/using-the-playground#playground-traces), unlocking annotations and evaluation.

* **Datasets: **Use [dataset examples](/phoenix/prompt-engineering/how-to-prompts/test-a-prompt) as a fixture to run a prompt variant through its paces and to evaluate it systematically.

* **Prompt** **Management**: [Load, edit, and save prompts](/phoenix/prompt-engineering/overview-prompts/prompt-management) directly within the playground.

To learn more on how to use the playground, see [Using the Playground](/phoenix/prompt-engineering/how-to-prompts/using-the-playground)


