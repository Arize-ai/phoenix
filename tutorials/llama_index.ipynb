{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (0.6.1)\n",
      "Requirement already satisfied: transformers in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (4.28.1)\n",
      "Requirement already satisfied: langchain>=0.0.154 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (0.0.161)\n",
      "Requirement already satisfied: requests<2.30.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (2.29.0)\n",
      "Requirement already satisfied: pandas in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (1.5.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (8.2.2)\n",
      "Requirement already satisfied: openai>=0.26.4 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (0.27.6)\n",
      "Requirement already satisfied: numpy in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (1.24.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from llama-index) (0.5.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (4.0.2)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (1.2.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (2.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (1.10.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (2.0.12)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (6.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from dataclasses-json->llama-index) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from dataclasses-json->llama-index) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from dataclasses-json->llama-index) (0.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from requests<2.30.0->llama-index) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from requests<2.30.0->llama-index) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from requests<2.30.0->llama-index) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from requests<2.30.0->llama-index) (2023.5.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from pandas->llama-index) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from transformers->llama-index) (23.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from transformers->llama-index) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from transformers->llama-index) (2023.5.5)\n",
      "Requirement already satisfied: filelock in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from transformers->llama-index) (3.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from transformers->llama-index) (0.13.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.1)\n",
      "Requirement already satisfied: fsspec in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->llama-index) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->llama-index) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from langchain import OpenAI\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "from llama_index.response.schema import Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database_df = pd.read_parquet(\"/Users/xandersong/Desktop/llama-index-data-full/splits/database.parquet\")\n",
    "# query_df = pd.read_parquet(\"/Users/xandersong/Desktop/llama-index-data/splits/query.parquet\")\n",
    "database_df = pd.read_parquet(\"/Users/xandersong/Downloads/database_openai.parquet\")\n",
    "query_df = pd.read_parquet(\"/Users/xandersong/Downloads/query_openai.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_index</th>\n",
       "      <th>granular_subject</th>\n",
       "      <th>broad_subject</th>\n",
       "      <th>text</th>\n",
       "      <th>text_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>FC_Barcelona</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Two days later, it was announced that Luis Enr...</td>\n",
       "      <td>[0.0009573115967214108, 0.0031192197930067778,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>New_Haven,_Connecticut</td>\n",
       "      <td>Geography and Places</td>\n",
       "      <td>A second New Haven gastronomical claim to fame...</td>\n",
       "      <td>[-0.0028259255923330784, 0.01535571739077568, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>Mandolin</td>\n",
       "      <td>Music</td>\n",
       "      <td>There are many styles of mandolin, but four ar...</td>\n",
       "      <td>[-0.005895992740988731, 0.015205282717943192, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>Chicago_Cubs</td>\n",
       "      <td>Sports</td>\n",
       "      <td>The Chicago Cubs are an American professional ...</td>\n",
       "      <td>[-0.0005755521706305444, -0.015405493788421154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430</td>\n",
       "      <td>Saint_Barth%C3%A9lemy</td>\n",
       "      <td>Geography and Places</td>\n",
       "      <td>Located approximately 250 kilometres (160 mi) ...</td>\n",
       "      <td>[0.0016602941323071718, -0.009640098549425602,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_index        granular_subject         broad_subject  \\\n",
       "0            139            FC_Barcelona                Sports   \n",
       "1            250  New_Haven,_Connecticut  Geography and Places   \n",
       "2            306                Mandolin                 Music   \n",
       "3            183            Chicago_Cubs                Sports   \n",
       "4            430   Saint_Barth%C3%A9lemy  Geography and Places   \n",
       "\n",
       "                                                text  \\\n",
       "0  Two days later, it was announced that Luis Enr...   \n",
       "1  A second New Haven gastronomical claim to fame...   \n",
       "2  There are many styles of mandolin, but four ar...   \n",
       "3  The Chicago Cubs are an American professional ...   \n",
       "4  Located approximately 250 kilometres (160 mi) ...   \n",
       "\n",
       "                                         text_vector  \n",
       "0  [0.0009573115967214108, 0.0031192197930067778,...  \n",
       "1  [-0.0028259255923330784, 0.01535571739077568, ...  \n",
       "2  [-0.005895992740988731, 0.015205282717943192, ...  \n",
       "3  [-0.0005755521706305444, -0.015405493788421154...  \n",
       "4  [0.0016602941323071718, -0.009640098549425602,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>granular_subject</th>\n",
       "      <th>broad_subject</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>text</th>\n",
       "      <th>is_answerable</th>\n",
       "      <th>text_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5729499d1d04691400779256</td>\n",
       "      <td>New_Haven,_Connecticut</td>\n",
       "      <td>Geography and Places</td>\n",
       "      <td>6</td>\n",
       "      <td>Exactly who were the slaves upon the Spanish s...</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.008130733855068684, -0.017305415123701096,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a555aad134fea001a0e1a4b</td>\n",
       "      <td>Computer_security</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>15</td>\n",
       "      <td>How wide-scale were the losses?</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.007133032660931349, -0.02135872282087803, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a2d6060f28ef0001a52650e</td>\n",
       "      <td>Santa_Monica,_California</td>\n",
       "      <td>Geography and Places</td>\n",
       "      <td>16</td>\n",
       "      <td>On what street does the Santa Monica Freeway b...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.025623859837651253, -0.007313745096325874, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5730245ca23a5019007fce41</td>\n",
       "      <td>Windows_8</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>9</td>\n",
       "      <td>What is the name of the character Microsoft us...</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.016982482746243477, -0.0013794071273878217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ace3e9b32bba1001ae4a036</td>\n",
       "      <td>Ann_Arbor,_Michigan</td>\n",
       "      <td>Geography and Places</td>\n",
       "      <td>19</td>\n",
       "      <td>What week in March is the Ann Arbor Art Fairs ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.006391833536326885, -0.02348998934030533, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id          granular_subject           broad_subject  \\\n",
       "0  5729499d1d04691400779256    New_Haven,_Connecticut    Geography and Places   \n",
       "1  5a555aad134fea001a0e1a4b         Computer_security  Science and Technology   \n",
       "2  5a2d6060f28ef0001a52650e  Santa_Monica,_California    Geography and Places   \n",
       "3  5730245ca23a5019007fce41                 Windows_8  Science and Technology   \n",
       "4  5ace3e9b32bba1001ae4a036       Ann_Arbor,_Michigan    Geography and Places   \n",
       "\n",
       "   paragraph_index                                               text  \\\n",
       "0                6  Exactly who were the slaves upon the Spanish s...   \n",
       "1               15                    How wide-scale were the losses?   \n",
       "2               16  On what street does the Santa Monica Freeway b...   \n",
       "3                9  What is the name of the character Microsoft us...   \n",
       "4               19  What week in March is the Ann Arbor Art Fairs ...   \n",
       "\n",
       "  is_answerable                                        text_vector  \n",
       "0          True  [-0.008130733855068684, -0.017305415123701096,...  \n",
       "1         False  [-0.007133032660931349, -0.02135872282087803, ...  \n",
       "2         False  [0.025623859837651253, -0.007313745096325874, ...  \n",
       "3          True  [-0.016982482746243477, -0.0013794071273878217...  \n",
       "4         False  [-0.006391833536326885, -0.02348998934030533, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exactly who were the slaves upon the Spanish slaveship?',\n",
       " 'What is the name of the character Microsoft used to make Windows 8 seem more personable?',\n",
       " 'Approximately how much was spent on non-food retail sales in London in 2010?',\n",
       " \"What type of campus did Northwestern begin construction of during Walter Dill Scott's presidency?\",\n",
       " 'What did the Shanghai Stock Exchange do?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df[(query_df[\"is_answerable\"] == \"True\")].head()[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[(query_df[\"is_answerable\"] == \"False\")].head()[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages/langchain/llms/openai.py:169: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/xandersong/.virtualenvs/phoenixdev/lib/python3.8/site-packages/langchain/llms/openai.py:687: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"/Users/xandersong/Desktop/llama-index-data-full/indexes/database_index\"\n",
    ")\n",
    "# model_name = \"text-davinci-003\"\n",
    "model_name = \"gpt-4\"\n",
    "llm = OpenAI(temperature=0, model_name=model_name)\n",
    "index = load_index_from_storage(storage_context, llm=llm)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_llama_index_response(response: Response) -> None:\n",
    "    \"\"\"\n",
    "    Displays a LlamaIndex response and its source nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Response\")\n",
    "    print(\"========\")\n",
    "    for line in textwrap.wrap(response.response.strip(), width=80):\n",
    "        print(line)\n",
    "    print()\n",
    "\n",
    "    print(\"Source Nodes\")\n",
    "    print(\"============\")\n",
    "    print()\n",
    "\n",
    "    for source_node in response.source_nodes:\n",
    "        print(f\"doc_id: {source_node.node.doc_id}\")\n",
    "        print(f\"score: {source_node.score}\")\n",
    "        print()\n",
    "        for line in textwrap.wrap(source_node.node.text, width=80):\n",
    "            print(line)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is the name of the character Microsoft used to make Windows 8 seem more personable?'\n",
    "# query = 'On what street does the Santa Monica Freeway begin?'\n",
    "response = query_engine.query(query)\n",
    "display_llama_index_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df_ = database_df.sample(frac=1)\n",
    "database_df_[\"is_answerable\"] = \"unknown\"\n",
    "query_df_ = query_df.sample(frac=1)\n",
    "query_df_[\"is_answerable\"] = query_df_[\"is_answerable\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = px.Schema(\n",
    "    embedding_feature_column_names={\n",
    "        \"text_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"text_vector\",\n",
    "            raw_data_column_name=\"text\",\n",
    "          )\n",
    "    },\n",
    "    tag_column_names=[\"granular_subject\", \"broad_subject\", \"is_answerable\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_ds = px.Dataset(database_df_, schema, name=\"database\")\n",
    "query_ds = px.Dataset(query_df_, schema, name=\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.launch_app(primary=query_ds, reference=database_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df_ = database_df[~database_df[\"granular_subject\"].isin([\"Beyoncé\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_subjects = random.sample(database_df[\"granular_subject\"].unique().tolist(), 10)\n",
    "random_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df_ = database_df[database_df[\"granular_subject\"].isin(random_subjects)]\n",
    "query_df_ = query_df[query_df[\"granular_subject\"].isin(random_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df_ = query_df.groupby([\"granular_subject\", \"paragraph_index\"], as_index=False).first().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(query_df.sample(n=2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(database_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def sample_by_percentage(df, percentage_map):\n",
    "    def sample_group(group):\n",
    "        subject = group.name\n",
    "        frac = percentage_map.get(subject, 0)\n",
    "        return group.sample(frac=frac)\n",
    "\n",
    "    sampled_df = df.groupby(\"broad_subject\").apply(sample_group).reset_index(drop=True)\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    \"broad_subject\": [\"Math\", \"Science\", \"Math\", \"Science\", \"Math\", \"Science\"],\n",
    "    \"score\": [90, 85, 95, 88, 92, 80],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the percentage map\n",
    "percentage_map = {\n",
    "    \"Math\": 0.5,  # Sample 50% of rows for Math\n",
    "    \"Science\": 0.3,  # Sample 30% of rows for Science\n",
    "}\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "sampled_df = sample_by_percentage(df, percentage_map)\n",
    "print(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_subject_to_sample_percentage = {\n",
    "    \"Architecture\": 5.0,\n",
    "    \"Business and Economy\": 0.5,\n",
    "    \"Education\": 0.5,\n",
    "    \"Entertainment and Arts\": 0.5,\n",
    "    \"Geography and Places\": 0.5,\n",
    "    \"Health and Medicine\": 0.5,\n",
    "    \"History\": 0.5,\n",
    "    \"Language and Linguistics\": 0.5,\n",
    "    \"Law and Legal\": 0.5,\n",
    "    \"Literature\": 0.5,\n",
    "    \"Media and Communication\": 0.5,\n",
    "    \"Music\": 0.5,\n",
    "    \"Nature and Environment\": 0.5,\n",
    "    \"Nonprofit Organizations\": 0.5,\n",
    "    \"People and Ethnicity\": 0.5,\n",
    "    \"Philosophy\": 0.5,\n",
    "    \"Politics and Government\": 0.5,\n",
    "    \"Religion and Spirituality\": 0.5,\n",
    "    \"Science and Technology\": 0.5,\n",
    "    \"Social Sciences\": 0.5,\n",
    "    \"Sports\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def get_token_count(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "database_df[\"text\"].map(get_token_count).sort_values(ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
