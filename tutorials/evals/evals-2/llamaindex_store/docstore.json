{"docstore/metadata": {"0": {"doc_hash": "6a7986747a39acd6b6b686433333eb0ae65fb366d14315adb1ea149dfbaedc3d"}, "1": {"doc_hash": "c9ffcaf14685cb0567ab5b38d6292a753abe711196b0b39b34053b796c6fae3b"}, "2": {"doc_hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231"}, "3": {"doc_hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9"}, "4": {"doc_hash": "f63b62abf1e588cb2fc85a74aa835d79678cf41541ba457e5780cf5cef3c87df"}, "5": {"doc_hash": "3275b0ac69e29f1fd4839b669ae9f54e68fcad315eb8e4b9ce59246efb780951"}, "6": {"doc_hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723"}, "7": {"doc_hash": "9d22ae9c3a3962612258545d5efa344dd51ba94cbe2e33107631900ab0c2dda6"}, "8": {"doc_hash": "6061eae548a3e68c6421a88a68d57832afc2a5fca1ed9a1dfa6b4094d7f7e9da"}, "9": {"doc_hash": "ab5f3c6c0a4968f65b3f14146e11971fa19139d1543f09a4b524d0c3c7a988c5"}, "10": {"doc_hash": "35472e69413e5a1251ae3cb2566fcffcc27dcf02e17f530516b6da2e805661fb"}, "11": {"doc_hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6"}, "12": {"doc_hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6"}, "13": {"doc_hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832"}, "14": {"doc_hash": "9c3ef16e9fac35b4ce33748caf152737b7517a744efba3f5f88836ac594aa83a"}, "15": {"doc_hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3"}, "16": {"doc_hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102"}, "17": {"doc_hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016"}, "18": {"doc_hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae"}, "19": {"doc_hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550"}, "e373ca6a-3c6d-49fc-aaba-e3d4ad17f558": {"doc_hash": "c2b06afbfbc92be8fed8a3b281d31d78411e867bf5138fd17f27fe4a3e5f0516", "ref_doc_id": "0"}, "ba4aea6e-719c-4479-bb13-89c7273317f8": {"doc_hash": "197418645a09d394af17b65e52d3adb1a7c83c0b609b897339a562773f963702", "ref_doc_id": "0"}, "ad6642be-d4a1-4492-8585-c2553992f634": {"doc_hash": "7442d904bae9e771048179c219f3b7490eb0e40a289c83504fe4cc81d4b65958", "ref_doc_id": "0"}, "a011d955-0190-4910-9d99-276d9c7157ce": {"doc_hash": "f1525dab7ba534a841e289380e4bf2efc7683a31be29474174a29d6c749b4a1b", "ref_doc_id": "1"}, "521a260b-e4c1-48d9-a2d9-e0364c094b23": {"doc_hash": "b0c3dfd6d48edeb32d415a7d2eedebb1a538cba862c881989d551cc08ba08a42", "ref_doc_id": "2"}, "f13a0ff9-602f-4d3d-8507-94cc7bf7f7df": {"doc_hash": "92875c4206bcc07b6b81fd205371fd24278b5c3eda04865ff6a03b34a1abf682", "ref_doc_id": "2"}, "58fafe87-9b10-476f-b90d-da582f136cf9": {"doc_hash": "29078e5db1b80d73bb075f94d9cbd684df93d6224c8637a3cca736fe9aab1e0f", "ref_doc_id": "2"}, "cf5202bc-1f43-4259-af24-6c692cae7096": {"doc_hash": "fd307107686322b5e647acdf38c5598f962a7fae2d9ed502ad8b22584c9e7f22", "ref_doc_id": "2"}, "33b69ca2-e895-42c3-8975-d30b09f71255": {"doc_hash": "5ab14f3d0bf68ba75091619582a3913be6ec297dd20b4dcbf993f697390a981e", "ref_doc_id": "2"}, "ce920e51-04a2-4e9f-a92f-279df00a9f65": {"doc_hash": "4d874d96c8ffa0c43946e9ac35396e8f8076444dda69c5dadf5aac499475b0ea", "ref_doc_id": "2"}, "76752c6f-969a-4e68-ac0d-727170129f06": {"doc_hash": "5ba587099876460430030fe8e3f5ed391f0a7373dd696ca9fa4e09d608e107df", "ref_doc_id": "3"}, "2d4f5695-7525-4793-b8bd-eb32a0058779": {"doc_hash": "ddcf6d2f1e1f6fd391b234e1504d588752b664a624c78d8ca30dd1a19de2b558", "ref_doc_id": "3"}, "cdc69adb-f6bf-4296-9caf-28ebf5a0671d": {"doc_hash": "373a406c872f84d6a961c64cbb5a2bcd758f406fd0c88ca4da5e78a3bd3d00da", "ref_doc_id": "3"}, "10af9110-0132-4d14-b20a-eecc18f55933": {"doc_hash": "d975e413da3d49cbf3290f4da4e99df43a8ac6c9f536b5c77c5b2be41ec38858", "ref_doc_id": "3"}, "88574f1c-afdd-49b8-a062-451e3ebff0ea": {"doc_hash": "3cc9164c51c3d3d4147affad43a44ec3c305bdecb65bb1f3f50ad9adb32b5c05", "ref_doc_id": "3"}, "5e9b4b14-b6a1-4140-9a02-9561ce8a8853": {"doc_hash": "16a6e3fde263a0f70002e36f2b3df4f277f38eedd344cc3533e95994d4b49536", "ref_doc_id": "3"}, "765f4bc9-fc87-4ec0-bace-ca663b60e518": {"doc_hash": "b4dda4d7c2058a3e5fa84748ecd6de3ea7c245c7b0dc5d0ed3b864c912dcd143", "ref_doc_id": "4"}, "ef505541-3953-48e6-8253-7beb582f3040": {"doc_hash": "faceabc345b7e7b558d12c1929586da44cec47ece77a7d7ee695778ab23f7d59", "ref_doc_id": "4"}, "c8de7cb6-af61-4893-9464-d1a7d401d27b": {"doc_hash": "9029b41bb2ac8b0c62617ab2a15fb6892f0d5e9a0fa2abc6835fb32d45d4f300", "ref_doc_id": "4"}, "e7b5712d-76b2-40d9-9d9a-8683bdbb0a77": {"doc_hash": "36ae055514add34be6cdcbab2f6dada2e98441010d11cdc802458fa517fe2417", "ref_doc_id": "4"}, "77dd73b4-5c54-408a-8523-49aef5ce8f00": {"doc_hash": "460fb3f3be12a87dc93490262afb2262f88abc775f107cae346a55ab91e43963", "ref_doc_id": "5"}, "ee787ea5-227e-4105-bd29-a07b6d688353": {"doc_hash": "ffc19c57cf11da5495aac13f71c16fb05a81b292c75d15d569e99c1dd503211e", "ref_doc_id": "5"}, "999a9bda-b816-4143-a7aa-10d0cf77bc00": {"doc_hash": "97627e43412eba8741ff920c106c5ac26db38a334c91e41fdf45101e70b3c446", "ref_doc_id": "5"}, "95d08505-b8e5-4481-bf41-5bd31dca616c": {"doc_hash": "1888fe0f92457dfccaed0431acab0b3dc12236afb018afd0be106dd331eac6db", "ref_doc_id": "5"}, "8d620ed0-e93d-47e2-ab49-4eb23d40dde3": {"doc_hash": "749d1c5bc9e379247e653b3adfef68ceffe562fab13e777c949316bf1313fd88", "ref_doc_id": "6"}, "19f83ba4-950d-485a-8ec5-090b58c32d8e": {"doc_hash": "b01e0e5e6752b350a47709b8f982797ddefa9ffba6bc1f94e05dc5a9c8406140", "ref_doc_id": "6"}, "01658214-645f-4424-b1ac-cfde9f4caa24": {"doc_hash": "a7415a63f71526fcca5e682b931bff2ac40632778a02aa6d53d2d41ad49f329e", "ref_doc_id": "6"}, "56dc0c80-3bd0-47ae-832d-2a404df630be": {"doc_hash": "9e2957f9c85a35031fc6c8476308486247c81188e6dc42a87a22575796d2c391", "ref_doc_id": "6"}, "e1d31a59-9af8-41f2-b157-be0092b7998e": {"doc_hash": "c3dc90204239dd34e3bfd3eb8d0cd491226e8d287be94f279ad08ac3a5785cbc", "ref_doc_id": "6"}, "a88c646e-7575-449f-96dc-8c59122648bd": {"doc_hash": "71c557c2bc9ba5fe4acd436c9d0233fa6ed38a323eb61ce9c8ff84e563b7f7e2", "ref_doc_id": "6"}, "5076442f-9d5a-4bc4-b93a-e0688bbe4a77": {"doc_hash": "76a292798e1f44037f6208f2f16ad43ebf3d4d6f9984b9ebdbc71970d0d676ed", "ref_doc_id": "6"}, "6ed35031-ec81-4fbd-94ff-d90254ba94e6": {"doc_hash": "1391f30bfeb84297f6462f2399894035936f6e145b161c4a81da76d70a5e9b6d", "ref_doc_id": "6"}, "4f940bd9-f787-4f7f-bfe3-61c6ce51bc5c": {"doc_hash": "7fee6ab5f7cc0811c2217386a3d950571efc30db2350970df358004ef339b83a", "ref_doc_id": "7"}, "f91c0019-fc6a-4196-a0d6-f689fbfd48b6": {"doc_hash": "29fa40a75edcfcfaf9eb248c074d2ba64a4f598b245f96ebd05a6da36bd98767", "ref_doc_id": "7"}, "9c479b87-9e55-4aed-b56c-c1b2363b60d5": {"doc_hash": "e37516c31062117a7cd17ec6982779bf4b938e5741c2adf3434a7f43680214d5", "ref_doc_id": "7"}, "d38281fb-a5cb-4b7f-81da-cfae2b159582": {"doc_hash": "0886d3eedaecba9683cedbba873cb45e1e6c473323b30c004ce59b7ecca79c34", "ref_doc_id": "7"}, "a59a292d-459c-4367-b64b-1f63b08be6f6": {"doc_hash": "258e554a09ad3bc8fe69a1f4dbedb75736f485ae1c03b1f9a8a86ffa28276757", "ref_doc_id": "7"}, "2a51115a-26d9-4445-aad7-abbae5f5e20a": {"doc_hash": "9a482c307ea76ac6ae8595a71322129c0a4c4e5efd40acd47e03f164d4913f00", "ref_doc_id": "8"}, "39bfd395-9f2d-4d81-b460-e8486271cc5b": {"doc_hash": "760fe5639c29d1ac97431a13c9f904747ec170a83567a44b7c550b429fc7462e", "ref_doc_id": "8"}, "8e07fb3e-2d9a-4d5f-b20d-8e29ceddd806": {"doc_hash": "119c99ae84220533094354f6cbbd9bf6fb58edcb12f433feceae802644921afd", "ref_doc_id": "8"}, "131db3e9-fcf2-41ac-bf30-b92152187672": {"doc_hash": "2da0ea751fd5cab4c800371cd077d001dc23f9db16c3de5dba3069f38969a457", "ref_doc_id": "9"}, "e32a7427-4a09-4cfb-b6a7-23701f5a9ca9": {"doc_hash": "05ebd7e6e3a66587b6853617636a02fa0d8411f35d109c3364c1905236117d9d", "ref_doc_id": "9"}, "ad511521-dd22-498f-8111-669566dee86a": {"doc_hash": "cafaca74c5496fc6efb0feaa54018936add5c1e5b1f9a8d5afa75946946f0381", "ref_doc_id": "9"}, "7426a009-ede2-4c41-a30a-b3bc52195092": {"doc_hash": "2cc6a07364b5221bb0a2e2d3d781bbeb8bab9c5c287e698ccbd9e3f0f9e88379", "ref_doc_id": "9"}, "5d31ab3c-c813-40be-8fa9-b0f8958b8c96": {"doc_hash": "8c35c980cd0a0d37bb90fd565a3de9e3884b0a1a19a2dbbef759a9fa25d785a7", "ref_doc_id": "10"}, "65477189-2b3a-4214-b30f-6f36ae619863": {"doc_hash": "60d615dfbf86f6193bddbd46de1e887f68d9290477d06c47acd85a950530beeb", "ref_doc_id": "10"}, "deea83e8-16cc-4aca-b15f-db68853d1c71": {"doc_hash": "906b21dd7ca17645141acfcdc45fa214affb3ef38da7c28f2c7a048d2ae92eb4", "ref_doc_id": "10"}, "debd681b-80fe-4b48-bfe5-ab0cf28023f0": {"doc_hash": "c4397f03e5f00f89aa129acec5c748bc6d17583f5cc901ea40ce092f004530c4", "ref_doc_id": "11"}, "1df0b303-84f6-410b-8421-60e44489f4cd": {"doc_hash": "db5a8d45c4b7f00c9c1c6ee36c8ec438e404a1aa6645bcf7714485859df5ec13", "ref_doc_id": "11"}, "d9db1d98-6162-49bd-a790-071a68aa2242": {"doc_hash": "6a269ee5a7e3c5cc34e46876f52646696b6ac52e4e1a8a8719daf5914e9523bd", "ref_doc_id": "11"}, "d2f0120b-892c-4851-95a4-60d9c303ca79": {"doc_hash": "841e2cc4aa1f2de5f101948a30bb74efc738b849542e5614b539fafc7b628268", "ref_doc_id": "11"}, "45fa019f-88b7-429e-b1c5-c7f28097f5c0": {"doc_hash": "488475d1ad8acc16a58f703f7d0f7a187943b23a1f6da5624cbaa6a8dd3d9779", "ref_doc_id": "11"}, "c24d900a-97cf-4a9c-a431-fa476932e093": {"doc_hash": "9a562ffcc04a7f535f335af55aa49dcf60725411de869c92986db7483ce82c76", "ref_doc_id": "11"}, "42178690-1c55-4503-be7e-9e9eb62663c8": {"doc_hash": "bb79632bb48f8d3b8e0aa2b596777b40280ce408df3f4035b399ec1d38d69906", "ref_doc_id": "11"}, "b885cc51-9921-4ecc-8b57-df4e636b037d": {"doc_hash": "4bc8c19e68c130da7309ad53576348a7b43ddc771c63b5a616cafe68359c32e7", "ref_doc_id": "11"}, "a5cde305-6f81-41a6-ac6c-02e58df5021b": {"doc_hash": "5de5d8f5bc05dbd1d27a4af6cdf129d3cfb816ccd9d51ace2dc73f9de510148e", "ref_doc_id": "11"}, "5c2b2147-2fc3-4e05-af4c-7b7abefb80b6": {"doc_hash": "815fcd70827de5144dece2600c83f89f479a93a6d4569e31df48e20d7869ae58", "ref_doc_id": "11"}, "2423159f-39bd-40b4-a367-26a9f1a550f3": {"doc_hash": "cf9f504d799ed62cb68105d0cf0c583ce27529b4c4c77683a26cf703d53398c7", "ref_doc_id": "11"}, "aefea3db-ed16-46a6-a25e-7f6e229d5c3e": {"doc_hash": "b2621715ca3c58bf53ff171f70b9fd4d7c8bff7465a814fbdd0e5566c70bbef7", "ref_doc_id": "11"}, "b00997e3-c12a-48d3-b013-07cec870f46c": {"doc_hash": "06a3179e5402fe9e495cdbaacb9958e7374e50a74c6763c4392b8f64d864b083", "ref_doc_id": "11"}, "db314eb6-b9b1-4eba-bea5-a3b4be6b532f": {"doc_hash": "b67b6a15bd16f6c5bfa05f71f0f2225a3d635869f583238c8151068d4ff68d5e", "ref_doc_id": "11"}, "8b125d31-589e-4e6a-9710-5fd7c80f5203": {"doc_hash": "1968aefb07630f73a36185d18306591d4111ad9637b30944fb37b908afac2f14", "ref_doc_id": "11"}, "691a0eb5-863c-4d0c-a7f6-a093ecf861e9": {"doc_hash": "6d315f0de39a220a598a7567d9dd9b06b00b3a20edb84d1923ee0439372a065f", "ref_doc_id": "11"}, "8cc6d4e2-dfc1-480f-a6d2-863c941c4161": {"doc_hash": "7919a7a297d25c14a3b40633bd87e2f59bc709dc0c1f10322e9b0049a7aad14c", "ref_doc_id": "11"}, "e8266e1e-ba6e-4087-8fa5-8e9a47db045d": {"doc_hash": "d8affd6736a6ba1158ec921fa46dd5bff1bdca53c165ed5ef9ee629603834f0e", "ref_doc_id": "11"}, "e9dddf6b-f08b-443e-b6dd-f99728950437": {"doc_hash": "f42f3ad1ec1a7f16b713c2f3dff24c3db124e94bf09fc561cc53c16aea14c480", "ref_doc_id": "12"}, "42f0d6fe-8000-493f-92f0-9c1062b1507d": {"doc_hash": "e743152df82d3713e62e52b813881b006f485155b819d0cd5116fa6d916eae86", "ref_doc_id": "12"}, "5e06bb71-a779-405e-aa94-452c1123cc19": {"doc_hash": "712ac57f8d8f9d722ff141d80038e9383ae38678d5ef86f97eb195765793f2ae", "ref_doc_id": "12"}, "689a8098-387b-4521-8a0d-22a40cc614de": {"doc_hash": "552288883aa1f107cf3746d1265eb4da79d29fc8841784cdbd7e7dc4cfe4b2c2", "ref_doc_id": "12"}, "576c22ef-d5f1-4455-930d-4af3352ff427": {"doc_hash": "5efdb64cadf2b90352ae005c6eab84dd9708c52bdac96a3a466d7ae26c0a8b27", "ref_doc_id": "12"}, "c7578c54-4432-4e56-a9fd-b28d99699820": {"doc_hash": "186e0dbf5a27d21fa2c396d637b9b75c4f33a415ba11843da0e19aa6355d8604", "ref_doc_id": "12"}, "b5318db7-2484-4841-b817-aed0cd6df884": {"doc_hash": "000ac3cc67c1528739be38e9c85478ad80bae7b2576746dc4a11e4ba91b8810d", "ref_doc_id": "12"}, "07aa589d-a86d-4694-8757-fb9dc4ab171d": {"doc_hash": "12d10e036645c39ff11c9af1832b47ae57d810c49c680f30d496ae83a24f34f7", "ref_doc_id": "13"}, "af0705c7-0e3d-4c08-8cb5-ea843c49d6f6": {"doc_hash": "6077971b6f99e7dd5e09a3a25edaf50cac9bbbef0a48aac6d5867397f5c16289", "ref_doc_id": "13"}, "ffc2b2cd-e530-4058-ac7a-ff17d5af24d3": {"doc_hash": "d141c72fee2dac9dc0d52e9e8d96130f1840ec9c3795a113315631f2792f882c", "ref_doc_id": "13"}, "3470cc4e-e26c-4a0f-a0d4-d84fd59bf625": {"doc_hash": "a80ae90e301b49329eec4c1346104c0c6f6774a8297ab5262b4384731c303e81", "ref_doc_id": "13"}, "4192e392-20ce-428f-abc8-e2bac794a237": {"doc_hash": "3c699053001ec786ca188ed8cd360974088824cc2bb21564fe1d09454cca4836", "ref_doc_id": "13"}, "eea6c1f7-ec92-4c93-aa05-d1ba5bdd1210": {"doc_hash": "b21a6f615d3dd5677b57930466eb4ed966348290233e07502ee6806da67276a0", "ref_doc_id": "13"}, "8796bb32-6d4c-473d-871d-b822ce8a6e9e": {"doc_hash": "99d7f97ca6121987d8ce2083977bc8b3a8d5ad6564338e30dd165bb9bd9df69e", "ref_doc_id": "13"}, "1822bc4f-4319-41a8-a280-c2e40d7d8d90": {"doc_hash": "e76599dd57bfa486d406d07738be851e734cef4e7a1750d136d604e0ea26ee3e", "ref_doc_id": "13"}, "7d21cbc0-db4a-43f6-adf9-3f5d922207a5": {"doc_hash": "28fde0d3d4b93baab75a2bfd7f7a9829a03827931c26b8c35abd053e7b8da4d8", "ref_doc_id": "13"}, "9069eda0-f363-47bc-9f89-e0888c6aeffb": {"doc_hash": "366bfb081d5b2a7fa3dd98f172ae62da0889937a7c684e0523e2eb73f22740fd", "ref_doc_id": "13"}, "a63e96f4-356b-4247-a451-b62171151193": {"doc_hash": "30e521914fdc124263c61f8fa0b21766f97b97fab2f7ce66e03a8b7c7c122df3", "ref_doc_id": "13"}, "bdcfd7ce-7b1b-4c85-8def-0203ddce26e2": {"doc_hash": "289116f400aac65f99649643327ec62953781543c129380c9270bc9669ac5c68", "ref_doc_id": "13"}, "1f3a10dc-a55c-4359-b6ef-8e63143e08d0": {"doc_hash": "e3c68bcd8db30a744c9c2805b515aed0aeea56261b62ff13cd76239d2fbc145b", "ref_doc_id": "13"}, "494cf316-3b15-4c28-8282-7a0ac4aed7b7": {"doc_hash": "337bedc612718e8e53b651c49185b35ed68884b7f055545067ec62f4f4e6abad", "ref_doc_id": "13"}, "a77a080e-5173-4671-8834-73146464a468": {"doc_hash": "96f005c8f2b053bfdf50e78231a20de2c457d361e22b97985ddabb111ee9fca9", "ref_doc_id": "13"}, "c91aae05-2a0e-42c8-9805-10d5ff56a49a": {"doc_hash": "22ae7e8cf37690c362bd923b8e8b66133580b1d9aa14f16d718337254a44d187", "ref_doc_id": "13"}, "9e726e5f-157b-458e-9622-ba84969f6f8e": {"doc_hash": "7aa5cce91289b4261672843204620142cbc9f06dc65fb0aae08e9fdebf6ffdf7", "ref_doc_id": "13"}, "4d9107d2-532d-49f5-ad5f-149f1ae99205": {"doc_hash": "21fb0039005c30eb6fc55ed9ff12fa389c7989b6647ff42fc8411e40dabcfbf6", "ref_doc_id": "13"}, "1dd85d3b-e027-46fe-874c-e21dbb04dd5c": {"doc_hash": "4be13deac1bba09a2435353110cfc49fafd767f06f1973bbaccddbc258ffe4c7", "ref_doc_id": "14"}, "33d9fe21-ec4b-4c55-a779-9ca87324dde4": {"doc_hash": "6b422b1b15ecf040088ee4c13f8517fcc1d4d7f368b43eae66c8cb53b64d0e87", "ref_doc_id": "14"}, "216f2a8e-6a05-47bb-8e16-b58aabc28b89": {"doc_hash": "cd84111cfb3f23e8f39cf6712aa3c564500eb1f416ebb73ee780769ee6add05b", "ref_doc_id": "14"}, "30f360d4-aff1-4f0d-a97d-6e9e9d966bb3": {"doc_hash": "39838077559f94a0c92ee037d6f81cf5626554c6233c5268f5787620e8694039", "ref_doc_id": "14"}, "7241756b-c9db-4648-b80a-ae76c1f0d3fb": {"doc_hash": "03c8330745c594fc586270124d60a3b840bb1648b3fe5ff374127c3373540ac9", "ref_doc_id": "14"}, "9ecfb8bd-a029-4c96-beb6-de99b381efd3": {"doc_hash": "e4b1a1b7ccbd21b2b5c291248fa52f9a50cc108b3eefb20ee83f84f652c730ff", "ref_doc_id": "15"}, "2da65707-71d4-4760-b5bb-4607bf462478": {"doc_hash": "dd5c12416d7c4b2cb0ae127a133758cb218850ed884a408b8e3bd0223df313bd", "ref_doc_id": "15"}, "73f77458-144a-43e8-a220-80e03f7131c9": {"doc_hash": "c2bbaeae0e82590db2c6a4a967089c7077ef5ab8af34ad4fa4c533aeab8e7f16", "ref_doc_id": "15"}, "fa32a53d-c5c3-4ae9-a61c-b6e1c2672056": {"doc_hash": "c60c3dafb02efadee709e96522239c01dfc577a99be13531fd84e652f556c28c", "ref_doc_id": "15"}, "d424ab39-4918-4e46-82b9-8da1d9c193f8": {"doc_hash": "169e017e898b8f227a2fa27bf6ad7040da79a10a84468244641cdd2a9a777816", "ref_doc_id": "15"}, "c55f8999-df3e-45ef-b669-3bcfeed68168": {"doc_hash": "4d66b79d961a25080213bd0e7e55ff525b3ad9d4895be128968cd925f6def16e", "ref_doc_id": "15"}, "205eded4-e2a6-414c-8c76-a86c56868495": {"doc_hash": "b1e34d81b8ffd7ba36e1df403d65ac6eda0246eef6dcf9008669afab8bac2070", "ref_doc_id": "15"}, "257c13d6-1e99-4e1a-972f-7a7b59a3199b": {"doc_hash": "095a68f6c22292d3e8f4593c6c957299de63b4901dd8a874feb66dcafc909942", "ref_doc_id": "15"}, "f7550c5e-9473-4711-b29d-5880713a084e": {"doc_hash": "24a3e26253cd91ba33f3522d741c8639f68ce96b7f6406227f720f4d820e148f", "ref_doc_id": "15"}, "ea29a4c0-036a-4e32-885a-ffe444689ae6": {"doc_hash": "5639838f8ede9953433f9da08e96df6ab22ac3291e7c9c934b106322dfab8470", "ref_doc_id": "15"}, "3f747d43-13cd-49ed-a786-1bdd7b431d7b": {"doc_hash": "89d6d6ce50a669269084be1374240a7e1e8dfec3781ed75e28f3e058aefaf9ca", "ref_doc_id": "15"}, "ea2ce78e-c967-410c-b8d8-97ee3709e39d": {"doc_hash": "8b524fc31f9f8da95db871de462cb01413a5edbdacb5b3c80f3594cdc2760b47", "ref_doc_id": "15"}, "e6c667ae-d966-4201-8291-6a610ca58d95": {"doc_hash": "0c19faba9a8534e4c52bf3fcc981297608c8458f7aab8a838afd7e2b9adaf231", "ref_doc_id": "16"}, "8290191e-e61d-4c09-b056-292488015dcc": {"doc_hash": "6a28eb4a855ed541f22f817bc6d1bc3d0b5d10f08d29e26482cd658efacb83e0", "ref_doc_id": "16"}, "ba2810cb-baaf-4743-b87d-b30bb057135e": {"doc_hash": "f7f702c50dfc900b863b0c18aff7230e582078c870849e10a6f826d7065ce587", "ref_doc_id": "16"}, "f144d6a5-ba9a-47d7-b4f7-56849d08b04b": {"doc_hash": "82949cab52a8db103998b7eaf59cd35d907b043f77f8855891b251797095f6b4", "ref_doc_id": "16"}, "f1af7701-3f3b-4b92-9695-71d10dff154a": {"doc_hash": "baae45775d5944d11d51e8ef42f972402a462572eee322594d013a89ff8df17c", "ref_doc_id": "16"}, "4eb7d804-73ff-4dbc-9008-abab68638ac8": {"doc_hash": "a8e8034f9d9ca89e897df701bcdf123e43f74b0f2fece88b2c36f92ed8258801", "ref_doc_id": "16"}, "e47220ba-d638-477f-9941-f02ec41c6320": {"doc_hash": "881e9899561fe23b2d386b12dd1847d02ecc892a8fc309d646638e6e155c1a2c", "ref_doc_id": "16"}, "7ab7ca72-264a-4759-8dea-ad741bd329df": {"doc_hash": "a2e88a98203285ca53cf34892f9df7c455893ff541fd0137a2e77acf326e33f5", "ref_doc_id": "16"}, "3a0c66fd-e068-4425-9120-cee9f639c13b": {"doc_hash": "2ae1505205529d9e9438c4e1e0e59098e79b1394a54608b0a9fec3b90f7c403b", "ref_doc_id": "16"}, "a1573b95-2444-47ed-9ba6-36cd7df91364": {"doc_hash": "b647ff7e0b272751a6ef26b47d39eed05dd3d82a8238ad5a34f80b1514143427", "ref_doc_id": "16"}, "418ac076-a0e4-4576-89ad-4dab8cb72ae4": {"doc_hash": "8256dff19874be812d9e71abc366dfad809905d417abb592b49577a0d2fedb0c", "ref_doc_id": "16"}, "4d3d7d13-9c4a-4135-9333-3a90684e7cbf": {"doc_hash": "d01ef1143d0b6407c493658a58608b78335ca1a6c8f155d9e3c64d9b53c17a7f", "ref_doc_id": "16"}, "be192bb3-314e-4ba3-9e07-4ba3e8efa663": {"doc_hash": "a43acf3754033f16921b226d0c797a13c8ac12981c54a144281df498101a3290", "ref_doc_id": "16"}, "c9bb97e6-cfdb-4bf1-b39d-e3ff0e0703d8": {"doc_hash": "184c42e9325eebd60ad9ed558a017252cedd91738cb2fca436ca3f4fefc8ebb2", "ref_doc_id": "16"}, "576291a0-c9bd-4c15-aa52-11f5a859c672": {"doc_hash": "a0d65607ffe10c04b4c250338dc2221c3754c07d77ad69d675d7aa6a12dd4a47", "ref_doc_id": "16"}, "7c6ebb2a-7ac1-4af9-ad0a-a670227b21d4": {"doc_hash": "346cd5d2f756785734088e6c7f812a8b935e06fe2294ff40cfcc42b63f4eb031", "ref_doc_id": "16"}, "82d68d5c-81f3-451e-add8-f6b1880722e1": {"doc_hash": "f18828a667f86523933c29cbb88e98744b8edfd97649ff796925737564e4c4e7", "ref_doc_id": "16"}, "4e3d9e20-9c10-48fe-8766-397da5b1daef": {"doc_hash": "04fdfec7d50be129b5fc28ee4e5a5028e7fd07a85ba4bc202542a5ee14ac503a", "ref_doc_id": "16"}, "58394294-6b3a-4776-856a-1fe0d7341bde": {"doc_hash": "38e767331f22b995292f6b73af20439b7cd423d4dafce9652ebb9b1f02d611a4", "ref_doc_id": "16"}, "6c8a1732-59f0-4956-8ea2-bbf44b1b0113": {"doc_hash": "386ac46430ddd18331f6cc3884ebd2ecfb50388c7c0e7cb11469f476a074cff4", "ref_doc_id": "16"}, "9b7e7206-4792-4a7a-8219-c721bccc88e1": {"doc_hash": "82ca58cacda8374f83bac8d5ce612c72aa7716a4d1212f2cfab9f23caf6fd43a", "ref_doc_id": "16"}, "0c926f42-462e-4e43-97eb-9fbb03f58eae": {"doc_hash": "ac29d31835947b141b655ed35a95946cb09b6408270c9bd092f39c434f13b4b2", "ref_doc_id": "16"}, "d8fcf933-bb27-4f37-bcb3-9fd4696d8594": {"doc_hash": "5884517158909cd4b1248fa22ae32c407598eba051801f0b0e7c02840f04292d", "ref_doc_id": "16"}, "b2e9beca-33c1-4417-a602-a4c3ce72ec5a": {"doc_hash": "d109c42f9840f0076c0520ff276b0f8c88ab0a3cf32c70a5b54455926c08ced7", "ref_doc_id": "16"}, "c72fc260-06de-438a-817a-d472d58724b1": {"doc_hash": "358a1b65c4021e9227488adb29012004b3dad8d2b2d1233c33ed8d606ff78f35", "ref_doc_id": "16"}, "b5b7f37d-54ac-4182-8840-f1c3923a581a": {"doc_hash": "0b6e0ee684a7d3d0cfbd4c4eb7ab7fef02d2714a71c5df79e3259a595269778c", "ref_doc_id": "16"}, "7499a60c-6249-48ee-9f90-85a5dcc341c5": {"doc_hash": "595eba601e121bc0667ab9ee468f3fa281e5da38c1adc93a07ef2d7334b5fb1f", "ref_doc_id": "16"}, "ae3db91f-256b-4c92-b8ba-c00b1a4b6526": {"doc_hash": "4c21f6fc9939cc1091ffb1d1c93fec36e0ababf9e4a08c8a08c979985a19ba34", "ref_doc_id": "16"}, "f031d920-4ae9-49d1-bd44-c199365df8a7": {"doc_hash": "1274b68cb5418a02cc32237139db8c03827cca360e99ff948ec86fcaabf7f257", "ref_doc_id": "16"}, "d35edacc-5c9d-41c1-bf00-1231e1ee9712": {"doc_hash": "33dbbc7cb2b01fce8279ffa85c04ded531efc27708f4293c32d1cc4a02b1a305", "ref_doc_id": "16"}, "9aa789f7-9e08-46c1-942b-f3ff0d62ac3b": {"doc_hash": "461c3b13da0b69530909192572d5460b6c81052c1e4483a65ee831842eaf4a86", "ref_doc_id": "16"}, "05438a62-53d7-4818-9a2d-43184a83fc5c": {"doc_hash": "be9bb8a6d79f9ac5f08b45199cf80a0020243951fc5c41bf1311fa8af4779d10", "ref_doc_id": "16"}, "f860b520-f5d3-4245-ab13-d0aa77e046f2": {"doc_hash": "ac1963e0dfcf02904f643ee7957f1b4b46ede45dce1f458f7a72440eeed100a4", "ref_doc_id": "16"}, "e5404591-a116-4806-8023-6d2bfb98049f": {"doc_hash": "c26225207b605a75c4c86eefe63772a0a46a141c38999d9a12a365cd67854261", "ref_doc_id": "16"}, "545a7bd1-ecba-4550-abee-dcf4d198df60": {"doc_hash": "1117592e666e28f4ec600fea244bdd91518af308d474347a07dd44c4df1b36e9", "ref_doc_id": "16"}, "8b6c8e8d-b6e0-4bf8-8931-e18beb1fe4c2": {"doc_hash": "bc7f83ae7220b8e0a09659e1d02c5686c11d993e898c80553061c97627736361", "ref_doc_id": "16"}, "927adbe4-83f6-45dd-9f54-e008b9e2bea6": {"doc_hash": "615549a4973b45a5bfc14087fd119f2a97f898e0319882a716ee6065b3fd4c88", "ref_doc_id": "16"}, "81f40d50-b18f-43de-bb9f-1f3e9a826fe4": {"doc_hash": "8dbf849733a2a9a387a90cf47eb4e21dd00d0f84f3aef9aff6ae211e71a909fe", "ref_doc_id": "16"}, "e074541d-bae1-4485-bd00-fde53ef59930": {"doc_hash": "a58671b234a763bc84e71aa670b44c5ada2baa5f508c805b5568089d6a71ee42", "ref_doc_id": "16"}, "fa3f327a-b69d-4829-9e91-8c63b826e51d": {"doc_hash": "38b5ebe14c6a3ba10738a5a64428c5a0002da009fc2386cbe63d4e800571976d", "ref_doc_id": "16"}, "e3db9384-437b-4504-a0b8-a95915f6b8c9": {"doc_hash": "faf27df5dabb5b46708db0d7802f59913082e0197dea2e88558aa23ef146d0e8", "ref_doc_id": "16"}, "f8d174ef-185c-47a0-961b-9267c3ebc5e1": {"doc_hash": "3aae9ec57f7dc032c673c3339bd097e9757f51289090ece18745391a79a2e00e", "ref_doc_id": "16"}, "161945f5-32ec-4696-9668-44baeeef0aa3": {"doc_hash": "147eef47a50524c005e2290687bdf5ba6a8481a3bac1916f7022b064ce12534a", "ref_doc_id": "16"}, "5822c51b-ddee-4b5a-94d4-c5391a0c8a3d": {"doc_hash": "630b60ce64dc41f81cada2b61edc68b7a75e4ff80d0fde43222ce756c89945fd", "ref_doc_id": "16"}, "59ffb54a-4f37-4a0d-a0cc-b5935ccfeaad": {"doc_hash": "752d557560c19d88d4abc40dcad95585a480e09e859c784a9769f41405b9c87a", "ref_doc_id": "16"}, "1dd22892-30b9-4fc6-8f98-20f9ee9b7dea": {"doc_hash": "afb91b74b49c9bbef8ff8f47e99a9fc46b7a26e3bcdb1cc16b4576be704e595b", "ref_doc_id": "16"}, "ab46cd9a-d603-48f9-a4ca-60b9ee6fe689": {"doc_hash": "76e2dd33b9e6f67a50947cc1abb76c21dd25701de76f58e6f91d6e1d15d88a4c", "ref_doc_id": "16"}, "534c6d6c-7b4b-4020-b737-b41dfb0741ed": {"doc_hash": "e6b1af8c0806ad4390aecddcc0a98e6ca2ecfa61859292a768c72a503977c2b6", "ref_doc_id": "16"}, "c4875247-518c-45dd-96d8-6c5e47a5ea2d": {"doc_hash": "ceda279ea86d2b0b69aef15193ec36d48387dae8f68f9be18aa96d75231cb69d", "ref_doc_id": "16"}, "67ef8885-8b92-4259-8e64-0a7606df6c57": {"doc_hash": "20968a68c2e07df70b1317647cc14ab2c3efcd66b27e11d1556199d741da795c", "ref_doc_id": "16"}, "49d65a3e-9d6d-437e-ab3c-20f9fa4b5437": {"doc_hash": "faa9f9984a6c6d57e23f4e44a6c28845c472b04cf3d97331228aa40ce094b9d9", "ref_doc_id": "16"}, "a06e2f94-aaf6-4a32-815b-de55f5e68210": {"doc_hash": "a6e58efad913257ac2148eb1b983c5bea95bfb69ddfc27cfbcd1a5d101dcfaf3", "ref_doc_id": "16"}, "6e6168c9-0387-4978-a29f-700673aa1fb7": {"doc_hash": "964fa159674edc9ca6ee47267f76c8f87c7c09bb19f7a1cf07ceb2b0dc2f2489", "ref_doc_id": "16"}, "3a5b3c2d-bbfb-4021-af7a-da9e63a32e2c": {"doc_hash": "17935dce0019a821feb4f52d5cebfce0a691d8fcf0dbed14102dba78ee65c62f", "ref_doc_id": "16"}, "ad545ae1-7067-4e8c-8162-3578b9cca697": {"doc_hash": "5e4877f80c35c22a93996d3bfa07cbc4a4636e344cf41665f73048ccdd78c920", "ref_doc_id": "16"}, "9553a3a8-55b2-43c7-a0f8-b606f8a19027": {"doc_hash": "5ad54a57b8c313590656770844809ffda8562e5fbe878c515ec8f61e0e445e87", "ref_doc_id": "16"}, "9b1fd7a4-5597-4b87-9cbc-f4b793956967": {"doc_hash": "c07ed4fff2d1b4fa278da628a2dbceaf315ba8311fc1b7095b231bc96a73ef90", "ref_doc_id": "17"}, "e2c2ab1d-d9fe-429f-ad9b-d23477f25035": {"doc_hash": "abf558a966394d54e1be532a6a5d16df8ee9aa817ba8f68b44ec0a047f91746e", "ref_doc_id": "17"}, "48ee0318-2226-4696-8169-5b3a411ead7f": {"doc_hash": "57bf4146f336d425f385631f1c3be9b9937c32fdee8084e6ea99bd4d5cad7c5d", "ref_doc_id": "17"}, "3b8e7d2c-aa69-4ce5-a916-3ce0b5b9ae61": {"doc_hash": "e67edc9015e5defe95bb4b7f911306102307d9d4416ab7e50edee5f6296cf574", "ref_doc_id": "17"}, "5c392767-e9bc-4c9d-b82a-ba4a9e400eb1": {"doc_hash": "53378500d243dfed5a4cf16468def4ff89b081a7189eedb830d6ff6bbc18c7f4", "ref_doc_id": "17"}, "d7ec8827-2b78-4836-83ef-197794a92c95": {"doc_hash": "88041c42f0f1d841f82f266ff46682797e986600e4db2b378d21d4b602fe0c82", "ref_doc_id": "17"}, "66a6b60d-bc5e-4374-b69d-cb01dfd634f4": {"doc_hash": "c024a5eaf6b0a8ed6a89a2a7b94f9fbf7c9f7957121ac6630b596b4b827fe001", "ref_doc_id": "17"}, "ab260da2-406f-4758-b0d6-f86f8268504b": {"doc_hash": "be33045afd455914eeb84ed605851188aec7472961e81038dcaf45a3a127f403", "ref_doc_id": "18"}, "8031be7e-a256-4d0f-b8dd-6f0529204353": {"doc_hash": "354ca3c9a233b64346f787faa4cc673293fe043c3492696acbafc556531c95d9", "ref_doc_id": "18"}, "c1b5f2a4-dd42-42e2-9668-5dffecb2364e": {"doc_hash": "5cd4127263adbafec132df2229c062f1147b0b20c38e93e9c8c01cb4bf980831", "ref_doc_id": "18"}, "f665aa08-b4b1-4885-b271-4e769afd80f9": {"doc_hash": "64140fd3b1def477fd008b1dbbac6672533389dbd45342da597fa2d27646a3a5", "ref_doc_id": "18"}, "8b2a57ef-4ca2-4f53-aa0a-037eff2ef072": {"doc_hash": "8431572f8bbce6740914a7ab8f47d1027a7827a8777f0e20edad28daead2aa5f", "ref_doc_id": "18"}, "4dd0f0ef-51d0-4ba6-ab8c-0da8474bb192": {"doc_hash": "e7023ba699f7871d825ca1917f9d900f0266d656235790ec0ad30a042731b563", "ref_doc_id": "18"}, "265c159b-54ab-493d-b7ce-582a12f6e683": {"doc_hash": "f334e2421ef007063dc55249b60cc393070a4c79d6a0eb1ea187e98f855f6765", "ref_doc_id": "18"}, "73f09848-129b-4388-bf94-3a9b490cc915": {"doc_hash": "b887d599344fe006a36befdd5de7af18eb434af7830f9eb2406dd153a6c0210e", "ref_doc_id": "18"}, "3e885ba5-cbc1-4dc4-a3cf-48db7e2ecc6a": {"doc_hash": "79693a6d761025bca491e55e344de3a0ca1368dead09dfd88720376e11945aef", "ref_doc_id": "18"}, "8611171f-9472-4f03-9a4f-ca31d3fd1998": {"doc_hash": "c919f3b2b0c9283037f4cfe1326ccc1eb05bdfe0ac1b6f2af8433d0611f39de6", "ref_doc_id": "18"}, "09be979f-2d00-4c4b-9940-802f4c9d0d62": {"doc_hash": "73a44356cc51d335ba43cacb26cb0aa7180e1ed625e7fb44bd3073dfeca9f513", "ref_doc_id": "18"}, "b0b11e00-37df-45b8-8eb6-dbdc64381a81": {"doc_hash": "84b11322a27c68d44db7c9b2e64924a529b11b6f34fa8e99d3c4509b7f656953", "ref_doc_id": "18"}, "3f99cd34-1307-4339-9c23-2ab4dd6cc4a7": {"doc_hash": "ef51a73d25ac01811072bcbae408e826f9caa429aa95ccb4543746bf8e38b4b4", "ref_doc_id": "18"}, "f04bb2ac-06e7-466f-b399-4895884230a5": {"doc_hash": "c56333318ed7a983d32e8f0681da9dc76b606d9b7e129d273e154648853e0e5a", "ref_doc_id": "18"}, "1637c3af-ad01-4d2c-b1e0-3952f8bd9460": {"doc_hash": "1d9492e94c747174c77f20c0b423246240a391fae877a818377de8c539462742", "ref_doc_id": "18"}, "252110de-689e-4281-8bc0-dbfb5bd4e2a6": {"doc_hash": "83a848b60155eeaded233a8bc198f90a82b61afad78bc90974caf86bdec1e8df", "ref_doc_id": "19"}, "0126db65-46d9-407e-bab2-34645eb23bc4": {"doc_hash": "0cfa0238f57b4cb477e40bf0dffcb500dc4ef7664c724feb209d25a4e8585457", "ref_doc_id": "19"}, "95958144-ff5a-40c6-a20f-25a531213d2f": {"doc_hash": "572c47777c7ada93bb4174077120bb131b8a81dd3b96194bacb6068ad5f040a1", "ref_doc_id": "19"}, "1d5a6903-e644-41f6-96da-19bb887ef111": {"doc_hash": "36af097b892ee17daf78f00b451436c71c7266ec3d3ba13975bf279f7345cdc5", "ref_doc_id": "19"}, "5a04d64a-65c2-4d9e-8970-db30a9b4b21a": {"doc_hash": "4544ec9b1bba8a44dd38c940567ed9c4487c5f0cfd63ed94b4e5b343f55dabfb", "ref_doc_id": "19"}, "4ee78a3c-2954-48c3-a27c-d87b4a5003f2": {"doc_hash": "5ed505e4cfdfe7c8f8eb119b7669d5ed29a74f0e82c54d085a14a2792cad0ed0", "ref_doc_id": "19"}, "d6e6d34b-d99e-4058-bed6-a465f3d2cbbd": {"doc_hash": "2c736fff94f17e22e4669a638a89b989e2df31075656e5d08c8c19b443ecfb0b", "ref_doc_id": "19"}, "8b7f6ff3-833c-408d-845c-3935decdbed1": {"doc_hash": "3bb9519d23ee180e2eb901a74f7adbbc44e8f0858a4320a07cfe8abf74c79837", "ref_doc_id": "19"}, "70cd81ad-f239-413a-bd73-ce4413d92e2a": {"doc_hash": "c64a768515f2437edfab82191bef84f7a73d75aad218eab34608e6da90ca8d28", "ref_doc_id": "19"}, "42908003-e72d-4bfb-be8d-23db30e7938c": {"doc_hash": "fd18fcb5862650f4b2b7f38000dad060d6ae374b151cdf889577555a9bb7b41e", "ref_doc_id": "19"}, "35a95c1d-1250-4e79-ba0c-059fb91d1ea2": {"doc_hash": "b56d8ce9833b66d73f9b6187b2aea0b279968d1151a8e40fa942f3923193f275", "ref_doc_id": "19"}, "cbaf087c-3db6-4926-be11-4a69eea18f2d": {"doc_hash": "8df8b4d71f8895b784c40ceb2eebec4644fac7d49dc2605afd5bbff77f2ad91a", "ref_doc_id": "19"}, "abddf7d5-2aa6-4361-ac77-38272c6c7ed7": {"doc_hash": "1fc9cf3c1c58819d56422c6e0c6df268ac7ec168b5403df1e406b2c443f2ae89", "ref_doc_id": "19"}, "5e975e2f-b34b-4362-b279-cba2c2540009": {"doc_hash": "45a68cc461398ac5d61dea00400e71738333e6741dd3dc26d28946b91aa138a7", "ref_doc_id": "19"}, "527bb4c7-2740-4f64-80ec-e4ba28137497": {"doc_hash": "4b6abb279d06aa88c6d1f064d595b5c9d830382fda906dcc4843c51bd83142a2", "ref_doc_id": "19"}, "cc9640d4-d7f0-4166-bdfe-792d84bc1dd4": {"doc_hash": "22da115b432161604155f12b33e6af4062634ea9049b38c7bf6ec17ad4f2bc50", "ref_doc_id": "19"}, "86f3bc33-ae35-4343-8928-110f8495083d": {"doc_hash": "10ee45fb4997cfdae9a93599050fb9526974b16e038ee0b4f4374cb8ea08c519", "ref_doc_id": "19"}, "e7d2d185-6e43-41a9-8d61-ca6cf6acc305": {"doc_hash": "b283d3ee10ff9dacaeb3a0c99d1bfec00b74f7db5777b227afda44055a8c74e3", "ref_doc_id": "19"}, "d20c864f-7aa7-4fc7-a4be-402e71af427e": {"doc_hash": "1c3a551927bb0c709f1645d58b3296f6b25229c7af7febe0ced3d31c31a7e17c", "ref_doc_id": "19"}, "c0b403d1-f8c4-48c0-90bf-ab39a1239637": {"doc_hash": "44fe7e1c8ef828ff03c2583b09637113ef1dba6798470857ae76496d082b1d39", "ref_doc_id": "19"}, "5509687d-5633-419b-9c49-d3c8c2ece59c": {"doc_hash": "5dd51b48e6b9549c7233c80e480800aef72af4d5acc7c71a1199e0bf9b1a14aa", "ref_doc_id": "19"}, "21aaaee8-939f-4a2d-b298-db323ec6ec00": {"doc_hash": "9c16e95c7c2ed5a4a0f3168fcbfbd995d8f171667e470ebc24d78fc9f5905d27", "ref_doc_id": "19"}, "fd1c253c-c9f8-41c0-a89b-bb33cc5826c4": {"doc_hash": "962253c349cf7009004ed8a6e3c194b51a83a5b4def4a778c134590479b195c7", "ref_doc_id": "19"}, "da8dff95-2d7e-4ffe-ad44-027dd67f9365": {"doc_hash": "9c55c9c8c55ae9940d2c431f91391ec9aa15a5c15bff36489cde77bf2a2ecd96", "ref_doc_id": "19"}}, "docstore/ref_doc_info": {"0": {"node_ids": ["e373ca6a-3c6d-49fc-aaba-e3d4ad17f558", "ba4aea6e-719c-4479-bb13-89c7273317f8", "ad6642be-d4a1-4492-8585-c2553992f634"], "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}}, "1": {"node_ids": ["a011d955-0190-4910-9d99-276d9c7157ce"], "metadata": {"source_url": "https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1aksw5rm/c2%20-%20session%2050%20-%20underground.docx?rlkey=ioqwgkd14i5xk20i3fp38nzgs&e=1&dl=0", "document_index": 1}}, "2": {"node_ids": ["521a260b-e4c1-48d9-a2d9-e0364c094b23", "f13a0ff9-602f-4d3d-8507-94cc7bf7f7df", "58fafe87-9b10-476f-b90d-da582f136cf9", "cf5202bc-1f43-4259-af24-6c692cae7096", "33b69ca2-e895-42c3-8975-d30b09f71255", "ce920e51-04a2-4e9f-a92f-279df00a9f65"], "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}}, "3": {"node_ids": ["76752c6f-969a-4e68-ac0d-727170129f06", "2d4f5695-7525-4793-b8bd-eb32a0058779", "cdc69adb-f6bf-4296-9caf-28ebf5a0671d", "10af9110-0132-4d14-b20a-eecc18f55933", "88574f1c-afdd-49b8-a062-451e3ebff0ea", "5e9b4b14-b6a1-4140-9a02-9561ce8a8853"], "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}}, "4": {"node_ids": ["765f4bc9-fc87-4ec0-bace-ca663b60e518", "ef505541-3953-48e6-8253-7beb582f3040", "c8de7cb6-af61-4893-9464-d1a7d401d27b", "e7b5712d-76b2-40d9-9d9a-8683bdbb0a77"], "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}}, "5": {"node_ids": ["77dd73b4-5c54-408a-8523-49aef5ce8f00", "ee787ea5-227e-4105-bd29-a07b6d688353", "999a9bda-b816-4143-a7aa-10d0cf77bc00", "95d08505-b8e5-4481-bf41-5bd31dca616c"], "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}}, "6": {"node_ids": ["8d620ed0-e93d-47e2-ab49-4eb23d40dde3", "19f83ba4-950d-485a-8ec5-090b58c32d8e", "01658214-645f-4424-b1ac-cfde9f4caa24", "56dc0c80-3bd0-47ae-832d-2a404df630be", "e1d31a59-9af8-41f2-b157-be0092b7998e", "a88c646e-7575-449f-96dc-8c59122648bd", "5076442f-9d5a-4bc4-b93a-e0688bbe4a77", "6ed35031-ec81-4fbd-94ff-d90254ba94e6"], "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}}, "7": {"node_ids": ["4f940bd9-f787-4f7f-bfe3-61c6ce51bc5c", "f91c0019-fc6a-4196-a0d6-f689fbfd48b6", "9c479b87-9e55-4aed-b56c-c1b2363b60d5", "d38281fb-a5cb-4b7f-81da-cfae2b159582", "a59a292d-459c-4367-b64b-1f63b08be6f6"], "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}}, "8": {"node_ids": ["2a51115a-26d9-4445-aad7-abbae5f5e20a", "39bfd395-9f2d-4d81-b460-e8486271cc5b", "8e07fb3e-2d9a-4d5f-b20d-8e29ceddd806"], "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}}, "9": {"node_ids": ["131db3e9-fcf2-41ac-bf30-b92152187672", "e32a7427-4a09-4cfb-b6a7-23701f5a9ca9", "ad511521-dd22-498f-8111-669566dee86a", "7426a009-ede2-4c41-a30a-b3bc52195092"], "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}}, "10": {"node_ids": ["5d31ab3c-c813-40be-8fa9-b0f8958b8c96", "65477189-2b3a-4214-b30f-6f36ae619863", "deea83e8-16cc-4aca-b15f-db68853d1c71"], "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}}, "11": {"node_ids": ["debd681b-80fe-4b48-bfe5-ab0cf28023f0", "1df0b303-84f6-410b-8421-60e44489f4cd", "d9db1d98-6162-49bd-a790-071a68aa2242", "d2f0120b-892c-4851-95a4-60d9c303ca79", "45fa019f-88b7-429e-b1c5-c7f28097f5c0", "c24d900a-97cf-4a9c-a431-fa476932e093", "42178690-1c55-4503-be7e-9e9eb62663c8", "b885cc51-9921-4ecc-8b57-df4e636b037d", "a5cde305-6f81-41a6-ac6c-02e58df5021b", "5c2b2147-2fc3-4e05-af4c-7b7abefb80b6", "2423159f-39bd-40b4-a367-26a9f1a550f3", "aefea3db-ed16-46a6-a25e-7f6e229d5c3e", "b00997e3-c12a-48d3-b013-07cec870f46c", "db314eb6-b9b1-4eba-bea5-a3b4be6b532f", "8b125d31-589e-4e6a-9710-5fd7c80f5203", "691a0eb5-863c-4d0c-a7f6-a093ecf861e9", "8cc6d4e2-dfc1-480f-a6d2-863c941c4161", "e8266e1e-ba6e-4087-8fa5-8e9a47db045d"], "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}}, "12": {"node_ids": ["e9dddf6b-f08b-443e-b6dd-f99728950437", "42f0d6fe-8000-493f-92f0-9c1062b1507d", "5e06bb71-a779-405e-aa94-452c1123cc19", "689a8098-387b-4521-8a0d-22a40cc614de", "576c22ef-d5f1-4455-930d-4af3352ff427", "c7578c54-4432-4e56-a9fd-b28d99699820", "b5318db7-2484-4841-b817-aed0cd6df884"], "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}}, "13": {"node_ids": ["07aa589d-a86d-4694-8757-fb9dc4ab171d", "af0705c7-0e3d-4c08-8cb5-ea843c49d6f6", "ffc2b2cd-e530-4058-ac7a-ff17d5af24d3", "3470cc4e-e26c-4a0f-a0d4-d84fd59bf625", "4192e392-20ce-428f-abc8-e2bac794a237", "eea6c1f7-ec92-4c93-aa05-d1ba5bdd1210", "8796bb32-6d4c-473d-871d-b822ce8a6e9e", "1822bc4f-4319-41a8-a280-c2e40d7d8d90", "7d21cbc0-db4a-43f6-adf9-3f5d922207a5", "9069eda0-f363-47bc-9f89-e0888c6aeffb", "a63e96f4-356b-4247-a451-b62171151193", "bdcfd7ce-7b1b-4c85-8def-0203ddce26e2", "1f3a10dc-a55c-4359-b6ef-8e63143e08d0", "494cf316-3b15-4c28-8282-7a0ac4aed7b7", "a77a080e-5173-4671-8834-73146464a468", "c91aae05-2a0e-42c8-9805-10d5ff56a49a", "9e726e5f-157b-458e-9622-ba84969f6f8e", "4d9107d2-532d-49f5-ad5f-149f1ae99205"], "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}}, "14": {"node_ids": ["1dd85d3b-e027-46fe-874c-e21dbb04dd5c", "33d9fe21-ec4b-4c55-a779-9ca87324dde4", "216f2a8e-6a05-47bb-8e16-b58aabc28b89", "30f360d4-aff1-4f0d-a97d-6e9e9d966bb3", "7241756b-c9db-4648-b80a-ae76c1f0d3fb"], "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}}, "15": {"node_ids": ["9ecfb8bd-a029-4c96-beb6-de99b381efd3", "2da65707-71d4-4760-b5bb-4607bf462478", "73f77458-144a-43e8-a220-80e03f7131c9", "fa32a53d-c5c3-4ae9-a61c-b6e1c2672056", "d424ab39-4918-4e46-82b9-8da1d9c193f8", "c55f8999-df3e-45ef-b669-3bcfeed68168", "205eded4-e2a6-414c-8c76-a86c56868495", "257c13d6-1e99-4e1a-972f-7a7b59a3199b", "f7550c5e-9473-4711-b29d-5880713a084e", "ea29a4c0-036a-4e32-885a-ffe444689ae6", "3f747d43-13cd-49ed-a786-1bdd7b431d7b", "ea2ce78e-c967-410c-b8d8-97ee3709e39d"], "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}}, "16": {"node_ids": ["e6c667ae-d966-4201-8291-6a610ca58d95", "8290191e-e61d-4c09-b056-292488015dcc", "ba2810cb-baaf-4743-b87d-b30bb057135e", "f144d6a5-ba9a-47d7-b4f7-56849d08b04b", "f1af7701-3f3b-4b92-9695-71d10dff154a", "4eb7d804-73ff-4dbc-9008-abab68638ac8", "e47220ba-d638-477f-9941-f02ec41c6320", "7ab7ca72-264a-4759-8dea-ad741bd329df", "3a0c66fd-e068-4425-9120-cee9f639c13b", "a1573b95-2444-47ed-9ba6-36cd7df91364", "418ac076-a0e4-4576-89ad-4dab8cb72ae4", "4d3d7d13-9c4a-4135-9333-3a90684e7cbf", "be192bb3-314e-4ba3-9e07-4ba3e8efa663", "c9bb97e6-cfdb-4bf1-b39d-e3ff0e0703d8", "576291a0-c9bd-4c15-aa52-11f5a859c672", "7c6ebb2a-7ac1-4af9-ad0a-a670227b21d4", "82d68d5c-81f3-451e-add8-f6b1880722e1", "4e3d9e20-9c10-48fe-8766-397da5b1daef", "58394294-6b3a-4776-856a-1fe0d7341bde", "6c8a1732-59f0-4956-8ea2-bbf44b1b0113", "9b7e7206-4792-4a7a-8219-c721bccc88e1", "0c926f42-462e-4e43-97eb-9fbb03f58eae", "d8fcf933-bb27-4f37-bcb3-9fd4696d8594", "b2e9beca-33c1-4417-a602-a4c3ce72ec5a", "c72fc260-06de-438a-817a-d472d58724b1", "b5b7f37d-54ac-4182-8840-f1c3923a581a", "7499a60c-6249-48ee-9f90-85a5dcc341c5", "ae3db91f-256b-4c92-b8ba-c00b1a4b6526", "f031d920-4ae9-49d1-bd44-c199365df8a7", "d35edacc-5c9d-41c1-bf00-1231e1ee9712", "9aa789f7-9e08-46c1-942b-f3ff0d62ac3b", "05438a62-53d7-4818-9a2d-43184a83fc5c", "f860b520-f5d3-4245-ab13-d0aa77e046f2", "e5404591-a116-4806-8023-6d2bfb98049f", "545a7bd1-ecba-4550-abee-dcf4d198df60", "8b6c8e8d-b6e0-4bf8-8931-e18beb1fe4c2", "927adbe4-83f6-45dd-9f54-e008b9e2bea6", "81f40d50-b18f-43de-bb9f-1f3e9a826fe4", "e074541d-bae1-4485-bd00-fde53ef59930", "fa3f327a-b69d-4829-9e91-8c63b826e51d", "e3db9384-437b-4504-a0b8-a95915f6b8c9", "f8d174ef-185c-47a0-961b-9267c3ebc5e1", "161945f5-32ec-4696-9668-44baeeef0aa3", "5822c51b-ddee-4b5a-94d4-c5391a0c8a3d", "59ffb54a-4f37-4a0d-a0cc-b5935ccfeaad", "1dd22892-30b9-4fc6-8f98-20f9ee9b7dea", "ab46cd9a-d603-48f9-a4ca-60b9ee6fe689", "534c6d6c-7b4b-4020-b737-b41dfb0741ed", "c4875247-518c-45dd-96d8-6c5e47a5ea2d", "67ef8885-8b92-4259-8e64-0a7606df6c57", "49d65a3e-9d6d-437e-ab3c-20f9fa4b5437", "a06e2f94-aaf6-4a32-815b-de55f5e68210", "6e6168c9-0387-4978-a29f-700673aa1fb7", "3a5b3c2d-bbfb-4021-af7a-da9e63a32e2c", "ad545ae1-7067-4e8c-8162-3578b9cca697", "9553a3a8-55b2-43c7-a0f8-b606f8a19027"], "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}}, "17": {"node_ids": ["9b1fd7a4-5597-4b87-9cbc-f4b793956967", "e2c2ab1d-d9fe-429f-ad9b-d23477f25035", "48ee0318-2226-4696-8169-5b3a411ead7f", "3b8e7d2c-aa69-4ce5-a916-3ce0b5b9ae61", "5c392767-e9bc-4c9d-b82a-ba4a9e400eb1", "d7ec8827-2b78-4836-83ef-197794a92c95", "66a6b60d-bc5e-4374-b69d-cb01dfd634f4"], "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}}, "18": {"node_ids": ["ab260da2-406f-4758-b0d6-f86f8268504b", "8031be7e-a256-4d0f-b8dd-6f0529204353", "c1b5f2a4-dd42-42e2-9668-5dffecb2364e", "f665aa08-b4b1-4885-b271-4e769afd80f9", "8b2a57ef-4ca2-4f53-aa0a-037eff2ef072", "4dd0f0ef-51d0-4ba6-ab8c-0da8474bb192", "265c159b-54ab-493d-b7ce-582a12f6e683", "73f09848-129b-4388-bf94-3a9b490cc915", "3e885ba5-cbc1-4dc4-a3cf-48db7e2ecc6a", "8611171f-9472-4f03-9a4f-ca31d3fd1998", "09be979f-2d00-4c4b-9940-802f4c9d0d62", "b0b11e00-37df-45b8-8eb6-dbdc64381a81", "3f99cd34-1307-4339-9c23-2ab4dd6cc4a7", "f04bb2ac-06e7-466f-b399-4895884230a5", "1637c3af-ad01-4d2c-b1e0-3952f8bd9460"], "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}}, "19": {"node_ids": ["252110de-689e-4281-8bc0-dbfb5bd4e2a6", "0126db65-46d9-407e-bab2-34645eb23bc4", "95958144-ff5a-40c6-a20f-25a531213d2f", "1d5a6903-e644-41f6-96da-19bb887ef111", "5a04d64a-65c2-4d9e-8970-db30a9b4b21a", "4ee78a3c-2954-48c3-a27c-d87b4a5003f2", "d6e6d34b-d99e-4058-bed6-a465f3d2cbbd", "8b7f6ff3-833c-408d-845c-3935decdbed1", "70cd81ad-f239-413a-bd73-ce4413d92e2a", "42908003-e72d-4bfb-be8d-23db30e7938c", "35a95c1d-1250-4e79-ba0c-059fb91d1ea2", "cbaf087c-3db6-4926-be11-4a69eea18f2d", "abddf7d5-2aa6-4361-ac77-38272c6c7ed7", "5e975e2f-b34b-4362-b279-cba2c2540009", "527bb4c7-2740-4f64-80ec-e4ba28137497", "cc9640d4-d7f0-4166-bdfe-792d84bc1dd4", "86f3bc33-ae35-4343-8928-110f8495083d", "e7d2d185-6e43-41a9-8d61-ca6cf6acc305", "d20c864f-7aa7-4fc7-a4be-402e71af427e", "c0b403d1-f8c4-48c0-90bf-ab39a1239637", "5509687d-5633-419b-9c49-d3c8c2ece59c", "21aaaee8-939f-4a2d-b298-db323ec6ec00", "fd1c253c-c9f8-41c0-a89b-bb33cc5826c4", "da8dff95-2d7e-4ffe-ad44-027dd67f9365"], "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}}}, "docstore/data": {"e373ca6a-3c6d-49fc-aaba-e3d4ad17f558": {"__data__": {"id_": "e373ca6a-3c6d-49fc-aaba-e3d4ad17f558", "embedding": null, "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0", "node_type": "4", "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "hash": "6a7986747a39acd6b6b686433333eb0ae65fb366d14315adb1ea149dfbaedc3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba4aea6e-719c-4479-bb13-89c7273317f8", "node_type": "1", "metadata": {}, "hash": "b3d733d67205c02db76a69a30461c9814b47a794ab215733d125d985908a6202", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon's boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as \"Bal\u00f9nculo\", a portmanteau of the words \"bala\" (bullet) and \"hom\u00fanculo\" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player's movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker's expression in his Ammonomicon profile resembles that of the Bullet's avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n\"Of the gun\" is a play on the phrase \"of the cloth\", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4426, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba4aea6e-719c-4479-bb13-89c7273317f8": {"__data__": {"id_": "ba4aea6e-719c-4479-bb13-89c7273317f8", "embedding": null, "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0", "node_type": "4", "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "hash": "6a7986747a39acd6b6b686433333eb0ae65fb366d14315adb1ea149dfbaedc3d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e373ca6a-3c6d-49fc-aaba-e3d4ad17f558", "node_type": "1", "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "hash": "c2b06afbfbc92be8fed8a3b281d31d78411e867bf5138fd17f27fe4a3e5f0516", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad6642be-d4a1-4492-8585-c2553992f634", "node_type": "1", "metadata": {}, "hash": "cb56d64e73ef2e83a4b3deed65c6f08fe4264a21df5cfbd508ffb3e4f017f521", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Trivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n\"Of the gun\" is a play on the phrase \"of the cloth\", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote \"Cinder Fella\" is a clear wordplay between \"Cinderella\", the famous fairytale, and \"Fella\" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote \"Balle au bois dormant\" is also a wordplay between the fairytale \"La belle au bois dormant\" (Sleeping Beauty) and \"Balle\" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as \"Ex-Bal\u00f9nculo\" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin's behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless \"enemies\" that quickly run away from the player\u2014often leading them directly into the path of danger\u2014and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.", "mimetype": "text/plain", "start_char_idx": 3546, "end_char_idx": 7893, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad6642be-d4a1-4492-8585-c2553992f634": {"__data__": {"id_": "ad6642be-d4a1-4492-8585-c2553992f634", "embedding": null, "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0", "node_type": "4", "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "hash": "6a7986747a39acd6b6b686433333eb0ae65fb366d14315adb1ea149dfbaedc3d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba4aea6e-719c-4479-bb13-89c7273317f8", "node_type": "1", "metadata": {"source_url": "https://enterthegungeon.fandom.com/wiki/Bullet_Kin", "document_index": 0}, "hash": "197418645a09d394af17b65e52d3adb1a7c83c0b609b897339a562773f963702", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Keybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin's behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless \"enemies\" that quickly run away from the player\u2014often leading them directly into the path of danger\u2014and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin's subtitle is a reference to the common phrase \"No Second Chances.\"\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin's behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless \"enemies\" that quickly run away from the player\u2014often leading them directly into the path of danger\u2014and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest's splash art.\nThe Confirmed are referred to by numerous other names in the game's code, such as 'Kaliber Cultist', and 'Faceless Cultist'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin's design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt's possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.", "mimetype": "text/plain", "start_char_idx": 7026, "end_char_idx": 10654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a011d955-0190-4910-9d99-276d9c7157ce": {"__data__": {"id_": "a011d955-0190-4910-9d99-276d9c7157ce", "embedding": null, "metadata": {"source_url": "https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1aksw5rm/c2%20-%20session%2050%20-%20underground.docx?rlkey=ioqwgkd14i5xk20i3fp38nzgs&e=1&dl=0", "document_index": 1}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1", "node_type": "4", "metadata": {"source_url": "https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1aksw5rm/c2%20-%20session%2050%20-%20underground.docx?rlkey=ioqwgkd14i5xk20i3fp38nzgs&e=1&dl=0", "document_index": 1}, "hash": "c9ffcaf14685cb0567ab5b38d6292a753abe711196b0b39b34053b796c6fae3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "---The Paths through the Underground/Underdark---(9 days of travel)\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\n\nDay 1 goes without issue... sleep.\n\nDay 2 \u2013 Ropers\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\n---ENCOUNTER \u2013 Ropers x 2---\nDay 3 goes without issue...sleep.\n\nDay 4 - Kobold Trap\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\n\nThey are no more than 2-3 feet wide, and numerous (dozens).\n\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\n\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\n\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\n\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\n\u201cLoud food! Loud meal!\u201d\n\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\n\n\u201cYou! Give us stuffs! Give us foods! Drop things you have, or we stab stab!\u201d\n\nIf asked about tunnel \u201cBig worm eat through! Bring ingoeth! In and out, gone quick, leave mess!\u201d\n\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2750, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "521a260b-e4c1-48d9-a2d9-e0364c094b23": {"__data__": {"id_": "521a260b-e4c1-48d9-a2d9-e0364c094b23", "embedding": null, "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2", "node_type": "4", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f13a0ff9-602f-4d3d-8507-94cc7bf7f7df", "node_type": "1", "metadata": {}, "hash": "0a18c20cd6db2aaca93cebafd448ff0cb7f734fd79a68170664d9385e91de1db", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Semantic and Textual Inference Chatbot Interface (STICI-Note) - Part 1: Planning and Prototyping\n\nThe start of my RAG to riches story\n\nSTICI-note\n\nPublished: Mon, 27 May 2024\n\nLast modified: Tue, 04 Jun 2024\n\nIntroduction\n\nIn this three-part series, I will be talking you through how I built the Semantic and Textual Inference Chatbot Interface (or STICI-note for short), a locally run RAG chatbot that uses unstructured text documents to enhance its responses. I came up with the name when I was discussing this project with a friend and asked him whether he had any ideas of what to call it. He said, \"You should call it sticky because it sounds funny.\" The name... stuck...\n\nThe code for this project is available here.\n\nIn this part, I will be planning the project from the tech stack to the techniques I will use, and I will be building a prototype. I will be discussing all of the choices I made and all of the choices I didn\u2019t make, so I hope you find this insightful. Without further ado, let\u2019s get started.\n\nThe Problem\n\nIn my spare time, I occasionally play Dungeons and Dragons (DnD), a tabletop roleplaying game, and the stories are often told over several months, so details can be easily lost or forgotten over time. I can write notes on my laptop, but sometimes regular text search does not always provide me with the results I want when trying to search for specific notes. Some common examples include when a keyword is used often (e.g., I might write a lot about the actions of \u201cMiles Lawson,\u201d but only one segment of text might describe who he is, making searching for information on his character like finding a needle in a haystack) or when I simply cannot think of the correct keyword to search (e.g., what if I search \u201csilver\u201d instead of \u201cgold\u201d?).\n\nOne day, I thought to myself that it\u2019d be great if I had a tool that I could write my DnD notes into in an unstructured way and retrieve the information at any time with simple questions like \u201cWho is Miles Lawson?\u201d or \u201cHow much silver did I pay for a stay in ye olde tavern?\u201d. This tool could be extended to be used for querying my notes on many things that are not available online (and therefore not searchable on a search engine), such as documentation on software that I build, notes on things that I\u2019m learning about, such as AWS cloud infrastructure, and my diary of my deepest thoughts and feelings (at least I hope this is not available online). And thus, I decided to start working on STICI-note because the tools available online that do this cost money and run on the cloud, and I\u2019m a tight-fisted guy who\u2019s very sceptical about company promises to not sell your data.\n\nNarrowing Down Features\n\nAs with all projects, I began by deciding what features I needed from this tool.\n\nRequired features:\n\nChatbot that you can ask questions and get answers in response (conversational memory is not required).\nInformation is taken from an unstructured text file.\nIt must be able to tell me if it doesn\u2019t know the answer to my question.\nFast.\nEfficient enough to run on my MacBook with other programs without any performance issues.\nLocally run for privacy and to ensure it will always be free, runnable, and consistent.\nConversational memory is the memory of previous interactions given to an LLM. I decided not to require it as a feature because I just need the AI to answer my questions about the given text. It might be added as a feature in the future if I feel like I need it, but I do not plan to include it in the initial version of STICI-note.\n\nI knew that limiting it to running on my M1 MacBook with 8 GB of memory would greatly limit the performance of the tool as I would not be able to access truly large language models like GPT-4 and Claude 3 Opus, but I decided to do it anyway primarily for privacy but also to remove dependencies on external organisations to reduce the maintenance required for the tool in the future.\n\nPlanning How to Evaluate and Compare Solutions\n\nIf you don\u2019t evaluate a solution, how do you know whether it\u2019s an effective solution? You don\u2019t.\n\nI next planned how I would evaluate different variations of the tool. While I do not evaluate anything in this part, I decided to sketch out a rough plan of how I would evaluate different solutions to encourage designing a testable AI in the same way that Test-Driven Development (TDD) encourages you to write testable code.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4382, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f13a0ff9-602f-4d3d-8507-94cc7bf7f7df": {"__data__": {"id_": "f13a0ff9-602f-4d3d-8507-94cc7bf7f7df", "embedding": null, "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2", "node_type": "4", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "521a260b-e4c1-48d9-a2d9-e0364c094b23", "node_type": "1", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "b0c3dfd6d48edeb32d415a7d2eedebb1a538cba862c881989d551cc08ba08a42", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58fafe87-9b10-476f-b90d-da582f136cf9", "node_type": "1", "metadata": {}, "hash": "b6df05c1a531c4fdbc4f5a57c4b4efac0249e28e8cea96c1df6fe3e8493c7f52", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "I knew that limiting it to running on my M1 MacBook with 8 GB of memory would greatly limit the performance of the tool as I would not be able to access truly large language models like GPT-4 and Claude 3 Opus, but I decided to do it anyway primarily for privacy but also to remove dependencies on external organisations to reduce the maintenance required for the tool in the future.\n\nPlanning How to Evaluate and Compare Solutions\n\nIf you don\u2019t evaluate a solution, how do you know whether it\u2019s an effective solution? You don\u2019t.\n\nI next planned how I would evaluate different variations of the tool. While I do not evaluate anything in this part, I decided to sketch out a rough plan of how I would evaluate different solutions to encourage designing a testable AI in the same way that Test-Driven Development (TDD) encourages you to write testable code.\n\nAt first, I considered using Wikipedia pages as the data source and making my own questions about the content of the pages before I realised that this would lead to data leakage as many LLMs are trained on Wikipedia data.\n\nAn alternative dataset that I considered using for evaluation is the TREC 2024 RAG Corpus. This is a 28 GB corpus of text documents scraped from the internet. This corpus comes with thousands of queries, and the relevant documents for each query have been tagged as such. This is an amazing corpus for training and evaluating vector DataBase (DBs). Ignoring the fact that its questions do not come with answers, meaning I would have to write my own answers to use the document, there is one glaring flaw that makes it unusable for my use case: the documents are generally relatively short and describe a large variety of things. In my use case, I expect documents to be long and typically written about the same topic. If I were to use the corpus, I would have to stick documents together to present a realistic challenge in the semantic search of the vector DB vector space, but as each document will likely be about very different topics (e.g., one might be about aviation while another might be about economics), context retrieval would be unrealistically easy.\n\nAnother alternative evaluation dataset that I considered using was a synthetic dataset. By following a method like this, I can use an LLM to generate synthetic context and questions automatically. I decided not to do this as I was concerned that this would produce bad-quality data with a massive bias towards things an LLM might already know, despite the use case expecting data that the LLM does not already know.\n\nBecause the documents in my evaluation corpus need to be thousands of words in length while staying relevant to a topic and they need to include information that will not be in the LLM\u2019s training data, I decided that it would be best to manually curate a small dataset to evaluate my models. I plan to create documents from sources on the internet like videogame wikis, people\u2019s blogs, and scientific journals and write my own pairs of questions and answers about them. I will then evaluate the difference between the model\u2019s answer and my answer using a semantic similarity score.\n\nRAG vs a Really Big Context Window vs Infinite Context\n\nTo be able to answer questions about documents, the LLM would need to have access to information from the documents. I thought of three potential solutions for this:\n\nRetrieval Augmented Generation (RAG)\nAn LLM with a really big context window\nAn LLM that supports infinite context length\nUsing an LLM with a really big context window such as Anthropic\u2019s Claude 3 and Google\u2019s Gemini 1.5 would certainly give me the best results as it would allow inference using completely unfiltered and uncompressed context as they can handle inputs of over 700,000 words, but these models are closed-source, and there is absolutely no chance of a model of this size fitting into my tiny M1 MacBook with 8 GB of memory.\n\nBy \u201can LLM that supports infinite context length,\u201d I mean models like Mamba, Megalodon, and Infini-attention that compress context into a finite space. I decided not to use a model like this for two main reasons. Firstly, I have concerns about the performance. These architectures are in their infancy, and I do not expect them to outperform equivalently-sized traditional transformers. Secondly, as these architectures are very new and experimental, I do not expect much support for them, especially for Apple\u2019s M-series of chips, which have their own graphics API, metal, that is required for GPU acceleration on my MacBook. These architectures are very interesting, and I would love to try them out, but for this project, I will have to settle for a more tried-and-tested approach.\n\nThe more tried and tested approach that I settled with is RAG.", "mimetype": "text/plain", "start_char_idx": 3527, "end_char_idx": 8284, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58fafe87-9b10-476f-b90d-da582f136cf9": {"__data__": {"id_": "58fafe87-9b10-476f-b90d-da582f136cf9", "embedding": null, "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2", "node_type": "4", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f13a0ff9-602f-4d3d-8507-94cc7bf7f7df", "node_type": "1", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "92875c4206bcc07b6b81fd205371fd24278b5c3eda04865ff6a03b34a1abf682", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cf5202bc-1f43-4259-af24-6c692cae7096", "node_type": "1", "metadata": {}, "hash": "d4851d8fe169405d2be9410d2e512e4815619e8a16ce947cdbaf7514d639f3fd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "By \u201can LLM that supports infinite context length,\u201d I mean models like Mamba, Megalodon, and Infini-attention that compress context into a finite space. I decided not to use a model like this for two main reasons. Firstly, I have concerns about the performance. These architectures are in their infancy, and I do not expect them to outperform equivalently-sized traditional transformers. Secondly, as these architectures are very new and experimental, I do not expect much support for them, especially for Apple\u2019s M-series of chips, which have their own graphics API, metal, that is required for GPU acceleration on my MacBook. These architectures are very interesting, and I would love to try them out, but for this project, I will have to settle for a more tried-and-tested approach.\n\nThe more tried and tested approach that I settled with is RAG. It is an incredibly popular technique for allowing LLMs to make use of information that is too big to fit in their context windows. This technique is known to perform very well, is incredibly well supported by LLM frameworks like LangChain and llamaindex, and works well in resource-constrained environments like on my laptop. Given all this, RAG was an obvious choice.\n\nOptimising Models for Limited Memory Environments\n\nNext, I decided to investigate what kinds of optimisation strategies were available to use to try to fit bigger models into my M1 chip, as bigger LLMs typically perform better (I know, a groundbreaking revelation). To optimise the LLMs that I use, I considered four different techniques:\n\nQuantisation\nModel pruning\nModel/knowledge distillation\nAirLLM\nQuantisation is the most common method for making ML models smaller (and therefore faster and more capable of fitting into smaller spaces). It\u2019s well known for improving speed and memory usage with little loss in accuracy in return, which makes it very popular for production-level AI. Quantising a model would require being able to fit it into your GPU, but I\u2019m trying to quantise a model so that it can fit into my GPU, so without additional computing power, it\u2019s a bit of a chicken and egg problem. Luckily, because this is such a popular technique, there are many quantised versions of large, high-performance LLMs available on HuggingFace that I can use, so there is no need to do this myself.\n\nModel pruning is a less common method for reducing model sizes, but it is not a technique that one should overlook. This is a technique that can be combined with quantisation (or used on its own) to further reduce models at the expense of accuracy, but I do not plan to apply it myself due to its complexity and the fact that quantisation has the same effect. There are pruned models available on HuggingFace, but they don\u2019t typically perform as well as equivalently sized quantised models, so I do not plan to use any unless they have particularly good evaluation results on a common LLM benchmark.\n\nModel/knowledge distillation is another size reduction technique that I considered. Unlike the previous techniques, model distillation can actually improve accuracy in domain-specific tasks while making a smaller model. As with quantisation and model pruning, I will use pre-distiled models, but I will not distil any models myself due to the computing power it requires (which admittedly is far less than training a model from scratch) and the complexity it would add to the project.\n\nThe final optimisation technique that I considered, AirLLM, is quite different from the others in that instead of optimising the model weights, it optimises the model inference. Typically, LLMs are loaded onto the GPU in their entirety, requiring a lot of VRAM to run the larger, better-performing models. AirLLM is an open-source library that tackles this problem by using layered inference, an inference technique that involves loading layers individually when they are needed instead of all at once. This allows larger models to fit into smaller memory spaces without degrading performance. This method definitely has a high potential for accuracy, but I decided not to use it as I am concerned about compatibility and reliability issues as it is a new tool and the GitHub repo has been developed by a single person, so support for it is likely to be limited. Additionally, my M1 chip only has 8 GB of memory shared between the CPU and GPU, which is excellent for reducing data loading overhead costs, but it means that larger models that require AirLLM will be loaded directly from the SSD, so I am concerned that the model layer loading and unloading will become a massive bottleneck when doing inference on larger models. I will reconsider this option if I find that the models that can run on my MacBook do not have satisfactory accuracy.", "mimetype": "text/plain", "start_char_idx": 7436, "end_char_idx": 12191, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cf5202bc-1f43-4259-af24-6c692cae7096": {"__data__": {"id_": "cf5202bc-1f43-4259-af24-6c692cae7096", "embedding": null, "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2", "node_type": "4", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58fafe87-9b10-476f-b90d-da582f136cf9", "node_type": "1", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "29078e5db1b80d73bb075f94d9cbd684df93d6224c8637a3cca736fe9aab1e0f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33b69ca2-e895-42c3-8975-d30b09f71255", "node_type": "1", "metadata": {}, "hash": "0bf27ee717b49da77c18bd779f1b51a1c632e6d5a0a8e3e6bc515dfac9a39580", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This allows larger models to fit into smaller memory spaces without degrading performance. This method definitely has a high potential for accuracy, but I decided not to use it as I am concerned about compatibility and reliability issues as it is a new tool and the GitHub repo has been developed by a single person, so support for it is likely to be limited. Additionally, my M1 chip only has 8 GB of memory shared between the CPU and GPU, which is excellent for reducing data loading overhead costs, but it means that larger models that require AirLLM will be loaded directly from the SSD, so I am concerned that the model layer loading and unloading will become a massive bottleneck when doing inference on larger models. I will reconsider this option if I find that the models that can run on my MacBook do not have satisfactory accuracy.\n\nWhat Models Even Run on My MacBook?\n\nAfter getting an idea of what kinds of optimisation techniques were available, I decided to conduct some tests to find out what LLMs would actually run on my MacBook. You could argue that since I am only building a prototype right now, I only need to find one LLM that performs well on my MacBook, but I decided to find five models instead to give me an idea of what kinds of models I will be able to use. In particular, I wanted to know how big the models I could run were and what precision the weights would likely be.\n\nI tested models that I had heard were good or showed decent results on the Hugging Face H4 Open LLM Leaderboard. I found LM Studio incredibly useful for testing out LLMs without having to write any code, which saved me a lot of time. Below are the five suitable models that I found that could run on my MacBook and were fast enough to satisfy me:\n\ntinyllama-1.1b-chat-v1.0 Q6_K\nPhi 3 Q4_K_M\nbartowski/dolphin-2.8-experiment26-7b-GGUF Q3_K_L\nmgonzs13/Mistroll-7B-v2.2-GGU\nQuantFactory/Meta-Llama-3-8B-Instruct Q3_K_M\nThese models range from 1.17 GB up to 4.02 GB in size. I chose not to use any models that were any larger than 4 GB, as with only 8 GB of memory available, I expect that models that are any bigger would seriously impact the other applications that the user (i.e., me) is running on their device.\n\nI will likely test out more models than this while testing out different configurations for the tool, but for the prototype, this is enough.\n\nA Model Without a Framework is Like a Car Engine Without a Chassis\n\nTo run my models, I could have written a framework for loading, unloading, and executing the models, passing context and queries to the models, and integrating the vector DB (more on that later) with the inference model from scratch, but I didn\u2019t because I\u2019m not insane and I am not trying to learn how to make ML frameworks. A lot of university students (myself included) are conditioned to try to build things from scratch for fear of plagiarism and because they are used to building things from scratch as a learning exercise (a very effective one in my opinion), so it\u2019s difficult to unlearn the DIY mindset, but it\u2019s simply a lot quicker and a lot more reliable to use libraries than to reinvent the wheel. Saying that, I decided to use a relatively simple tech stack.\n\nPython was an obvious choice for me, given that I have a lot of experience with it and that it has an abundance of support for machine learning applications. I decided to use LangChain to orchestrate my RAG process from the vector DB to the inference, as it is a flexible tool for composing NLP pipelines. It is very popular and reliable, and it includes a lot of tools that make developing NLP applications easier. I considered using LlamaIndex as it is built more specifically for RAG applications, but LangChain is more general-purpose, which I expect will make it more extensible for times when I might want to add more features in the future. Additionally, I am more likely to use LangChain again for other applications in the future, so the experience will be more useful. I also considered using LitGPT, but I had some issues getting it to work with the M1 chip\u2019s Metal Performance Shaders (MPS), so I decided not to use it for fear of incompatibility. LitGPT is also intended more for training and fine-tuning LLMs, so it is likely not the best tool for simply deploying them in an application.", "mimetype": "text/plain", "start_char_idx": 11349, "end_char_idx": 15653, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "33b69ca2-e895-42c3-8975-d30b09f71255": {"__data__": {"id_": "33b69ca2-e895-42c3-8975-d30b09f71255", "embedding": null, "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2", "node_type": "4", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cf5202bc-1f43-4259-af24-6c692cae7096", "node_type": "1", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "fd307107686322b5e647acdf38c5598f962a7fae2d9ed502ad8b22584c9e7f22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ce920e51-04a2-4e9f-a92f-279df00a9f65", "node_type": "1", "metadata": {}, "hash": "6936c250e5ee30bd09d36f25901ca88a4b8642eb1f514c3969d00553db4fa844", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is very popular and reliable, and it includes a lot of tools that make developing NLP applications easier. I considered using LlamaIndex as it is built more specifically for RAG applications, but LangChain is more general-purpose, which I expect will make it more extensible for times when I might want to add more features in the future. Additionally, I am more likely to use LangChain again for other applications in the future, so the experience will be more useful. I also considered using LitGPT, but I had some issues getting it to work with the M1 chip\u2019s Metal Performance Shaders (MPS), so I decided not to use it for fear of incompatibility. LitGPT is also intended more for training and fine-tuning LLMs, so it is likely not the best tool for simply deploying them in an application.\n\nTo run inference on my models, I will need another library to actually execute the model. As I am using a range of pre-trained models, I will mainly use HuggingFace\u2019s transformers library and the Python bindings for llama.cpp library to load and execute models, as these provide simple interfaces for inference, and I don\u2019t need the additional control that deep learning frameworks like TensorFlow, PyTorch, and JAX provide as I\u2019m using pre-trained models. As I mentioned earlier, AirLLM is still on the table if I need better performance, but I will find out while evaluating models whether this is necessary.\n\nMagnitude + Direction DBs\n\nSince I was using RAG, I needed a vector DB. Deciding which one to use was the final step of the research and also the most difficult one, as vector DBs are the technology that I am least familiar with. For the vector DB, my main requirements were simple: it needed to be lightweight, locally runnable on a laptop, fast, and compatible with my MacBook. Lightweight and locally runnable sound like similar things, but I mean different things by each phrase. The locally runnable one is quite self-explanatory, but by lightweight, I mean quite minimal computation requirements that don\u2019t add features like heavy amounts of redundancy and heavy caching, which are useful for large-scale systems, but will simply drain resources in my application that is designed to run alongside an LLM and the user\u2019s other applications on 8 GB of memory shared between the CPU and GPU.\n\nI considered sixteen different vector DBs, but there were three different solutions that stood out to me for my use case: Chroma, Qdrant, and Vespa. These were all lightweight vector DBs that fit all of my requirements, but I decided to pick Chroma out of the three of them because it has a very batteries included approach, which is very useful for getting an application working quickly.\n\nBelow is an overview of my planned tech stack. I did not include any UI, as there are many options for this, and I plan to decide on the UI when building the final product.\n\nThe tech stack and data flow that I plan to use for STICI-note.\nThe tech stack and data flow that I plan to use for STICI-note.\n\nMaking the Prototype (A.K.A. the Easy Part)\n\nThe final step was to actually build the prototype/proof of concept (PoC) to find out whether this idea can actually be implemented using the tech stack that I have picked. I decided to implement it using the smallest of the 5 models that I had found earlier, tinyllama-1.1b-chat-v1.0 Q6_K, to minimise the chances of having any memory issues.\n\nYou can find my prototype code here.\n\nFor the prototype, I decided to make very basic configurations for everything to develop it quickly, and I tested it by asking a question about Grace Hopper, one of the most influential programmers to have ever lived, in two versions of the prototype: one with Grace Hopper\u2019s Wikipedia page in its vector DB and one with Alan Turing\u2019s Wikipedia page in its vector DB.\n\nThe question was:\n\n\u201cWhat programming language was Grace Hopper known for creating?\u201d\n\nAs expected, the version with Alan Turing\u2019s Wikipedia page failed miserably, hallucinating its entire response:\n\nGrace Hopper was a computer scientist who is best known for her work on developing an early version of BASIC, which was one of the first low-level programming languages designed for mainframe computers. Hopper worked at Digital Equipment Corporation (DEC) in the mid-1960s and was responsible for creating several key BASIC versions that were used by DEC's mainframe computers. In 1973, she left DEC to work on a new low-level programming language called PASCAL, which became one of the most popular programming languages of its time.", "mimetype": "text/plain", "start_char_idx": 14857, "end_char_idx": 19386, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ce920e51-04a2-4e9f-a92f-279df00a9f65": {"__data__": {"id_": "ce920e51-04a2-4e9f-a92f-279df00a9f65", "embedding": null, "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2", "node_type": "4", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "60ef0721c9077dd29cf3318d41beb2a887defb8d5ca3269b115aa83d385d3231", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33b69ca2-e895-42c3-8975-d30b09f71255", "node_type": "1", "metadata": {"source_url": "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping", "document_index": 2}, "hash": "5ab14f3d0bf68ba75091619582a3913be6ec297dd20b4dcbf993f697390a981e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The question was:\n\n\u201cWhat programming language was Grace Hopper known for creating?\u201d\n\nAs expected, the version with Alan Turing\u2019s Wikipedia page failed miserably, hallucinating its entire response:\n\nGrace Hopper was a computer scientist who is best known for her work on developing an early version of BASIC, which was one of the first low-level programming languages designed for mainframe computers. Hopper worked at Digital Equipment Corporation (DEC) in the mid-1960s and was responsible for creating several key BASIC versions that were used by DEC's mainframe computers. In 1973, she left DEC to work on a new low-level programming language called PASCAL, which became one of the most popular programming languages of its time. However, her contributions to BASIC are still remembered today as it was one of the first widely used and easy-to-understand programming languages for mainframe computers.\n\nThis behaviour of hallucinating will need to be fixed in the final product, likely through prompt engineering.\n\nAs expected, the version with Grace Hopper\u2019s Wikipedia page gave a much more accurate response but it unexpectedly contained far more spelling errors:\n\nGrace Hopper is credited with creating the first computer programming languaige called FLOW-MATIC. This language was developed in 1954 and was based on English words. Hopper's work on this languaige led to a machine-indepenent programming language, COBOL, which used English words instead of symbols for input and output. Her compiler, A-0, also utilized the FLOW-MATIIC language as its basis for compiling programs into executable code. In 1952, Hopper published her first paper on the topic of compiler design, \"The Compiler\" in the IEEE Transactions on Computers, in which she discussed her work with A-0 and other programming languaiges.\n\nUnfortunately, this response was not free from hallucinations either. Hopper\u2019s A-0 compiler did not use the FLOW-MATIC programming language, and she never published a paper called \u201cThe Compiler\u201d in IEEE Transactions on Computers (a real journal that is not mentioned in the Wikipedia page). It looks like hallucinations are likely to be a major issue for this tool, but that is a problem I will solve when refining the AI.\n\nOn the bright side, inference was ~120 tokens/second, so at least this model will output words much faster than I can read them.\n\nConclusion\n\nIn this blog, I built a locally run prototype for my chatbot for querying unstructured text documents. It doesn\u2019t have a UI, and it hallucinates a lot, but it is nonetheless capable of querying unstructured text.\n\nIt\u2019s such a shame that after I had done the research and written all of the code, while I was writing this blog, I read about llmware, a very promising Python framework for building RAG pipelines with small models (sound familiar?). It was even chosen for GitHub Accelerator 2024, a competition for open-source projects on GitHub where chosen projects are given funding, mentorship, and access to resources to help them grow their project. Since I had already built the prototype in LangChain, it didn\u2019t make much sense to tear it down and rebuild it in a fancy new framework that wasn\u2019t as tried-and-tested. I\u2019d love to try the framework out one day if I build another RAG application after this one.\n\nIn the next part of the STICI-note blog series, I will be building an evaluation suite to test and compare different inference models and vector DB configurations, so stay tuned and follow me on LinkedIn to be notified when it comes out!", "mimetype": "text/plain", "start_char_idx": 18654, "end_char_idx": 22187, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "76752c6f-969a-4e68-ac0d-727170129f06": {"__data__": {"id_": "76752c6f-969a-4e68-ac0d-727170129f06", "embedding": null, "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3", "node_type": "4", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2d4f5695-7525-4793-b8bd-eb32a0058779", "node_type": "1", "metadata": {}, "hash": "1c2850f8c3d5369e7df9b4c56c1229c8ff4cf75914b34d9a6cdaad6080df2a79", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "llmware\n\nBuilding Enterprise RAG Pipelines with Small, Specialized Models\nllmware provides a unified framework for building LLM-based applications (e.g, RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.\n\nllmware has two main components:\n\nRAG Pipeline - integrated components for the full lifecycle of connecting knowledge sources to generative AI models; and\n\n50+ small, specialized models fine-tuned for key tasks in enterprise process automation, including fact-based question-answering, classification, summarization, and extraction.\n\nBy bringing together both of these components, along with integrating leading open source models and underlying technologies, llmware offers a comprehensive set of tools to rapidly build knowledge-based enterprise LLM applications.\n\nMost of our examples can be run without a GPU server - get started right away on your laptop.\n\nJoin us on Discord | Watch Youtube Tutorials | Explore our Model Families on Huggingface\n\nNew to RAG? Check out the Fast Start video series\n\nMulti-Model Agents with SLIM Models - Intro-Video\n\nIntro to SLIM Function Call Models\nCan't wait? Get SLIMs right away:\n\nfrom llmware.models import ModelCatalog\n\nModelCatalog().get_llm_toolkit()  # get all SLIM models, delivered as small, fast quantized tools\nModelCatalog().tool_test_run(\"slim-sentiment-tool\") # see the model in action with test script included\nKey features\nWriting code withllmware is based on a few main concepts:\n\nModel Catalog: Access all models the same way with easy lookup, regardless of underlying implementation.\nLibrary: ingest, organize and index a collection of knowledge at scale - Parse, Text Chunk and Embed.\nQuery: query libraries with mix of text, semantic, hybrid, metadata, and custom filters.\nPrompt with Sources: the easiest way to combine knowledge retrieval with a LLM inference.\nRAG-Optimized Models - 1-7B parameter models designed for RAG workflow integration and running locally.\nSimple-to-Scale Database Options - integrated data stores from laptop to parallelized cluster.\nAgents with Function Calls and SLIM Models\nStart coding - Quick Start for RAG\nWhat's New?\n-Best New Small RAG Model - BLING finetune of Phi-3 - \"bling-phi-3-gguf\" - see the video\n\n-Web Services with Agent Calls for Financial Research - end-to-end scenario - video and example\n\n-Voice Transcription with WhisperCPP - getting_started, using_sample_files, and analysis_use_case with great_speeches_video\n\n-Phi-3 GGUF Streaming Local Chatbot with UI - setup your own Phi-3-gguf chatbot on your laptop in minutes - example with video\n\n-Small, specialized, function-calling Extract Model - introducing slim-extract - video and example\n\n-LLM to Answer Yes/No questions - introducing slim-boolean model - video and example\n\n-Natural Language Query to CSV End to End example - using slim-sql model - video and example and now using Custom Tables on Postgres example\n\n-Multi-Model Agents with SLIM models - multi-step Agents with SLIMs on CPU - video - example\n\n-OCR Embedded Document Images Example - systematically extract text from images embedded in documents example\n\n-Enhanced Parser Functions for PDF, Word, Powerpoint and Excel - new text-chunking controls and strategies, extract tables, images, header text - example\n\n-Agent Inference Server - set up multi-model Agents over Inference Server example\n\n-GGUF - Getting Started - check out examples - GGUF (example) and Videos video\n\n-Optimizing Accuracy of RAG Prompts - check out example and videos - part I and part II\n\nGetting Started\nStep 1 - Install llmware - pip3 install llmware or pip3 install 'llmware[full]'\n\nnote: starting with v0.3.0, we provide options for a core install (minimal set of dependencies) or full install (adds to the core with wider set of related python libraries).\nStep 2- Go to Examples - Get Started Fast with 100+ 'Cut-and-Paste' Recipes\nStep 3 - Tutorial Videos - check out our Youtube channel for high-impact 5-10 minute tutorials on the latest examples.\n\u270dWorking with the llmware Github repository\nThe llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.\n\ngit clone git@github.com:llmware-ai/llmware.git\nWe have provided a welcome_to_llmware automation script in the root of the repository folder.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4449, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2d4f5695-7525-4793-b8bd-eb32a0058779": {"__data__": {"id_": "2d4f5695-7525-4793-b8bd-eb32a0058779", "embedding": null, "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3", "node_type": "4", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "76752c6f-969a-4e68-ac0d-727170129f06", "node_type": "1", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "5ba587099876460430030fe8e3f5ed391f0a7373dd696ca9fa4e09d608e107df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cdc69adb-f6bf-4296-9caf-28ebf5a0671d", "node_type": "1", "metadata": {}, "hash": "501826bfc90cad1119beeafc3725c61933443cf64fbf677c8f45ac0015ad8bea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Step 2- Go to Examples - Get Started Fast with 100+ 'Cut-and-Paste' Recipes\nStep 3 - Tutorial Videos - check out our Youtube channel for high-impact 5-10 minute tutorials on the latest examples.\n\u270dWorking with the llmware Github repository\nThe llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.\n\ngit clone git@github.com:llmware-ai/llmware.git\nWe have provided a welcome_to_llmware automation script in the root of the repository folder. After cloning:\n\nOn Windows command line: .\\welcome_to_llmware_windows.sh\nOn Mac / Linux command line: sh ./welcome_to_llmware.sh\nAlternatively, if you prefer to complete setup without the welcome automation script, then the next steps include:\n\ninstall requirements.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements.txt\n\ninstall requirements_extras.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements_extras.txt (Depending upon your use case, you may not need all or any of these installs, but some of these will be used in the examples.)\n\nrun examples - copy one or more of the example .py files into the root project path. (We have seen several IDEs that will attempt to run interactively from the nested /example path, and then not have access to the /llmware module - the easy fix is to just copy the example you want to run into the root path).\n\ninstall vector db - no-install vector db options include milvus lite, chromadb, faiss and lancedb - which do not require a server install, but do require that you install the python sdk library for that vector db, e.g., pip3 install pymilvus, or pip3 install chromadb. If you look in examples/Embedding, you will see examples for getting started with various vector DB, and in the root of the repo, you will see easy-to-get-started docker compose scripts for installing milvus, postgres/pgvector, mongo, qdrant, neo4j, and redis.\n\nNote: we have seen recently issues with Pytorch==2.3 on some platforms - if you run into any issues, we have seen that uninstalling Pytorch and downleveling to Pytorch==2.1 usually solves the problem.\n\nData Store Options\nFast Start: use SQLite3 and ChromaDB (File-based) out-of-the-box - no install required\nSpeed + Scale: use MongoDB (text collection) and Milvus (vector db) - install with Docker Compose\nPostgres: use Postgres for both text collection and vector DB - install with Docker Compose\nMix-and-Match: LLMWare supports 3 text collection databases (Mongo, Postgres, SQLite) and 10 vector databases (Milvus, PGVector-Postgres, Neo4j, Redis, Mongo-Atlas, Qdrant, Faiss, LanceDB, ChromaDB and Pinecone)\nMeet our Models\nSLIM model series: small, specialized models fine-tuned for function calling and multi-step, multi-model Agent workflows.\nDRAGON model series: Production-grade RAG-optimized 6-7B parameter models - \"Delivering RAG on ...\" the leading foundation base models.\nBLING model series: Small CPU-based RAG-optimized, instruct-following 1B-3B parameter models.\nIndustry BERT models: out-of-the-box custom trained sentence transformer embedding models fine-tuned for the following industries: Insurance, Contracts, Asset Management, SEC.\nGGUF Quantization: we provide 'gguf' and 'tool' versions of many SLIM, DRAGON and BLING models, optimized for CPU deployment.\nUsing LLMs and setting-up API keys & secrets\nLLMWare is an open platform and supports a wide range of open source and proprietary models. To use LLMWare, you do not need to use any proprietary LLM - we would encourage you to experiment with SLIM, BLING, DRAGON, Industry-BERT, the GGUF examples, along with bringing in your favorite models from HuggingFace and Sentence Transformers.\n\nIf you would like to use a proprietary model, you will need to provide your own API Keys. API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or passed directly to method calls.\n\nRoadmap - Where are we going ...\nInterested in contributing to llmware? Information on ways to participate can be found in our Contributors Guide. As with all aspects of this project, contributing is governed by our Code of Conduct.", "mimetype": "text/plain", "start_char_idx": 3929, "end_char_idx": 8104, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cdc69adb-f6bf-4296-9caf-28ebf5a0671d": {"__data__": {"id_": "cdc69adb-f6bf-4296-9caf-28ebf5a0671d", "embedding": null, "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3", "node_type": "4", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2d4f5695-7525-4793-b8bd-eb32a0058779", "node_type": "1", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "ddcf6d2f1e1f6fd391b234e1504d588752b664a624c78d8ca30dd1a19de2b558", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10af9110-0132-4d14-b20a-eecc18f55933", "node_type": "1", "metadata": {}, "hash": "f601c356dbae176ffcc1cb782e144c2ab221eb5b0b69c89b29a11521755bffd2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Using LLMs and setting-up API keys & secrets\nLLMWare is an open platform and supports a wide range of open source and proprietary models. To use LLMWare, you do not need to use any proprietary LLM - we would encourage you to experiment with SLIM, BLING, DRAGON, Industry-BERT, the GGUF examples, along with bringing in your favorite models from HuggingFace and Sentence Transformers.\n\nIf you would like to use a proprietary model, you will need to provide your own API Keys. API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or passed directly to method calls.\n\nRoadmap - Where are we going ...\nInterested in contributing to llmware? Information on ways to participate can be found in our Contributors Guide. As with all aspects of this project, contributing is governed by our Code of Conduct.\n\nQuestions and discussions are welcome in our github discussions.\n\nRelease notes and Change Log\nSee also additional deployment/install release notes in wheel_archives\n\nThursday, June 6 - v0.3.1-WIP\n\nAdded module 3 to Fast Start example series examples 7-9 on Agents & Function Calls\nAdded reranker Jina model for in-memory semantic similarity RAG - see example\nChanges merged into main branch - expected next pypi release at end of week\nTuesday, June 4 - v0.3.0\n\nAdded support for new Milvus Lite embedded 'no-install' database - see example.\nAdded two new SLIM models to catalog and agent processes - 'q-gen' and 'qa-gen'\nUpdated model class instantiation to provide more extensibility to add new classes in different modules\nNew welcome_to_llmware.sh and welcome_to_llmware_windows.sh fast install scripts\nEnhanced Model class base with new configurable post_init and register methods\nCreated InferenceHistory to track global state of all inferences completed\nMultiple improvements and updates to logging at module level\nNote: starting with v0.3.0, pip install provides two options - a base minimal install pip3 install llmware which will support most use cases, and a larger install pip3 install 'llmware[full]' with other commonly-used libraries.\nWednesday, May 22 - v0.2.15\n\nImprovements in Model class handling of Pytorch and Transformers dependencies (just-in-time loading, if needed)\nExpanding API endpoint options and inference server functionality - see new client access options and server_launch\nSaturday, May 18 - v0.2.14\n\nNew OCR image parsing methods with example\nAdding first part of logging improvements (WIP) in Configs and Models.\nNew embedding model added to catalog - industry-bert-loans.\nUpdates to model import methods and configurations.\nSunday, May 12 - v0.2.13\n\nNew GGUF streaming method with basic example and phi3 local chatbot\nSignificant cleanups in ancillary imports and dependencies to reduce install complexity - note: the updated requirements.txt and setup.py files.\nDefensive code to provide informative warning of any missing dependencies in specialized parts of the code, e.g., OCR, Web Parser.\nUpdates of tests, notice and documentation.\nOpenAIConfigs created to support Azure OpenAI.\nSunday, May 5 - v0.2.12 Update\n\nLaunched \"bling-phi-3\" and \"bling-phi-3-gguf\" in ModelCatalog - newest and most accurate BLING/DRAGON model\nNew long document summarization method using slim-summary-tool example\nNew Office (Powerpoint, Word, Excel) sample files example\nAdded support for Python 3.12\nDeprecated faiss and replaced with 'no-install' chromadb in Fast Start examples\nRefactored Datasets, Graph and Web Services classes\nUpdated Voice parsing with WhisperCPP into Library\nMonday, April 29 - v0.2.11 Update\n\nUpdates to gguf libs for Phi-3 and Llama-3\nAdded Phi-3 example and Llama-3 example and Quantized Versions to Model Catalog\nIntegrated WhisperCPP Model class and prebuilt shared libraries - getting-started-example\nNew voice sample files for testing - example\nImproved CUDA detection on Windows and safety checks for older Mac OS versions\nMonday, April 22 - v0.2.10 Update\n\nUpdates to Agent class to support Natural Language queries of Custom Tables on Postgres example\nNew Agent API endpoint implemented with LLMWare Inference Server and new Agent capabilities example\nTuesday, April 16 - v0.2.9 Update\n\nNew CustomTable class to rapidly create custom DB tables in conjunction with LLM-based workflows.\nEnhanced methods for converting CSV and JSON/JSONL files into DB tables.", "mimetype": "text/plain", "start_char_idx": 7262, "end_char_idx": 11618, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10af9110-0132-4d14-b20a-eecc18f55933": {"__data__": {"id_": "10af9110-0132-4d14-b20a-eecc18f55933", "embedding": null, "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3", "node_type": "4", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cdc69adb-f6bf-4296-9caf-28ebf5a0671d", "node_type": "1", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "373a406c872f84d6a961c64cbb5a2bcd758f406fd0c88ca4da5e78a3bd3d00da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "88574f1c-afdd-49b8-a062-451e3ebff0ea", "node_type": "1", "metadata": {}, "hash": "614841e9488f4f57fd069644b4a021d3abc673f8ac1ee80bd271129ee88ce7d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Enhanced methods for converting CSV and JSON/JSONL files into DB tables.\nSee new examples Creating Custom Table example\nTuesday, April 9 - v0.2.8 Update\n\nOffice Parser (Word Docx, Powerpoint PPTX, and Excel XLSX) - multiple improvements - new libs + Python method.\nIncludes: several fixes, improved text chunking controls, header text extraction and configuration options.\nGenerally, new office parser options conform with the new PDF parser options.\nPlease see Office Parsing Configs example\nWednesday, April 3 - v0.2.7 Update\n\nPDF Parser - multiple improvements - new libs + Python methods.\nIncludes: UTF-8 encoding for European languages.\nIncludes: Better text chunking controls, header text extraction and configuration options.\nPlease see PDF Parsing Configs example for more details.\nNote: deprecating support for aarch64-linux (will use 0.2.6 parsers). Full support going forward for Linux Ubuntu20+ on x86_64 + with CUDA.\nFriday, March 22 - v0.2.6 Update\n\nNew SLIM models: summary, extract, xsum, boolean, tags-3b, and combo sentiment-ner.\nNew logit and sampling analytics.\nNew SLIM examples showing how to use the new models.\nThursday, March 14 - v0.2.5 Update\n\nImproved support for GGUF on CUDA (Windows and Linux), with new prebuilt binaries and exception handling.\nEnhanced model configuration options (sampling, temperature, top logit capture).\nAdded full back-level support for Ubuntu 20+ with parsers and GGUF engine.\nSupport for new Anthropic Claude 3 models.\nNew retrieval methods: document_lookup and aggregate_text.\nNew model: bling-stablelm-3b-tool - fast, accurate 3b quantized question-answering model - one of our new favorites.\nWednesday, February 28 - v0.2.4 Update\n\nMajor upgrade of GGUF Generative Model class - support for Stable-LM-3B, CUDA build options, and better control over sampling strategies.\nNote: new GGUF llama.cpp built libs packaged with build starting in v0.2.4.\nImproved GPU support for HF Embedding Models.\nFriday, February 16 - v0.2.3 Update\n\nAdded 10+ embedding models to ModelCatalog - nomic, jina, bge, gte, ember and uae-large.\nUpdated OpenAI support >=1.0 and new text-3 embedding models.\nSLIM model keys and output_values now accessible in ModelCatalog.\nUpdating encodings to 'utf-8-sig' to better handle txt/csv files with bom.\nSupported Operating Systems: MacOS (Metal and x86), Linux (x86 and aarch64), Windows\n\nnote on Linux: we test most extensively on Ubuntu 22 and now Ubuntu 20 and recommend where possible\nif you need another Linux version, please raise an issue - we will prioritize testing and ensure support.\nSupported Vector Databases: Milvus, Postgres (PGVector), Neo4j, Redis, LanceDB, ChromaDB, Qdrant, FAISS, Pinecone, Mongo Atlas Vector Search\n\nSupported Text Index Databases: MongoDB, Postgres, SQLite\n\nOptional\nDocker\n\nTo enable the OCR parsing capabilities, install Tesseract v5.3.3 and Poppler v23.10.0 native packages.", "mimetype": "text/plain", "start_char_idx": 11546, "end_char_idx": 14439, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "88574f1c-afdd-49b8-a062-451e3ebff0ea": {"__data__": {"id_": "88574f1c-afdd-49b8-a062-451e3ebff0ea", "embedding": null, "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3", "node_type": "4", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10af9110-0132-4d14-b20a-eecc18f55933", "node_type": "1", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "d975e413da3d49cbf3290f4da4e99df43a8ac6c9f536b5c77c5b2be41ec38858", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e9b4b14-b6a1-4140-9a02-9561ce8a8853", "node_type": "1", "metadata": {}, "hash": "a59b2b954b3c43f994f27c2a732489e31a793e80520e146ccdd311f15caeba72", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SLIM model keys and output_values now accessible in ModelCatalog.\nUpdating encodings to 'utf-8-sig' to better handle txt/csv files with bom.\nSupported Operating Systems: MacOS (Metal and x86), Linux (x86 and aarch64), Windows\n\nnote on Linux: we test most extensively on Ubuntu 22 and now Ubuntu 20 and recommend where possible\nif you need another Linux version, please raise an issue - we will prioritize testing and ensure support.\nSupported Vector Databases: Milvus, Postgres (PGVector), Neo4j, Redis, LanceDB, ChromaDB, Qdrant, FAISS, Pinecone, Mongo Atlas Vector Search\n\nSupported Text Index Databases: MongoDB, Postgres, SQLite\n\nOptional\nDocker\n\nTo enable the OCR parsing capabilities, install Tesseract v5.3.3 and Poppler v23.10.0 native packages.\n\nChange Log\nLatest Updates - 19 Jan 2024 - llmware v0.2.0\n\nAdded new database integration options - Postgres and SQlite\nImproved status update and parser event logging options for parallelized parsing\nSignificant enhancements to interactions between Embedding + Text collection databases\nImproved error exception handling in loading dynamic modules\nLatest Updates - 15 Jan 2024: llmware v0.1.15\n\nEnhancements to dual pass retrieval queries\nExpanded configuration objects and options for endpoint resources\nLatest Updates - 30 Dec 2023: llmware v0.1.14\n\nAdded support for Open Chat inference servers (compatible with OpenAI API)\nImproved capabilities for multiple embedding models and vector DB configurations\nAdded docker-compose install scripts for PGVector and Redis vector databases\nAdded 'bling-tiny-llama' to model catalog\nLatest Updates - 22 Dec 2023: llmware v0.1.13\n\nAdded 3 new vector databases - Postgres (PG Vector), Redis, and Qdrant\n\nImproved support for integrating sentence transformers directly in the model catalog\n\nImprovements in the model catalog attributes\n\nMultiple new Examples in Models & Embeddings, including GGUF, Vector database, and model catalog\n\n17 Dec 2023: llmware v0.1.12\n\ndragon-deci-7b added to catalog - RAG-finetuned model on high-performance new 7B model base from Deci\nNew GGUFGenerativeModel class for easy integration of GGUF Models\nAdding prebuilt llama_cpp / ctransformer shared libraries for Mac M1, Mac x86, Linux x86 and Windows\n3 DRAGON models packaged as Q4_K_M GGUF models for CPU laptop use (dragon-mistral-7b, dragon-llama-7b, dragon-yi-6b)\n4 leading open source chat models added to default catalog with Q4_K_M\n8 Dec 2023: llmware v0.1.11\n\nNew fast start examples for high volume Document Ingestion and Embeddings with Milvus.\nNew LLMWare 'Pop up' Inference Server model class and example script.\nNew Invoice Processing example for RAG.\nImproved Windows stack management to support parsing larger documents.\nEnhancing debugging log output mode options for PDF and Office parsers.\n30 Nov 2023: llmware v0.1.10\n\nWindows added as a supported operating system.\nFurther enhancements to native code for stack management.\nMinor defect fixes.\n24 Nov 2023: llmware v0.1.9\n\nMarkdown (.md) files are now parsed and treated as text files.\nPDF and Office parser stack optimizations which should avoid the need to set ulimit -s.\nNew llmware_models_fast_start.py example that allows discovery and selection of all llmware HuggingFace models.\nNative dependencies (shared libraries and dependencies) now included in repo to faciliate local development.\nUpdates to the Status class to support PDF and Office document parsing status updates.\nMinor defect fixes including image block handling in library exports.\n17 Nov 2023: llmware v0.1.8\n\nEnhanced generation performance by allowing each model to specific the trailing space parameter.\nImproved handling for eos_token_id for llama2 and mistral.\nImproved support for Hugging Face dynamic loading\nNew examples with the new llmware DRAGON models.\n14 Nov 2023: llmware v0.1.7\n\nMoved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.\nModelCatalog enhancements:\nOpenAI update to include newly announced \u2018turbo\u2019 4 and 3.5 models.\nCohere embedding v3 update to include new Cohere embedding models.\nBLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the \u201chf=True\u201d flag.", "mimetype": "text/plain", "start_char_idx": 13686, "end_char_idx": 17948, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e9b4b14-b6a1-4140-9a02-9561ce8a8853": {"__data__": {"id_": "5e9b4b14-b6a1-4140-9a02-9561ce8a8853", "embedding": null, "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3", "node_type": "4", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "220abde7fff083bd72929245fc8355c08241e46a6ea3a46a45d70ab210c018d9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "88574f1c-afdd-49b8-a062-451e3ebff0ea", "node_type": "1", "metadata": {"source_url": "https://github.com/llmware-ai/llmware", "document_index": 3}, "hash": "3cc9164c51c3d3d4147affad43a44ec3c305bdecb65bb1f3f50ad9adb32b5c05", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Minor defect fixes including image block handling in library exports.\n17 Nov 2023: llmware v0.1.8\n\nEnhanced generation performance by allowing each model to specific the trailing space parameter.\nImproved handling for eos_token_id for llama2 and mistral.\nImproved support for Hugging Face dynamic loading\nNew examples with the new llmware DRAGON models.\n14 Nov 2023: llmware v0.1.7\n\nMoved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.\nModelCatalog enhancements:\nOpenAI update to include newly announced \u2018turbo\u2019 4 and 3.5 models.\nCohere embedding v3 update to include new Cohere embedding models.\nBLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the \u201chf=True\u201d flag.\nAbility to register new model names, within existing model classes, with the register method in ModelCatalog.\nPrompt enhancements:\n\u201cevidence_metadata\u201d added to prompt_main output dictionaries allowing prompt_main responses to be plug into the evidence and fact-checking steps without modification.\nAPI key can now be passed directly in a prompt.load_model(model_name, api_key = \u201c[my-api-key]\u201d)\nLLMWareInference Server - Initial delivery:\nNew Class for LLMWareModel which is a wrapper on a custom HF-style API-based model.\nLLMWareInferenceServer is a new class that can be instantiated on a remote (GPU) server to create a testing API-server that can be integrated into any Prompt workflow.\n03 Nov 2023: llmware v0.1.6\n\nUpdated packaging to require mongo-c-driver 1.24.4 to temporarily workaround segmentation fault with mongo-c-driver 1.25.\nUpdates in python code needed in anticipation of future Windows support.\n27 Oct 2023: llmware v0.1.5\n\nFour new example scripts focused on RAG workflows with small, fine-tuned instruct models that run on a laptop (llmware BLING models).\nExpanded options for setting temperature inside a prompt class.\nImprovement in post processing of Hugging Face model generation.\nStreamlined loading of Hugging Face generative models into prompts.\nInitial delivery of a central status class: read/write of embedding status with a consistent interface for callers.\nEnhanced in-memory dictionary search support for multi-key queries.\nRemoved trailing space in human-bot wrapping to improve generation quality in some fine-tuned models.\nMinor defect fixes, updated test scripts, and version update for Werkzeug to address dependency security alert.\n20 Oct 2023: llmware v0.1.4\n\nGPU support for Hugging Face models.\nDefect fixes and additional test scripts.\n13 Oct 2023: llmware v0.1.3\n\nMongoDB Atlas Vector Search support.\nSupport for authentication using a MongoDB connection string.\nDocument summarization methods.\nImprovements in capturing the model context window automatically and passing changes in the expected output length.\nDataset card and description with lookup by name.\nProcessing time added to model inference usage dictionary.\nAdditional test scripts, examples, and defect fixes.\n06 Oct 2023: llmware v0.1.1\n\nAdded test scripts to the github repository for regression testing.\nMinor defect fixes and version update of Pillow to address dependency security alert.\n02 Oct 2023: llmware v0.1.0 Initial release of llmware to open source!!", "mimetype": "text/plain", "start_char_idx": 17116, "end_char_idx": 20421, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "765f4bc9-fc87-4ec0-bace-ca663b60e518": {"__data__": {"id_": "765f4bc9-fc87-4ec0-bace-ca663b60e518", "embedding": null, "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4", "node_type": "4", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "f63b62abf1e588cb2fc85a74aa835d79678cf41541ba457e5780cf5cef3c87df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef505541-3953-48e6-8253-7beb582f3040", "node_type": "1", "metadata": {}, "hash": "bb05e6bf458ac4aff5e502f453b50b12b8d7ce10076ba74cd51091e7d03dc3e3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recipes\nThis page includes code snippets or \u201crecipes\u201d for a variety of common tasks. Use them as building blocks or examples when making your own notebooks.\n\nIn these recipes, each code block represents a cell.\n\nControl Flow\nShow an output conditionally\nUse cases. Hide an output until a condition is met (e.g., until algorithm parameters are valid), or show different outputs depending on the value of a UI element or some other Python object\n\nRecipe.\n\nUse an if expression to choose which output to show.\n\n# condition is a boolean, True of False\ncondition = True\n\"condition is True\" if condition else None\nRun a cell on a timer\nUse cases.\n\nLoad new data periodically, and show updated plots or other outputs. For example, in a dashboard monitoring a training run, experiment trial, real-time weather data, \u2026\n\nRun a job periodically\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a mo.ui.refresh timer that fires once a second:\n\nrefresh = mo.ui.refresh(default_interval=\"1s\")\n# This outputs a timer that fires once a second\nrefresh\nReference the timer by name to make this cell run once a second\n\nimport random\n\n# This cell will run once a second!\nrefresh\n\nmo.md(\"#\" + \"\" * random.randint(1, 10))\nRequire form submission before sending UI value\nUse cases. UI elements automatically send their values to the Python when they are interacted with, and run all cells referencing the elements. This makes marimo notebooks responsive, but it can be an issue when the downstream cells are expensive, or when the input (such as a text box) needs to be filled out completely before it is considered valid. Forms let you gate submission of UI element values on manual confirmation, via a button press.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a submittable form.\n\nform = mo.ui.text(label=\"Your name\").form()\nform\nGet the value of the form.\n\nform.value\nStop execution of a cell and its descendants\nUse cases. For example, don\u2019t run a cell or its descendants if a form is unsubmitted.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a submittable form.\n\nform = mo.ui.text(label=\"Your name\").form()\nform\nUse mo.stop to stop execution when the form is unsubmitted.\n\nmo.stop(form.value is None, mo.md(\"Submit the form to continue\"))\n\nmo.md(f\"Hello, {form.value}!\")\nGrouping UI elements together\nCreate an array of UI elements\nUse cases. In order to synchronize UI elements between the frontend and backend (Python), marimo requires you to assign UI elements to global variables. But sometimes you don\u2019t know the number of elements to make until runtime: for example, maybe you want o make a list of sliders, and the number of sliders to make depends on the value of some other UI element.\n\nYou might be tempted to create a Python list of UI elements, such as l = [mo.ui.slider(1, 10) for i in range(number.value)]: however, this won\u2019t work, because the sliders are not bound to global variables.\n\nFor such cases, marimo provides the \u201chigher-order\u201d UI element mo.ui.array, which lets you make a new UI element out of a list of UI elements: l = mo.ui.array([mo.ui.slider(1, 10) for i in range(number.value)]). The value of an array element is a list of the values of the elements it wraps (in this case, a list of the slider values). Any time you interact with any of the UI elements in the array, all cells referencing the array by name (in this case, \u201cl\u201d) will run automatically.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.array to group together many UI elements into a list.\n\nimport random\n\n# instead of random.randint, in your notebook you'd use the value of\n# an upstream UI element or other Python object\narray = mo.ui.array([mo.ui.text() for i in range(random.randint(1, 10))])\narray\nGet the value of the UI elements using array.value\n\narray.value\nCreate a dictionary of UI elements\nUse cases. Same as for creating an array of UI elements, but lets you name each of the wrapped elements with a string key.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.dictionary to group together many UI elements into a list.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4055, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef505541-3953-48e6-8253-7beb582f3040": {"__data__": {"id_": "ef505541-3953-48e6-8253-7beb582f3040", "embedding": null, "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4", "node_type": "4", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "f63b62abf1e588cb2fc85a74aa835d79678cf41541ba457e5780cf5cef3c87df", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "765f4bc9-fc87-4ec0-bace-ca663b60e518", "node_type": "1", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "b4dda4d7c2058a3e5fa84748ecd6de3ea7c245c7b0dc5d0ed3b864c912dcd143", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c8de7cb6-af61-4893-9464-d1a7d401d27b", "node_type": "1", "metadata": {}, "hash": "9c79fd751184dba0fa8fd5650bba179b18fe3ce39e16e1f331758fc7fe96431c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Any time you interact with any of the UI elements in the array, all cells referencing the array by name (in this case, \u201cl\u201d) will run automatically.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.array to group together many UI elements into a list.\n\nimport random\n\n# instead of random.randint, in your notebook you'd use the value of\n# an upstream UI element or other Python object\narray = mo.ui.array([mo.ui.text() for i in range(random.randint(1, 10))])\narray\nGet the value of the UI elements using array.value\n\narray.value\nCreate a dictionary of UI elements\nUse cases. Same as for creating an array of UI elements, but lets you name each of the wrapped elements with a string key.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.dictionary to group together many UI elements into a list.\n\nimport random\n\n# instead of random.randint, in your notebook you'd use the value of\n# an upstream UI element or other Python object\ndictionary = mo.ui.dictionary({str(i): mo.ui.text() for i in range(random.randint(1, 10))})\ndictionary\nGet the value of the UI elements using dictionary.value\n\ndictionary.value\nEmbed a dynamic number of UI elements in another output\nUse cases. When you want to embed a dynamic number of UI elements in other outputs (like tables or markdown).\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nGroup the elements with mo.ui.dictionary or mo.ui.array, then retrieve them from the container and display them elsewhere.\n\nimport random\n\nn_items = random.randint(2, 5)\n\n# Create a dynamic number of elements using `mo.ui.dictionary` and\n# `mo.ui.array`\nelements = mo.ui.dictionary(\n    {\n        \"checkboxes\": mo.ui.array([mo.ui.checkbox() for _ in range(n_items)]),\n        \"texts\": mo.ui.array(\n            [mo.ui.text(placeholder=\"task ...\") for _ in range(n_items)]\n        ),\n    }\n)\n\nmo.md(\n    f\"\"\"\n    Here's a TODO list of {n_items} items\\n\\n\n    \"\"\"\n    + \"\\n\\n\".join(\n        # Iterate over the elements and embed them in markdown\n        [\n            f\"{checkbox} {text}\"\n            for checkbox, text in zip(\n                elements[\"checkboxes\"], elements[\"texts\"]\n            )\n        ]\n    )\n)\nGet the value of the elements\n\nelements.value\nCreate a hstack (or vstack) of UI elements with on_change handlers\nUse cases. Arrange a dynamic number of UI elements in a hstack or vstack, for example some number of buttons, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate buttons in mo.ui.array and pass them to hstack \u2013 a regular Python list won\u2019t work. Make sure to assign the array to a global variable.\n\nimport random\n\n\n# Create a state object that will store the index of the\n# clicked button\nget_state, set_state = mo.state(None)\n\n# Create an mo.ui.array of buttons - a regular Python list won't work.\nbuttons = mo.ui.array(\n    [\n        mo.ui.button(\n            label=\"button \" + str(i), on_change=lambda v, i=i: set_state(i)\n        )\n        for i in range(random.randint(2, 5))\n    ]\n)\n\nmo.hstack(buttons)\nGet the state value\n\nget_state()\nCreate a table column of buttons with on_change handlers\nUse cases. Arrange a dynamic number of UI elements in a column of a table, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate buttons in mo.ui.array and pass them to mo.ui.table. Make sure to assign the table and array to global variables\n\nimport random\n\n\n# Create a state object that will store the index of the\n# clicked button\nget_state, set_state = mo.state(None)\n\n# Create an mo.ui.array of buttons - a regular Python list won't work.\nbuttons = mo.ui.array(\n    [\n        mo.ui.button(\n            label=\"button \" + str(i), on_change=lambda v, i=i: set_state(i)\n        )\n        for i in range(random.randint(2, 5))\n    ]\n)\n\n# Put the buttons array into the table\ntable = mo.ui.table(\n    {\n        \"Action\": [\"Action Name\"] * len(buttons),\n        \"Trigger\": list(buttons),\n    }\n)\ntable\nGet the state value\n\nget_state()\nCreate a form with multiple UI elements\nUse cases. Combine multiple UI elements into a form so that submission of the form sends all its elements to Python.\n\nRecipe.\n\nImport packages.", "mimetype": "text/plain", "start_char_idx": 3244, "end_char_idx": 7513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c8de7cb6-af61-4893-9464-d1a7d401d27b": {"__data__": {"id_": "c8de7cb6-af61-4893-9464-d1a7d401d27b", "embedding": null, "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4", "node_type": "4", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "f63b62abf1e588cb2fc85a74aa835d79678cf41541ba457e5780cf5cef3c87df", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef505541-3953-48e6-8253-7beb582f3040", "node_type": "1", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "faceabc345b7e7b558d12c1929586da44cec47ece77a7d7ee695778ab23f7d59", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e7b5712d-76b2-40d9-9d9a-8683bdbb0a77", "node_type": "1", "metadata": {}, "hash": "b90b7685d5af6cbdbdaf1cb131f54854aae4ba51f7d2fca7da83225553a66ff6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Create a state object that will store the index of the\n# clicked button\nget_state, set_state = mo.state(None)\n\n# Create an mo.ui.array of buttons - a regular Python list won't work.\nbuttons = mo.ui.array(\n    [\n        mo.ui.button(\n            label=\"button \" + str(i), on_change=lambda v, i=i: set_state(i)\n        )\n        for i in range(random.randint(2, 5))\n    ]\n)\n\n# Put the buttons array into the table\ntable = mo.ui.table(\n    {\n        \"Action\": [\"Action Name\"] * len(buttons),\n        \"Trigger\": list(buttons),\n    }\n)\ntable\nGet the state value\n\nget_state()\nCreate a form with multiple UI elements\nUse cases. Combine multiple UI elements into a form so that submission of the form sends all its elements to Python.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.form and Html.batch to create a form with multiple elements.\n\nform = mo.md(\n   r\"\"\"\n   Choose your algorithm parameters:\n\n   - $\\epsilon$: {epsilon}\n   - $\\delta$: {delta}\n   \"\"\"\n).batch(epsilon=mo.ui.slider(0.1, 1, step=0.1), delta=mo.ui.number(1, 10)).form()\nform\nGet the submitted form value.\n\nform.value\nWorking with buttons\nCreate a button that triggers computation when clicked\nUse cases. To trigger a computation on button click and only on button click, use mo.ui.run_button().\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a run button\n\nbutton = mo.ui.run_button()\nbutton\nRun something only if the button has been clicked.\n\nmo.stop(not button.value, \"Click 'run' to generate a random number\")\n\nimport random\nrandom.randint(0, 1000)\nCreate a counter button\nUse cases. A counter button, i.e. a button that counts the number of times it has been clicked, is a helpful building block for reacting to button clicks (see other recipes in this section).\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nUse mo.ui.button and its on_click argument to create a counter button.\n\n# Initialize the button value to 0, increment it on every click\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nGet the button value\n\nbutton.value\nCreate a toggle button\nUse cases. Toggle between two states using a button with a button that toggles between True and False. (Tip: you can also just use mo.ui.switch.)\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nUse mo.ui.button and its on_click argument to create a toggle button.\n\n# Initialize the button value to False, flip its value on every click.\nbutton = mo.ui.button(value=False, on_click=lambda value: not value)\nbutton\nToggle between two outputs using the button value.\n\nmo.md(\"True!\") if button.value else mo.md(\"False!\")\nRe-run a cell when a button is pressed\nUse cases. For example, you have a cell showing a random sample of data, and you want to resample on button press.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a button without a value, to function as a trigger.\n\nbutton = mo.ui.button()\nbutton\nReference the button in another cell.\n\n# the button acts as a trigger: every time it is clicked, this cell is run\nbutton\n\n# Replace with your custom lgic\nimport random\nrandom.randint(0, 100)\nRun a cell when a button is pressed, but not before\nUse cases. Wait for confirmation before executing downstream cells (similar to a form).\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a counter button.\n\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nOnly execute when the count is greater than 0.\n\n# Don't run this cell if the button hasn't been clicked, using mo.stop.\n# Alternatively, use an if expression.\nmo.stop(button.value == 0)\n\nmo.md(f\"The button was clicked {button.value} times\")\nReveal an output when a button is pressed\nUse cases. Incrementally reveal a user interface.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a counter button.\n\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nShow an output after the button is clicked.\n\nmo.md(\"#\" + \"\" * button.value) if button.value > 0 else None\nCaching\nCache expensive computations\nUse case. Because marimo runs cells automatically as code and UI elements change, it can be helpful to cache expensive intermediate computations.", "mimetype": "text/plain", "start_char_idx": 6758, "end_char_idx": 10871, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7b5712d-76b2-40d9-9d9a-8683bdbb0a77": {"__data__": {"id_": "e7b5712d-76b2-40d9-9d9a-8683bdbb0a77", "embedding": null, "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4", "node_type": "4", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "f63b62abf1e588cb2fc85a74aa835d79678cf41541ba457e5780cf5cef3c87df", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8de7cb6-af61-4893-9464-d1a7d401d27b", "node_type": "1", "metadata": {"source_url": "https://docs.marimo.io/recipes.html", "document_index": 4}, "hash": "9029b41bb2ac8b0c62617ab2a15fb6892f0d5e9a0fa2abc6835fb32d45d4f300", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "button = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nOnly execute when the count is greater than 0.\n\n# Don't run this cell if the button hasn't been clicked, using mo.stop.\n# Alternatively, use an if expression.\nmo.stop(button.value == 0)\n\nmo.md(f\"The button was clicked {button.value} times\")\nReveal an output when a button is pressed\nUse cases. Incrementally reveal a user interface.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a counter button.\n\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nShow an output after the button is clicked.\n\nmo.md(\"#\" + \"\" * button.value) if button.value > 0 else None\nCaching\nCache expensive computations\nUse case. Because marimo runs cells automatically as code and UI elements change, it can be helpful to cache expensive intermediate computations. For example, perhaps your notebook computes t-SNE, UMAP, or PyMDE embeddings, and exposes their parameters as UI elements. Caching the embeddings for different configurations of the elements would greatly speed up your notebook.\n\nRecipe.\n\nUse functools to cache function outputs given inputs.\n\nimport functools\n\n@functools.cache\ndef compute_predictions(problem_parameters):\n   # replace with your own function/parameters\n   ...\nWhenever compute_predictions is called with a value of problem_parameters it has not seen, it will compute the predictions and store them in a cache. The next time it is called with the same parameters, instead of recomputing the predictions, it will return the previously computed value from the cache.\n\nSee our best practices guide to learn more.", "mimetype": "text/plain", "start_char_idx": 10033, "end_char_idx": 11648, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "77dd73b4-5c54-408a-8523-49aef5ce8f00": {"__data__": {"id_": "77dd73b4-5c54-408a-8523-49aef5ce8f00", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "3275b0ac69e29f1fd4839b669ae9f54e68fcad315eb8e4b9ce59246efb780951", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee787ea5-227e-4105-bd29-a07b6d688353", "node_type": "1", "metadata": {}, "hash": "424482c213707e2473f00225b63d9ef9b324ffa2512e221a0ecb8651191fe8cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don\u2019t even care about your output; they care about the impact you drive.\n\nWhat\u2019s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it\u2019s key to focus on impact.\n\nIn this post I\u2019ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet\u2019s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already\u2026\nmedium.com\n\nWhy should I focus on impact; isn\u2019t that my manager\u2019s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn\u2019t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you\u2019ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you\u2019ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don\u2019t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn\u2019t everyone doing this?\nBecause it\u2019s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (\u201cI went to the gym\u201d or \u201cI did three loads of laundry\u201d) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It\u2019s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can\u2019t guarantee that it will actually move the business forward.\n\nIt can also feel like we\u2019re doing someone else\u2019s job. You built the dashboard; now it\u2019s the other team\u2019s problem how they\u2019re going use it and get value from it. You can definitely take this stance; but don\u2019t you want to see your work move the needle?\n\nLastly, sometimes it\u2019s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I\u2019ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like \u201cI launched 5 experiments\u201d or \u201cI built this model\u201d and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it\u2019s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3558, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ee787ea5-227e-4105-bd29-a07b6d688353": {"__data__": {"id_": "ee787ea5-227e-4105-bd29-a07b6d688353", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "3275b0ac69e29f1fd4839b669ae9f54e68fcad315eb8e4b9ce59246efb780951", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77dd73b4-5c54-408a-8523-49aef5ce8f00", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "460fb3f3be12a87dc93490262afb2262f88abc775f107cae346a55ab91e43963", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "999a9bda-b816-4143-a7aa-10d0cf77bc00", "node_type": "1", "metadata": {}, "hash": "8ba732ab84a520fdbce8cf8407d6df8601d6e379cf8466db32c4f33e27807606", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Image by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou\u2019re a Marketing Data Scientist? Assume you\u2019re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou\u2019re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don\u2019t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you\u2019ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou\u2019ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won\u2019t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don\u2019t rely on this: Managers don\u2019t always do a perfect job, and you\u2019ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team\u2019s planning materials to get an idea of what they\u2019re trying to accomplish in the next 1\u20132 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you\u2019ll be in for a bad time if key stakeholders are not bought in.\n\nYou don\u2019t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn\u2019t address. To avoid this, you\u2019ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I\u2019ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you\u2019re in, you\u2019re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let\u2019s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt\u2019s easy to get caught up in the craziness of daily business only to realize you didn\u2019t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it\u2019s less exciting than strategic projects, it\u2019s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it\u2019s time to talk to your manager. I\u2019m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.", "mimetype": "text/plain", "start_char_idx": 3561, "end_char_idx": 7589, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "999a9bda-b816-4143-a7aa-10d0cf77bc00": {"__data__": {"id_": "999a9bda-b816-4143-a7aa-10d0cf77bc00", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "3275b0ac69e29f1fd4839b669ae9f54e68fcad315eb8e4b9ce59246efb780951", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee787ea5-227e-4105-bd29-a07b6d688353", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "ffc19c57cf11da5495aac13f71c16fb05a81b292c75d15d569e99c1dd503211e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "95d08505-b8e5-4481-bf41-5bd31dca616c", "node_type": "1", "metadata": {}, "hash": "1b2ba94647a13fb32c93118d0139c238f339307d1c5ae7dc45132f932ee537f3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Image by author\nDon\u2019t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn\u2019t seem to be going anywhere. Maybe you realized the premise didn\u2019t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you\u2019re doubling down to get it over the finish line. After all, you don\u2019t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (\u201cimpact killers\u201d)\nHow do you minimize the odds of wasting time on a project that won\u2019t lead to impact? There are a few warning signs:\n\n\u201cAcademic\u201d projects: Any time a project is pitched to you along the lines of \u201cThis would be interesting to understand\u201d you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the \u201cbest\u201d driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple \u201cone-size-fits-all\u201d answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it\u2019s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you\u2019re unsure what exactly you\u2019re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn\u2019t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and \u201conly\u201d need to close the loop with stakeholders.", "mimetype": "text/plain", "start_char_idx": 7592, "end_char_idx": 10092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "95d08505-b8e5-4481-bf41-5bd31dca616c": {"__data__": {"id_": "95d08505-b8e5-4481-bf41-5bd31dca616c", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "3275b0ac69e29f1fd4839b669ae9f54e68fcad315eb8e4b9ce59246efb780951", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "999a9bda-b816-4143-a7aa-10d0cf77bc00", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1", "document_index": 5}, "hash": "97627e43412eba8741ff920c106c5ac26db38a334c91e41fdf45101e70b3c446", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Image by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don\u2019t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a \u201cmetrics dump\u201d with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn\u2019t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don\u2019t get used, it\u2019s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don\u2019t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don\u2019t know how it works, they\u2019ll be suspicious.\n\nSolution: It\u2019s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you\u2019ll need to be able to explain why, or you\u2019ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I\u2019ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn\u2019t get used, it\u2019s likely one of these things is true:\n\nThe dashboard doesn\u2019t directly address an urgent business use case\nYou didn\u2019t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don\u2019t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn\u2019t get used. If you cannot (or don\u2019t want to) simplify the dash further, you\u2019ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users\u2019 needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it\u2019s what ultimately gets you promotions and new job opportunities.\n\nAnd isn\u2019t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.", "mimetype": "text/plain", "start_char_idx": 10095, "end_char_idx": 14278, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8d620ed0-e93d-47e2-ab49-4eb23d40dde3": {"__data__": {"id_": "8d620ed0-e93d-47e2-ab49-4eb23d40dde3", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "19f83ba4-950d-485a-8ec5-090b58c32d8e", "node_type": "1", "metadata": {}, "hash": "9490ea9509c3b8be50268c26da6e2907196f447ee6a876709f431cdcf9b2a002", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called \u201cgeneral-purpose AI models\u201d that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk\u2013based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5244, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "19f83ba4-950d-485a-8ec5-090b58c32d8e": {"__data__": {"id_": "19f83ba4-950d-485a-8ec5-090b58c32d8e", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8d620ed0-e93d-47e2-ab49-4eb23d40dde3", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "749d1c5bc9e379247e653b3adfef68ceffe562fab13e777c949316bf1313fd88", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "01658214-645f-4424-b1ac-cfde9f4caa24", "node_type": "1", "metadata": {}, "hash": "b069cb15743ba5944c5063ba6396c24ec81d1603a9d413122dd9c73c8538d566", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of \u2018high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?", "mimetype": "text/plain", "start_char_idx": 4282, "end_char_idx": 9493, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "01658214-645f-4424-b1ac-cfde9f4caa24": {"__data__": {"id_": "01658214-645f-4424-b1ac-cfde9f4caa24", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19f83ba4-950d-485a-8ec5-090b58c32d8e", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "b01e0e5e6752b350a47709b8f982797ddefa9ffba6bc1f94e05dc5a9c8406140", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56dc0c80-3bd0-47ae-832d-2a404df630be", "node_type": "1", "metadata": {}, "hash": "cdd41d72941a1a37c7f00fb0d4fe9715c73b9f7c162453a2a2b761d0f09847f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "High-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.", "mimetype": "text/plain", "start_char_idx": 8533, "end_char_idx": 13627, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "56dc0c80-3bd0-47ae-832d-2a404df630be": {"__data__": {"id_": "56dc0c80-3bd0-47ae-832d-2a404df630be", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01658214-645f-4424-b1ac-cfde9f4caa24", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "a7415a63f71526fcca5e682b931bff2ac40632778a02aa6d53d2d41ad49f329e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e1d31a59-9af8-41f2-b157-be0092b7998e", "node_type": "1", "metadata": {}, "hash": "49e3f15c64abd7e072e3e9767502214949bf21ef7d7929905a773abd0bf1a064", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (\u2018black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.", "mimetype": "text/plain", "start_char_idx": 12583, "end_char_idx": 17850, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e1d31a59-9af8-41f2-b157-be0092b7998e": {"__data__": {"id_": "e1d31a59-9af8-41f2-b157-be0092b7998e", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "56dc0c80-3bd0-47ae-832d-2a404df630be", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "9e2957f9c85a35031fc6c8476308486247c81188e6dc42a87a22575796d2c391", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a88c646e-7575-449f-96dc-8c59122648bd", "node_type": "1", "metadata": {}, "hash": "3531acb127bbd00b33ca32b7b586720cdf270791e41377300b632d0841591f81", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (\u2018black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.", "mimetype": "text/plain", "start_char_idx": 16907, "end_char_idx": 22261, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a88c646e-7575-449f-96dc-8c59122648bd": {"__data__": {"id_": "a88c646e-7575-449f-96dc-8c59122648bd", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e1d31a59-9af8-41f2-b157-be0092b7998e", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "c3dc90204239dd34e3bfd3eb8d0cd491226e8d287be94f279ad08ac3a5785cbc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5076442f-9d5a-4bc4-b93a-e0688bbe4a77", "node_type": "1", "metadata": {}, "hash": "12a529486b31859e6b41dce6a4d0fad7b832629376d416d70a1f3086a5d996f3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "How will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to \u20ac35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to \u20ac15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to \u20ac7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority.", "mimetype": "text/plain", "start_char_idx": 21500, "end_char_idx": 27169, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5076442f-9d5a-4bc4-b93a-e0688bbe4a77": {"__data__": {"id_": "5076442f-9d5a-4bc4-b93a-e0688bbe4a77", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a88c646e-7575-449f-96dc-8c59122648bd", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "71c557c2bc9ba5fe4acd436c9d0233fa6ed38a323eb61ce9c8ff84e563b7f7e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ed35031-ec81-4fbd-94ff-d90254ba94e6", "node_type": "1", "metadata": {}, "hash": "40ab37c53ffdff166a45d867096699ab14d01f5a2de9b850cf7b13ca25413ce5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g.", "mimetype": "text/plain", "start_char_idx": 26653, "end_char_idx": 32313, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6ed35031-ec81-4fbd-94ff-d90254ba94e6": {"__data__": {"id_": "6ed35031-ec81-4fbd-94ff-d90254ba94e6", "embedding": null, "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6", "node_type": "4", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "8fc4e11ea0e26e62312d2a431c6e2ec16461ef9fbff371cd55182d1a234be723", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5076442f-9d5a-4bc4-b93a-e0688bbe4a77", "node_type": "1", "metadata": {"source_url": "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683", "document_index": 6}, "hash": "76a292798e1f44037f6208f2f16ad43ebf3d4d6f9984b9ebdbc71970d0d676ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023", "mimetype": "text/plain", "start_char_idx": 31457, "end_char_idx": 35485, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4f940bd9-f787-4f7f-bfe3-61c6ce51bc5c": {"__data__": {"id_": "4f940bd9-f787-4f7f-bfe3-61c6ce51bc5c", "embedding": null, "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7", "node_type": "4", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "9d22ae9c3a3962612258545d5efa344dd51ba94cbe2e33107631900ab0c2dda6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f91c0019-fc6a-4196-a0d6-f689fbfd48b6", "node_type": "1", "metadata": {}, "hash": "2e79050e5653ff27c8d07c69d3467ba4682368821a950afa7bf71062229b8613", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The Emperor is a mind flayer who appears in Baldur's Gate 3. It[note 1] plays a key role in the main story, but its identity is intentionally obscured until later parts of the game, allowing the player to ultimately decide for themselves if they want to know more about it, and whether or not it is trustworthy.\n\n\nContents\nOverview\nIdentity\nPersonal quest\nRecruitment\nRomance\nHistory\nEvents of Baldur's Gate 3\nAct Two finale\nAct Three\nElfsong Tavern\nThe Wyrmway\nEndings\nList of interactions\nConversation scenes\nIdentity revealed\nRegarding Duke Stelmane\nOn conclusion of Visit the Emperor's Old Hideout\nRomance\nAchievements\nGallery\nNotes\nFootnotes\nReferences\nOverview\nIdentity\nThe Emperor plays a key role in the main story of Baldur's Gate 3, and as part of this role its identity and personal background are kept obfuscated for much of the game. It very carefully divulges information that it deems necessary, sometimes arguing that the player is not ready for the answer yet, or that it will reveal specific information in the future.\n\nDuring Acts One and Two, the Emperor only \"meets\" with the player as the Dream Guardian. At the beginning of Act Three, the player finally meets the Emperor face to face, an event which reveals that it is a mind flayer.\n\nThrough all three Acts, the Emperor generally serves as a guide, and unlikely ally to the party, having the means to protect their minds from the influence of the Absolute, through the use of the prisoner within the Astral Prism.\n\n\"Don't let my form deceive you. I am the one that's been protecting you. I am the one that came to you in your dreams. Help me.\n\u2014 The Emperor, during Act 3\nPersonal quest\nAfter reaching the Elfsong Tavern in Act Three, the Emperor will initiate the quest Visit the Emperor's Old Hideout, in which the player can better get to know the Emperor. It discloses some of its past, during its time in the city and from before it became illithid.\n\nRecruitment\nThe Emperor can appear in multiple combat encounters as a controllable ally, a neutral ally, or an enemy. It cannot, however, become a full member of the player's party or camp.\n\nRomance\nThe Emperor can have a romance with the player during Act Three. See Romance.\n\nHistory\nDetails about the Emperor's personal history are intentionally obfuscated during most of the game, but the player has the opportunity to learn more about it through conversations, interactions with other characters, reading books, and completing specific side quests.\n\nIco knownSpells lvl 03.png Act 3 Spoilers! This section reveals details about the story of Baldur's Gate 3.\n\n\nAn Adventurer, I came from Baldur's Gate, though I was never one to be constrained by circumstance. I longed for more.\n\nThat longing brought me to Moonrise Towers on a search for treasure. To a colony of mind flayers who caught me and changed me.\nThe Emperor was once Balduran, an adventurer who founded a coastal village called Grey Harbour. After securing enough money to fund the building of the Wall that led to Baldur's Gate being founded, he felt the call of the sea once more. On the voyage, and following a shipwreck, Balduran made his way to Moonrise Towers in search of fortune. There, he found a coven of mind flayers who infected him with an illithid tadpole. As a record of his interrogation by Enver Gortash during the planning phases of the Absolute Hoax states, he spent ten years under the thrall of the Moonrise Elder Brain.\n\nAfter Balduran was reborn as an illithid and broke free from the Elder Brain the Absolute, it returned to Baldur's Gate, living in the shadows and feeding on the brains of criminals. Initially struggling with its identity as a mind flayer, Balduran eventually embraced its new form.\n\nBalduran's new acceptance of its illithid form caused a wedge to form between it and its close companion, the dragon Ansur. Ansur attempted to kill Balduran as it slept, believing this would be a merciful death. The Emperor sensed the attempt, and in its struggle to protect itself from being murdered, it killed Ansur in self-defence. [1]\n\nAfter Ansur's death, Balduran came to be called the Emperor as it used its newfound psychic influence to rule Baldur's Gate from the shadows. For the next four centuries, it made its haven under the Elfsong tavern, keeping various sentimental knick knacks from its time as Balduran.\n\n\nI had the fortune of meeting Duke Stelmane.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4392, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f91c0019-fc6a-4196-a0d6-f689fbfd48b6": {"__data__": {"id_": "f91c0019-fc6a-4196-a0d6-f689fbfd48b6", "embedding": null, "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7", "node_type": "4", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "9d22ae9c3a3962612258545d5efa344dd51ba94cbe2e33107631900ab0c2dda6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f940bd9-f787-4f7f-bfe3-61c6ce51bc5c", "node_type": "1", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "7fee6ab5f7cc0811c2217386a3d950571efc30db2350970df358004ef339b83a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c479b87-9e55-4aed-b56c-c1b2363b60d5", "node_type": "1", "metadata": {}, "hash": "83da82ecb3a7056330d27080e288c87924658540e7fc955a5099ff26bf62068b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "I had the fortune of meeting Duke Stelmane. We formed a partnership\nDuring those four centuries, it also came to be associated with the Knights of the Shield, a lawful and neutral evil conglomerate of politicians and merchants manipulating events behind the scenes. Duke Stelmane was a major figure of this secret society, acting as the Emperor's envoy while it secretly kept her enthralled. [note 2]\n\nSometime before the events of the game, Enver Gortash and the Dark Urge captured the Emperor, and brought it back under the thrall of the Moonrise Elder Brain, who was now wearing the Crown of Karsus and had become the Netherbrain masquerading as the Absolute. The Netherbrain, sought to have all three Chosen of the Dead Three killed, and specifically picked the Emperor, unbeknown to it, to lead a team of illithids on a nautiloid to search for and steal from the Githyanki the Astral Prism containing their prince, Orpheus.[2]\nEvents of Baldur's Gate 3\nAct Two finale\nMain article: Help Your Protector\nOn the way to Baldur's Gate, the party will be ambushed by a group of Gish'ra warriors while resting at Wyrm's Lookout. Entering the portal to the Astral Prism, the party will hear their Dream Guardian calling out for help. However, when the party reaches them, it is only to discover that the true identity of their visitor is the illithid known as the Emperor.\n\nAfter defending the Emperor, it will explain how it used the power of the Prism and Orpheus to protect the party from the Absolute, and recite to the party its history as an adventurer and finding freedom from the Absolute. The Emperor will offer the party an Astral Touched Tadpole, which causes the user to transform into a partial-illithid. It insists the path of the mind flayer is preferable, regardless of the player's view on them.\n\nThough this may seen contradictory to its previous promise as the Dream Guardian; to ensure the party do not become mind flayers, this promise refers to the player becoming a mind flayer unwillingly because of the Elder Brain. The Emperor is in favour of the player becoming a mind flayer of their own volition and without the influence of the Elder Brain.\n\nAct Three\nElfsong Tavern\nMain article: Visit the Emperor's Old Hideout\nAs the party nears the Elfsong, the Emperor will remark that the tavern is the location of its old hideout. The hideout proper is in the basement, past the Knights of the Shield's hideout. In it, the player will find various sentimental knick knacks from the Emperor's previous life, before becoming an illithid.\n\nAround the room is its old dog Rascal's collar, its favourite recipe (fiddlehead soup), its first adventuring sword, and part of a cutlery set from its mother; the butter knife having been lost during its last shipwreck on the Isle of Balduran, inside the wreck of the Wandering Eye ship.\n\nThere are also some more illithid-adequate items such as chains for its preferred prey - allegedly criminals and lawbreakers - and jars for brains.\n\nThe Wyrmway\nSee also: Wyrmway and The Blade of Frontiers\nOnce the party completes the Wyrmway trials, they will find the corpse of Ansur the Dragon. Interacting with his body will awaken Ansur's spirit, which briefly possesses the player in order to communicate. As Ansur's introduction concludes, he will detect the Emperor within the Astral Prism.\n\nIco knownSpells lvl 03.png Act 3 Spoilers! This section reveals details about the story of Baldur's Gate 3.\n\nAnsur will reveal that the Emperor in fact was formerly Balduran, the founder of Baldur's Gate. Furthermore, he explains that while the Emperor initially did not want to become a mind flayer, it eventually fully embraced its new form, and its comfort with this caused a rift between the Emperor and Ansur. After \"exhausting all possibility of reversing (the Emperor's) condition\", Ansur was agonizing and the Emperor (as seen in the letter on Ansur's body) attempted to convince him to leave. Ansur then attempted to murder the Emperor during its sleep as a mercy killing, and the Emperor killed Ansur in self-defense.\n\nThis development is somewhat foreshadowed when the player first meets The Emperor in their true form, as the song that plays during the encounter is a variation of The Elf Song, which prominently features Balduran in its lyrics.\nEndings\nIco knownSpells lvl 03.png Act 3 Spoilers!", "mimetype": "text/plain", "start_char_idx": 4349, "end_char_idx": 8701, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9c479b87-9e55-4aed-b56c-c1b2363b60d5": {"__data__": {"id_": "9c479b87-9e55-4aed-b56c-c1b2363b60d5", "embedding": null, "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7", "node_type": "4", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "9d22ae9c3a3962612258545d5efa344dd51ba94cbe2e33107631900ab0c2dda6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f91c0019-fc6a-4196-a0d6-f689fbfd48b6", "node_type": "1", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "29fa40a75edcfcfaf9eb248c074d2ba64a4f598b245f96ebd05a6da36bd98767", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d38281fb-a5cb-4b7f-81da-cfae2b159582", "node_type": "1", "metadata": {}, "hash": "6ab781c070f10b9b722e1329f043626aabf13e2aa2bec7d6c031757d57534426", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Ansur will reveal that the Emperor in fact was formerly Balduran, the founder of Baldur's Gate. Furthermore, he explains that while the Emperor initially did not want to become a mind flayer, it eventually fully embraced its new form, and its comfort with this caused a rift between the Emperor and Ansur. After \"exhausting all possibility of reversing (the Emperor's) condition\", Ansur was agonizing and the Emperor (as seen in the letter on Ansur's body) attempted to convince him to leave. Ansur then attempted to murder the Emperor during its sleep as a mercy killing, and the Emperor killed Ansur in self-defense.\n\nThis development is somewhat foreshadowed when the player first meets The Emperor in their true form, as the song that plays during the encounter is a variation of The Elf Song, which prominently features Balduran in its lyrics.\nEndings\nIco knownSpells lvl 03.png Act 3 Spoilers! This section reveals details about the story of Baldur's Gate 3.\n\nLet the Emperor use the Netherstones\nThe Emperor unless convinced otherwise is mostly concerned with its survival and prosperity. Should the player allow it to wield the Netherstones, it will follow through on destroying the Elder Brain, at the cost of letting it \"assimilate\" with Orpheus.\nIf the player suggests to the Emperor to take control of the Netherbrain, it will mention that the thought of becoming the Absolute did cross its mind. But unless otherwise persuaded, it will refuse, claiming that whoever becomes the leader of the Cult of the Absolute will be in an open war with the Githyanki, which is a war it is not certain it will survive. The Emperor will destroy the Netherbrain, and the parasites within its control in this ending.\nThe Emperor controls the Netherbrain\nIt is also possible, after suggesting it to take control of the Netherbrain, to persuade it. In this scenario, it does not free the player or their party, instead making them mindless thralls and assuming absolute control of them, continuing the Grand Design.\nOrpheus is freed\nIf the player frees Orpheus, the Emperor will abandon the party, and side with the Netherbrain for the sake of its own survival, as it believes that Orpheus will kill it.\nAttack the Emperor\nThe Emperor can be attacked and killed when it first reveals itself to be a mind flayer. This will result in the influence of the Netherbrain taking over control of the party, ending the game.\nList of interactions\nSee Dream Guardian to read about its previous conversations with the player when it was in disguise.\nCharm Person Icon.png Romance Spoilers This section reveals details about romance and may contain mature themes.\n\nPlayers have a limited number of opportunities to interact with the Emperor, and as such, opportunities for conversation are much more limited compared to that of companions.\n\nConversation scenes are available, but only occur during Act 3, after its \"true\" identity is revealed to the player, and all scenes require a long rest to trigger. The Emperor will occasionally also talk to the player as they walk through different locations in Baldur's Gate.\n\nConversation scenes\nKnown conversation opportunities with the Emperor currently include the following cases, but each scene appears to have multiple outcomes that affect the tone of all subsequent conversations.\n\nDepending on the player's choices, the Emperor's behaviour has many possible states. The more the player treats the Emperor like a \"person\", the more it will act as such, compared to other illithids. The more the player treats The Emperor like a monstrosity with hostile intent, the more it will respond to the player with threatening language and visions of it acting like a hostile illithid.\n\nIdentity revealed\nDuring Help Your Protector at the start of Act 3, a conversation is automatically triggered when the player ventures far enough into the Astral Plane. A combat encounter in some form is inevitable from this conversation, and then another set of conversation options are available after the combat resolves. The Emperor will have nothing further to say when this conversation ends, even if the player tries to interact with it further.\n\nRegarding Duke Stelmane\nWhen the player first explores the Rivington area, being in proximity to certain characters or objects will \"inform\" the player about the recent death of Duke Belynne Stelmane. This will trigger a line of ambient commentary from The Emperor. The next time a Long Rest is triggered, the player may trigger a scene discussing The Emperor's reactions in more depth. Certain dialogue choices made during earlier conversations seem to disqualify the player from this scene. If the player does not long rest before completing the quest Visit the Emperor's Old Hideout, this scene will be skipped entirely.", "mimetype": "text/plain", "start_char_idx": 7802, "end_char_idx": 12588, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d38281fb-a5cb-4b7f-81da-cfae2b159582": {"__data__": {"id_": "d38281fb-a5cb-4b7f-81da-cfae2b159582", "embedding": null, "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7", "node_type": "4", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "9d22ae9c3a3962612258545d5efa344dd51ba94cbe2e33107631900ab0c2dda6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c479b87-9e55-4aed-b56c-c1b2363b60d5", "node_type": "1", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "e37516c31062117a7cd17ec6982779bf4b938e5741c2adf3434a7f43680214d5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a59a292d-459c-4367-b64b-1f63b08be6f6", "node_type": "1", "metadata": {}, "hash": "9d8c7171880e0d3cfe24e97113bc5ccb5f1a638ba9a2b473adae63ce01cce766", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A combat encounter in some form is inevitable from this conversation, and then another set of conversation options are available after the combat resolves. The Emperor will have nothing further to say when this conversation ends, even if the player tries to interact with it further.\n\nRegarding Duke Stelmane\nWhen the player first explores the Rivington area, being in proximity to certain characters or objects will \"inform\" the player about the recent death of Duke Belynne Stelmane. This will trigger a line of ambient commentary from The Emperor. The next time a Long Rest is triggered, the player may trigger a scene discussing The Emperor's reactions in more depth. Certain dialogue choices made during earlier conversations seem to disqualify the player from this scene. If the player does not long rest before completing the quest Visit the Emperor's Old Hideout, this scene will be skipped entirely.\n\nOn conclusion of Visit the Emperor's Old Hideout\nThis scene may be available to trigger (by long resting) after the player completes the quest Visit the Emperor's Old Hideout.\n\nPossible states for this scene appear to vary heavily depending on the player's choices in prior conversation scenes, with the general differentiating factor being the \"attitude\" the player appears to express towards illithids, and towards the Emperor, through their selected options in these prior scenes.\n\nIf the player tried to kill the Emperor in Act One, by choosing the dialogue option \"You do a great impression of a human. But you're not fooling me.\" , the Emperor offers to share memories through a vision. This vision shows Stelmane paralysed in pain, being brainwashed, and turning into the Emperor's puppet. Her face emotionless, and the Emperor puppeteering her gestures to get a sense of company. Such was its true relationship with Duke Stelmane. [note 2]\n\nThe Emperor uses this memory to frighten the player. It gives them orders, and threatens to make them half-illithid even if they refuse.\n\nRomance\nIn terms of game mechanics, it is technically possible to romance the Emperor. [note 3]\n\nIf the player chooses to reject its advances, the Emperor's attitude in conversation will change in a way that appears to be reactively appropriate to the way it was treated. For example, if the option \"Absolutely not, you freak!\" is chosen at any opportunity, the Emperor's treatment of the player takes a much more hostile tone in all future interactions.\n\nPlayers have a limited number of opportunities to interact with the Emperor, and as such, opportunities for romantically-styled interactions are much more limited compared to the other primary companions.\n\nIf the player visits Cr\u00e8che Y'llek prior to the start of Act 3, killing the Dream Guardian will subsequently lock the player out of romancing the Emperor, and from interacting with it in general.\n\nThere are many possible ways to interact with the Emperor in the available conversation scenes. It currently seems that the primary way to unlock \"romantic\" options is by choosing dialogue that generally treats the Emperor more like \"any other person\", and does not show explicit hostility towards its actions, or its illithid characteristics.\n\nThe player does not need to accept the powers of the Astral-Touched Tadpole to unlock this option. The Emperor seems to take offence to destroying the tadpole, but more testing is needed to determine if this has any effect on the available scenes.\n\nThe scene that occurs after completing Visit the Emperor's Old Hideout is generally regarded as the \"primary\" romantic scene. As long as the player is receptive to the Emperor's advances, conclusions to this scene will allow the player to engage in more intimate activities with it.\n\nConversation options that acknowledge this romance (after the primary scene has concluded) appear to exist in a limited number of places. For example, it is possible to tell Raphael \"I don't want any part of this \u2014 the Emperor is my lover.\" during a specific conversation, if initiated after the romance scene has happened.\n\nEngaging in the primary scene has no effect on other ongoing romances, even when romancing Lae'zel, who is generally hostile to illithids.\n\nAchievements\nA-Mind Blown.jpg\nMind Blown\nRomance the Emperor.\n\n\nGallery\nThey called me The Emperor\nThey called me The Emperor\n\n\nThe Emperor feeding on criminals\nThe Emperor feeding on criminals\n\n\nCharacter portrait by Edward Vanderghote\nCharacter portrait by Edward Vanderghote", "mimetype": "text/plain", "start_char_idx": 11680, "end_char_idx": 16156, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a59a292d-459c-4367-b64b-1f63b08be6f6": {"__data__": {"id_": "a59a292d-459c-4367-b64b-1f63b08be6f6", "embedding": null, "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7", "node_type": "4", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "9d22ae9c3a3962612258545d5efa344dd51ba94cbe2e33107631900ab0c2dda6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d38281fb-a5cb-4b7f-81da-cfae2b159582", "node_type": "1", "metadata": {"source_url": "https://bg3.wiki/wiki/The_Emperor", "document_index": 7}, "hash": "0886d3eedaecba9683cedbba873cb45e1e6c473323b30c004ce59b7ecca79c34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As long as the player is receptive to the Emperor's advances, conclusions to this scene will allow the player to engage in more intimate activities with it.\n\nConversation options that acknowledge this romance (after the primary scene has concluded) appear to exist in a limited number of places. For example, it is possible to tell Raphael \"I don't want any part of this \u2014 the Emperor is my lover.\" during a specific conversation, if initiated after the romance scene has happened.\n\nEngaging in the primary scene has no effect on other ongoing romances, even when romancing Lae'zel, who is generally hostile to illithids.\n\nAchievements\nA-Mind Blown.jpg\nMind Blown\nRomance the Emperor.\n\n\nGallery\nThey called me The Emperor\nThey called me The Emperor\n\n\nThe Emperor feeding on criminals\nThe Emperor feeding on criminals\n\n\nCharacter portrait by Edward Vanderghote\nCharacter portrait by Edward Vanderghote\n\n\nThe Emperor's model\nThe Emperor's model\n\nNotes\nThe Emperor's existence confirms the Dream Guardian as being an illithid influence, albeit in a different way.\nIn Early Access, the Dream Guardian (known then as Dream Visitor) was implied to be a mental manifestation of the player's tadpole, as it eased them towards using their powers more, as well as showing them a future of domination and control.\nIn the Full Release, the Emperor plays a similar role, in the sense that it also encourages the player to expand their potential through using the tadpole's power, but it is much more passive. In addition, its interests seem to be aligned against the Absolute.\nFootnotes\n The Emperor, like other mind flayers, is addressed using the \"it\" pronoun. It is incidentally referred to as \"he\" in-game, and \"they\" in the game's files, possibly due to an oversight, or characters conflating its current and previous identities.\n The Emperor's vision of its control over Belynne Stelmane is corroborated by the 5e module,  Baldur's Gate: Descent into Avernus. In it, Stelmane is described as having a secret, mental battle against a mind flayer. This mind flayer is very likely the Emperor itself, and as a result, puts its entire \"alliance\" with Stelmane into question. It is very possible the Emperor and Stelmane did not have a proper alliance at all, and rather, the Emperor enthralled her for its needs. Whether this was always the case, or if they had a genuine alliance beforehand, isn't fully clear.\n This romance behaves somewhat differently from that with companions, as the Emperor generally cannot be interacted with outside of cutscenes, and romantic progression is limited to the final act of the game.\nReferences\n Dialogue with Ansur.\n The Netherbrain's dialogue to the player at the Morphic Pool.", "mimetype": "text/plain", "start_char_idx": 15256, "end_char_idx": 17961, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2a51115a-26d9-4445-aad7-abbae5f5e20a": {"__data__": {"id_": "2a51115a-26d9-4445-aad7-abbae5f5e20a", "embedding": null, "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8", "node_type": "4", "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "hash": "6061eae548a3e68c6421a88a68d57832afc2a5fca1ed9a1dfa6b4094d7f7e9da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "39bfd395-9f2d-4d81-b460-e8486271cc5b", "node_type": "1", "metadata": {}, "hash": "87d47bac6295a679e68a5f0df657ebbf297c4dfdbd67dcb48b3ce60d3bcf03df", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "so into northern spain!\nour magical urban-plus-outdoor-adventure itinerary\nCAROLINE CHAMBERS\nMAY 29, 2024\n\nI recently returned from a trip to Northern Spain with two of my best friends, Lily and Nellie, sponsored by elsewhere, a travel company that works with local experts to create truly unique travel experiences.\n\nOn our last day in Spain, we had an incredible private tour of the Guggenheim Museum Bilbao, and then partook in our favorite trip ritual: hopping around from pintxo bar to pintxo bar (pintxos = small little plates of food \u2014 similar to tapas but they are typically sitting on the bar and you point to what you want), drinking txakoli (a lightly effervescent white wine that is very, very popular in the region), and playing gin rummy.\n\nWe then headed back to our hotel room, crammed onto the bed with, well, another bottle of txakoli, and recorded what I can only assume was the greatest podcast episode of all time. We recapped the full trip, what we loved, what we would change. We shared the most absurd moments. We laughed so hard and made so much fun of each other in a way that only really old friends who have just spent 12 days straight together can do. I\u2019ve been so excited to share it.\n\nBut\u2026 the recording failed. I have no idea what happened, but I blame the txakoli.\n\nI thought about re-recording with them remotely, but the magic of that moment, being there together on the last night of a truly perfect trip, is gone. So instead, I\u2019ll share the highlights here! Full itinerary with ALL the details is here.\n\n\nWe spent two nights in Madrid and could have spent at least four. There\u2019s so much to see and do here, and we barely scratched the surface. Our highlights were shopping in the Chueca and Salamanca neighborhoods \u2014 Malababa, Soeur, and Sess\u00f9n were some of our favorite shops. We had a wonderful meal at Charr\u00faa Madrid and fun cocktails at Ficus Bar. You can find all of our favorite shops, tapas bars, and many places that we didn\u2019t get to explore but wanted to on my Spain map here.\n\n\nstrolling the charming, windy streets of chueca!\n\nSan Sebasti\u00e1n is the coolest town \u2014 worth a trip to Spain all on its own. It\u2019s a coastal town on the Northern coast of Spain, right next to the French border, and it fully charmed us. It\u2019s that perfect European blend of old meets new \u2014 hip young surfers going to 200-year-old pintxo bars to meet up with their friends after surfing all afternoon, 100-year-old pastry shops next door to chic Spanish design ateliers. We spent three nights there and loved every minute, but these were our highlights:\n\ncooking in a private gastronomic club\nWhen you\u2019re wandering the cobblestone streets of San Sebasti\u00e1n looking for your next pintxo, you might find yourself stumbling through the doorway of a friendly looking restaurant, only to be turned away. \u201cDisculpa, privado!\u201d they\u2019ll tell you \u2014 \u201cSorry, private!\u201d\n\nYou\u2019ve stumbled into a sociedad gastron\u00f3mica \u2014 one of San Sebasti\u00e1n\u2019s 100+ private gastronomic clubs. Each one has its own personality and offering, but at its core is this: it\u2019s a private social club centered around cooking and eating with fellow members. Members reserve a time to cook \u2014 depending on the size of the club, three to four members can cook at a time \u2014 and they can invite guests to join them. Members will head to one of the many local markets, grab their food, and then bring it back to the shared kitchen to cook for/with their friends and family.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3441, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "39bfd395-9f2d-4d81-b460-e8486271cc5b": {"__data__": {"id_": "39bfd395-9f2d-4d81-b460-e8486271cc5b", "embedding": null, "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8", "node_type": "4", "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "hash": "6061eae548a3e68c6421a88a68d57832afc2a5fca1ed9a1dfa6b4094d7f7e9da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2a51115a-26d9-4445-aad7-abbae5f5e20a", "node_type": "1", "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "hash": "9a482c307ea76ac6ae8595a71322129c0a4c4e5efd40acd47e03f164d4913f00", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8e07fb3e-2d9a-4d5f-b20d-8e29ceddd806", "node_type": "1", "metadata": {}, "hash": "07e085b7ef88f5376110ee1e1825e20bd8a00615fb2f3d98b44d6050715b0025", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "post-lunch txakoli on the deck at the club\nThe only hitch? You have to be with a member to go inside of one! This was the coolest tour that elsewhere set up for us \u2014 Jani, our guide, was an incredibly cool young mom and entrepreneur (she owns her own tour company) and is a member of several clubs. She picked us up at our hotel, took us to her favorite local market and farmer\u2019s market to grab ingredients, and then back to her club, which was a stone building with wooden beams and felt like a scene out of a Game of Thrones banquet. We cooked a local fish dish, a tomato salad, and seared white asparagus, and she taught us all about Basque cuisine and the local gastronomic clubs.\n\nWe spent the entire afternoon cooking and eating and drinking txakoli on the deck of her club overlooking the city. A cannot miss experience if you find yourself in San Seb! Here\u2019s a great Saveur article if you want to read more about the clubs.\n\npintxo hopping\nPick three or four pintxos bars that are close together, and hop from bar to bar, eating a snack and having a glass of txakoli at each one. This is always my favorite way to explore a new place on limited time \u2014 an appetizer at one spot, a meal at another, after-dinner drinks at a third, so the pintxos culture really allows you to see a lot of places in one night!\n\nMy map has a lot of great pintxos bars saved, but here\u2019s an especially great hop (these are all on my map):\n\nStart at Ganbara and grab whatever looks good \u2014 we had delightful fried padr\u00f3n peppers.\n\nWalk over to Txepetxa Taberna for a little sandwich \u2014 my favorites were the simple ones filled with local j\u00e1mon and idiaz\u00e1bal cheese (similar to manchego).\n\nThe cheesy risotto at Borda Berri was phenomenal.\n\nFinish your night at Otaegui, the oldest bakery in the city, for pantxineta, a delightful puff pastry and custard-filled local treat, and a slice of Basque cheesecake.\n\n\npintxo hopping around the old town!\nsurfing\nNellie is a big surfer and after a full 24 hours of pestering, finally convinced me to go out with her. There are tons of surf shops that rent wetsuits and boards lining the beach, so it was really easy to get into the water. The waves were absolutely perfect. Gentle, clear water, no getting-stuck-in-a-washing-machine vibes when you fall of your board. It was so, so much fun.\n\n\n\nMy favorite part of the trip was our four days on the camino. The Camino de Santiago, also known as the Way of Saint James, is a well-trod pilgrimage route that traverses Spain, culminating at the Cathedral of Santiago de Compostela in Galicia. The camino has origins back to the medieval era and has four routes connecting different parts of Spain to Galicia. The routes consist of trails, modern roads, and original medieval stone pathways\u2026\n\n\nthat pass through everything from modern city to medieval village\u2026\n\n\nto small fishing town\u2026\n\n\nto stunning wilderness landscapes.\n\n\nThe flysch was truly breathtaking. If you wind up in San Sabasti\u00e1n and want to walk just one day of the camino, walk from Orio to Zumaia, all the way out past the town to see the flysch, then sleep at Hotel Iturregi that night!\nThe Camino Franc\u00e9s is the most popular route, but my friends and I did a small portion of the Camino Norte, which San Sebasti\u00e1n is right on. The Norte is challenging and stunningly beautiful, with steep, rugged terrain, but with plenty of stopping places for pintxos and a glass of wine along the way. It\u2019s hard to sum up what a wonderful experience hiking it was.\n\nWe originally wanted to hike directly from one location to the next \u2014 to hike from one hotel to the next without ever getting in a car \u2014 15 to 20 miles per day on the camino. However, the hotels along the route are rustic, more rustic than we were up for, so we wound up switching to stay at a gorgeous hotel in a txakoli vineyard, and just took cabs to and from the camino for our last two days.\n\nHiking the camino was a bucket list experience \u2014 we hiked through fishing villages and past a truly breathtaking flysch rock formation, a cult tried to recruit us by beckoning us in with warm tea and cake, we talked about everything, we talked about nothing, we laughed so hard it hurt. I cannot wait to get back to the camino one day.", "mimetype": "text/plain", "start_char_idx": 3444, "end_char_idx": 7665, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8e07fb3e-2d9a-4d5f-b20d-8e29ceddd806": {"__data__": {"id_": "8e07fb3e-2d9a-4d5f-b20d-8e29ceddd806", "embedding": null, "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8", "node_type": "4", "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "hash": "6061eae548a3e68c6421a88a68d57832afc2a5fca1ed9a1dfa6b4094d7f7e9da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39bfd395-9f2d-4d81-b460-e8486271cc5b", "node_type": "1", "metadata": {"source_url": "https://whattocook.substack.com/p/so-into-northern-spain", "document_index": 8}, "hash": "760fe5639c29d1ac97431a13c9f904747ec170a83567a44b7c550b429fc7462e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bilbao was an excellent urban re-introduction at the end of four days on the camino. We really didn\u2019t know what to expect, and we were pleasantly surprised. I wouldn\u2019t make a trip to Spain specifically for Bilbao, but I\u2019d certainly make an effort to visit if I was in Northern Spain.\n\nThe Guggenheim alone could occupy an entire day \u2014 it\u2019s a massive collection of modern and contemporary art. The architecture itself is reason alone to visit. We loved touring the museum with a private tour guide who regaled us with detailed information about every single piece.\n\n\nWe strolled along the river from the Guggenheim all the way to the seven streets area, where we bopped between shops and pintxo bars for the rest of the day. Admittedly, we enjoyed a lot of Italian food in Bilbao as we were feeling a little burnt out on Basque food by this point in the trip. No shame in dabbling in a little pizza while in Spain! You\u2019ll find lots of Basque and Italian recs on my map!\n\nAfter two nights in Bilbao, we headed home. It was a truly magical trip that we\u2019ll still be laughing and reminiscing about when we\u2019re old ladies.\n\n\n\nI love electrolyte powders but so many brands have a lot of sodium in them, which can make me feel really bloated. Ultima is lower-sodium and the flavors are great!\n\nLily had a lanyard strap iPhone case that I was really jealous of. Kind of dorky looking but who cares, it was so convenient to have her phone handy for photos and looking up directions!\n\nI will never stop yappin\u2019 about my Owala water bottle. Having the ability to drink out of the straw or tilt it and chug it never gets old!\n\nI brought disposable cameras for each of us and I can\u2019t wait to get the film back!! Mattis saw them and has been begging me to get him one \u2014 it would be fun to give your kids a disposable camera to capture a summer trip!\n\n\n\nPan-fried dover sole with buttery tomato sauce and corn risotto. The reviews on this week\u2019s recipe are RAVING! It really is so good and fancy feeling. You have to make this one ASAP, especially if you travel somewhere with access to great fish this summer!\n\nSunshine curry was a cult fave last summer \u2014 of yours and of mine! I love making a huge batch and eating it for lunch all week long (a perk of the fact that my kids won\u2019t touch it, though I know many kids love this one!).\n\nMy summer tomato galette is the stuff of summer produce dreams. Buy a store-bought pie crust to make it even easier, but it\u2019s worth making the crust from scratch if you have 15 extra minutes! PS: Make the boursin summer squash galette while you\u2019re at it. Two summery galettes + a simple salad of romaine tossed with salt, pepper, really good extra-virgin olive oil, and balsamic, with shaved Parm, and chopped almonds would be such a chic little meal.\n\nChicken panzanella is one of my all-time faves. Crisp croutons, juicy tomatoes, perfectly cooked chicken, balsamic, olive oil, basil, with big hunks of melty goat cheese. It\u2019s the perfect summer lunch or dinner! Don\u2019t let your croutons burn!\n\n\nI loved reading about all of your happy places in the comments of last week\u2019s post! My number one takeaway is that I need to spend more time in Maine \u2014 so many of your happy places are there! Including this week\u2019s winner, Heather.\n\n\nDreamy! And now you can bring your new pair of Lake Pajamas to Boothbay Harbor this summer! Email me your size and address!\n\nDo you have any Spain recs to add? Anyone taking an exciting trip this summer? We\u2019re staying local for most of the summer so that we can enjoy our new cabin, minus our annual two-week Southern voyage to DeBordieu, SC to visit George\u2019s family and Bald Head Island, NC to visit mine!", "mimetype": "text/plain", "start_char_idx": 7668, "end_char_idx": 11322, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "131db3e9-fcf2-41ac-bf30-b92152187672": {"__data__": {"id_": "131db3e9-fcf2-41ac-bf30-b92152187672", "embedding": null, "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9", "node_type": "4", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "ab5f3c6c0a4968f65b3f14146e11971fa19139d1543f09a4b524d0c3c7a988c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e32a7427-4a09-4cfb-b6a7-23701f5a9ca9", "node_type": "1", "metadata": {}, "hash": "1e51421937b2f3d9104fbad96367214b23407ddc69f288a98a1f8905e7988e4d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2018The Zone Of Interest\u2019 Ending Explained & Film Summary: What Happens To Rudolf And Hedwig Hoss?\nPUBLISHED\n\nFEBRUARY 21, 2024\nBY\nSOURYA SUR ROY\n0COMMENTS\nThe Zone Of Interest Ending Explained Film Summary Hedwig Ross, Rudolph Ross\nCredits: A24\nThe Zone of Interest is a new historical drama film by English filmmaker Jonathan Glazer that manages to recreate a terrible moment from history with a unique and devastating effect. Loosely adapted from Martin Amis\u2019 novel of the same name, the film\u2019s plot follows the Hoss family, who live right beside the Auschwitz concentration camp, going about their usual lives with no concern for the terrible crimes being committed right outside. The Zone of Interest is all about subtle, indirect expressions that are poignant enough to pierce through the visual layer, successfully making the viewer all the more uncomfortable with every passing minute.\n\nSpoiler Alert\n\nPlot Summary: What Is The Film About?\nThe Zone of Interest opens with a noticeably long black screen, with only a soft sound being eerily stretched in the background, perhaps preparing us for what is to unfold on screen over the next hundred or so minutes. When the visuals come on, though, there is nothing unusual or out of the ordinary, as a family is seen spending some personal time by the forested banks of a river. This is a secluded spot reserved only for the family, and it seems to be their most common way of spending leisure time. As the girls are led by a nanny through the bushes, possibly for some lesson in gardening and wildlife, the boys jump into the river along with their father. Sometime later, the family reunites and leaves the riverbank, driving away in two black, sinister-looking cars. On that very night, the father of the house is seen going around, switching off all the lights, before going to bed.\n\nWhile there is really nothing odd in this whole presentation of a family spending a day with themselves, the chilling reality of the matter is revealed when the film introduces the particular lot. The family is that of Rudolf Hoss, a notorious real figure from history, infamous for being a distinguished SS officer and the commander of the Auschwitz concentration camp. Most of the entire film, and the whole of the opening scene, actually takes place in Auschwitz, meaning that the leisurely picnic of the big family literally took place only a few miles away from the spot of the ongoing genocide. This is the very premise of The Zone of Interest, for it shows the tumultuous time of history from the perspective of the Hoss family, mainly the patriarch Rudolf and his wife, Hedwig.\n\nThe couple lives in an idyllic resort with their two sons and three daughters, the youngest still a baby, right on the other side of the high walls of the concentration camp. Despite the inhuman torture and killing going on right outside the walls that separate their lives, the Hoss family members are not perturbed by the matter at all. Instead, they are rather accustomed to Auschwitz, cherishing their time and accepting it as their new home.\n\nHow Does The Film Powerfully Present The Harrowing Events Of The Holocaust?\nThe most remarkable thing about The Zone of Interest is how it manages to say so much without directly saying it, combining the visual and the aural through a unique dissonance. With regards to the visuals, meaning scenes that play out to take forward the mostly simple and common story, the camera hardly ever leaves the confines of the host house. While some exceptions take place towards the latter part of the film, when Rudolf is transferred to a different concentration camp and he is seen at his new post, almost no scene of the camp in Auschwitz is seen. But the audio track picks up on numerous cries, lashes, and sounds that clearly come from the outside world but are heavily ignored. There is only one brief scene in which we are shown a side-angled close-up of Rudolf while he is at his workplace, which is a camp intended to kill Jews by the thousands. Indeed, the man is shot looking at the work he is rather proud of doing, amidst thick smoke bellowing out and loud cries and shrieks of helpless people. Rudolf certainly has no reservations about overseeing a genocide, but the film particularly shines with respect to how it uses the very usual to highlight the horrific context in the backdrop.\n\nEarly on in the film, Rudolf\u2019s family and his subordinates celebrate the man\u2019s birthday with a fancy cake, and all the Nazi soldiers come to his house to greet him. This merrymaking literally takes place all while hundreds, if not thousands, of families, are kept locked in the concentration camps and forced into the gas chambers.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4694, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e32a7427-4a09-4cfb-b6a7-23701f5a9ca9": {"__data__": {"id_": "e32a7427-4a09-4cfb-b6a7-23701f5a9ca9", "embedding": null, "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9", "node_type": "4", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "ab5f3c6c0a4968f65b3f14146e11971fa19139d1543f09a4b524d0c3c7a988c5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "131db3e9-fcf2-41ac-bf30-b92152187672", "node_type": "1", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "2da0ea751fd5cab4c800371cd077d001dc23f9db16c3de5dba3069f38969a457", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad511521-dd22-498f-8111-669566dee86a", "node_type": "1", "metadata": {}, "hash": "caab142f86cf0aa81d9721a0d568ad6e2972cd52a7508bce3b097d0d63717495", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "There is only one brief scene in which we are shown a side-angled close-up of Rudolf while he is at his workplace, which is a camp intended to kill Jews by the thousands. Indeed, the man is shot looking at the work he is rather proud of doing, amidst thick smoke bellowing out and loud cries and shrieks of helpless people. Rudolf certainly has no reservations about overseeing a genocide, but the film particularly shines with respect to how it uses the very usual to highlight the horrific context in the backdrop.\n\nEarly on in the film, Rudolf\u2019s family and his subordinates celebrate the man\u2019s birthday with a fancy cake, and all the Nazi soldiers come to his house to greet him. This merrymaking literally takes place all while hundreds, if not thousands, of families, are kept locked in the concentration camps and forced into the gas chambers. But nobody seems to notice, or rather, everyone pretends to look through the entire matter, as if nothing shocking is in the works. Rudolf is also seen meeting with a businessman in his house, who comes to show the commander plans and designs for a new, more effective gas chamber that he wants to build for his government. Rudolf goes through the plans without any hesitation and then also reports about this businessman\u2019s portfolio to his higher authorities, convinced that sturdier and better-designed gas chambers are needed to take his beloved nation and his government forward. The Zone of Interest does not really differentiate between evil-doers and those supporting such evil, but Rudolf is definitely in the first category, as he clearly enjoys the torture and killing of people.\n\nWhat comes as even a bigger shock is the reaction of his wife, Hedwig, for she does not react to any of these massacres either. Rather, the woman is extremely accustomed to the life of the commander\u2019s wife, and she enjoys the perks it brings along. She often receives luxury and expensive items that have been taken away from the prisoners, and on one particular occasion, she is seen receiving a fancy fur coat, since the Nazis did not differentiate between the rich and the poor among their targets. Hedwig immediately throws the coat on her body and tries it out in front of the mirror, only to realize that there is still lipstick lying inside one of the pockets. The presence of the lipstick would obviously be a bold reminder to anyone of the previous owner of the coat and the atrocious torture she must be subjected to at present. However, Hedwig has been wired to not think like that, and instead of any guilt or remorse, she feels rather excited to try on the lipstick, which is now hers as well.\n\nHedwig maintains a calm and composed nature, without any worry in the world, as she focuses on her gardening and getting a pool built for her children in their compound. The thick, dark smoke from the chimneys of the gas chambers on one side and from the steam engine train that brings in Jewish prisoners every day on the other does not affect the woman at all. The irony of the matter is all the more glaring when Hedwig is absolutely livid that her husband has to be transferred away from Auschwitz. She decides to stay back at the place along with her children because she is unwilling to uproot the life she had built there, including the fancy garden and the greenhouse, and shift somewhere else, which is probably too cold for her comfort as well. The fact that thousands were being faced with worse persecution and millions more would be uprooted, killed, or left disbanded very easily eludes her thought. In this regard, Jonathan Glazer\u2019s film is a really fascinating note on not just the Holocaust but also the effect of systematized violence and the tendency of the masses to side with the oppressors in any given scenario.\n\nThe Hoss children are also equally desensitized to seeing murder and killing around them. The boys play around with toy soldiers, all waging war against invisible enemies. Shockingly, they are also seen collecting and playing with gold teeth, which are literally the remains of people who had been killed in the camp. One of the daughters does seem to feel something odd about their house, or she simply sleepwalks as a habit and sits by the door as if waiting for someone to arrive. Nonetheless, this young girl would also grow accustomed to the situation one day and not find anything strange about it. The Jewish prisoners are allowed to get close to the house and the family, as many of them are given the task of cleaning the boots and bringing supplies to the place. But there is also a clear distinction that the Nazi commander maintains from them, which highlights the pure hatred breeding inside his perspective of the people.", "mimetype": "text/plain", "start_char_idx": 3845, "end_char_idx": 8565, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad511521-dd22-498f-8111-669566dee86a": {"__data__": {"id_": "ad511521-dd22-498f-8111-669566dee86a", "embedding": null, "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9", "node_type": "4", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "ab5f3c6c0a4968f65b3f14146e11971fa19139d1543f09a4b524d0c3c7a988c5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e32a7427-4a09-4cfb-b6a7-23701f5a9ca9", "node_type": "1", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "05ebd7e6e3a66587b6853617636a02fa0d8411f35d109c3364c1905236117d9d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7426a009-ede2-4c41-a30a-b3bc52195092", "node_type": "1", "metadata": {}, "hash": "bdc7d429fc2e86efaeccb62d17c6dbb0ea8b9b83c1cef567de924e4c87dbe44b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The Hoss children are also equally desensitized to seeing murder and killing around them. The boys play around with toy soldiers, all waging war against invisible enemies. Shockingly, they are also seen collecting and playing with gold teeth, which are literally the remains of people who had been killed in the camp. One of the daughters does seem to feel something odd about their house, or she simply sleepwalks as a habit and sits by the door as if waiting for someone to arrive. Nonetheless, this young girl would also grow accustomed to the situation one day and not find anything strange about it. The Jewish prisoners are allowed to get close to the house and the family, as many of them are given the task of cleaning the boots and bringing supplies to the place. But there is also a clear distinction that the Nazi commander maintains from them, which highlights the pure hatred breeding inside his perspective of the people. As soon as Rudolf finds a skull and some ashes in the river that he and his sons were bathing in, he scurries back to his house, and the children are scrubbed clean with utmost precision. In another instance, it is suggested that Rudolf forces himself upon a helpless prisoner woman, but he ensures that he scrubs his private parts before retiring for the night.\n\nThe only exception to the unaffected response by the entire family is by Hedwig\u2019s mother, who finds it bizarre that her daughter, her husband, and their children can really live at such a place. The elderly woman definitely has no sympathies for the prisoners, though, but she is rather unable to live with so many signs and reminders of death all around. The stench of burning human bodies and the ash flying around keep her up all night, but the very same elements are like playthings for the two young boys who still lay awake in their room. On a similar night, filled with reminders of the ongoing genocide, Hedwig is seen asking Rudolf to take her on a romantic trip, in the most romantic conversation between the couple in the film. Ultimately, the mother leaves the house unannounced very early the next morning, only leaving behind a note for her daughter. Hedwig simply tosses the note into her furnace insignificantly, almost insulted that someone would find her beloved home distasteful or discomforting. Even after Rudolf leaves for Oranienburg, Hedwig stays at their Auschwitz house with the children.\n\nWhat Do The Scenes In Infrared Signify?\nThe Zone of Interest also sparsely presents a few scenes, in which an unacquainted young girl is seen going around Auschwitz, hiding apples and other meager food items inside the trenches. She is clearly doing this extremely dangerous work only to help the prisoners and ease their suffering in whatever little way she can. But interestingly, these scenes are in infrared, or negative, although only as long as the girl is in the outside world. As soon as she returns home, the visuals turn normal, then switch to infrared when she or her mother step out on the balcony. The family is revealed to be Polish locals who have no interest in Nazi ideals and dream of liberation one day. However, the mere fact that the family is still alive, irrespective of whether they are Jewish or not, suggests that they also have to work as collaborators for the Nazis to a certain degree. This was definitely the case with numerous non-Jews during the Nazi occupation who had to work for the horrific authorities despite not wanting to. Going by that logic, the significance of the use of infrared might be in stating how the family cannot be themselves as soon as they step out of their house or into the open balcony as well. Although the girl takes on the dangerous responsibility of helping the prisoners, she still cannot express her true self in public, leading to her being shown in infrared. Another perspective is that the girl and her mother truly stand out in this horrific world solely because of their generous actions. Therefore, in a film like this, in which the Nazis and the enablers are the \u201cnormal\u201d people, anyone with any sense of humanity has to be visually differentiated from the Hoss family members.\n\nWhat Happens To Rudolf Hoss?\nDuring The Zone of Interest\u2018s ending, Rudolf is seen in his Berlin office as he telephones Hedwig and tells her about his excitement for the concentration camps being built. Rudolf had been given the responsibility of overseeing a new Nazi order in which Hungarian Jews were to be arrested and killed. Although Hedwig refuses to be part of this very direct talk of violence, for she prefers such matters to be in the background, the commander still feels thrilled. He is seen walking down the stairs from his office when suddenly bouts of violent retching hit him on two occasions.", "mimetype": "text/plain", "start_char_idx": 7630, "end_char_idx": 12407, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7426a009-ede2-4c41-a30a-b3bc52195092": {"__data__": {"id_": "7426a009-ede2-4c41-a30a-b3bc52195092", "embedding": null, "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9", "node_type": "4", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "ab5f3c6c0a4968f65b3f14146e11971fa19139d1543f09a4b524d0c3c7a988c5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad511521-dd22-498f-8111-669566dee86a", "node_type": "1", "metadata": {"source_url": "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/", "document_index": 9}, "hash": "cafaca74c5496fc6efb0feaa54018936add5c1e5b1f9a8d5afa75946946f0381", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Another perspective is that the girl and her mother truly stand out in this horrific world solely because of their generous actions. Therefore, in a film like this, in which the Nazis and the enablers are the \u201cnormal\u201d people, anyone with any sense of humanity has to be visually differentiated from the Hoss family members.\n\nWhat Happens To Rudolf Hoss?\nDuring The Zone of Interest\u2018s ending, Rudolf is seen in his Berlin office as he telephones Hedwig and tells her about his excitement for the concentration camps being built. Rudolf had been given the responsibility of overseeing a new Nazi order in which Hungarian Jews were to be arrested and killed. Although Hedwig refuses to be part of this very direct talk of violence, for she prefers such matters to be in the background, the commander still feels thrilled. He is seen walking down the stairs from his office when suddenly bouts of violent retching hit him on two occasions. In the middle of these two instances, The Zone of Interest briefly moves to modern times, and various reminders of the Holocaust are seen being maintained at the Auschwitz-Birkenau State Museum, right before the place is opened to public visitors. The last scene returns to the past once more, and Rudolf is seen feeling slightly odd, as if someone is watching him, as he continues down the stairs.\n\nThe Zone of Interest\u2018s ending scene seems to suggest that deep in his conscience, Rudolf Hoss does know that his actions can only make one retch, and almost like a fortune-teller, he has an uneasy feeling that his legacy will go down terribly in history. The scene of the museum is a fast jolt back to the right perspective, which had been missing throughout the film. Throughout the entire duration of The Zone of Interest, Rudolf, his family, and his professional associates had all been extremely invested in hiding the evidence and changing the narrative, but ultimately, the thousands of shoes or the torn, ragged uniforms still exist as reminders of the horrible genocide.", "mimetype": "text/plain", "start_char_idx": 11472, "end_char_idx": 13486, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d31ab3c-c813-40be-8fa9-b0f8958b8c96": {"__data__": {"id_": "5d31ab3c-c813-40be-8fa9-b0f8958b8c96", "embedding": null, "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10", "node_type": "4", "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "hash": "35472e69413e5a1251ae3cb2566fcffcc27dcf02e17f530516b6da2e805661fb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "65477189-2b3a-4214-b30f-6f36ae619863", "node_type": "1", "metadata": {}, "hash": "747a82daab8fe37d6cb727563f6f40f1294e01f135dd1598bd25fd3821ad9bbb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "manicfesto proposals\n26m tonnes of waste plastic bottles are discarded every year in the UK of which only 45% are recycled. The Loony Party has the answer.. Stop making them..\n\nBefore you ask\u2026We have found an alternative. Its called glass.\n\nSome of our Proposals for other elections\nAlong with the existing Government policy for levelling up the North with the South             we will provide free Spirit Levels to all\n\nWe will reduce inflation by giving everyone free pins.\n\nTo make trains safer, we will fit them all with cushions on the front.\n\nAny possible schemes thought up by Government, Council , NHS etc,  such as closure of Hosptitals, workplace parking levy etc will be preceded with a Public Consultation which we will then ignore.\n\nWe will combat corruption in public life by taking part in it openly, we will                              introduce the Board of Bribery who will set standardised rates?. #sleaze for the many not just the few\n\nWe propose to prevent identity theft instantly by calling everyone Chris.\n\nAll political and electoral leaflets will be printed on soft paper so that it may be recycled in the appropriate manner.\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce                   pregnancy from nine to seven months ?\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.\n\nWith Government helped finance, AstraZeneca should buy out Pfizer, then, as we would have the rights to Viagra, the economy may stay up longer.\n\nRedundant Red Phones boxes will be converted to bijou accommodation to ease the housing shortage.\n\nTo make things fairer we will introduce a Court of Human Lefts.\n\nGeneral Election 2022 Manicfesto\nGeneral Election 2022 Manicfesto  \u2014\u2014 For the Manic, Not the Few\n\nWe pledge to fight this election on an invisible platform so that people cannot see the floors in our policies.\n\nOnce in Government, we will replace the Foreign Secretary with a British one!\n\nWaitng Lists\n\nWe will reduce hospital waiting lists by using a smaller font.\n\nImmigration\n\nWe will reduce net migration by making sure that any nets are secured more firmly to the ground.\n\nInflation\n\nWe will reduce inflation by giving everyone free pins\n\nGovernment Policy\n\nWhen formulating Policies the Government relies heavily on Expert Advise. Remember  \u2013 Experts built the Titanic\n\nThe Loony Party will also take into account the opinion of \u201cDave on Facebook\u201d\n\nEnergy Policy\n\nWe will get rid of the Energy Price Cap and replace it with a Top Hat (This will also help our Millenery Industry)\n2. We will get rid of all Standing Charges. (We are quite capable of sitting down and freezing to death)\n3. All the hot air spoken in Parliament will be redirected to the Gas Distribution Networks.\nStressful times in the House\nIn order to calm down the passions and stresses currently exhibited in Parliament, the Loony Party would make all M.P\u2019s have half an hours compulsory Tai chi everyday.\nThis would counteract the other 23 \u00bd hours Chi Ting they do for the rest of the time\n\nCorruption\n\nWe in The Loony Party are quite willing to accept bribes , and inducements from the Government in exchange that we don\u2019t stand in the election.\nWe will combat corruption in public life by taking part in it openly, we will also introduce the Board of Bribery who will set standardised rates?\nNorthern Powerhouse\n\nThe Loony party will invest millions in the Northern Powerhouse.\nFor clarification all parties agree that, as normal, the North starts at Hadrians Wall and ends where Scotland starts\n\nBrexit\n\nThe Border in Northern Ireland would be made out of sponge to prevent a Hard Border\nWe will renegotiate to stay and lead the E.U and then sack the other 27 countries\nIdentity Theft\n\nWe propose to prevent identity theft instantly by calling everyone Dave.\n\nPlay Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy\u2019s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\n\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4633, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "65477189-2b3a-4214-b30f-6f36ae619863": {"__data__": {"id_": "65477189-2b3a-4214-b30f-6f36ae619863", "embedding": null, "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10", "node_type": "4", "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "hash": "35472e69413e5a1251ae3cb2566fcffcc27dcf02e17f530516b6da2e805661fb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5d31ab3c-c813-40be-8fa9-b0f8958b8c96", "node_type": "1", "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "hash": "8c35c980cd0a0d37bb90fd565a3de9e3884b0a1a19a2dbbef759a9fa25d785a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "deea83e8-16cc-4aca-b15f-db68853d1c71", "node_type": "1", "metadata": {}, "hash": "372495c3755b47762a57f544e5bbf04c34915a56d86c2afa38555fde70268d00", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Play Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy\u2019s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\n\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?\n\nGeneral Election 2019 Manicfesto\nGeneral Election 2019 Manicfesto  \u2014\u2014 For the Manic, Not the Few\n\nWe pledge to fight this election on an invisible platform so that people cannot see the floors in our policies.\n\nStressful times in the House\nIn order to calm down the passions and stresses currently exhibited in Parliament, the Loony Party would make all M.P\u2019s have half an hours compulsory Tai chi everyday.\nThis would counteract the other 23 \u00bd hours Chi Ting they do for the rest of the time\n\nCorruption\n\nWe in The Loony Party are quite willing to accept bribes , and inducements from the Government in exchange that we don\u2019t stand in the election.\nWe will combat corruption in public life by taking part in it openly, we will also introduce the Board of Bribery who will set standardised rates?\nNorthern Powerhouse\n\nThe Loony party will invest millions in the Northern Powerhouse.\nFor clarification all parties agree that, as normal, the North starts at Hadrians Wall and ends where Scotland starts\n\nBrexit\n\nThe Border in Northern Ireland would be made out of sponge to prevent a Hard Border\nWe will renegotiate to stay and lead the E.U and then sack the other 27 countries\nIdentity Theft\n\nWe propose to prevent identity theft instantly by calling everyone Dave.\n\nPlay Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy\u2019s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will rename the current Oyster cards, \u2018Sardine Cards\u2019 to better reflect the experience when travelling on public transport\n2. We will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?\n\nPolicies\nWe encourage everyone, even current politicians, to submit ideas to our world famous #Manicfesto! The following are some of the most recent from our wonderful Twitter followers\u2026\n\nOnce in Government, anyone applying for 7 figure salary positions with the World Health Organisation or as Govt Health Advisors, will have to answer 15 correct questions on \u201cWHO wants to be a Millionaire\u201d.\nIn Brexit Trade Deals: Germany will be required to pay for treatment of Measles, and Spain will be required to pay for cases of Spanish Flu. The French will pay for all accidents resulting from kissing & broken letters & the Dutch will split all future expenses 50/50.\nWe will place in law measures to stop panic buying as COVID19 restrictions take hold. Shoppers will only be permitted to buy one panic per person.\nIt is evident that the 10pm pub curfew is not working , We propose that pubs ask people to leave in alphabetical order.\nShamefully Lord Sutch has never been allowed to take his place in the House of Lords. Nor were Duke Ellington, Count Basie or Lord Rockingham We will end this discrimination against musicians.\nTo unite the population, we will surround the UK with a large cardboard box so people can be both in and/or out of the EU. This will be known as Schrodinger\u2019s Brexit.\nTo get more children reading, fish and chips will once again be wrapped in newspaper.\nOnce in Government we will introduce the Ministry of Clarity. The role of this Ministry will ensure that only the clearest clarity is made clear and the unclear clarity is cleared out. We hope that our position on this is now clear to all.", "mimetype": "text/plain", "start_char_idx": 3830, "end_char_idx": 8449, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "deea83e8-16cc-4aca-b15f-db68853d1c71": {"__data__": {"id_": "deea83e8-16cc-4aca-b15f-db68853d1c71", "embedding": null, "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10", "node_type": "4", "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "hash": "35472e69413e5a1251ae3cb2566fcffcc27dcf02e17f530516b6da2e805661fb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65477189-2b3a-4214-b30f-6f36ae619863", "node_type": "1", "metadata": {"source_url": "https://www.loonyparty.com/about/policy-proposals/", "document_index": 10}, "hash": "60d615dfbf86f6193bddbd46de1e887f68d9290477d06c47acd85a950530beeb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Shoppers will only be permitted to buy one panic per person.\nIt is evident that the 10pm pub curfew is not working , We propose that pubs ask people to leave in alphabetical order.\nShamefully Lord Sutch has never been allowed to take his place in the House of Lords. Nor were Duke Ellington, Count Basie or Lord Rockingham We will end this discrimination against musicians.\nTo unite the population, we will surround the UK with a large cardboard box so people can be both in and/or out of the EU. This will be known as Schrodinger\u2019s Brexit.\nTo get more children reading, fish and chips will once again be wrapped in newspaper.\nOnce in Government we will introduce the Ministry of Clarity. The role of this Ministry will ensure that only the clearest clarity is made clear and the unclear clarity is cleared out. We hope that our position on this is now clear to all.\nIn Government, we will complete a 5 year Parliament in only 4 years. This policy not only ensures a 20% saving for the public purse but also gives everyone in the UK a year off from listening to our politicians.\nThe MOT is an annual test to ensure that your car is roadworthy. We will introduce a ROT, an annual test to make sure all roads are car worthy.\nAnd from 1st January 2021, passports will be issued in the colour of political voting. Tories will be Blue, Labour will be Red, Greens will be green. Official Loonies will have leopard spots, and Lib Dem\u2019s will be invisible.\nChinners\n\nForeign Policy\nWe will Admit Shamima Begum back to the country only when she accepts Screaming Lord Sutch as her saviour.\n\nMinistry of Info\nWe will create a New Ministry of Information. It shall consist of the former board of directors of Cambridge Analytica. They already know everything.\n\nBrexit Proposals\nWe will Send Noel Edmonds to negotiate Brexit because he understands Deal or No Deal.\nThere will be no need for a backstop to the Brexit negotiations. We\u2019ll have Alec Stewart as wicket-keeper.\nJames Wallace\n\nEducational Funding\nThe Loony Party proposes that all Schools would have a Jumble sale or fete or other fundraising event at least twice per month to help raise funds for those little extras. . . such as Desks, Books, paper, pens , etc\nR.U. Seerius\n\nPensions \u2013 triple lock\nIn keeping with the Labour Party\u2019s latest bid to get one or two pensioners to vote for them they have brought out a new policy guaranteeing the Triple lock on pensions until 2025 if they get voted in.\nThe Loony party of course will go one better and buy a padlock, and as its now safer than a bank,  new mattresses for all pensioners on less than 20p per week.\nR.U. Seerius", "mimetype": "text/plain", "start_char_idx": 7583, "end_char_idx": 10203, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "debd681b-80fe-4b48-bfe5-ab0cf28023f0": {"__data__": {"id_": "debd681b-80fe-4b48-bfe5-ab0cf28023f0", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1df0b303-84f6-410b-8421-60e44489f4cd", "node_type": "1", "metadata": {}, "hash": "ee0cbd5765ec5e66dd556bb6afba4578cd6118335ee25e1173d0fe8fc58337f3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning\n2023-01-30 by Tim Dettmers 1,664 Comments\n\nDeep learning is a field with intense computational requirements, and your choice of GPU will fundamentally determine your deep learning experience. But what features are important if you want to buy a new GPU? GPU RAM, cores, tensor cores, caches? How to make a cost-efficient choice? This blog post will delve into these questions, tackle common misconceptions, give you an intuitive understanding of how to think about GPUs, and will lend you advice, which will help you to make a choice that is right for you.\n\nThis blog post is designed to give you different levels of understanding of GPUs and the new Ampere series GPUs from NVIDIA. You have the choice: (1) If you are not interested in the details of how GPUs work, what makes a GPU fast compared to a CPU, and what is unique about the new NVIDIA RTX 40 Ampere series, you can skip right to the performance and performance per dollar charts and the recommendation section. The cost/performance numbers form the core of the blog post and the content surrounding it explains the details of what makes up GPU performance.\n\n(2) If you worry about specific questions, I have answered and addressed the most common questions and misconceptions in the later part of the blog post.\n\n(3) If you want to get an in-depth understanding of how GPUs, caches, and Tensor Cores work, the best is to read the blog post from start to finish. You might want to skip a section or two based on your understanding of the presented topics.\n\nContents  hide\nOverview\nHow do GPUs work?\nThe Most Important GPU Specs for Deep Learning Processing Speed\nTensor Cores\nMatrix multiplication without Tensor Cores\nMatrix multiplication with Tensor Cores\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nMemory Bandwidth\nL2 Cache / Shared Memory / L1 Cache / Registers\nEstimating Ada / Hopper Deep Learning Performance\nPractical Ada / Hopper Speed Estimates\nPossible Biases in Estimates\nAdvantages and Problems for RTX40 and RTX 30 Series\nSparse Network Training\nLow-precision Computation\nFan Designs and GPUs Temperature Issues\n3-slot Design and Power Issues\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\n8-bit Float Support in H100 and RTX 40 series GPUs\nRaw Performance Ranking of GPUs\nGPU Deep Learning Performance per Dollar\nGPU Recommendations\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nDo I need 8x/16x PCIe lanes?\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nCan I use multiple GPUs of different GPU types?\nWhat is NVLink, and is it useful?\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nWhat do I need to parallelize across two machines?\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nDo I need an Intel CPU to power a multi-GPU setup?\nDoes computer case design matter for cooling?\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nVersion History\nAcknowledgments\nRelated\nRelated Posts\nOverview\nThis blog post is structured in the following way. First, I will explain what makes a GPU fast. I will discuss CPUs vs GPUs, Tensor Cores, memory bandwidth, and the memory hierarchy of GPUs and how these relate to deep learning performance. These explanations might help you get a more intuitive sense of what to look for in a GPU. I discuss the unique features of the new NVIDIA RTX 40 Ampere GPU series that are worth considering if you buy a GPU. From there, I make GPU recommendations for different scenarios. After that follows a Q&A section of common questions posed to me in Twitter threads; in that section, I will also address common misconceptions and some miscellaneous issues, such as cloud vs desktop, cooling, AMD vs NVIDIA, and others.\n\nHow do GPUs work?\nIf you use GPUs frequently, it is useful to understand how they work.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4345, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1df0b303-84f6-410b-8421-60e44489f4cd": {"__data__": {"id_": "1df0b303-84f6-410b-8421-60e44489f4cd", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "debd681b-80fe-4b48-bfe5-ab0cf28023f0", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "c4397f03e5f00f89aa129acec5c748bc6d17583f5cc901ea40ce092f004530c4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9db1d98-6162-49bd-a790-071a68aa2242", "node_type": "1", "metadata": {}, "hash": "baedfb74f5eba473b462725ce5d3a60b938246cd7a0d9bba95c5bff9222e6818", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Version History\nAcknowledgments\nRelated\nRelated Posts\nOverview\nThis blog post is structured in the following way. First, I will explain what makes a GPU fast. I will discuss CPUs vs GPUs, Tensor Cores, memory bandwidth, and the memory hierarchy of GPUs and how these relate to deep learning performance. These explanations might help you get a more intuitive sense of what to look for in a GPU. I discuss the unique features of the new NVIDIA RTX 40 Ampere GPU series that are worth considering if you buy a GPU. From there, I make GPU recommendations for different scenarios. After that follows a Q&A section of common questions posed to me in Twitter threads; in that section, I will also address common misconceptions and some miscellaneous issues, such as cloud vs desktop, cooling, AMD vs NVIDIA, and others.\n\nHow do GPUs work?\nIf you use GPUs frequently, it is useful to understand how they work. This knowledge will help you to undstand cases where are GPUs fast or slow. In turn, you might be able to understand better why you need a GPU in the first place and how other future hardware options might be able to compete. You can skip this section if you just want the useful performance numbers and arguments to help you decide which GPU to buy. The best high-level explanation for the question of how GPUs work is my following Quora answer:\n\nRead Tim Dettmers\u2018 answer to Why are GPUs well-suited to deep learning? on Quora\nThis is a high-level explanation that explains quite well why GPUs are better than CPUs for deep learning. If we look at the details, we can understand what makes one GPU better than another.\n\nThe Most Important GPU Specs for Deep Learning Processing Speed\nThis section can help you build a more intuitive understanding of how to think about deep learning performance. This understanding will help you to evaluate future GPUs by yourself. This section is sorted by the importance of each component. Tensor Cores are most important, followed by memory bandwidth of a GPU, the cache hierachy, and only then FLOPS of a GPU.\n\nTensor Cores\nTensor Cores are tiny cores that perform very efficient matrix multiplication. Since the most expensive part of any deep neural network is matrix multiplication Tensor Cores are very useful. In fast, they are so powerful, that I do not recommend any GPUs that do not have Tensor Cores.\n\nIt is helpful to understand how they work to appreciate the importance of these computational units specialized for matrix multiplication. Here I will show you a simple example of A*B=C matrix multiplication, where all matrices have a size of 32\u00d732, what a computational pattern looks like with and without Tensor Cores. This is a simplified example, and not the exact way how a high performing matrix multiplication kernel would be written, but it has all the basics. A CUDA programmer would take this as a first \u201cdraft\u201d and then optimize it step-by-step with concepts like double buffering, register optimization, occupancy optimization, instruction-level parallelism, and many others, which I will not discuss at this point.\n\nTo understand this example fully, you have to understand the concepts of cycles. If a processor runs at 1GHz, it can do 10^9 cycles per second. Each cycle represents an opportunity for computation. However, most of the time, operations take longer than one cycle. Thus we essentially have a queue where the next operations needs to wait for the next operation to finish. This is also called the latency of the operation.\n\nHere are some important latency cycle timings for operations. These times can change from GPU generation to GPU generation. These numbers are for Ampere GPUs, which have relatively slow caches.\n\nGlobal memory access (up to 80GB): ~380 cycles\nL2 cache: ~200 cycles\nL1 cache or Shared memory access (up to 128 kb per Streaming Multiprocessor): ~34 cycles\nFused multiplication and addition, a*b+c (FFMA): 4 cycles\nTensor Core matrix multiply: 1 cycle\nEach operation is always performed by a pack of 32 threads. This pack is termed a warp of threads. Warps usually operate in a synchronous pattern \u2014 threads within a warp have to wait for each other. All memory operations on the GPU are optimized for warps. For example, loading from global memory happens at a granularity of 32*4 bytes, exactly 32 floats, exactly one float for each thread in a warp. We can have up to 32 warps = 1024 threads in a streaming multiprocessor (SM), the GPU-equivalent of a CPU core. The resources of an SM are divided up among all active warps.", "mimetype": "text/plain", "start_char_idx": 3443, "end_char_idx": 7970, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d9db1d98-6162-49bd-a790-071a68aa2242": {"__data__": {"id_": "d9db1d98-6162-49bd-a790-071a68aa2242", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1df0b303-84f6-410b-8421-60e44489f4cd", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "db5a8d45c4b7f00c9c1c6ee36c8ec438e404a1aa6645bcf7714485859df5ec13", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d2f0120b-892c-4851-95a4-60d9c303ca79", "node_type": "1", "metadata": {}, "hash": "3321a18c3bb3499959fde19c7bdc299846896210a98e035c9534578c24d16035", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This pack is termed a warp of threads. Warps usually operate in a synchronous pattern \u2014 threads within a warp have to wait for each other. All memory operations on the GPU are optimized for warps. For example, loading from global memory happens at a granularity of 32*4 bytes, exactly 32 floats, exactly one float for each thread in a warp. We can have up to 32 warps = 1024 threads in a streaming multiprocessor (SM), the GPU-equivalent of a CPU core. The resources of an SM are divided up among all active warps. This means that sometimes we want to run fewer warps to have more registers/shared memory/Tensor Core resources per warp.\n\nFor both of the following examples, we assume we have the same computational resources. For this small example of a 32\u00d732 matrix multiply, we use 8 SMs (about 10% of an RTX 3090) and 8 warps per SM.\n\nTo understand how the cycle latencies play together with resources like threads per SM and shared memory per SM, we now look at examples of matrix multiplication. While the following example roughly follows the sequence of computational steps of matrix multiplication for both with and without Tensor Cores, please note that these are very simplified examples. Real cases of matrix multiplication involve much larger shared memory tiles and slightly different computational patterns.\n\nMatrix multiplication without Tensor Cores\nIf we want to do an A*B=C matrix multiply, where each matrix is of size 32\u00d732, then we want to load memory that we repeatedly access into shared memory because its latency is about five times lower (200 cycles vs 34 cycles). A memory block in shared memory is often referred to as a memory tile or just a tile. Loading two 32\u00d732 floats into a shared memory tile can happen in parallel by using 2*32 warps. We have 8 SMs with 8 warps each, so due to parallelization, we only need to do a single sequential load from global to shared memory, which takes 200 cycles.\n\nTo do the matrix multiplication, we now need to load a vector of 32 numbers from shared memory A and shared memory B and perform a fused multiply-and-accumulate (FFMA). Then store the outputs in registers C. We divide the work so that each SM does 8x dot products (32\u00d732) to compute 8 outputs of C. Why this is exactly 8 (4 in older algorithms) is very technical. I recommend Scott Gray\u2019s blog post on matrix multiplication to understand this. This means we have 8x shared memory accesses at the cost of 34 cycles each and 8 FFMA operations (32 in parallel), which cost 4 cycles each. In total, we thus have a cost of:\n\n200 cycles (global memory) + 8*34 cycles (shared memory) + 8*4 cycles (FFMA) = 504 cycles\n\nLet\u2019s look at the cycle cost of using Tensor Cores.\n\nMatrix multiplication with Tensor Cores\nWith Tensor Cores, we can perform a 4\u00d74 matrix multiplication in one cycle. To do that, we first need to get memory into the Tensor Core. Similarly to the above, we need to read from global memory (200 cycles) and store in shared memory. To do a 32\u00d732 matrix multiply, we need to do 8\u00d78=64 Tensor Cores operations. A single SM has 8 Tensor Cores. So with 8 SMs, we have 64 Tensor Cores \u2014 just the number that we need! We can transfer the data from shared memory to the Tensor Cores with 1 memory transfers (34 cycles) and then do those 64 parallel Tensor Core operations (1 cycle). This means the total cost for Tensor Cores matrix multiplication, in this case, is:\n\n200 cycles (global memory) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 235 cycles.\n\nThus we reduce the matrix multiplication cost significantly from 504 cycles to 235 cycles via Tensor Cores. In this simplified case, the Tensor Cores reduced the cost of both shared memory access and FFMA operations.\n\nThis example is simplified, for example, usually each thread needs to calculate which memory to read and write to as you transfer data from global memory to shared memory. With the new Hooper (H100) architectures we additionally have the Tensor Memory Accelerator (TMA) compute these indices in hardware and thus help each thread to focus on more computation rather than computing indices.", "mimetype": "text/plain", "start_char_idx": 7456, "end_char_idx": 11559, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d2f0120b-892c-4851-95a4-60d9c303ca79": {"__data__": {"id_": "d2f0120b-892c-4851-95a4-60d9c303ca79", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9db1d98-6162-49bd-a790-071a68aa2242", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "6a269ee5a7e3c5cc34e46876f52646696b6ac52e4e1a8a8719daf5914e9523bd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45fa019f-88b7-429e-b1c5-c7f28097f5c0", "node_type": "1", "metadata": {}, "hash": "e64d933e58463364347e93376b64f936640e30f4ad3558060bc1c8d262e8f5b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This means the total cost for Tensor Cores matrix multiplication, in this case, is:\n\n200 cycles (global memory) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 235 cycles.\n\nThus we reduce the matrix multiplication cost significantly from 504 cycles to 235 cycles via Tensor Cores. In this simplified case, the Tensor Cores reduced the cost of both shared memory access and FFMA operations.\n\nThis example is simplified, for example, usually each thread needs to calculate which memory to read and write to as you transfer data from global memory to shared memory. With the new Hooper (H100) architectures we additionally have the Tensor Memory Accelerator (TMA) compute these indices in hardware and thus help each thread to focus on more computation rather than computing indices.\n\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nThe RTX 30 Ampere and RTX 40 Ada series GPUs additionally have support to perform asynchronous transfers between global and shared memory. The H100 Hopper GPU extends this further by introducing the Tensor Memory Accelerator (TMA) unit. the TMA unit combines asynchronous copies and index calculation for read and writes simultaneously \u2014 so each thread no longer needs to calculate which is the next element to read and each thread can focus on doing more matrix multiplication calculations. This looks as follows.\n\nThe TMA unit fetches memory from global to shared memory (200 cycles). Once the data arrives, the TMA unit fetches the next block of data asynchronously from global memory. While this is happening, the threads load data from shared memory and perform the matrix multiplication via the tensor core. Once the threads are finished they wait for the TMA unit to finish the next data transfer, and the sequence repeats.\n\nAs such, due to the asynchronous nature, the second global memory read by the TMA unit is already progressing as the threads process the current shared memory tile. This means, the second read takes only 200 \u2013 34 \u2013 1 = 165 cycles.\n\nSince we do many reads, only the first memory access will be slow and all other memory accesses will be partially overlapped with the TMA unit. Thus on average, we reduce the time by 35 cycles.\n\n165 cycles (wait for async copy to finish) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 200 cycles.\n\nWhich accelerates the matrix multiplication by another 15%.\n\nFrom these examples, it becomes clear why the next attribute, memory bandwidth, is so crucial for Tensor-Core-equipped GPUs. Since global memory is the by far the largest cycle cost for matrix multiplication with Tensor Cores, we would even have faster GPUs if the global memory latency could be reduced. We can do this by either increasing the clock frequency of the memory (more cycles per second, but also more heat and higher energy requirements) or by increasing the number of elements that can be transferred at any one time (bus width).\n\nMemory Bandwidth\nFrom the previous section, we have seen that Tensor Cores are very fast. So fast, in fact, that they are idle most of the time as they are waiting for memory to arrive from global memory. For example, during GPT-3-sized training, which uses huge matrices \u2014 the larger, the better for Tensor Cores \u2014 we have a Tensor Core TFLOPS utilization of about 45-65%, meaning that even for the large neural networks about 50% of the time, Tensor Cores are idle.\n\nThis means that when comparing two GPUs with Tensor Cores, one of the single best indicators for each GPU\u2019s performance is their memory bandwidth. For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of speedup of an A100 vs V100 is 1555/900 = 1.73x.\n\nL2 Cache / Shared Memory / L1 Cache / Registers\nSince memory transfers to the Tensor Cores are the limiting factor in performance, we are looking for other GPU attributes that enable faster memory transfer to Tensor Cores. L2 cache, shared memory, L1 cache, and amount of registers used are all related. To understand how a memory hierarchy enables faster memory transfers, it helps to understand how matrix multiplication is performed on a GPU.\n\nTo perform matrix multiplication, we exploit the memory hierarchy of a GPU that goes from slow global memory, to faster L2 memory, to fast local shared memory, to lightning-fast registers. However, the faster the memory, the smaller it is.", "mimetype": "text/plain", "start_char_idx": 10773, "end_char_idx": 15198, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "45fa019f-88b7-429e-b1c5-c7f28097f5c0": {"__data__": {"id_": "45fa019f-88b7-429e-b1c5-c7f28097f5c0", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d2f0120b-892c-4851-95a4-60d9c303ca79", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "841e2cc4aa1f2de5f101948a30bb74efc738b849542e5614b539fafc7b628268", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c24d900a-97cf-4a9c-a431-fa476932e093", "node_type": "1", "metadata": {}, "hash": "d3320f6ce281afc630e36454f3d1927684f3fb97043472e70ead778f980cc192", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of speedup of an A100 vs V100 is 1555/900 = 1.73x.\n\nL2 Cache / Shared Memory / L1 Cache / Registers\nSince memory transfers to the Tensor Cores are the limiting factor in performance, we are looking for other GPU attributes that enable faster memory transfer to Tensor Cores. L2 cache, shared memory, L1 cache, and amount of registers used are all related. To understand how a memory hierarchy enables faster memory transfers, it helps to understand how matrix multiplication is performed on a GPU.\n\nTo perform matrix multiplication, we exploit the memory hierarchy of a GPU that goes from slow global memory, to faster L2 memory, to fast local shared memory, to lightning-fast registers. However, the faster the memory, the smaller it is.\n\nWhile logically, L2 and L1 memory are the same, L2 cache is larger and thus the average physical distance that need to be traversed to retrieve a cache line is larger. You can see the L1 and L2 caches as organized warehouses where you want to retrieve an item. You know where the item is, but to go there takes on average much longer for the larger warehouse. This is the essential difference between L1 and L2 caches. Large = slow, small = fast.\n\nFor matrix multiplication we can use this hierarchical separate into smaller and smaller and thus faster and faster chunks of memory to perform very fast matrix multiplications. For that, we need to chunk the big matrix multiplication into smaller sub-matrix multiplications. These chunks are called memory tiles, or often for short just tiles.\n\nWe perform matrix multiplication across these smaller tiles in local shared memory that is fast and close to the streaming multiprocessor (SM) \u2014 the equivalent of a CPU core. With Tensor Cores, we go a step further: We take each tile and load a part of these tiles into Tensor Cores which is directly addressed by registers. A matrix memory tile in L2 cache is 3-5x faster than global GPU memory (GPU RAM), shared memory is ~7-10x faster than the global GPU memory, whereas the Tensor Cores\u2019 registers are ~200x faster than the global GPU memory.\n\nHaving larger tiles means we can reuse more memory. I wrote about this in detail in my TPU vs GPU blog post. In fact, you can see TPUs as having very, very, large tiles for each Tensor Core. As such, TPUs can reuse much more memory with each transfer from global memory, which makes them a little bit more efficient at matrix multiplications than GPUs.\n\nEach tile size is determined by how much memory we have per streaming multiprocessor (SM) and how much we L2 cache we have across all SMs. We have the following shared memory sizes on the following architectures:\n\nVolta (Titan V): 128kb shared memory / 6 MB L2\nTuring (RTX 20s series): 96 kb shared memory / 5.5 MB L2\nAmpere (RTX 30s series): 128 kb shared memory / 6 MB L2\nAda (RTX 40s series): 128 kb shared memory / 72 MB L2\nWe see that Ada has a much larger L2 cache allowing for larger tile sizes, which reduces global memory access. For example, for BERT large during training, the input and weight matrix of any matrix multiplication fit neatly into the L2 cache of Ada (but not other Us). As such, data needs to be loaded from global memory only once and then data is available throught the L2 cache, making matrix multiplication about 1.5 \u2013 2.0x faster for this architecture for Ada. For larger models the speedups are lower during training but certain sweetspots exist which may make certain models much faster. Inference, with a batch size larger than 8 can also benefit immensely from the larger L2 caches.\n\nEstimating Ada / Hopper Deep Learning Performance\nThis section is for those who want to understand the more technical details of how I derive the performance estimates for Ampere GPUs. If you do not care about these technical aspects, it is safe to skip this section.\n\nPractical Ada / Hopper Speed Estimates\nSuppose we have an estimate for one GPU of a GPU-architecture like Hopper, Ada, Ampere, Turing, or Volta. It is easy to extrapolate these results to other GPUs from the same architecture/series.", "mimetype": "text/plain", "start_char_idx": 14347, "end_char_idx": 18518, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c24d900a-97cf-4a9c-a431-fa476932e093": {"__data__": {"id_": "c24d900a-97cf-4a9c-a431-fa476932e093", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45fa019f-88b7-429e-b1c5-c7f28097f5c0", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "488475d1ad8acc16a58f703f7d0f7a187943b23a1f6da5624cbaa6a8dd3d9779", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42178690-1c55-4503-be7e-9e9eb62663c8", "node_type": "1", "metadata": {}, "hash": "c231358c65e510a5414af6682db28efd0460a28e3f0687e4e7c939ce029db0b3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For larger models the speedups are lower during training but certain sweetspots exist which may make certain models much faster. Inference, with a batch size larger than 8 can also benefit immensely from the larger L2 caches.\n\nEstimating Ada / Hopper Deep Learning Performance\nThis section is for those who want to understand the more technical details of how I derive the performance estimates for Ampere GPUs. If you do not care about these technical aspects, it is safe to skip this section.\n\nPractical Ada / Hopper Speed Estimates\nSuppose we have an estimate for one GPU of a GPU-architecture like Hopper, Ada, Ampere, Turing, or Volta. It is easy to extrapolate these results to other GPUs from the same architecture/series. Luckily, NVIDIA already benchmarked the A100 vs V100 vs H100 across a wide range of computer vision and natural language understanding tasks. Unfortunately, NVIDIA made sure that these numbers are not directly comparable by using different batch sizes and the number of GPUs whenever possible to favor results for the H100 GPU. So in a sense, the benchmark numbers are partially honest, partially marketing numbers. In general, you could argue that using larger batch sizes is fair, as the H100/A100 GPU has more memory. Still, to compare GPU architectures, we should evaluate unbiased memory performance with the same batch size.\n\nTo get an unbiased estimate, we can scale the data center GPU results in two ways: (1) account for the differences in batch size, (2) account for the differences in using 1 vs 8 GPUs. We are lucky that we can find such an estimate for both biases in the data that NVIDIA provides.\n\nDoubling the batch size increases throughput in terms of images/s (CNNs) by 13.6%. I benchmarked the same problem for transformers on my RTX Titan and found, surprisingly, the very same result: 13.5% \u2014 it appears that this is a robust estimate.\n\nAs we parallelize networks across more and more GPUs, we lose performance due to some networking overhead. The A100 8x GPU system has better networking (NVLink 3.0) than the V100 8x GPU system (NVLink 2.0) \u2014 this is another confounding factor. Looking directly at the data from NVIDIA, we can find that for CNNs, a system with 8x A100 has a 5% lower overhead than a system of 8x V100. This means if going from 1x A100 to 8x A100 gives you a speedup of, say, 7.00x, then going from 1x V100 to 8x V100 only gives you a speedup of 6.67x.  For transformers, the figure is 7%.\n\nUsing these figures, we can estimate the speedup for a few specific deep learning architectures from the direct data that NVIDIA provides. The Tesla A100 offers the following speedup over the Tesla V100:\n\nSE-ResNeXt101: 1.43x\nMasked-R-CNN: 1.47x\nTransformer (12 layer, Machine Translation, WMT14 en-de): 1.70x\nThus, the figures are a bit lower than the theoretical estimate for computer vision. This might be due to smaller tensor dimensions, overhead from operations that are needed to prepare the matrix multiplication like img2col or Fast Fourier Transform (FFT), or operations that cannot saturate the GPU (final layers are often relatively small). It could also be artifacts of the specific architectures (grouped convolution).\n\nThe practical transformer estimate is very close to the theoretical estimate. This is probably because algorithms for huge matrices are very straightforward. I will use these practical estimates to calculate the cost efficiency of GPUs.\n\nPossible Biases in Estimates\nThe estimates above are for H100, A100 , and V100 GPUs. In the past, NVIDIA sneaked unannounced performance degradations into the \u201cgaming\u201d RTX GPUs: (1) Decreased Tensor Core utilization, (2) gaming fans for cooling, (3) disabled peer-to-peer GPU transfers. It might be possible that there are unannounced performance degradations in the RTX 40 series compared to the full Hopper H100.\n\nAs of now, one of these degradations was found for Ampere GPUs: Tensor Core performance was decreased so that RTX 30 series GPUs are not as good as Quadro cards for deep learning purposes. This was also done for the RTX 20 series, so it is nothing new, but this time it was also done for the Titan equivalent card, the RTX 3090. The RTX Titan did not have performance degradation enabled.", "mimetype": "text/plain", "start_char_idx": 17789, "end_char_idx": 22028, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42178690-1c55-4503-be7e-9e9eb62663c8": {"__data__": {"id_": "42178690-1c55-4503-be7e-9e9eb62663c8", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c24d900a-97cf-4a9c-a431-fa476932e093", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "9a562ffcc04a7f535f335af55aa49dcf60725411de869c92986db7483ce82c76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b885cc51-9921-4ecc-8b57-df4e636b037d", "node_type": "1", "metadata": {}, "hash": "7601207d101e6fd794e31fdc1799c9f552b2d4c7cba8fb7a834a9589b95ae598", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Possible Biases in Estimates\nThe estimates above are for H100, A100 , and V100 GPUs. In the past, NVIDIA sneaked unannounced performance degradations into the \u201cgaming\u201d RTX GPUs: (1) Decreased Tensor Core utilization, (2) gaming fans for cooling, (3) disabled peer-to-peer GPU transfers. It might be possible that there are unannounced performance degradations in the RTX 40 series compared to the full Hopper H100.\n\nAs of now, one of these degradations was found for Ampere GPUs: Tensor Core performance was decreased so that RTX 30 series GPUs are not as good as Quadro cards for deep learning purposes. This was also done for the RTX 20 series, so it is nothing new, but this time it was also done for the Titan equivalent card, the RTX 3090. The RTX Titan did not have performance degradation enabled.\n\nCurrently, no degradation for Ada GPUs are known, but I update this post with news on this and let my followers on twitter know.\n\nAdvantages and Problems for RTX40 and RTX 30 Series\nThe new NVIDIA Ampere RTX 30 series has additional benefits over the NVIDIA Turing RTX 20 series, such as sparse network training and inference. Other features, such as the new data types, should be seen more as an ease-of-use-feature as they provide the same performance boost as Turing does but without any extra programming required.\n\nThe Ada RTX 40 series has even further advances like 8-bit Float (FP8) tensor cores. The RTX 40 series also has similar power and temperature issues compared to the RTX 30. The issue of melting power connector cables in the RTX 40 can be easily prevented by connecting the power cable correctly.\n\nSparse Network Training\nAmpere allows for fine-grained structure automatic sparse matrix multiplication at dense speeds. How does this work? Take a weight matrix and slice it into pieces of 4 elements. Now imagine 2 elements of these 4 to be zero. Figure 1 shows how this could look like.\n\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool's GTC 2020 presentation on  Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool\u2019s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nWhen you multiply this sparse weight matrix with some dense inputs, the sparse matrix tensor core feature in Ampere automatically compresses the sparse matrix to a dense representation that is half the size as can be seen in Figure 2. After this compression, the densely compressed matrix tile is fed into the tensor core which computes a matrix multiplication of twice the usual size. This effectively yields a 2x speedup since the bandwidth requirements during matrix multiplication from shared memory are halved.\n\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed.\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed. The figure is taken from Jeff Pool\u2019s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nI was working on sparse network training in my research and I also wrote a blog post about sparse training. One criticism of my work was that \u201cYou reduce the FLOPS required for the network, but it does not yield speedups because GPUs cannot do fast sparse matrix multiplication.\u201d Well, with the addition of the sparse matrix multiplication feature for Tensor Cores, my algorithm, or other sparse training algorithms, now actually provide speedups of up to 2x during training.\n\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nWhile this feature is still experimental and training sparse networks are not commonplace yet, having this feature on your GPU means you are ready for the future of sparse training.", "mimetype": "text/plain", "start_char_idx": 21224, "end_char_idx": 25736, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b885cc51-9921-4ecc-8b57-df4e636b037d": {"__data__": {"id_": "b885cc51-9921-4ecc-8b57-df4e636b037d", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42178690-1c55-4503-be7e-9e9eb62663c8", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "bb79632bb48f8d3b8e0aa2b596777b40280ce408df3f4035b399ec1d38d69906", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a5cde305-6f81-41a6-ac6c-02e58df5021b", "node_type": "1", "metadata": {}, "hash": "e32412839d503cfa4b1c48b4133c8f99c614c1fa1f3cb98a26eaf989bdc0f955", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nWhile this feature is still experimental and training sparse networks are not commonplace yet, having this feature on your GPU means you are ready for the future of sparse training.\n\nLow-precision Computation\nIn my work, I\u2019ve previously shown that new data types can improve stability during low-precision backpropagation.\n\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nCurrently, if you want to have stable backpropagation with 16-bit floating-point numbers (FP16), the big problem is that ordinary FP16 data types only support numbers in the range [-65,504, 65,504]. If your gradient slips past this range, your gradients explode into NaN values. To prevent this during FP16 training, we usually perform loss scaling where you multiply the loss by a small number before backpropagating to prevent this gradient explosion.\n\nThe BrainFloat 16 format (BF16) uses more bits for the exponent such that the range of possible numbers is the same as for FP32: [-3*10^38, 3*10^38]. BF16 has less precision, that is significant digits, but gradient precision is not that important for learning. So what BF16 does is that you no longer need to do any loss scaling or worry about the gradient blowing up quickly. As such, we should see an increase in training stability by using the BF16 format as a slight loss of precision.\n\nWhat this means for you: With BF16 precision, training might be more stable than with FP16 precision while providing the same speedups. With 32-bit TensorFloat (TF32) precision, you get near FP32 stability while giving the speedups close to FP16. The good thing is, to use these data types, you can just replace FP32 with TF32 and FP16 with BF16 \u2014 no code changes required!\n\nOverall, though, these new data types can be seen as lazy data types in the sense that you could have gotten all the benefits with the old data types with some additional programming efforts (proper loss scaling, initialization, normalization, using Apex). As such, these data types do not provide speedups but rather improve ease of use of low precision for training.\n\nFan Designs and GPUs Temperature Issues\nWhile the new fan design of the RTX 30 series performs very well to cool the GPU, different fan designs of non-founders edition GPUs might be more problematic. If your GPU heats up beyond 80C, it will throttle itself and slow down its computational speed / power. This overheating can happen in particular if you stack multiple GPUs next to each other. A solution to this is to use PCIe extenders to create space between GPUs.\n\nSpreading GPUs with PCIe extenders is very effective for cooling, and other fellow PhD students at the University of Washington and I use this setup with great success. It does not look pretty, but it keeps your GPUs cool! This has been running with no problems at all for 4 years now. It can also help if you do not have enough space to fit all GPUs in the PCIe slots. For example, if you can find the space within a desktop computer case, it might be possible to buy standard 3-slot-width RTX 4090 and spread them with PCIe extenders within the case.", "mimetype": "text/plain", "start_char_idx": 24977, "end_char_idx": 29433, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a5cde305-6f81-41a6-ac6c-02e58df5021b": {"__data__": {"id_": "a5cde305-6f81-41a6-ac6c-02e58df5021b", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b885cc51-9921-4ecc-8b57-df4e636b037d", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "4bc8c19e68c130da7309ad53576348a7b43ddc771c63b5a616cafe68359c32e7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c2b2147-2fc3-4e05-af4c-7b7abefb80b6", "node_type": "1", "metadata": {}, "hash": "553d2f6caec0073b905a150cb747269ab343ba0dcf4bdb61b8e18e0b4bc16def", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If your GPU heats up beyond 80C, it will throttle itself and slow down its computational speed / power. This overheating can happen in particular if you stack multiple GPUs next to each other. A solution to this is to use PCIe extenders to create space between GPUs.\n\nSpreading GPUs with PCIe extenders is very effective for cooling, and other fellow PhD students at the University of Washington and I use this setup with great success. It does not look pretty, but it keeps your GPUs cool! This has been running with no problems at all for 4 years now. It can also help if you do not have enough space to fit all GPUs in the PCIe slots. For example, if you can find the space within a desktop computer case, it might be possible to buy standard 3-slot-width RTX 4090 and spread them with PCIe extenders within the case. With this, you might solve both the space issue and cooling issue for a 4x RTX 4090 setup with a single simple solution.\n\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 2 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 4 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\n3-slot Design and Power Issues\nThe RTX 3090 and RTX 4090 are 3-slot GPUs, so one will not be able to use it in a 4x setup with the default fan design from NVIDIA. This is kind of justified because it runs at over 350W TDP, and it will be difficult to cool in a multi-GPU 2-slot setting. The RTX 3080 is only slightly better at 320W TDP, and cooling a 4x RTX 3080 setup will also be very difficult.\n\nIt is also difficult to power a 4x 350W = 1400W or 4x 450W = 1800W system in the 4x RTX 3090 or 4x RTX 4090 case. Power supply units (PSUs) of 1600W are readily available, but having only 200W to power the CPU and motherboard can be too tight. The components\u2019 maximum power is only used if the components are fully utilized, and in deep learning, the CPU is usually only under weak load. With that, a 1600W PSU might work quite well with a 4x RTX 3080 build, but for a 4x RTX 3090 build, it is better to look for high wattage PSUs (+1700W). Some of my followers have had great success with cryptomining PSUs \u2014 have a look in the comment section for more info about that. Otherwise, it is important to note that not all outlets support PSUs above 1600W, especially in the US. This is the reason why in the US, there are currently few standard desktop PSUs above 1600W on the market. If you get a server or cryptomining PSUs, beware of the form factor \u2014 make sure it fits into your computer case.\n\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nIt is possible to set a power limit on your GPUs. So you would be able to programmatically set the power limit of an RTX 3090 to 300W instead of their standard 350W. In a 4x GPU system, that is a saving of 200W, which might just be enough to build a 4x RTX 3090 system with a 1600W PSU feasible. It also helps to keep the GPUs cool. So setting a power limit can solve the two major problems of a 4x RTX 3080 or 4x RTX 3090 setups, cooling, and power, at the same time. For a 4x setup, you still need effective blower GPUs (and the standard design may prove adequate for this), but this resolves the PSU problem.\n\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.", "mimetype": "text/plain", "start_char_idx": 28613, "end_char_idx": 32381, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c2b2147-2fc3-4e05-af4c-7b7abefb80b6": {"__data__": {"id_": "5c2b2147-2fc3-4e05-af4c-7b7abefb80b6", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a5cde305-6f81-41a6-ac6c-02e58df5021b", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5de5d8f5bc05dbd1d27a4af6cdf129d3cfb816ccd9d51ace2dc73f9de510148e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2423159f-39bd-40b4-a367-26a9f1a550f3", "node_type": "1", "metadata": {}, "hash": "5420e7409a26d7196a57818b227dd7dffcc535d31b8ecb045fbef4d12c32c853", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It also helps to keep the GPUs cool. So setting a power limit can solve the two major problems of a 4x RTX 3080 or 4x RTX 3090 setups, cooling, and power, at the same time. For a 4x setup, you still need effective blower GPUs (and the standard design may prove adequate for this), but this resolves the PSU problem.\n\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nYou might ask, \u201cDoesn\u2019t this slow down the GPU?\u201d Yes, it does, but the question is by how much. I benchmarked the 4x RTX 2080 Ti system shown in Figure 5 under different power limits to test this. I benchmarked the time for 500 mini-batches for BERT Large during inference (excluding the softmax layer). I choose BERT Large inference since, from my experience, this is the deep learning model that stresses the GPU the most. As such, I would expect power limiting to have the most massive slowdown for this model. As such, the slowdowns reported here are probably close to the maximum slowdowns that you can expect. The results are shown in Figure 7.\n\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nAs we can see, setting the power limit does not seriously affect performance. Limiting the power by 50W \u2014 more than enough to handle 4x RTX 3090 \u2014 decreases performance by only 7%.\n\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\nThere was a misconception that RTX 4090 power cables melt because they were bent. However, it was found that only 0.1% of users had this problem and the problem occured due to user error. Here a video that shows that the main problem is that cables were not inserted correctly.\n\nSo using RTX 4090 cards is perfectly safe if you follow the following install instructions:\n\nIf you use an old cable or old GPU make sure the contacts are free of debri / dust.\nUse the power connector and stick it into the socket until you hear a *click* \u2014 this is the most important part.\nTest for good fit by wiggling the power cable left to right. The cable should not move.\nCheck the contact with the socket visually, there should be no gap between cable and socket.\n8-bit Float Support in H100 and RTX 40 series GPUs\nThe support of the 8-bit Float (FP8) is a huge advantage for the RTX 40 series and H100 GPUs. With 8-bit inputs it allows you to load the data for matrix multiplication twice as fast, you can store twice as much matrix elements in your caches which in the Ada and Hopper architecture are very large, and now with FP8 tensor cores you get 0.66 PFLOPS of compute for a RTX 4090 \u2014 this is more FLOPS then the entirety of the worlds fastest supercomputer in year 2007. 4x RTX 4090 with FP8 compute rival the faster supercomputer in the world in year 2010 (deep learning started to work just in 2009).\n\nThe main problem with using 8-bit precision is that transformers can get very unstable with so few bits and crash during training or generate non-sense during inference. I have written a paper about the emergence of instabilities in large language models and I also written a more accessible blog post.\n\nThe main take-way is this: Using 8-bit instead of 16-bit makes things very unstable, but if you keep a couple of dimensions in high precision everything works just fine.", "mimetype": "text/plain", "start_char_idx": 31725, "end_char_idx": 35542, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2423159f-39bd-40b4-a367-26a9f1a550f3": {"__data__": {"id_": "2423159f-39bd-40b4-a367-26a9f1a550f3", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c2b2147-2fc3-4e05-af4c-7b7abefb80b6", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "815fcd70827de5144dece2600c83f89f479a93a6d4569e31df48e20d7869ae58", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aefea3db-ed16-46a6-a25e-7f6e229d5c3e", "node_type": "1", "metadata": {}, "hash": "24b82d4ac3f894c676783db9dcfde244223eb8164caa5f47e504901cfee781f5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4x RTX 4090 with FP8 compute rival the faster supercomputer in the world in year 2010 (deep learning started to work just in 2009).\n\nThe main problem with using 8-bit precision is that transformers can get very unstable with so few bits and crash during training or generate non-sense during inference. I have written a paper about the emergence of instabilities in large language models and I also written a more accessible blog post.\n\nThe main take-way is this: Using 8-bit instead of 16-bit makes things very unstable, but if you keep a couple of dimensions in high precision everything works just fine.\n\n\nMain results from my work on 8-bit matrix multiplication for Large Language Models (LLMs). We can see that the best 8-bit baseline fails to deliver good zero-shot performance. The method that I developed, LLM.int8(), can perform Int8 matrix multiplication with the same results as the 16-bit baseline.\nBut Int8 was already supported by the RTX 30 / A100 / Ampere generation GPUs, why is FP8 in the RTX 40 another big upgrade? The FP8 data type is much more stable than the Int8 data type and its easy to use it in functions like layer norm or non-linear functions, which are difficult to do with Integer data types. This will make it very straightforward to use it in training and inference. I think this will make FP8 training and inference relatively common in a couple of months.\n\nIf you want to read more about the advantages of Float vs Integer data types you can read my recent paper about k-bit inference scaling laws. Below you can see one relevant main result for Float vs Integer data types from this paper. We can see that bit-by-bit, the FP4 data type preserve more information than Int4 data type and thus improves the mean LLM zeroshot accuracy across 4 tasks.\n\n\n4-bit Inference scaling laws for Pythia Large Language Models for different data types. We see that bit-by-bit, 4-bit float data types have better zeroshot accuracy compared to the Int4 data types.\nRaw Performance Ranking of GPUs\nBelow we see a chart of raw relevative performance across all GPUs. We see that there is a gigantic gap in 8-bit performance of H100 GPUs and old cards that are optimized for 16-bit performance.", "mimetype": "text/plain", "start_char_idx": 34936, "end_char_idx": 37146, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "aefea3db-ed16-46a6-a25e-7f6e229d5c3e": {"__data__": {"id_": "aefea3db-ed16-46a6-a25e-7f6e229d5c3e", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2423159f-39bd-40b4-a367-26a9f1a550f3", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "cf9f504d799ed62cb68105d0cf0c583ce27529b4c4c77683a26cf703d53398c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b00997e3-c12a-48d3-b013-07cec870f46c", "node_type": "1", "metadata": {}, "hash": "5219e5cb2816b19c4a8118274160dbc94e2cc79a10eba5d51228a4b792c32666", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4-bit Inference scaling laws for Pythia Large Language Models for different data types. We see that bit-by-bit, 4-bit float data types have better zeroshot accuracy compared to the Int4 data types.\nRaw Performance Ranking of GPUs\nBelow we see a chart of raw relevative performance across all GPUs. We see that there is a gigantic gap in 8-bit performance of H100 GPUs and old cards that are optimized for 16-bit performance.\n\n\nShown is raw relative transformer performance of GPUs. For example, an RTX 4090 has about 0.33x performance of a H100 SMX for 8-bit inference. In other words, a H100 SMX is three times faster for 8-bit inference compared to a RTX 4090.\nFor this data, I did not model 8-bit compute for older GPUs. I did so, because 8-bit Inference and training are much more effective on Ada/Hopper GPUs because of the 8-bit Float data type and Tensor Memory Accelerator (TMA) which saves the overhead of computing read/write indices which is particularly helpful for 8-bit matrix multiplication. Ada/Hopper also have FP8 support, which makes in particular 8-bit training much more effective.\n\nI did not model numbers for 8-bit training because to model that I need to know the latency of L1 and L2 caches on Hopper/Ada GPUs, and they are unknown and I do not have access to such GPUs. On Hopper/Ada, 8-bit training performance can well be 3-4x of 16-bit training performance if the caches are as fast as rumored.\n\nBut even with the new FP8 tensor cores there are some additional issues which are difficult to take into account when modeling GPU performance. For example, FP8 tensor cores do not support transposed matrix multiplication which means backpropagation needs either a separate transpose before multiplication or one needs to hold two sets of weights \u2014 one transposed and one non-transposed \u2014 in memory. I used two sets of weight when I experimented with Int8 training in my LLM.int8() project and this reduced the overall speedups quite significantly. I think one can do better with the right algorithms/software, but this shows that missing features like a transposed matrix multiplication for tensor cores can affect performance.\n\nFor old GPUs, Int8 inference performance is close to the 16-bit inference performance for models below 13B parameters. Int8 performance on old GPUs is only relevant if you have relatively large models with 175B parameters or more. If you are interested in 8-bit performance of older GPUs, you can read the Appendix D of my LLM.int8() paper where I benchmark Int8 performance.\n\nGPU Deep Learning Performance per Dollar\nBelow we see the chart for the performance per US dollar for all GPUs sorted by 8-bit inference performance. How to use the chart to find a suitable GPU for you is as follows:\n\nDetermine the amount of GPU memory that you need (rough heuristic: at least 12 GB for image generation; at least 24 GB for work with transformers)\nWhile 8-bit inference and training is experimental, it will become standard within 6 months. You might need to do some extra difficult coding to work with 8-bit in the meantime. Is that OK for you? If not, select for 16-bit performance.\nUsing the metric determined in (2), find the GPU with the highest relative performance/dollar that has the amount of memory you need.\nWe can see that the RTX 4070 Ti is most cost-effective for 8-bit and 16-bit inference while the RTX 3080 remains most cost-effective for 16-bit training. While these GPUs are most cost-effective, they are not necessarily recommended as they do not have sufficient memory for many use-cases. However, it might be the ideal cards to get started on your deep learning journey. Some of these GPUs are excellent for Kaggle competition where one can often rely on smaller models. Since to do well in Kaggle competitions the method of how you work is more important than the models size, many of these smaller GPUs are excellent for Kaggle competitions.\n\nThe best GPUs for academic and startup servers seem to be A6000 Ada GPUs (not to be confused with A6000 Turing). The H100 SXM GPU is also very cost effective and has high memory and very strong performance. If I would build a small cluster for a company/academic lab, I would use 66-80% A6000 GPUs and 20-33% H100 SXM GPUs. If I get a good deal on L40 GPUs, I would also pick them instead of A6000, so you can always ask for a quote on these.", "mimetype": "text/plain", "start_char_idx": 36722, "end_char_idx": 41080, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b00997e3-c12a-48d3-b013-07cec870f46c": {"__data__": {"id_": "b00997e3-c12a-48d3-b013-07cec870f46c", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aefea3db-ed16-46a6-a25e-7f6e229d5c3e", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "b2621715ca3c58bf53ff171f70b9fd4d7c8bff7465a814fbdd0e5566c70bbef7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "db314eb6-b9b1-4eba-bea5-a3b4be6b532f", "node_type": "1", "metadata": {}, "hash": "7b4a09f58e242acf4a2e687380cb46c5ccc18d6eb097f571593c66a0e683bdfa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Shown is relative performance per US Dollar of GPUs normalized by the cost for a desktop computer and the average Amazon and eBay price for each GPU. Additionally, the electricity cost of ownership for 5 years is added with an electricity price of 0.175 USD per kWh and a 15% GPU utilization rate. The electricity cost for a RTX 4090 is about $100 per year. How to read and interpret the chart: a desktop computer with RTX 4070 Ti cards owned for 5 years yields about 2x more 8-bit inference performance per dollar compared to a RTX 3090 GPU.\nGPU Recommendations\nI have a create a recommendation flow-chart that you can see below (click here for interactive app from Nan Xiao). While this chart will help you in 80% of cases, it might not quite work for you because the options might be too expensive. In that case, try to look at the benchmarks above and pick the most cost effective GPU that still has enough GPU memory for your use-case. You can estimate the GPU memory needed by running your problem in the vast.ai or Lambda Cloud for a while so you know what you need. The vast.ai or Lambda Cloud might also work well if you only need a GPU very sporadically (every couple of days for a few hours) and you do not need to download and process large dataset to get started. However, cloud GPUs are usually not a good option if you use your GPU for many months with a high usage rate each day (12 hours each day). You can use the example in the \u201cWhen is it better to use the cloud vs a dedicated GPU desktop/server?\u201d section below to determine if cloud GPUs are good for you.\n\n\nGPU recommendation chart for Ada/Hopper GPUs. Follow the answers to the Yes/No questions to find the GPU that is most suitable for you. While this chart works well in about 80% of cases, you might end up with a GPU that is too expensive. Use the cost/performance charts above to make a selection instead. [interactive app]\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nTo understand if it makes sense to skip this generation and buy the next generation of GPUs, it makes sense to talk a bit about what improvements in the future will look like.\n\nIn the past it was possible to shrink the size of transistors to improve speed of a processor. This is coming to an end now. For example, while shrinking SRAM increased its speed (smaller distance, faster memory access), this is no longer the case. Current improvements in SRAM do not improve its performance anymore and might even be negative. While logic such as Tensor Cores get smaller, this does not necessarily make GPU faster since the main problem for matrix multiplication is to get memory to the tensor cores which is dictated by SRAM and GPU RAM speed and size. GPU RAM still increases in speed if we stack memory modules into high-bandwidth modules (HBM3+), but these are too expensive to manufacture for consumer applications. The main way to improve raw speed of GPUs is to use more power and more cooling as we have seen in the RTX 30s and 40s series. But this cannot go on for much longer.\n\nChiplets such as used by AMD CPUs are another straightforward way forward. AMD beat Intel by developing CPU chiplets. Chiplets are small chips that are fused together with a high speed on-chip network. You can think about them as two GPUs that are so physically close together that you can almost consider them a single big GPU. They are cheaper to manufacture, but more difficult to combine into one big chip. So you need know-how and fast connectivity between chiplets. AMD has a lot of experience with chiplet design. AMD\u2019s next generation GPUs are going to be chiplet designs, while NVIDIA currently has no public plans for such designs. This may mean that the next generation of AMD GPUs might be better in terms of cost/performance compared to NVIDIA GPUs.\n\nHowever, the main performance boost for GPUs is currently specialized logic. For example, the asynchronous copy hardware units on the Ampere generation (RTX 30 / A100 / RTX 40) or the extension, the Tensor Memory Accelerator (TMA), both reduce the overhead of copying memory from the slow global memory to fast shared memory (caches) through specialized hardware and so each thread can do more computation. The TMA also reduces overhead by performing automatic calculations of read/write indices which is particularly important for 8-bit computation where one has double the elements for the same amount of memory compared to 16-bit computation. So specialized hardware logic can accelerate matrix multiplication further.", "mimetype": "text/plain", "start_char_idx": 41083, "end_char_idx": 45628, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "db314eb6-b9b1-4eba-bea5-a3b4be6b532f": {"__data__": {"id_": "db314eb6-b9b1-4eba-bea5-a3b4be6b532f", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b00997e3-c12a-48d3-b013-07cec870f46c", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "06a3179e5402fe9e495cdbaacb9958e7374e50a74c6763c4392b8f64d864b083", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b125d31-589e-4e6a-9710-5fd7c80f5203", "node_type": "1", "metadata": {}, "hash": "ded86783049e00e1089aefa9af296370a51e93edc57caecc80efe967ea8eec8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "AMD\u2019s next generation GPUs are going to be chiplet designs, while NVIDIA currently has no public plans for such designs. This may mean that the next generation of AMD GPUs might be better in terms of cost/performance compared to NVIDIA GPUs.\n\nHowever, the main performance boost for GPUs is currently specialized logic. For example, the asynchronous copy hardware units on the Ampere generation (RTX 30 / A100 / RTX 40) or the extension, the Tensor Memory Accelerator (TMA), both reduce the overhead of copying memory from the slow global memory to fast shared memory (caches) through specialized hardware and so each thread can do more computation. The TMA also reduces overhead by performing automatic calculations of read/write indices which is particularly important for 8-bit computation where one has double the elements for the same amount of memory compared to 16-bit computation. So specialized hardware logic can accelerate matrix multiplication further.\nLow-bit precision is another straightforward way forward for a couple of years. We will see widespread adoption of 8-bit inference and training in the next months. We will see widespread 4-bit inference in the next year. Currently, the technology for 4-bit training does not exists, but research looks promising and I expect the first high performance FP4 Large Language Model (LLM) with competitive predictive performance to be trained in 1-2 years time.\n\nGoing to 2-bit precision for training currently looks pretty impossible, but it is a much easier problem than shrinking transistors further. So progress in hardware mostly depends on software and algorithms that make it possible to use specialized features offered by the hardware.\n\nWe will probably be able to still improve the combination of algorithms + hardware to the year 2032, but after that will hit the end of GPU improvements (similar to smartphones). The wave of performance improvements after 2032 will come from better networking algorithms and mass hardware. It is uncertain if consumer GPUs will be relevant at this point. It might be that you need an RTX 9090 to run run Super HyperStableDiffusion Ultra Plus 9000 Extra or OpenChatGPT 5.0, but it might also be that some company will offer a high-quality API that is cheaper than the electricity cost for a RTX 9090 and you want to use a laptop + API for image generation and other tasks.\n\nOverall, I think investing into a 8-bit capable GPU will be a very solid investment for the next 9 years. Improvements at 4-bit and 2-bit are likely small and other features like Sort Cores would only become relevant once sparse matrix multiplication can be leveraged well. We will probably see some kind of other advancement in 2-3 years which will make it into the next GPU 4 years from now, but we are running out of steam if we keep relying on matrix multiplication. This makes investments into new GPUs last longer.\n\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nGenerally, no. PCIe 5.0 or 4.0 is great if you have a GPU cluster. It is okay if you have an 8x GPU machine, but otherwise, it does not yield many benefits. It allows better parallelization and a bit faster data transfer. Data transfers are not a bottleneck in any application. In computer vision, in the data transfer pipeline, the data storage can be a bottleneck, but not the PCIe transfer from CPU to GPU. So there is no real reason to get a PCIe 5.0 or 4.0 setup for most people. The benefits will be maybe 1-7% better parallelization in a 4 GPU setup.\n\nDo I need 8x/16x PCIe lanes?\nSame as with PCIe 4.0 \u2014 generally, no. PCIe lanes are needed for parallelization and fast data transfers, which are seldom a bottleneck. Operating GPUs on 4x lanes is fine, especially if you only have 2 GPUs. For a 4 GPU setup, I would prefer 8x lanes per GPU, but running them at 4x lanes will probably only decrease performance by around 5-10% if you parallelize across all 4 GPUs.\n\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nYou need to get one of the two-slot variants, or you can try to spread them out with PCIe extenders. Besides space, you should also immediately think about cooling and a suitable PSU.\n\nPCIe extenders might also solve both space and cooling issues, but you need to make sure that you have enough space in your case to spread out the GPUs.", "mimetype": "text/plain", "start_char_idx": 44664, "end_char_idx": 49010, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b125d31-589e-4e6a-9710-5fd7c80f5203": {"__data__": {"id_": "8b125d31-589e-4e6a-9710-5fd7c80f5203", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db314eb6-b9b1-4eba-bea5-a3b4be6b532f", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "b67b6a15bd16f6c5bfa05f71f0f2225a3d635869f583238c8151068d4ff68d5e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "691a0eb5-863c-4d0c-a7f6-a093ecf861e9", "node_type": "1", "metadata": {}, "hash": "ac767fa6550dc8072fb89d89c920ab07d6dce157d72e56b1ffed0afe1506ac99", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PCIe lanes are needed for parallelization and fast data transfers, which are seldom a bottleneck. Operating GPUs on 4x lanes is fine, especially if you only have 2 GPUs. For a 4 GPU setup, I would prefer 8x lanes per GPU, but running them at 4x lanes will probably only decrease performance by around 5-10% if you parallelize across all 4 GPUs.\n\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nYou need to get one of the two-slot variants, or you can try to spread them out with PCIe extenders. Besides space, you should also immediately think about cooling and a suitable PSU.\n\nPCIe extenders might also solve both space and cooling issues, but you need to make sure that you have enough space in your case to spread out the GPUs. Make sure your PCIe extenders are long enough!\n\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nSee the previous section.\n\nCan I use multiple GPUs of different GPU types?\nYes, you can! But you cannot parallelize efficiently across GPUs of different types since you will often go at the speed of the slowest GPU (data and fully sharded parallelism). So different GPUs work just fine, but parallelization across those GPUs will be inefficient since the fastest GPU will wait for the slowest GPU to catch up to a synchronization point (usually gradient update).\n\nWhat is NVLink, and is it useful?\nGenerally, NVLink is not useful. NVLink is a high speed interconnect between GPUs. It is useful if you have a GPU cluster with +128 GPUs. Otherwise, it yields almost no benefits over standard PCIe transfers.\n\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nDefinitely buy used GPUs. You can buy a small cheap GPU for prototyping and testing and then roll out for full experiments to the cloud like vast.ai or Lambda Cloud. This can be cheap if you train/fine-tune/inference on large models only every now and then and spent more time protoyping on smaller models.\n\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nI built a carbon calculator for calculating your carbon footprint for academics (carbon from flights to conferences + GPU time). The calculator can also be used to calculate a pure GPU carbon footprint. You will find that GPUs produce much, much more carbon than international flights. As such, you should make sure you have a green source of energy if you do not want to have an astronomical carbon footprint. If no electricity provider in our area provides green energy, the best way is to buy carbon offsets. Many people are skeptical about carbon offsets. Do they work? Are they scams?\n\nI believe skepticism just hurts in this case, because not doing anything would be more harmful than risking the probability of getting scammed. If you worry about scams, just invest in a portfolio of offsets to minimize risk.\n\nI worked on a project that produced carbon offsets about ten years ago. The carbon offsets were generated by burning leaking methane from mines in China. UN officials tracked the process, and they required clean digital data and physical inspections of the project site. In that case, the carbon offsets that were produced were highly reliable. I believe many other projects have similar quality standards.\n\nWhat do I need to parallelize across two machines?\nIf you want to be on the safe side, you should get at least +50Gbits/s network cards to gain speedups if you want to parallelize across machines. I recommend having at least an EDR Infiniband setup, meaning a network card with at least 50 GBit/s bandwidth. Two EDR cards with cable are about $500 on eBay.\n\nIn some cases, you might be able to get away with 10 Gbit/s Ethernet, but this is usually only the case for special networks (certain convolutional networks) or if you use certain algorithms (Microsoft DeepSpeed).\n\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nIt does not seem so. Since the granularity of the sparse matrix needs to have 2 zero-valued elements, every 4 elements, the sparse matrices need to be quite structured. It might be possible to adjust the algorithm slightly, which involves that you pool 4 values into a compressed representation of 2 values, but this also means that precise arbitrary sparse matrix multiplication is not possible with Ampere GPUs.\n\nDo I need an Intel CPU to power a multi-GPU setup?\nI do not recommend Intel CPUs unless you heavily use CPUs in Kaggle competitions (heavy linear algebra on the CPU).", "mimetype": "text/plain", "start_char_idx": 48259, "end_char_idx": 52759, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "691a0eb5-863c-4d0c-a7f6-a093ecf861e9": {"__data__": {"id_": "691a0eb5-863c-4d0c-a7f6-a093ecf861e9", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b125d31-589e-4e6a-9710-5fd7c80f5203", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "1968aefb07630f73a36185d18306591d4111ad9637b30944fb37b908afac2f14", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8cc6d4e2-dfc1-480f-a6d2-863c941c4161", "node_type": "1", "metadata": {}, "hash": "66ec93e8da39d2cba161d029427b228a7a0991be1531d9a26f1983085fce0137", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Two EDR cards with cable are about $500 on eBay.\n\nIn some cases, you might be able to get away with 10 Gbit/s Ethernet, but this is usually only the case for special networks (certain convolutional networks) or if you use certain algorithms (Microsoft DeepSpeed).\n\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nIt does not seem so. Since the granularity of the sparse matrix needs to have 2 zero-valued elements, every 4 elements, the sparse matrices need to be quite structured. It might be possible to adjust the algorithm slightly, which involves that you pool 4 values into a compressed representation of 2 values, but this also means that precise arbitrary sparse matrix multiplication is not possible with Ampere GPUs.\n\nDo I need an Intel CPU to power a multi-GPU setup?\nI do not recommend Intel CPUs unless you heavily use CPUs in Kaggle competitions (heavy linear algebra on the CPU). Even for Kaggle competitions AMD CPUs are still great, though. AMD CPUs are cheaper and better than Intel CPUs in general for deep learning. For a 4x GPU built, my go-to CPU would be a Threadripper. We built dozens of systems at our university with Threadrippers, and they all work great \u2014 no complaints yet. For 8x GPU systems, I would usually go with CPUs that your vendor has experience with. CPU and PCIe/system reliability is more important in 8x systems than straight performance or straight cost-effectiveness.\n\nDoes computer case design matter for cooling?\nNo. GPUs are usually perfectly cooled if there is at least a small gap between GPUs. Case design will give you 1-3 C better temperatures, space between GPUs will provide you with 10-30 C improvements. The bottom line, if you have space between GPUs, cooling does not matter. If you have no space between GPUs, you need the right cooler design (blower fan) or another solution (water cooling, PCIe extenders), but in either case, case design and case fans do not matter.\n\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nNot in the next 1-2 years. It is a three-way problem: Tensor Cores, software, and community.\n\nAMD GPUs are great in terms of pure silicon: Great FP16 performance, great memory bandwidth. However, their lack of Tensor Cores or the equivalent makes their deep learning performance poor compared to NVIDIA GPUs. Packed low-precision math does not cut it. Without this hardware feature, AMD GPUs will never be competitive. Rumors show that some data center card with Tensor Core equivalent is planned for 2020, but no new data emerged since then. Just having data center cards with a Tensor Core equivalent would also mean that few would be able to afford such AMD GPUs, which would give NVIDIA a competitive advantage.\n\nLet\u2019s say AMD introduces a Tensor-Core-like-hardware feature in the future. Then many people would say, \u201cBut there is no software that works for AMD GPUs! How am I supposed to use them?\u201d This is mostly a misconception. The AMD software via ROCm has come to a long way, and support via PyTorch is excellent. While I have not seen many experience reports for AMD GPUs + PyTorch, all the software features are integrated. It seems, if you pick any network, you will be just fine running it on AMD GPUs. So here AMD has come a long way, and this issue is more or less solved.\n\nHowever, if you solve software and the lack of Tensor Cores, AMD still has a problem: the lack of community. If you have a problem with NVIDIA GPUs, you can Google the problem and find a solution. That builds a lot of trust in NVIDIA GPUs. You have the infrastructure that makes using NVIDIA GPUs easy (any deep learning framework works, any scientific problem is well supported). You have the hacks and tricks that make usage of NVIDIA GPUs a breeze (e.g., apex). You can find experts on NVIDIA GPUs and programming around every other corner while I knew much less AMD GPU experts.\n\nIn the community aspect, AMD is a bit like Julia vs Python. Julia has a lot of potential, and many would say, and rightly so, that it is the superior programming language for scientific computing. Yet, Julia is barely used compared to Python. This is because the Python community is very strong. Numpy, SciPy, Pandas are powerful software packages that a large number of people congregate around. This is very similar to the NVIDIA vs AMD issue.\n\nThus, it is likely that AMD will not catch up until Tensor Core equivalent is introduced (1/2 to 1 year?)", "mimetype": "text/plain", "start_char_idx": 51827, "end_char_idx": 56282, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8cc6d4e2-dfc1-480f-a6d2-863c941c4161": {"__data__": {"id_": "8cc6d4e2-dfc1-480f-a6d2-863c941c4161", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "691a0eb5-863c-4d0c-a7f6-a093ecf861e9", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "6d315f0de39a220a598a7567d9dd9b06b00b3a20edb84d1923ee0439372a065f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e8266e1e-ba6e-4087-8fa5-8e9a47db045d", "node_type": "1", "metadata": {}, "hash": "2365bec898ed966636a3a003c2cbc98a681e7e03b16972ced3ba1ca1c169793e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "You have the infrastructure that makes using NVIDIA GPUs easy (any deep learning framework works, any scientific problem is well supported). You have the hacks and tricks that make usage of NVIDIA GPUs a breeze (e.g., apex). You can find experts on NVIDIA GPUs and programming around every other corner while I knew much less AMD GPU experts.\n\nIn the community aspect, AMD is a bit like Julia vs Python. Julia has a lot of potential, and many would say, and rightly so, that it is the superior programming language for scientific computing. Yet, Julia is barely used compared to Python. This is because the Python community is very strong. Numpy, SciPy, Pandas are powerful software packages that a large number of people congregate around. This is very similar to the NVIDIA vs AMD issue.\n\nThus, it is likely that AMD will not catch up until Tensor Core equivalent is introduced (1/2 to 1 year?) and a strong community is built around ROCm (2 years?). AMD will always snatch a part of the market share in specific subgroups (e.g., cryptocurrency mining, data centers). Still, in deep learning, NVIDIA will likely keep its monopoly for at least a couple more years.\n\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nRule-of-thumb: If you expect to do deep learning for longer than a year, it is cheaper to get a desktop GPU. Otherwise, cloud instances are preferable unless you have extensive cloud computing skills and want the benefits of scaling the number of GPUs up and down at will.\n\nNumbers in the following paragraphs are going to change, but it serves as a scenario that helps you to understand the rough costs. You can use similar math to determine if cloud GPUs are the best solution for you.\n\nFor the exact point in time when a cloud GPU is more expensive than a desktop depends highly on the service that you are using, and it is best to do a little math on this yourself. Below I do an example calculation for an AWS V100 spot instance with 1x V100 and compare it to the price of a desktop with a single RTX 3090 (similar performance). The desktop with RTX 3090 costs $2,200 (2-GPU barebone + RTX 3090). Additionally, assuming you are in the US, there is an additional $0.12 per kWh for electricity. This compares to $2.14 per hour for the AWS on-demand instance.\n\nAt 15% utilization per year, the desktop uses:\n\n(350 W (GPU) + 100 W (CPU))*0.15 (utilization) * 24 hours * 365 days = 591 kWh per year\n\nSo 591 kWh of electricity per year, that is an additional $71.\n\nThe break-even point for a desktop vs a cloud instance at 15% utilization (you use the cloud instance 15% of time during the day), would be about 300 days ($2,311 vs $2,270):\n\n$2.14/h * 0.15 (utilization) * 24 hours * 300 days = $2,311\n\nSo if you expect to run deep learning models after 300 days, it is better to buy a desktop instead of using AWS on-demand instances.\n\nYou can do similar calculations for any cloud service to make the decision if you go for a cloud service or a desktop.\n\nCommon utilization rates are the following:\n\nPhD student personal desktop: < 15%\nPhD student slurm GPU cluster: > 35%\nCompany-wide slurm research cluster: > 60%\nIn general, utilization rates are lower for professions where thinking about cutting edge ideas is more important than developing practical products. Some areas have low utilization rates (interpretability research), while other areas have much higher rates (machine translation, language modeling). In general, the utilization of personal machines is almost always overestimated. Commonly, most personal systems have a utilization rate between 5-10%. This is why I would highly recommend slurm GPU clusters for research groups and companies instead of individual desktop GPU machines.\n\nVersion History\n2023-01-30: Improved font and recommendation chart. Added 5 years cost of ownership electricity perf/USD chart. Updated Async copy and TMA functionality. Slight update to FP8 training. General improvements.\n2023-01-16: Added Hopper and Ada GPUs. Added GPU recommendation chart. Added information about the TMA unit and L2 cache.\n2020-09-20: Added discussion of using power limiting to run 4x RTX 3090 systems. Added older GPUs to the performance and cost/performance charts. Added figures for sparse matrix multiplication.", "mimetype": "text/plain", "start_char_idx": 55386, "end_char_idx": 59664, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e8266e1e-ba6e-4087-8fa5-8e9a47db045d": {"__data__": {"id_": "e8266e1e-ba6e-4087-8fa5-8e9a47db045d", "embedding": null, "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11", "node_type": "4", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "5032148e317c4b605ed486437dcbec1477cc2a09553162399d20acd2b6ca7be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8cc6d4e2-dfc1-480f-a6d2-863c941c4161", "node_type": "1", "metadata": {"source_url": "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/", "document_index": 11}, "hash": "7919a7a297d25c14a3b40633bd87e2f59bc709dc0c1f10322e9b0049a7aad14c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In general, the utilization of personal machines is almost always overestimated. Commonly, most personal systems have a utilization rate between 5-10%. This is why I would highly recommend slurm GPU clusters for research groups and companies instead of individual desktop GPU machines.\n\nVersion History\n2023-01-30: Improved font and recommendation chart. Added 5 years cost of ownership electricity perf/USD chart. Updated Async copy and TMA functionality. Slight update to FP8 training. General improvements.\n2023-01-16: Added Hopper and Ada GPUs. Added GPU recommendation chart. Added information about the TMA unit and L2 cache.\n2020-09-20: Added discussion of using power limiting to run 4x RTX 3090 systems. Added older GPUs to the performance and cost/performance charts. Added figures for sparse matrix multiplication.\n2020-09-07: Added NVIDIA Ampere series GPUs. Included lots of good-to-know GPU details.\n2019-04-03: Added RTX Titan and GTX 1660 Ti. Updated TPU section. Added startup hardware discussion.\n2018-11-26: Added discussion of overheating issues of RTX cards.\n2018-11-05: Added RTX 2070 and updated recommendations. Updated charts with hard performance data. Updated TPU section.\n2018-08-21: Added RTX 2080 and RTX 2080 Ti; reworked performance analysis\n2017-04-09: Added cost-efficiency analysis; updated recommendation with NVIDIA Titan Xp\n2017-03-19: Cleaned up blog post; added GTX 1080 Ti\n2016-07-23: Added Titan X Pascal and GTX 1060; updated recommendations\n2016-06-25: Reworked multi-GPU section; removed simple neural network memory section as no longer relevant; expanded convolutional memory section; truncated AWS section due to not being efficient anymore; added my opinion about the Xeon Phi; added updates for the GTX 1000 series\n2015-08-20: Added section for AWS GPU instances; added GTX 980 Ti to the comparison relation\n2015-04-22: GTX 580 no longer recommended; added performance relationships between cards\n2015-03-16: Updated GPU recommendations: GTX 970 and GTX 580\n2015-02-23: Updated GPU recommendations and memory calculations\n2014-09-28: Added emphasis for memory requirement of CNNs\nAcknowledgments\nI thank Suhail for making me aware of outdated prices on H100 GPUs, Gjorgji Kjosev for pointing out font issues, Anonymous for pointing out that the TMA unit does not exist on Ada GPUs, Scott Gray for pointing out that FP8 tensor cores have no transposed matrix multiplication, and reddit and HackerNews users for pointing out many other improvements.\n\nFor past updates of this blog post, I want to thank Mat Kelcey for helping me to debug and test custom code for the GTX 970; I want to thank Sander Dieleman for making me aware of the shortcomings of my GPU memory advice for convolutional nets; I want to thank Hannes Bretschneider for pointing out software dependency problems for the GTX 580; and I want to thank Oliver Griesel for pointing out notebook solutions for AWS instances. I want to thank Brad Nemire for providing me with an RTX Titan for benchmarking purposes. I want to thank Agrin Hilmkil, Ari Holtzman, Gabriel Ilharco, Nam Pho for their excellent feedback on the previous version of this blog post.", "mimetype": "text/plain", "start_char_idx": 58839, "end_char_idx": 62004, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e9dddf6b-f08b-443e-b6dd-f99728950437": {"__data__": {"id_": "e9dddf6b-f08b-443e-b6dd-f99728950437", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42f0d6fe-8000-493f-92f0-9c1062b1507d", "node_type": "1", "metadata": {}, "hash": "aae431ef4a789de33db64ce25794a99cb42079b45e5d1b196575f4aeeef5b563", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gleam for Python users\nHello productive pragmatic Pythonistas!\n\na soft wavey boundary between two sections of the website\nComments\nVariables\nMatch operator\nVariables type annotations\nFunctions\nExporting functions\nFunction type annotations\nReferencing functions\nLabelled arguments\nOperators\nConstants\nBlocks\nData types\nStrings\nTuples\nLists\nDicts\nFlow control\nCase\nTry\nType aliases\nCustom types\nRecords\nUnions\nOpaque custom types\nModules\nImports\nNamed imports\nUnqualified imports\nComments\nPython\nIn Python, comments are written with a # prefix.\n\n# Hello, Joe!\nA docstring (matching \u201c\u201d\u201d) that occurs as the first statement in a module, function, class, or method definition will become the __doc__ attribute of that object.\n\ndef a_function():\n    \"\"\"Return some important data.\"\"\"\n    pass\nGleam\nIn Gleam, comments are written with a // prefix.\n\n// Hello, Joe!\nComments starting with /// are used to document the following statement. Comments starting with //// are used to document the current module.\n\n//// This module is very important.\n\n/// The answer to life, the universe, and everything.\nconst answer: Int = 42\nVariables\nYou can reassign variables in both languages.\n\nPython\nsize = 50\nsize = size + 100\nsize = 1\nPython has no specific variable keyword. You choose a name and that\u2019s it!\n\nGleam\nGleam has the let keyword before its variable names.\n\nlet size = 50\nlet size = size + 100\nlet size = 1\nMatch operator\nPython\nPython supports basic, one directional destructuring (also called unpacking). Tuple of values can be unpacked and inner values can be assigned to left-hand variable names.\n\n(a, b) = (1, 2)\n# a == 1\n# b == 2\n\n# works also for for-loops\nfor key, value in enumerate(a_dict):\n    print(key, value)\nGleam\nIn Gleam, let and = can be used for pattern matching, but you\u2019ll get compile errors if there\u2019s a type mismatch, and a runtime error if there\u2019s a value mismatch. For assertions, the equivalent let assert keyword is preferred.\n\nlet #(x, _) = #(1, 2)\nlet assert [] = [1] // runtime error\nlet assert [y] = \"Hello\" // compile error, type mismatch\nVariables type annotations\nPython\nPython is a dynamically typed language. Types are only checked at runtime and a variable can have different types in its lifetime.\n\nType hints (Python 3+) are optional annotations that document the code with type information. These annotations are accessible at runtime via the __annotations__ module-level variable.\n\nThese hints will mainly be used to inform static analysis tools like IDEs, linters\u2026\n\nsome_list: list[int] = [1, 2, 3]\nGleam\nIn Gleam type annotations can optionally be given when binding variables.\n\nlet some_list: List(Int) = [1, 2, 3]\nGleam will check the type annotation to ensure that it matches the type of the assigned value. It does not need annotations to type check your code, but you may find it useful to annotate variables to hint to the compiler that you want a specific type to be inferred.\n\nFunctions\nPython\nIn Python, you can define functions with the def keyword. In that case, the return keyword is mandatory.\n\ndef sum(x, y):\n    return x + y\nAnonymous functions returning a single expression can also be defined with the lambda keyword and be assigned into variables.\n\nmul = lambda x, y: x * y\nmul(1, 2)\nGleam\nGleam\u2019s functions are declared using a syntax similar to Rust or JavaScript. Gleam\u2019s anonymous functions have a similar syntax and don\u2019t need a . when called.\n\npub fn sum(x, y) {\n  x + y\n}\n\nlet mul = fn(x, y) { x * y }\nmul(1, 2)\nExporting functions\nPython\nIn Python, top level functions are exported by default. There is no notion of private module-level functions.\n\nGleam\nIn Gleam, functions are private by default and need the pub keyword to be public.\n\n// this is public\npub fn sum(x, y) {\n  x + y\n}\n\n// this is private\nfn mul(x, y) {\n  x * y\n}\nFunction type annotations\nPython\nType hints can be used to optionally annotate function arguments and return types.\n\nDiscrepancies between type hints and actual values at runtime do not prevent interpretation of the code.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4013, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42f0d6fe-8000-493f-92f0-9c1062b1507d": {"__data__": {"id_": "42f0d6fe-8000-493f-92f0-9c1062b1507d", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e9dddf6b-f08b-443e-b6dd-f99728950437", "node_type": "1", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "f42f3ad1ec1a7f16b713c2f3dff24c3db124e94bf09fc561cc53c16aea14c480", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e06bb71-a779-405e-aa94-452c1123cc19", "node_type": "1", "metadata": {}, "hash": "7fac22d0788b5a0c68990a0d8fadae6666bbcbc77a629243219d43503849147c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gleam\u2019s anonymous functions have a similar syntax and don\u2019t need a . when called.\n\npub fn sum(x, y) {\n  x + y\n}\n\nlet mul = fn(x, y) { x * y }\nmul(1, 2)\nExporting functions\nPython\nIn Python, top level functions are exported by default. There is no notion of private module-level functions.\n\nGleam\nIn Gleam, functions are private by default and need the pub keyword to be public.\n\n// this is public\npub fn sum(x, y) {\n  x + y\n}\n\n// this is private\nfn mul(x, y) {\n  x * y\n}\nFunction type annotations\nPython\nType hints can be used to optionally annotate function arguments and return types.\n\nDiscrepancies between type hints and actual values at runtime do not prevent interpretation of the code.\n\nStatic code analysers (IDE tooling, type checkers like mypy) will be required to detect those errors.\n\ndef sum(x: int, y: int) -> int:\n    return x + y\n\ndef mul(x: int, y: int) -> bool:\n    # no errors from the interpreter.\n    return x * y\nGleam\nFunctions can optionally have their argument and return types annotated in Gleam. These type annotations will always be checked by the compiler and throw a compilation error if not valid. The compiler will still type check your program using type inference if annotations are omitted.\n\npub fn add(x: Int, y: Int) -> Int {\n  x + y\n}\n\npub fn mul(x: Int, y: Int) -> Bool { // compile error, type mismatch\n  x * y\n}\nReferencing functions\nPython\nAs long as functions are in scope they can be assigned to a new variable. There is no special syntax to assign a module function to a variable.\n\nGleam\nGleam has a single namespace for value and functions within a module, so there is no need for a special syntax to assign a module function to a variable.\n\nfn identity(x) {\n  x\n}\n\nfn main() {\n  let func = identity\n  func(100)\n}\nLabelled arguments\nBoth Python and Gleam have ways to give arguments names and in any order.\n\nPython\nKeyword arguments are evaluated once at function definition time, and there is no evidence showing a noticeable performance penalty when using named arguments.\n\nWhen calling a function, arguments can be passed\n\npositionally, in the same order of the function declaration\nby name, in any order\ndef replace(inside: str, each: str, with_string: str):\n    pass\n\n# equivalent calls\nreplace('hello world', 'world', 'you')\nreplace(each='world', inside='hello world',  with_string='you')\nGleam\nIn Gleam arguments can be given a label as well as an internal name. Contrary to Python, the name used at the call-site does not have to match the name used for the variable inside the function.\n\npub fn replace(inside string, each pattern, with replacement) {\n  go(string, pattern, replacement)\n}\nreplace(each: \",\", with: \" \", inside: \"A,B,C\")\nThere is no performance cost to Gleam\u2019s labelled arguments as they are optimised to regular function calls at compile time, and all the arguments are fully type checked.\n\nOperators\nOperator\tPython\tGleam\tNotes\nEqual\t==\t==\tIn Gleam both values must be of the same type\nStrictly equal to\t==\t==\tComparison in Gleam is always strict. (see note for Python)\nReference equality\tis\t \tTrue only if the two objects have the same reference\nNot equal\t!=\t!=\tIn Gleam both values must be of the same type\nGreater than\t>\t>\tIn Gleam both values must be ints\nGreater than\t>\t>.\tIn Gleam both values must be floats\nGreater or equal\t>=\t>=\tIn Gleam both values must be ints\nGreater or equal\t>=\t>=.\tIn Gleam both values must be floats\nLess than\t<\t<\tIn Gleam both values must be ints\nLess than\t<\t<.\tIn Gleam both values must be floats\nLess or equal\t<=\t<=\tIn Gleam both values must be ints\nLess or equal\t<=\t<=.\tIn Gleam both values must be floats\nBoolean and\tand\t&&\tIn Gleam both values must be bools\nLogical and\tand\t \tNot available in Gleam\nBoolean or\tor\t||\tIn Gleam both values must be bools\nLogical or\tor\t \tNot available in Gleam\nAdd\t+\t+\tIn Gleam both values must be ints\nAdd\t+\t+.", "mimetype": "text/plain", "start_char_idx": 3321, "end_char_idx": 7170, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e06bb71-a779-405e-aa94-452c1123cc19": {"__data__": {"id_": "5e06bb71-a779-405e-aa94-452c1123cc19", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42f0d6fe-8000-493f-92f0-9c1062b1507d", "node_type": "1", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "e743152df82d3713e62e52b813881b006f485155b819d0cd5116fa6d916eae86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "689a8098-387b-4521-8a0d-22a40cc614de", "node_type": "1", "metadata": {}, "hash": "0792c7ed1446aed3e533415493d782d82a76b3275c5f84fac0885b84afa413cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In Gleam both values must be floats\nGreater or equal\t>=\t>=\tIn Gleam both values must be ints\nGreater or equal\t>=\t>=.\tIn Gleam both values must be floats\nLess than\t<\t<\tIn Gleam both values must be ints\nLess than\t<\t<.\tIn Gleam both values must be floats\nLess or equal\t<=\t<=\tIn Gleam both values must be ints\nLess or equal\t<=\t<=.\tIn Gleam both values must be floats\nBoolean and\tand\t&&\tIn Gleam both values must be bools\nLogical and\tand\t \tNot available in Gleam\nBoolean or\tor\t||\tIn Gleam both values must be bools\nLogical or\tor\t \tNot available in Gleam\nAdd\t+\t+\tIn Gleam both values must be ints\nAdd\t+\t+.\tIn Gleam both values must be floats\nSubtract\t-\t-\tIn Gleam both values must be ints\nSubtract\t-\t-.\tIn Gleam both values must be floats\nMultiply\t*\t*\tIn Gleam both values must be ints\nMultiply\t*\t*.\tIn Gleam both values must be floats\nDivide\t/\t/\tIn Gleam both values must be ints\nDivide\t/\t/.\tIn Gleam both values must be floats\nRemainder\t%\t%\tIn Gleam both values must be ints, in Gleam negative values behave differently: Use int.modulo to mimick Python\u2019s behavior.\nConcatenate\t+\t<>\tIn Gleam both values must be strings\nPipe\t \t|>\tGleam\u2019s pipe can pipe into anonymous functions. This operator does not exist in python\nSome notes for Python:\n\n== is by default comparing by value:\n\nscalars will have their value compared\nthe only type cast will be for 0 and 1 that will be coerced to False and True respectively\nvariables that point to the same object will be equal with ==\ntwo objects with the same members values won\u2019t be equal:\n\nno structural equality, unless the __eq__ operator is redefined.\nPython operators are short-circuiting as in Gleam.\nPython operators can be overloaded and be applied to any types with potential custom behaviors\nConstants\nPython\nIn Python, top-level declarations are in the global/module scope is the highest possible scope. Any variables and functions defined will be accessible from anywhere in the code.\n\nThere is no notion of constant variables in Python.\n\n# in the global scope\nTHE_ANSWER = 42\nGleam\nIn Gleam constants can be created using the const keyword.\n\nconst the_answer = 42\n\npub fn main() {\n  the_answer\n}\nBlocks\nPython\nPython blocks are always associated with a function / conditional / class declarations\u2026 There is no way to create multi-line expressions blocks like in Gleam.\n\nBlocks are declared via indentation.\n\ndef a_func():\n    # A block here\n    pass\nGleam\nIn Gleam braces { } are used to group expressions.\n\npub fn main() {\n  let x = {\n    some_function(1)\n    2\n  }\n  let y = x * {x + 10} // braces are used to change arithmetic operations order\n  y\n}\nData types\nStrings\nIn Python, strings are stored as unicode code-points sequence. Strings can be encoded or decoded to/from a specific encoding.\n\nIn Gleam all strings are UTF-8 encoded binaries.\n\nPython\n\"Hell\u00f8, world!\"\nGleam\n\"Hell\u00f8, world!\"\nTuples\nTuples are very useful in Gleam as they\u2019re the only collection data type that allows mixed types in the collection.\n\nPython\nPython tuples are immutable, fixed-size lists that can contain mixed value types. Unpacking can be used to bind a name to a specific value of the tuple.\n\nmy_tuple = (\"username\", \"password\", 10)\n_, password, _ = my_tuple\nGleam\nlet my_tuple = #(\"username\", \"password\", 10)\nlet #(_, password, _) = my_tuple\nLists\nLists in Python are allowed to have values of mixed types, but not in Gleam.\n\nPython\nPython can emulate the cons operator of Gleam using the * operator and unpacking:\n\nlist = [2, 3, 4]\n[head, *tail] = list\n# head == 2\n# tail == [3, 4]\nGleam\nGleam has a cons operator that works for lists destructuring and pattern matching. In Gleam lists are immutable so adding and removing elements from the start of a list is highly efficient.", "mimetype": "text/plain", "start_char_idx": 6571, "end_char_idx": 10282, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "689a8098-387b-4521-8a0d-22a40cc614de": {"__data__": {"id_": "689a8098-387b-4521-8a0d-22a40cc614de", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e06bb71-a779-405e-aa94-452c1123cc19", "node_type": "1", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "712ac57f8d8f9d722ff141d80038e9383ae38678d5ef86f97eb195765793f2ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "576c22ef-d5f1-4455-930d-4af3352ff427", "node_type": "1", "metadata": {}, "hash": "96eddca6c3c01fbdc7ec4e11f24c851ed85b31f1c89fa33b3628fb83b2f10e6f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Python\nPython tuples are immutable, fixed-size lists that can contain mixed value types. Unpacking can be used to bind a name to a specific value of the tuple.\n\nmy_tuple = (\"username\", \"password\", 10)\n_, password, _ = my_tuple\nGleam\nlet my_tuple = #(\"username\", \"password\", 10)\nlet #(_, password, _) = my_tuple\nLists\nLists in Python are allowed to have values of mixed types, but not in Gleam.\n\nPython\nPython can emulate the cons operator of Gleam using the * operator and unpacking:\n\nlist = [2, 3, 4]\n[head, *tail] = list\n# head == 2\n# tail == [3, 4]\nGleam\nGleam has a cons operator that works for lists destructuring and pattern matching. In Gleam lists are immutable so adding and removing elements from the start of a list is highly efficient.\n\nlet list = [2, 3, 4]\nlet list = [1, ..list]\nlet [1, second_element, ..] = list\n[1.0, ..list] // compile error, type mismatch\nDictionaries\nIn Python, dictionaries can have keys of any type as long as:\n\nthe key type is hashable, such as integers, strings, tuples (due to their immutable values), functions\u2026 and custom mutable objects implementing the __hash__ method.\nthe key is unique in the dictionary. and values of any type.\nIn Gleam, dicts can have keys and values of any type, but all keys must be of the same type in a given dict and all values must be of the same type in a given dict.\n\nThere is no dict literal syntax in Gleam, and you cannot pattern match on a dict. Dicts are generally not used much in Gleam, custom types are more common.\n\nPython\n{\"key1\": \"value1\", \"key2\": \"value2\"}\n{\"key1\":  \"1\", \"key2\": 2}\nGleam\nimport gleam/dict\n\ndict.from_list([#(\"key1\", \"value1\"), #(\"key2\", \"value2\")])\ndict.from_list([#(\"key1\", \"value1\"), #(\"key2\", 2)]) // Type error!\nFlow control\nCase\nCase is one of the most used control flows in Gleam. It can be seen as a switch statement on steroids. It provides a terse way to match a value type to an expression. Gleam\u2019s case expression is fairly similar to Python\u2019s match statement.\n\nPython\nMatching on primitive types:\n\ndef http_error(status):\n    match status:\n        case 400:\n            return \"Bad request\"\n        case 404:\n            return \"Not found\"\n        case 418:\n            return \"I'm a teapot\"\nMatching on tuples with variable capturing:\n\nmatch point:\n    case (0, 0):\n        print(\"Origin\")\n    case (0, y):\n        print(f\"Y={y}\")\n    case (x, 0):\n        print(f\"X={x}\")\n    case (x, y):\n        print(f\"\"X={x}, Y={y}\"\")\n    case _:\n        raise ValueError(\"Not a point\")\nMatching on type constructors:\n\nmatch point:\n    case Point(x=0, y=0):\n        print(\"Origin is the point's location.\")\n    case Point(x=0, y=y):\n        print(f\"Y={y} and the point is on the y-axis.\")\n    case Point(x=x, y=0):\n        print(f\"X={x} and the point is on the x-axis.\")\n    case Point():\n        print(\"The point is located somewhere else on the plane.\")\n    case _:\n        print(\"Not a point\")\nThe match expression supports guards, similar to Gleam:\n\nmatch point:\n    case Point(x, y) if x == y:\n        print(f\"The point is located on the diagonal Y=X at {x}.\")\n    case Point(x, y):\n        print(f\"Point is not on the diagonal.\")\nGleam\nThe case operator is a top level construct in Gleam:\n\ncase some_number {\n  0 -> \"Zero\"\n  1 -> \"One\"\n  2 -> \"Two\"\n  n -> \"Some other number\" // This matches anything\n}\nThe case operator especially coupled with destructuring to provide native pattern matching:\n\ncase xs {\n  [] -> \"This list is empty\"\n  [a] -> \"This list has 1 element\"\n  [a, b] -> \"This list has 2 elements\"\n  _other -> \"This list has more than 2 elements\"\n}\nThe case operator supports guards:\n\ncase xs {\n  [a, b, c] if a >.", "mimetype": "text/plain", "start_char_idx": 9535, "end_char_idx": 13170, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "576c22ef-d5f1-4455-930d-4af3352ff427": {"__data__": {"id_": "576c22ef-d5f1-4455-930d-4af3352ff427", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "689a8098-387b-4521-8a0d-22a40cc614de", "node_type": "1", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "552288883aa1f107cf3746d1265eb4da79d29fc8841784cdbd7e7dc4cfe4b2c2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7578c54-4432-4e56-a9fd-b28d99699820", "node_type": "1", "metadata": {}, "hash": "d7eee46b55b65e8a33a09e02093e400eb2867601a92bc5f470bb9c246644409a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "case Point(x, y):\n        print(f\"Point is not on the diagonal.\")\nGleam\nThe case operator is a top level construct in Gleam:\n\ncase some_number {\n  0 -> \"Zero\"\n  1 -> \"One\"\n  2 -> \"Two\"\n  n -> \"Some other number\" // This matches anything\n}\nThe case operator especially coupled with destructuring to provide native pattern matching:\n\ncase xs {\n  [] -> \"This list is empty\"\n  [a] -> \"This list has 1 element\"\n  [a, b] -> \"This list has 2 elements\"\n  _other -> \"This list has more than 2 elements\"\n}\nThe case operator supports guards:\n\ncase xs {\n  [a, b, c] if a >. b && a <=. c -> \"ok\"\n  _other -> \"ko\"\n}\nand disjoint union matching:\n\ncase number {\n  2 | 4 | 6 | 8 -> \"This is an even number\"\n  1 | 3 | 5 | 7 -> \"This is an odd number\"\n  _ -> \"I'm not sure\"\n}\nTry\nError management is approached differently in Python and Gleam.\n\nPython\nPython uses the notion of exceptions to interrupt the current code flow and pop up the error to the caller.\n\nAn exception is raised using the keyword raise.\n\ndef a_function_that_fails():\n    raise Exception(\"an error\")\nThe callee block will be able to capture any exception raised in the block using a try/except set of blocks:\n\ntry:\n    print(\"executed\")\n    a_function_that_fails()\n    print(\"not_executed\")\nexcept Exception as e:\n    print(\"doing something with the exception\", e)\n\nGleam\nIn contrast in Gleam, errors are just containers with an associated value.\n\nA common container to model an operation result is Result(ReturnType, ErrorType).\n\nA Result is either:\n\nan Error(ErrorValue)\nor an Ok(Data) record\nHandling errors actually means to match the return value against those two scenarios, using a case for instance:\n\ncase int.parse(\"123\") {\n  Error(e) -> io.println(\"That wasn't an Int\")\n  Ok(i) -> io.println(\"We parsed the Int\")\n}\nIn order to simplify this construct, we can use the use expression with the try function from the gleam/result module.\n\nbind a value to the providing name if Ok(Something) is matched\ninterrupt the flow and return Error(Something)\nlet a_number = \"1\"\nlet an_error = \"ouch\"\nlet another_number = \"3\"\n\nuse int_a_number <- try(parse_int(a_number))\nuse attempt_int <- try(parse_int(an_error)) // Error will be returned\nuse int_another_number <- try(parse_int(another_number)) // never gets executed\n\nOk(int_a_number + attempt_int + int_another_number) // never gets executed\nType aliases\nType aliases allow for easy referencing of arbitrary complex types. Even though their type systems does not serve the same function, both Python and Gleam provide this feature.\n\nPython\nA simple variable can store the result of a compound set of types.\n\ntype Headers = list[tuple[str, str]]\n\n# can now be used to annotate a variable\nheaders: Headers = [(\"Content-Type\", \"application/json\")]\nGleam\nThe type keyword can be used to create aliases:\n\npub type Headers =\n  List(#(String, String))\n\nlet headers: Headers = [#(\"Content-Type\", \"application/json\")]\nCustom types\nRecords\nCustom type allows you to define a collection data type with a fixed number of named fields, and the values in those fields can be of differing types.\n\nPython\nPython uses classes to define user-defined, record-like types. Properties are defined as class members and initial values are generally set in the constructor.\n\nBy default the constructor does not provide base initializers in the constructor so some boilerplate is needed:\n\nclass Person:\n    name: str\n    age: int\n\n    def __init__(name: str, age: int) -> None:\n        self.name = name\n        self.age = age\n\nperson = Person(name=\"Jake\", age=20)\n# or with positional arguments Person(\"Jake\", 20)\nname = person.name\nMore recent alternatives are to use dataclasses or to leverage the NamedTuple base type to generate a constructor with initializers.", "mimetype": "text/plain", "start_char_idx": 12609, "end_char_idx": 16351, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c7578c54-4432-4e56-a9fd-b28d99699820": {"__data__": {"id_": "c7578c54-4432-4e56-a9fd-b28d99699820", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "576c22ef-d5f1-4455-930d-4af3352ff427", "node_type": "1", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "5efdb64cadf2b90352ae005c6eab84dd9708c52bdac96a3a466d7ae26c0a8b27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5318db7-2484-4841-b817-aed0cd6df884", "node_type": "1", "metadata": {}, "hash": "ec4eff148fe8885b0e104627be8199dad75c923aad5d9c9268044e34faf0a590", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Python\nPython uses classes to define user-defined, record-like types. Properties are defined as class members and initial values are generally set in the constructor.\n\nBy default the constructor does not provide base initializers in the constructor so some boilerplate is needed:\n\nclass Person:\n    name: str\n    age: int\n\n    def __init__(name: str, age: int) -> None:\n        self.name = name\n        self.age = age\n\nperson = Person(name=\"Jake\", age=20)\n# or with positional arguments Person(\"Jake\", 20)\nname = person.name\nMore recent alternatives are to use dataclasses or to leverage the NamedTuple base type to generate a constructor with initializers.\n\nBy default a class created with the dataclass decorator is mutable (although you can pass options to the dataclass decorator to change the behavior):\n\nfrom dataclasses import dataclasses\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n\nperson = Person(name=\"Jake\", age=20)\nname = person.name\nperson.name = \"John\"  # The name is now \"John\"\nNamedTuples on the other hand are immutable:\n\nfrom typing import NamedTuple\n\nclass Person(NamedTuple):\n    name: str\n    age: int\n\nperson = Person(name=\"Jake\", age=20)\nname = person.name\n\n# cannot reassign a value\nperson.name = \"John\"  # error\nGleam\nGleam\u2019s custom types can be used in much the same way that structs are used in Elixir. At runtime, they have a tuple representation and are compatible with Erlang records.\n\ntype Person {\n  Person(name: String, age: Int)\n}\n\nlet person = Person(name: \"Jake\", age: 35)\nlet name = person.name\nAn important difference to note is there is no OOP in Gleam. Methods can not be added to types.\n\nUnions\nIn Python unions can be declared with the | operator.\n\nIn Gleam functions must always take and receive one type. To have a union of two different types they must be wrapped in a new custom type.\n\nPython\ndef int_or_float(x: int | float) -> str:\n    if isinstance(x, int):\n        return f\"It's an integer: {x}\"\n    else:\n        return f\"It's a float: {x}\"\nGleam\ntype IntOrFloat {\n  AnInt(Int)\n  AFloat(Float)\n}\n\nfn int_or_float(x) {\n  case x {\n    AnInt(1) -> \"It's an integer: 1\"\n    AFloat(1.0) -> \"It's a float: 1.0\"\n  }\n}\nOpaque custom types\nIn Python, constructors cannot be marked as private. Opaque types can be imperfectly emulated using a class method and some magic property that only updates via the class factory method.\n\nIn Gleam, custom types can be defined as being opaque, which causes the constructors for the custom type not to be exported from the module. Without any constructors to import other modules can only interact with opaque types using the intended API.\n\nPython\nclass OnlyCreatable:\n\n    __create_key = object()\n\n    @classmethod\n    def create(cls, value):\n        return OnlyCreatable(cls.__create_key, value)\n\n    def __init__(self, create_key, value):\n        assert(create_key == OnlyCreatable.__create_key), \\\n            \"OnlyCreatable objects must be created using OnlyCreatable.create\"\n        self.value = value\nGleam\npub opaque type Identifier {\n  Identifier(Int)\n}\n\npub fn get_id() {\n  Identifier(100)\n}\nModules\nPython\nThere is no special syntax to define modules as files are modules in Python\n\nGleam\nGleam\u2019s file is a module and named by the file name (and its directory path). Since there is no special syntax to create a module, there can be only one module in a file.\n\n// in file foo.gleam\npub fn identity(x) {\n  x\n}\n// in file main.gleam\nimport foo // if foo was in a folder called `lib` the import would be `lib/foo`\npub fn main() {\n  foo.identity(1)\n}\nImports\nPython\n# inside module src/nasa/moon_base.py\n# imports module src/nasa/rocket_ship.py\nfrom nasa import rocket_ship\n\ndef explore_space():\n    rocket_ship.launch()\nGleam\nImports are relative to the root src folder.\n\nModules in the same directory will need to reference the entire path from src for the target module, even if the target module is in the same folder.", "mimetype": "text/plain", "start_char_idx": 15694, "end_char_idx": 19613, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5318db7-2484-4841-b817-aed0cd6df884": {"__data__": {"id_": "b5318db7-2484-4841-b817-aed0cd6df884", "embedding": null, "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12", "node_type": "4", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "87b15ed0db71cde8e663a4760b6e028d2665fa786eb89ef3304de246c96729f6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7578c54-4432-4e56-a9fd-b28d99699820", "node_type": "1", "metadata": {"source_url": "https://gleam.run/cheatsheets/gleam-for-python-users/", "document_index": 12}, "hash": "186e0dbf5a27d21fa2c396d637b9b75c4f33a415ba11843da0e19aa6355d8604", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since there is no special syntax to create a module, there can be only one module in a file.\n\n// in file foo.gleam\npub fn identity(x) {\n  x\n}\n// in file main.gleam\nimport foo // if foo was in a folder called `lib` the import would be `lib/foo`\npub fn main() {\n  foo.identity(1)\n}\nImports\nPython\n# inside module src/nasa/moon_base.py\n# imports module src/nasa/rocket_ship.py\nfrom nasa import rocket_ship\n\ndef explore_space():\n    rocket_ship.launch()\nGleam\nImports are relative to the root src folder.\n\nModules in the same directory will need to reference the entire path from src for the target module, even if the target module is in the same folder.\n\n// inside module src/nasa/moon_base.gleam\n// imports module src/nasa/rocket_ship.gleam\nimport nasa/rocket_ship\n\npub fn explore_space() {\n  rocket_ship.launch()\n}\nNamed imports\nPython\nimport unix.cat as kitty\nGleam\nimport unix/cat as kitty\nUnqualified imports\nPython\nfrom animal.cat import Cat, stroke\n\ndef main():\n    kitty = Cat(name=\"Nubi\")\n    stroke(kitty)\nGleam\nimport animal/cat.{Cat, stroke}\n\npub fn main() {\n  let kitty = Cat(name: \"Nubi\")\n  stroke(kitty)\n}", "mimetype": "text/plain", "start_char_idx": 18962, "end_char_idx": 20080, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07aa589d-a86d-4694-8757-fb9dc4ab171d": {"__data__": {"id_": "07aa589d-a86d-4694-8757-fb9dc4ab171d", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af0705c7-0e3d-4c08-8cb5-ea843c49d6f6", "node_type": "1", "metadata": {}, "hash": "ec1a1cf02030c57fe4799e44c950d7467a4a5d66134b1d287cbe5d9445d4724d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GPT from Scratch with MLX\nDefine and train GPT-2 on your MacBook\nPranav Jadhav\nTowards Data Science\nPranav Jadhav\n\n\u00b7\nFollow\n\nPublished in\nTowards Data Science\n\n31 min read\n\u00b7\n2 days ago\n\nTable of Contents\nPreparing the data\nCoding GPT-2\nInput Embeddings\nPositional Embeddings\nSelf Attention\nKeys, Queries, and Values\nMulti-Head Attention\nMLP\nBlock\nLayernorms and Skip Connections\nForward Pass\nSampling\nInitialization\nTraining Loop\nReferences\nPreparing the data\nInstall mlx and run the following imports.\n\nimport mlx.core as mx\nimport mlx.nn as nn\nimport mlx.optimizers as optim\nimport mlx.utils as utils\nimport numpy as np\nimport math\nThe first step to training an LLM is collecting a large corpus of text data and then tokenizing it. Tokenization is the process of mapping text to integers, which can be fed into the LLM. Our training corpus for this model will be the works of Shakespeare concatenated into one file. This is roughly 1 million characters and looks like this:\n\nFirst Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n...\nFirst, we read the file as a single long string into the text variable. Then we use the set() function to get all the unique characters in the text which will be our vocabulary. By printing vocab you can see all the characters in our vocabulary as one string, and we have a total of 65 characters which till be our tokens.\n\n# Creating the vocabulary\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\nvocab = sorted(list(set(text)))\nvocab_size = len(vocab)\n\nprint(''.join(vocab))\n# !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\nprint(vocab_size)\n# 65\nProduction models will use tokenization algorithms like byte-pair encoding to generate a larger vocabulary of sub-word chunks. Since our focus today is on the architecture, we will continue with character-level tokenization. Next, we will map our vocabulary to integers known as token IDs. Then we can encode our text into tokens and decode them back to a string.\n\n# Create mapping from vocab to integers\nitos = {i:c for i,c in enumerate(vocab)} # int to string\nstoi = {c:i for i,c in enumerate(vocab)} # string to int\nencode = lambda x: [stoi[c] for c in x]\ndecode = lambda x: ''.join([itos[i] for i in x])\n\nprint(encode(\"hello world\"))\n# [46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\nprint(decode(encode(\"hello world\")))\n# hello world\nWe use theenumerate() function to iterate over all characters and their index in the vocabulary and create a dictionary itos which maps integers to characters and stoi which maps strings to integers. Then we use these mappings to create our encode and decode functions. Now we can encode the entire text and split training and validation data.\n\ndata = encode(text)\nsplit = int(0.9 * len(data))\ntrain_data = data[:split]\nval_data = data[split:]\nCurrently, our training data is just a very long string of tokens. However, we are trying to train our model to predict the next token some given previous tokens. Therefore our dataset should be comprised of examples where the input is some string of tokens and the label is the correct next token. We need to define a model parameter called context length which is the maximum number of tokens used to predict the next token. Our training examples will be the length of our context length.\n\nLet\u2019s look at the first ctx_len+1 tokens.\n\nctx_len = 8\nprint(train_data[:ctx_len + 1])\n# [18, 47, 56, 57, 58,  1, 15, 47, 58]\n# x: [18, 47, 56, 57, 58,  1, 15, 47] | y: 58\nThis is one training example where the input is \u201c18, 47, 56, 57, 58, 1, 15, 47\u201d and the desired output is \u201c58\u201d. This is 8 tokens of context.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3804, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af0705c7-0e3d-4c08-8cb5-ea843c49d6f6": {"__data__": {"id_": "af0705c7-0e3d-4c08-8cb5-ea843c49d6f6", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07aa589d-a86d-4694-8757-fb9dc4ab171d", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "12d10e036645c39ff11c9af1832b47ae57d810c49c680f30d496ae83a24f34f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ffc2b2cd-e530-4058-ac7a-ff17d5af24d3", "node_type": "1", "metadata": {}, "hash": "01ddb955f7ddbe6ba5de3a3004e0e9779c102edadeefe86d4a53f73092b8b242", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We need to define a model parameter called context length which is the maximum number of tokens used to predict the next token. Our training examples will be the length of our context length.\n\nLet\u2019s look at the first ctx_len+1 tokens.\n\nctx_len = 8\nprint(train_data[:ctx_len + 1])\n# [18, 47, 56, 57, 58,  1, 15, 47, 58]\n# x: [18, 47, 56, 57, 58,  1, 15, 47] | y: 58\nThis is one training example where the input is \u201c18, 47, 56, 57, 58, 1, 15, 47\u201d and the desired output is \u201c58\u201d. This is 8 tokens of context. However, we also want to train the model to predict the next token given only 7, 6, 5 \u2026 0 tokens as context which is needed during generation. Therefore we also consider the 8 sub examples packed into this example:\n\nctx_len = 8\nprint(train_data[:ctx_len + 1])\n# [18, 47, 56, 57, 58,  1, 15, 47, 58]\n# 8 sub examples\n# [18] --> 47\n# [18, 47] --> 56\n# [18, 47, 56] --> 57\n# [18, 47, 56, 57] --> 58\n# [18, 47, 56, 57, 58] --> 1\n# [18, 47, 56, 57, 58, 1] --> 15\n# [18, 47, 56, 57, 58, 1, 15] --> 47\n# [18, 47, 56, 57, 58, 1, 15, 47] --> 58\nNotice that the labels are simply the inputs shifted left.\n\nprint(\"inputs: \", train_data[:ctx_len])\nprint(\"labels: \", train_data[1:ctx_len+1]) # labels = inputs indexed 1 higher\n# inputs: [18, 47, 56, 57, 58,  1, 15, 47]\n# labels: [47, 56, 57, 58,  1, 15, 47, 58]\nAt index 0 the input is 18 and the label is 47. At index 1 the input is everything before and including index 1 which is [18, 47] and the label is 56, etc. Now that we understand that the labels are simply the input sequence indexed one higher we can build our datasets.\n\n# Creating training and validation datasets\nctx_len = 8\nX_train = mx.array([train_data[i:i+ctx_len] for i in range(0, len(train_data) - ctx_len, ctx_len)])\ny_train = mx.array([train_data[i+1:i+ctx_len+1] for i in range(0, len(train_data) - ctx_len, ctx_len)])\nX_val = mx.array([val_data[i:i+ctx_len] for i in range(0, len(val_data) - ctx_len, ctx_len)])\ny_val = mx.array([val_data[i+1:i+ctx_len+1] for i in range(0, len(val_data) - ctx_len, ctx_len)])\nWe loop through the data and take chunks of size ctx_len as the inputs (X) and then take the same chunks but at 1 higher index as the labels (y). Then we take these Python lists and create mlx array objects from them. The model internals will be written with mlx so we want our inputs to be mlx arrays.\n\nOne more thing. During training we don\u2019t want to feed the model one example at a time, we want to feed it multiple examples in parallel for efficiency. This group of examples is called our batch, and the number of examples in a group is our batch size. Thus we define a function to generate batches for training.", "mimetype": "text/plain", "start_char_idx": 3299, "end_char_idx": 5945, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ffc2b2cd-e530-4058-ac7a-ff17d5af24d3": {"__data__": {"id_": "ffc2b2cd-e530-4058-ac7a-ff17d5af24d3", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af0705c7-0e3d-4c08-8cb5-ea843c49d6f6", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "6077971b6f99e7dd5e09a3a25edaf50cac9bbbef0a48aac6d5867397f5c16289", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3470cc4e-e26c-4a0f-a0d4-d84fd59bf625", "node_type": "1", "metadata": {}, "hash": "991742a6ff7c31988e98249765f3bf173c1a6acb4bdcfadb1a582b4feba87568", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we take these Python lists and create mlx array objects from them. The model internals will be written with mlx so we want our inputs to be mlx arrays.\n\nOne more thing. During training we don\u2019t want to feed the model one example at a time, we want to feed it multiple examples in parallel for efficiency. This group of examples is called our batch, and the number of examples in a group is our batch size. Thus we define a function to generate batches for training.\n\ndef get_batches(X, y, b_size, shuffle=True):\n    if shuffle:\n        ix = np.arange(X.shape[0])\n        np.random.shuffle(ix)\n        ix = mx.array(ix)\n        X = X[ix]\n        y = y[ix]\n    for i in range(0, X.shape[0], b_size):\n        input = X[i:i+b_size]\n        label = y[i:i+b_size]\n        yield input, label\nIf shuffle=True, we shuffle the data by indexing it with a randomly shuffled index. Then we loop through our dataset and return batch-size chunks from input and label datasets. These chunks are known as mini-batches and are just stacked examples that we process in parallel. These mini-batches will be our input to the model during training.\n\nHere\u2019s an example of a minibatch of 4 examples with context length 8.\n\n\nA single minibatch (image by author)\nThis minibatch packs 32 next-token prediction problems. The model will predict the next token for each token in the input and the labels will be used to calculate the loss. Notice that the labels contain the next token for each index of the inputs.\n\nYou\u2019ll want to keep this picture in your mind because the shapes of these tensors will get hairy. For now, just remember that we will input a tensor of shape (batch_size, ctx_len) to the model.\n\nCoding GPT-2\nLet\u2019s look at the GPT-2 architecture to get an overview of what we are trying to implement.\n\n\nGPT-2 Architecture (image by author)\nDon\u2019t worry if this looks confusing. We will implement it step by step from bottom to top. Let\u2019s start by implementing the input embeddings.\n\nInput Embeddings\nThe purpose of the input embedding layer is to map token IDs to vectors. Each token will be mapped to a vector which will be its representation as it is forwarded through the model. The vectors for each token will accumulate and exchange information as they pass through the model and eventually be used to predict the next token. These vectors are called embeddings.\n\nThe simplest way to map token IDs to vectors is through a lookup table. We create a matrix of size (vocab_size, n_emb) where each row is the embedding vector for the corresponding token. This matrix is known as the embedding weights.", "mimetype": "text/plain", "start_char_idx": 5475, "end_char_idx": 8067, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3470cc4e-e26c-4a0f-a0d4-d84fd59bf625": {"__data__": {"id_": "3470cc4e-e26c-4a0f-a0d4-d84fd59bf625", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ffc2b2cd-e530-4058-ac7a-ff17d5af24d3", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "d141c72fee2dac9dc0d52e9e8d96130f1840ec9c3795a113315631f2792f882c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4192e392-20ce-428f-abc8-e2bac794a237", "node_type": "1", "metadata": {}, "hash": "053fce02e85a1ce5a42fd1ee4e6a9b77d9284c5daba80fd728ddc7e455c5112d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GPT-2 Architecture (image by author)\nDon\u2019t worry if this looks confusing. We will implement it step by step from bottom to top. Let\u2019s start by implementing the input embeddings.\n\nInput Embeddings\nThe purpose of the input embedding layer is to map token IDs to vectors. Each token will be mapped to a vector which will be its representation as it is forwarded through the model. The vectors for each token will accumulate and exchange information as they pass through the model and eventually be used to predict the next token. These vectors are called embeddings.\n\nThe simplest way to map token IDs to vectors is through a lookup table. We create a matrix of size (vocab_size, n_emb) where each row is the embedding vector for the corresponding token. This matrix is known as the embedding weights.\n\n\nEmbedding Layer (image by author)\nThe diagram shows an example embedding layer of size (65, 6). This means there are 65 tokens in the vocabulary and each one will be represented by a length 6 embedding vector. The inputted sequence will be used to index the embedding weights to get the vector corresponding to each token. Remember the minibatches we input into the model? Originally the minibatch is size (batch_size, ctx_len). After passing through the embedding layer it is size (batch_size, ctx_len, n_emb). Instead of each token being a single integer, each token is now a vector of length n_emb.\n\nLet\u2019s define the embedding layer in code now.\n\nn_emb = 6 # You can add these hyperparams at the top of your file\nclass GPT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocab_size, n_emb)\nWe will define a class to organize our implementation. We subclass nn.Module to take advantage of mlx\u2019s features. Then in the init function, we call the superclass constructor and initialize our token embedding layer called wte .\n\nPositional Embeddings\nNext up is the positional embeddings. The purpose of positional embeddings is to encode information about the position of each token in the sequence. This can be added to our input embeddings to get a complete representation of each token that contains information about the token\u2019s position in the sequence.\n\nclass GPT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocab_size, n_emb) # token embeddings\n        self.wpe = nn.Embedding(ctx_len, n_emb) # position embeddings\nThe position embeddings work the same as token embeddings, except instead of having a row for each token we have a row for each possible position index. This means our embedding weights will be of shape (ctx_len, n_emb). Now we implement the __call__ function in our GPT class. This function will contain the forward pass of the model.\n\n# Tensor shapes commented\ndef __call__(self, x):\n    B, T = x.shape # (B = batch_size, T = ctx_len)\n    tok_emb = self.wte(x) # (B, T, n_emb)\n    pos_emb = self.wpe(mx.arange(T)) # (T, n_emb)\n    x = tok_emb + pos_emb # (B, T, n_emb)\nFirst, we break out the dimensions of our input into variables B and T for easy handling. In sequence modeling contexts B and T are usually used as shorthand for \u201cbatch\u201d and \u201ctime\u201d dimensions. In this case, the \u201ctime\u201d dimension of our sequence is the context length.\n\nNext, we calculate token and position embeddings. Notice that for the position embeddings, our input is mx.arange(T) . This will output an array of consecutive integers from 0 to T-1 which is exactly what we want because those are the positions we want to embed. After passing that through the embedding layer we will have a tensor of shape (T, n_emb) because the embedding layer plucks out the n_emb length vector for each of the T positions. Note that even though pos_emb is not the same shape as tok_emb we can add the two because mlx will broadcast, or replicate pos_emb across the batch dimension to allow elementwise addition. Finally, we perform the addition to get the new representations of the tokens with positional information.\n\nSelf-Attention\nSo far the representation vectors for each token have been calculated independently. They have not had the opportunity to exchange any information. This is intuitively bad in language modeling because the meaning and usage of words depend on the surrounding context. Self-attention is how we incorporate information from previous tokens into a given token.\n\nFirst, let\u2019s consider a naive approach. What if we simply represented each token as the average of its representation vector and the vectors of all the tokens before it? This achieves our goal of packing information from previous tokens into the representation for a given token. Here\u2019s what it would look like.", "mimetype": "text/plain", "start_char_idx": 7269, "end_char_idx": 11950, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4192e392-20ce-428f-abc8-e2bac794a237": {"__data__": {"id_": "4192e392-20ce-428f-abc8-e2bac794a237", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3470cc4e-e26c-4a0f-a0d4-d84fd59bf625", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "a80ae90e301b49329eec4c1346104c0c6f6774a8297ab5262b4384731c303e81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eea6c1f7-ec92-4c93-aa05-d1ba5bdd1210", "node_type": "1", "metadata": {}, "hash": "aac543744be46c1819a8df5435de0153541a91dede013a4a2bb27d6b1d665ef2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "image by author\nBut self-attention doesn\u2019t involve writing a for-loop. The key insight is we can achieve this previous token averaging with matrix multiplication!\n\n\nimage by author\nBy multiplying our input sequence on the left by a special matrix we get the desired result. This matrix is known as the attention weights. Notice that each row of the attention weight matrix specificies \u201chow much\u201d of each other token goes into the representation for any given token. For example in row two, we have [0.5, 0.5, 0, 0]. This means that row two of the result will be 0.5*token1 + 0.5*token2 + 0*token3 + 0*token4 , or the average of token1 and token2. Note that the attention weights are a lower-triangular matrix (zeros in upper right entries). This ensures that future tokens will not be included in the representation of a given token. This ensures that tokens can only communicate with the previous tokens because during generation the model will only have access to previous tokens.\n\nLet\u2019s look at how we can construct the attention weight matrix.\n\n\nimage by author\nNotice that if we create an array of zeros with -inf in the upper right entries and then perform row-wise softmax we get the desired attention weights. A good exercise is to step through the softmax calculation for a row to see how this works. The takeaway is that we can take some array of size (ctx_len, ctx_len) and softmax each row to get attention weights that sum to one.\n\nNow we can leave the realm of naive self-attention. Instead of simply averaging previous tokens, we use arbitrary weighted sums over previous tokens. Notice what happens when we do row-wise softmax of an arbitrary matrix.\n\n\nimage by author\nWe still get weights that sum to one on each row. During training, we can learn the numbers in the matrix on the left which will specify how much each token goes into the representation for another token. This is how tokens pay \u201cattention\u201d to each other. But we still haven\u2019t understood where this matrix on the left came from. These pre-softmax attention weights are calculated from the tokens themselves, but indirectly through three linear projections.\n\nKeys, Queries, and Values\n\nimage by author\nEach token in our sequence emits 3 new vectors. These vectors are called keys, queries, and values. We use the dot product of the query vector of one token and the key vector of another token to quantify the \u201caffinity\u201d those two tokens have. We want to calculate the pairwise affinities of each token with every other token, therefore we multiply the query vector (4x3) with the key vector transposed (3x4) to get the raw attention weights (4x4). Due to the way matrix multiplication works the (i,j) entry in the raw attention weights will be the query of token i dot the key of token j or the \u201caffinity\u201d between the two. Thus we have calculated interactions between every token. However, we don\u2019t want past tokens interacting with future tokens so we apply a mask of -inf to the upper right entries to ensure they will zero out after softmax. Then we perform row-wise softmax to get the final attention weights. Instead of multiplying these weights directly with the input, we multiply them with the value projection. This results in the new representations.\n\nNow that we understand attention conceptually, let\u2019s implement it.\n\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n\nWe start by defining the key, query, and value projection layers. Note that instead of going from n_emb to n_emb, we project from n_emb to head_size. This doesn\u2019t change anything, it just means the new representations calculated by attention will be dimension head_size.", "mimetype": "text/plain", "start_char_idx": 11953, "end_char_idx": 15849, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eea6c1f7-ec92-4c93-aa05-d1ba5bdd1210": {"__data__": {"id_": "eea6c1f7-ec92-4c93-aa05-d1ba5bdd1210", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4192e392-20ce-428f-abc8-e2bac794a237", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "3c699053001ec786ca188ed8cd360974088824cc2bb21564fe1d09454cca4836", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8796bb32-6d4c-473d-871d-b822ce8a6e9e", "node_type": "1", "metadata": {}, "hash": "17e51d005026719072acabb0f92802bb9e92d28954e8372606fef21d29aadb7e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we perform row-wise softmax to get the final attention weights. Instead of multiplying these weights directly with the input, we multiply them with the value projection. This results in the new representations.\n\nNow that we understand attention conceptually, let\u2019s implement it.\n\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n\nWe start by defining the key, query, and value projection layers. Note that instead of going from n_emb to n_emb, we project from n_emb to head_size. This doesn\u2019t change anything, it just means the new representations calculated by attention will be dimension head_size.\n\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n    def __call__(self, x): # shapes commented\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\nThe forward pass begins by calculating the key, query, and value projections. We also break out the input shape into the variables B, T, and C for future convenience.\n\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        attn_weights = (Q @ K.transpose([0, 2, 1])) / math.sqrt(self.head_size)\n        # attn_weights.shape = (B, T, T)\nNext, we calculate the attention weights. We only want to transpose the last two dimensions of the key tensor, because the batch dimension is just there so we can forward multiple training examples in parallel. The mlx transpose function expects the new order of the dimensions as input, so we pass it [0, 2, 1] to transpose the last two dimensions. One more thing: we scale the attention weights by the inverse square root of head_size. This is known as scaled attention and the purpose is to ensure that when Q and K are unit variance, attn_weights will be unit variance. If the variance of attn_weights is high, then the softmax will map these small and large values to 0 or 1which results in less complex representations.\n\nThe next step is to apply the mask to ensure we are doing causal language modeling i.e. ensuring tokens cannot attend to future tokens.", "mimetype": "text/plain", "start_char_idx": 14982, "end_char_idx": 18093, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8796bb32-6d4c-473d-871d-b822ce8a6e9e": {"__data__": {"id_": "8796bb32-6d4c-473d-871d-b822ce8a6e9e", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eea6c1f7-ec92-4c93-aa05-d1ba5bdd1210", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "b21a6f615d3dd5677b57930466eb4ed966348290233e07502ee6806da67276a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1822bc4f-4319-41a8-a280-c2e40d7d8d90", "node_type": "1", "metadata": {}, "hash": "8730bb5a20315440986c434559536064e4e91e34e774ca7a2eed529b9caef81f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We only want to transpose the last two dimensions of the key tensor, because the batch dimension is just there so we can forward multiple training examples in parallel. The mlx transpose function expects the new order of the dimensions as input, so we pass it [0, 2, 1] to transpose the last two dimensions. One more thing: we scale the attention weights by the inverse square root of head_size. This is known as scaled attention and the purpose is to ensure that when Q and K are unit variance, attn_weights will be unit variance. If the variance of attn_weights is high, then the softmax will map these small and large values to 0 or 1which results in less complex representations.\n\nThe next step is to apply the mask to ensure we are doing causal language modeling i.e. ensuring tokens cannot attend to future tokens.\n\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        attn_weights = (Q @ K.transpose([0, 2, 1])) / math.sqrt(self.head_size)\n        # attn_weights.shape = (B, T, T)\nWe create the mask with a clever broadcasting trick. Let\u2019s say our ctx_len=4 like in the diagrams above. First, we use mx.arange(4) to set the indices variable to [0, 1, 2, 3].\n\n\nimage by author\nThen we can index like so indices[:, None] to generate a column vector with the values of indices. Similarly, we can get a row vector using indices[None]. Then when we do the < comparison, mlx broadcasts the vectors because they have mismatching shapes so they can\u2019t be compared elementwise. Broadcasting means mlx will replicate the vectors along the lacking dimension. This results in an elementwise comparison of two (4, 4) matrices which makes sense. Side note: I recommend familiarizing yourself with the details of broadcasting by reading this, it comes up all the time when dealing with tensors.\n\nAfter the elementwise comparison, we are left with the following tensor:\n\n[[False,  True,  True,  True],\n [False, False,  True,  True],\n [False, False, False,  True],\n [False, False, False, False]]\nMultiplying this tensor by -1e9, we get:\n\n[[-0e+00, -1e+09, -1e+09, -1e+09],\n [-0e+00, -0e+00, -1e+09, -1e+09],\n [-0e+00, -0e+00, -0e+00, -1e+09],\n [-0e+00, -0e+00, -0e+00, -0e+00]]\nNow we have an additive mask. We can add this matrix to our attention weights to make all the upper right entries very large negative numbers. This will cause them to be zeroed out after the softmax operation. Also, note that we add \u201c_\u201d as a prefix to the attribute name _causal_mask which marks it as a private variable. This signals to mlx that it is not a parameter and should not be updated during training.", "mimetype": "text/plain", "start_char_idx": 17273, "end_char_idx": 20488, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1822bc4f-4319-41a8-a280-c2e40d7d8d90": {"__data__": {"id_": "1822bc4f-4319-41a8-a280-c2e40d7d8d90", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8796bb32-6d4c-473d-871d-b822ce8a6e9e", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "99d7f97ca6121987d8ce2083977bc8b3a8d5ad6564338e30dd165bb9bd9df69e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7d21cbc0-db4a-43f6-adf9-3f5d922207a5", "node_type": "1", "metadata": {}, "hash": "e22ec8d68b785fc705938b8410a9989334dd2ad09e1fd71b1583885c7ce26a9b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We can add this matrix to our attention weights to make all the upper right entries very large negative numbers. This will cause them to be zeroed out after the softmax operation. Also, note that we add \u201c_\u201d as a prefix to the attribute name _causal_mask which marks it as a private variable. This signals to mlx that it is not a parameter and should not be updated during training.\n\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        attn_weights = (Q @ K.transpose([0, 2, 1])) / math.sqrt(self.head_size)\n        # attn_weights.shape = (B, T, T)\n        attn_weights = attn_weights + self._causal_mask\n        attn_weights = mx.softmax(attn_weights, axis=-1)\n        o = (attn_weights @ V) # (B, T, head_size)\nNow we can softmax row-wise to get the final attention weights and multiply these weights by the values to get our output. Note we pass axis=-1 to softmax which specifies that we want to softmax across the last dimension which are the rows.\n\nThe final step is output linear projection and dropout.\n\ndropout = 0.1 # add this with hyperparams at top of file\nclass Attention(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n        self.c_proj = nn.Linear(head_size, n_emb) # output projection\n        self.resid_dropout = nn.Dropout(dropout)\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        attn_weights = (Q @ K.transpose([0, 2, 1])) / math.sqrt(self.head_size)\n        # attn_weights.shape = (B, T, T)\n        attn_weights = attn_weights + self._causal_mask\n        attn_weights = mx.softmax(attn_weights, axis=-1)\n        o = (attn_weights @ V) # (B, T, head_size)\n        o = self.c_proj(self.resid_dropout(o))\n        return o\nWe add two new layers, c_proj and resid_dropout which are the output projection and residual dropout. The output projection is to return the vectors to their original dimension n_emb. The dropout is added for regularization and training stability which is important as we start layering the transformer blocks to get a deep network. And that\u2019s it for implementing one attention head!\n\nMulti-Head Attention\nInstead of having just one attention head LLMs often use multiple attention heads in parallel and concatenate their outputs to create the final representation. For example, let\u2019s say we had one attention head with head_size=64 so the vector it produced for each token was 64 dimensional. We could achieve the same thing with 4 parallel attention heads each with head_size=16 by concatenating their outputs to produce a 16x4 = 64 dimensional output. Multi-head attention allows the model to learn more complex representations because each head learns different projections and attention weights.", "mimetype": "text/plain", "start_char_idx": 20107, "end_char_idx": 23963, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d21cbc0-db4a-43f6-adf9-3f5d922207a5": {"__data__": {"id_": "7d21cbc0-db4a-43f6-adf9-3f5d922207a5", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1822bc4f-4319-41a8-a280-c2e40d7d8d90", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "e76599dd57bfa486d406d07738be851e734cef4e7a1750d136d604e0ea26ee3e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9069eda0-f363-47bc-9f89-e0888c6aeffb", "node_type": "1", "metadata": {}, "hash": "967e39891cb86e37bd1f729447c89991f94522ed7413f2e8baf982457c34ea86", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The output projection is to return the vectors to their original dimension n_emb. The dropout is added for regularization and training stability which is important as we start layering the transformer blocks to get a deep network. And that\u2019s it for implementing one attention head!\n\nMulti-Head Attention\nInstead of having just one attention head LLMs often use multiple attention heads in parallel and concatenate their outputs to create the final representation. For example, let\u2019s say we had one attention head with head_size=64 so the vector it produced for each token was 64 dimensional. We could achieve the same thing with 4 parallel attention heads each with head_size=16 by concatenating their outputs to produce a 16x4 = 64 dimensional output. Multi-head attention allows the model to learn more complex representations because each head learns different projections and attention weights.\n\nn_heads = 4\nclass MultiHeadAttention(nn.Module): # naive implementation\n    def __init__(self):\n        super().__init__()\n        self.heads = [Attention(head_size // n_heads) for _ in range(n_heads)]\n    def __call__(self, x):\n        return mx.concatenate([head(x) for head in self.heads], axis=-1)\nThe straightforward implementation is to create a list of n_heads attention heads where each one has size equal to our final head size divided by n_heads. Then we concatenate the output of each head over the last axis. However, this implementation is inefficient and does not take advantage of the speed of tensors. Let\u2019s implement multi-head attention with the power of tensors.\n\nhead_size = 64 # put at top of file\nclass MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n        self.c_proj = nn.Linear(head_size, n_emb) # output projection\n        self.resid_dropout = nn.Dropout(dropout)\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\nWe start with our single-head attention implementation. The __init__() function has not changed. The forward pass begins as normal with the creation of the key, query, and value projections.\n\nhead_size = 64 # put at top of file\nn_heads = 8 # put at top of file\nclass MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n        self.c_proj = nn.Linear(head_size, n_emb) # output projection\n        self.resid_dropout = nn.Dropout(dropout)\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        mha_shape = (B, T, n_heads, head_size//n_heads)\n        K = mx.as_strided(K, (mha_shape)) # (B, T, n_heads, head_size//n_heads)\n        Q = mx.as_strided(Q, (mha_shape)) # (B, T, n_heads, head_size//n_heads)\n        V = mx.as_strided(V, (mha_shape)) # (B, T, n_heads, head_size//n_heads)\nThe next thing we need to do is introduce a new dimension for the number of heads n_heads .", "mimetype": "text/plain", "start_char_idx": 23065, "end_char_idx": 26860, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9069eda0-f363-47bc-9f89-e0888c6aeffb": {"__data__": {"id_": "9069eda0-f363-47bc-9f89-e0888c6aeffb", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d21cbc0-db4a-43f6-adf9-3f5d922207a5", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "28fde0d3d4b93baab75a2bfd7f7a9829a03827931c26b8c35abd053e7b8da4d8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a63e96f4-356b-4247-a451-b62171151193", "node_type": "1", "metadata": {}, "hash": "859bd2c50b1655679651478def43f6b31c098e94e6e76c1dc735688cb5b900a8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the naive implementation, we had separate attention objects each with their own key, query, and value tensors but now we have them all in one tensor, therefore we need a dimension for the heads. We define the new shape we want in mha_shape . Then we use mx.as_strided() to reshape each tensor to have the head dimension. This function is equivalent to view from pytorch and tells mlx to treat this array as a different shape. But we still have a problem. Notice that we if try to multiply Q @ K_t (where K_t is K transposed over it\u2019s last 2 dims) to compute attention weights as we did before, we will be multiplying the following shapes:\n\n(B, T, n_heads, head_size//n_heads) @ (B, T, head_size//n_heads, n_heads)\nResult shape: (B, T, n_heads, n_heads)\nThis would result in a tensor of shape (B, T, n_heads, n_heads) which is incorrect. With one head our attention weights were shape (B, T, T) which makes sense because it gives us the interaction between each pair of tokens. So now our shape should be the same but with a heads dimension: (B, n_heads, T, T) . We achieve this by transposing the dimensions of keys, queries, and values after we reshape them to make n_heads dimension 1 instead of 2.\n\nhead_size = 64 # put at top of file\nn_heads = 8 # put at top of file\nclass MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n        self.c_proj = nn.Linear(head_size, n_emb) # output projection\n        self.attn_dropout = nn.Dropout(dropout)\n        self.resid_dropout = nn.Dropout(dropout)\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        mha_shape = (B, T, n_heads, head_size//n_heads)\n        K = mx.as_strided(K, (mha_shape)).transpose([0, 2, 1, 3]) # (B, n_heads, T, head_size//n_heads)\n        Q = mx.as_strided(Q, (mha_shape)).transpose([0, 2, 1, 3]) # (B, n_heads, T, head_size//n_heads)\n        V = mx.as_strided(V, (mha_shape)).transpose([0, 2, 1, 3]) # (B, n_heads, T, head_size//n_heads)\n        attn_weights = (Q @ K.transpose([0, 1, 3, 2])) / math.sqrt(Q.shape[-1]) # (B, n_heads, T, T)\n        attn_weights = attn_weights + self._causal_mask[:T, :T]\n        attn_weights = mx.softmax(attn_weights, axis=-1)\n        attn_weights = self.attn_dropout(attn_weights)\n        o = (attn_weights @ V) # (B, n_heads, T, head_size//n_heads)\n\nNow we can calculate the correction attention weights. Notice that we scale the attention weights by the size of an individual attention head rather than head_size which would be the size after concatenation. We also apply dropout to the attention weights.\n\nFinally, we perform the concatenation and apply the output projection and dropout.", "mimetype": "text/plain", "start_char_idx": 26861, "end_char_idx": 30002, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a63e96f4-356b-4247-a451-b62171151193": {"__data__": {"id_": "a63e96f4-356b-4247-a451-b62171151193", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9069eda0-f363-47bc-9f89-e0888c6aeffb", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "366bfb081d5b2a7fa3dd98f172ae62da0889937a7c684e0523e2eb73f22740fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdcfd7ce-7b1b-4c85-8def-0203ddce26e2", "node_type": "1", "metadata": {}, "hash": "cb2dbfd5dc5787a26937b4ff1fcd5c179ff98b8455a8635a167e9a1b5f2a4d13", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Notice that we scale the attention weights by the size of an individual attention head rather than head_size which would be the size after concatenation. We also apply dropout to the attention weights.\n\nFinally, we perform the concatenation and apply the output projection and dropout.\n\nhead_size = 64 # put at top of file\nn_heads = 8 # put at top of file\nclass MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n        indices = mx.arange(ctx_len)\n        mask = indices[:, None] < indices[None] # broadcasting trick\n        self._causal_mask = mask * -1e9\n        self.c_proj = nn.Linear(head_size, n_emb) # output projection\n        self.attn_dropout = nn.Dropout(dropout)\n        self.resid_dropout = nn.Dropout(dropout)\n    def __call__(self, x):\n        B, T, C = x.shape # (batch_size, ctx_len, n_emb)\n        K = self.k_proj(x) # (B, T, head_size)\n        Q = self.q_proj(x) # (B, T, head_size)\n        V = self.v_proj(x) # (B, T, head_size)\n        mha_shape = (B, T, n_heads, head_size//n_heads)\n        K = mx.as_strided(K, (mha_shape)).transpose([0, 2, 1, 3]) # (B, n_heads, T, head_size//n_heads)\n        Q = mx.as_strided(Q, (mha_shape)).transpose([0, 2, 1, 3]) # (B, n_heads, T, head_size//n_heads)\n        V = mx.as_strided(V, (mha_shape)).transpose([0, 2, 1, 3]) # (B, n_heads, T, head_size//n_heads)\n        attn_weights = (Q @ K.transpose([0, 1, 3, 2])) / math.sqrt(Q.shape[-1]) # (B, n_heads, T, T)\n        attn_weights = attn_weights + self._causal_mask[:T, :T]\n        attn_weights = mx.softmax(attn_weights, axis=-1)\n        attn_weights = self.attn_dropout(attn_weights)\n        o = (attn_weights @ V) # (B, n_heads, T, head_size//n_heads)\n        o = o.transpose([0, 2, 1, 3]).reshape((B, T, head_size)) # concat heads\n        o = self.c_proj(self.resid_dropout(o))\n        return o\nSince we have everything in one tensor, we can do some shape manipulation to do the concatenation. First, we move n_heads back to the second to last dimension with the transpose function. Then we reshape back to the original size to undo the splitting into heads we performed earlier. This is the same as concatenating the final vectors from each head. And that\u2019s it for multi-head attention! We\u2019ve gotten through the most intense part of our implementation.\n\nMLP\nThe next part of the architecture is the multilayer perception or MLP. This is a fancy way of saying 2 stacked linear layers. There\u2019s not much to be said here, it is a standard neural network.\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.c_fc = nn.Linear(n_emb, 4 * n_emb)\n        self.gelu = nn.GELU()\n        self.c_proj = nn.Linear(4 * n_emb, n_emb)\n        self.dropout = nn.Dropout(dropout)\n    def __call__(self, x):\n        x = self.gelu(self.c_fc(x))\n        x = self.c_proj(x)\n        x = self.dropout(x)\n        return x\nWe take the input and project it to a higher dimension with c_fc . Then we apply gelu nonlinearity and project it back down to the embedding dimension with c_proj . Finally, we apply dropout and return. The purpose of the MLP is to allow for some computation after the vectors have communicated during attention. We will stack these communication layers (attention) and computation layers (mlp) into a block.\n\nBlock\nA GPT block consists of attention followed by an MLP. These blocks will be repeated to make the architecture deep.", "mimetype": "text/plain", "start_char_idx": 29717, "end_char_idx": 33310, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bdcfd7ce-7b1b-4c85-8def-0203ddce26e2": {"__data__": {"id_": "bdcfd7ce-7b1b-4c85-8def-0203ddce26e2", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a63e96f4-356b-4247-a451-b62171151193", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "30e521914fdc124263c61f8fa0b21766f97b97fab2f7ce66e03a8b7c7c122df3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1f3a10dc-a55c-4359-b6ef-8e63143e08d0", "node_type": "1", "metadata": {}, "hash": "28d5aba4aef3123717c2e715e2c3b97c334a6ec7ff748993a23c7e20088a9f1c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we apply gelu nonlinearity and project it back down to the embedding dimension with c_proj . Finally, we apply dropout and return. The purpose of the MLP is to allow for some computation after the vectors have communicated during attention. We will stack these communication layers (attention) and computation layers (mlp) into a block.\n\nBlock\nA GPT block consists of attention followed by an MLP. These blocks will be repeated to make the architecture deep.\n\nclass Block(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mlp = MLP()\n        self.mha = MultiHeadAttention()\n    def __call__(self, x):\n        x = self.mha(x)\n        x = self.mlp(x)\n        return x\nNow, we need to add two more features to improve training stability. Let\u2019s take a look at the architecture diagram again.\n\nLayernorms and Skip Connections\n\nimage by author\nWe still need to implement the components highlighted in red. The arrows are skip connections. Instead of the input being transformed directly, the effect of the attention and MLP layers is additive. Their result is added to the input instead of directly replacing it. This is good for the training stability of deep networks since in the backward pass, the operands of an addition operation will receive the same gradient as their sum. Gradients can thus flow backwards freely which prevents issues like vanishing/exploding gradients that plague deep networks. Layernorm also helps with training stability by ensuring activations are normally distributed. Here is the final implementation.\n\nclass Block(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mlp = MLP()\n        self.mha = MultiHeadAttention()\n        self.ln_1 = nn.LayerNorm(dims=n_emb)\n        self.ln_2 = nn.LayerNorm(dims=n_emb)\n    def __call__(self, x):\n        x = x + self.mha(self.ln_1(x))\n        x = x + self.mlp(self.ln_2(x))\n        return x\nLayernorm is applied before multi-head attention and MLP. The skip connections are added with x = x + ... making the operations additive.\n\nForward Pass\nWith the Block defined, we can finish the full GPT-2 forward pass.\n\nn_layers = 3 # put at top of file\nclass GPT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocab_size, n_emb) # token embeddings\n        self.wpe = nn.Embedding(ctx_len, n_emb) # position embeddings\n        self.blocks = nn.Sequential(\n            *[Block() for _ in range(n_layers)],\n        ) # transformer blocks\n        self.ln_f = nn.LayerNorm(dims=n_emb) # final layernorm\n        self.lm_head = nn.Linear(n_emb, vocab_size) # output projection\n    # Tensor shapes commented\n    def __call__(self, x):\n        B, T = x.shape # (B = batch_size, T = ctx_len)\n        tok_emb = self.wte(x) # (B, T, n_emb)\n        pos_emb = self.wpe(mx.arange(T)) # (T, n_emb)\n        x = tok_emb + pos_emb # (B, T, n_emb)\n        x = self.blocks(x) # (B, T, n_emb)\n        x = self.ln_f(x) # (B, T, b_emb)\n        logits = self.lm_head(x) # (B, T, vocab_size)\n        return logits\nWe create a container for the blocks using nn.Sequential which takes any input and passes it sequentially through the contained layers. Then we can apply all the blocks with self.blocks(x) . Finally, we apply a layer norm and then the lm_head. The lm_head or language modeling head is just a linear layer that maps from the embedding dimension to the vocab size. The model will output a vector containing some value for each word in our vocabulary, or the logits. We can softmax the logits to get a probability distribution over the vocabulary which we can sample from to get the next token. We will also use the logits to calculate the loss during training. There are just two more things we need to implement before we begin training.\n\nSampling\nWe need to write a generate function to sample from the model once training is complete. The idea is that we start with some sequence of our choice, then we predict the next token and append this to our sequence. Then we feed the new sequence in and predict the next token again. This continues until we decide to stop.", "mimetype": "text/plain", "start_char_idx": 32847, "end_char_idx": 36963, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1f3a10dc-a55c-4359-b6ef-8e63143e08d0": {"__data__": {"id_": "1f3a10dc-a55c-4359-b6ef-8e63143e08d0", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdcfd7ce-7b1b-4c85-8def-0203ddce26e2", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "289116f400aac65f99649643327ec62953781543c129380c9270bc9669ac5c68", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "494cf316-3b15-4c28-8282-7a0ac4aed7b7", "node_type": "1", "metadata": {}, "hash": "84e3b704def75e8a5dbf61b9d281b511b49bf94a2fd62a16a03b92387368b31c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we can apply all the blocks with self.blocks(x) . Finally, we apply a layer norm and then the lm_head. The lm_head or language modeling head is just a linear layer that maps from the embedding dimension to the vocab size. The model will output a vector containing some value for each word in our vocabulary, or the logits. We can softmax the logits to get a probability distribution over the vocabulary which we can sample from to get the next token. We will also use the logits to calculate the loss during training. There are just two more things we need to implement before we begin training.\n\nSampling\nWe need to write a generate function to sample from the model once training is complete. The idea is that we start with some sequence of our choice, then we predict the next token and append this to our sequence. Then we feed the new sequence in and predict the next token again. This continues until we decide to stop.\n\n# method of GPT class\ndef generate(self, max_new_tokens):\n  ctx = mx.zeros((1, 1), dtype=mx.int32)\nWe prompt the model with a single token, zero. Zero is the newline character so it is a natural place to start the generation since we just want to see how Shakespeare-like our model can get. Note that we initialize the shape to (1, 1) to simulate a single batch with a sequence length of one.\n\n# method of GPT class\ndef generate(self, max_new_tokens):\n  ctx = mx.zeros((1, 1), dtype=mx.int32)\n  for _ in range(max_new_tokens):\n    logits = self(ctx[:, -ctx_len:]) # pass in last ctx_len characters\n    logits = logits[:, -1, :] # get logits for the next token\n    next_tok = mx.random.categorical(logits, num_samples=1)\n    ctx = mx.concatenate((ctx, next_tok), axis=1)\nreturn ctx\nThen we get the logits for the next token by passing in the last ctx_len characters to the model. However, our model output is of shape (B, T, vocab_size) since it predicts the next token logits for each token in the input. We use all of that during training, but now we only want the logits for the last token because we can use this to sample a new token. Therefore we index the logits to get the last element in the first dimension which is the sequence dimension. Then we sample the next token using the mx.random.categorical() function which takes the logits and the number of samples we want as input. This function will softmax the logits to turn them into a probability distribution and then randomly sample a token according to the probabilities. Finally, we concatenate the new token to the context and repeat the process max_new_tokens number of times.\n\nInitialization\nThe last thing to do is handle weight initialization which is important for training dynamics.\n\n# method of GPT\ndef _init_parameters(self):\n    normal_init = nn.init.normal(mean=0.0, std=0.02)\n    residual_init = nn.init.normal(mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\nFirst, we define two different nn.init.normal functions. The first one is for initializing all linear and embedding layers. The second one is for initializing linear layers that are specifically residual projections i.e. the last linear layer inside multi-head attention and MLP. The reason for this special initialization is that it checks accumulation along the residual path as model depth increases according to the GPT-2 paper [2].\n\nIn mlx we can change the parameters of the model using the mx.update() function. Checking the docs, it expects a complete or partial dictionary of the new model parameters. We can see what this dictionary looks like by printing out self.parameters() inside the GPT class.", "mimetype": "text/plain", "start_char_idx": 36033, "end_char_idx": 39611, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "494cf316-3b15-4c28-8282-7a0ac4aed7b7": {"__data__": {"id_": "494cf316-3b15-4c28-8282-7a0ac4aed7b7", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f3a10dc-a55c-4359-b6ef-8e63143e08d0", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "e3c68bcd8db30a744c9c2805b515aed0aeea56261b62ff13cd76239d2fbc145b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a77a080e-5173-4671-8834-73146464a468", "node_type": "1", "metadata": {}, "hash": "1e9a1567738f8d853ac7df6a256cf710ad968bab0adf131ec3e9c973071b5c87", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# method of GPT\ndef _init_parameters(self):\n    normal_init = nn.init.normal(mean=0.0, std=0.02)\n    residual_init = nn.init.normal(mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\nFirst, we define two different nn.init.normal functions. The first one is for initializing all linear and embedding layers. The second one is for initializing linear layers that are specifically residual projections i.e. the last linear layer inside multi-head attention and MLP. The reason for this special initialization is that it checks accumulation along the residual path as model depth increases according to the GPT-2 paper [2].\n\nIn mlx we can change the parameters of the model using the mx.update() function. Checking the docs, it expects a complete or partial dictionary of the new model parameters. We can see what this dictionary looks like by printing out self.parameters() inside the GPT class.\n\n{'wte': {'weight': array([[-0.025084, -0.0197523, -0.0341617, ..., -0.0979123, -0.0830218, -0.0784692],\n       [-0.00777913, -0.117002, -0.0310708, ..., 0.0128591, 0.122941, 0.000414443],\n       [0.0240044, -0.0859084, 0.0253116, ..., 0.108967, 0.0767123, 0.0221565],\n       ...,\n       [0.050729, -0.04578, 0.0685943, ..., -0.0496998, -0.00350879, -0.00631825],\n       [0.00518804, 0.0499818, 0.0330045, ..., 0.0300661, 0.0431054, 0.000958906],\n       [-0.0323007, 0.0132046, 0.0208218, ..., -0.0785159, 0.00436121, -0.00726994]], dtype=float32)}, 'wpe': {'weight': array([[0.000797923, -0.0396898, -0.029047, ..., -0.0132273, 0.00684483, -0.0067624],\n       [-0.0247021, -0.0274349, 0.0310587, ..., -0.100099, 0.0301566, -0.0178732],\n       [0.0929172, -0.0468649, 0.0101506, ..., -0.0341086, -0.0516283, 0.0447596],\n       ...,\n       [-0.0508172, 0.0892201, -0.00183612, ..., -0.00341944, 0.023437, 0.0296461],\n       [0.0105829, 0.0688093, 0.146744, ..., -0.0836337, 0.0206679, 0.0184166],\n       [-0.00578717, -0.0606196, -0.0917056, ..., -0.0641549, -0.0490424, 0.0998114]], dtype=float32)}, 'blocks': {'layers': [{'mlp': {'c_fc': {'weight': array([[0.0169199, 0.00264431, 0.0316978, ..., -0.0596867, -0.0153549, 0.0176386],\n       ...\nIt\u2019s a nested dictionary containing each model weight as an mx.array. So to initialize the parameters of our model we need to build up a dictionary like this with our new params and pass them to self.update() .", "mimetype": "text/plain", "start_char_idx": 38722, "end_char_idx": 41066, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a77a080e-5173-4671-8834-73146464a468": {"__data__": {"id_": "a77a080e-5173-4671-8834-73146464a468", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "494cf316-3b15-4c28-8282-7a0ac4aed7b7", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "337bedc612718e8e53b651c49185b35ed68884b7f055545067ec62f4f4e6abad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c91aae05-2a0e-42c8-9805-10d5ff56a49a", "node_type": "1", "metadata": {}, "hash": "3b5985ef333bf0b47e4995c2895c6076b7b02e7601fa9c64fe6c22b96158fef4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "So to initialize the parameters of our model we need to build up a dictionary like this with our new params and pass them to self.update() . We can achieve this as follows:\n\n# method of GPT\ndef _init_parameters(self):\n    normal_init = nn.init.normal(mean=0.0, std=0.02)\n    residual_init = nn.init.normal(mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\n    new_params = []\n    for name, module in self.named_modules():\n        if isinstance(module, nn.layers.linear.Linear):\n            new_params.append((name + '.weight', normal_init(module.weight)))\n        elif isinstance(module, nn.layers.embedding.Embedding):\n            new_params.append((name + '.weight', normal_init(module.weight)\nWe maintain a list of tuples called new_params which will contain tuples of (parameter_name, new_value). Next, we loop through each nn.Module object in our model with self.named_modules() which returns tuples of (name, module). If we print out the module names within the loop we see that they look like this:\n\nlm_head\nblocks\nblocks.layers.4\nblocks.layers.3\nblocks.layers.3.ln_2\nblocks.layers.3.ln_1\nblocks.layers.3.mha\nblocks.layers.3.mha.resid_dropout\nblocks.layers.3.mha.c_proj\nblocks.layers.3.mha.attn_dropout\nblocks.layers.3.mha.c_attn\n...\nblocks.layers.0.mlp.dropout\nblocks.layers.0.mlp.c_proj\nblocks.layers.0.mlp.gelu\nblocks.layers.0.mlp.c_fc\nwpe\nwte\nWe use the isinstance() function to find the linear and embedding layers and then add them to our list. For example, say we are looping and reach \u201cblocks.layers.0.mlp.c_fc\u201d which is the first linear layer in the MLP. This would trigger the first if statement, and the tuple (\"block.layers.0.mlp.c_fc.weight\", [<normally initialized weight here>]) would be added to our list. We have to add \u201c.weight\u201d to the name because we specifically want to initialize the weight in this way, not the bias. Now we need to handle the residual projection initialization.\n\n# method of GPT\ndef _init_parameters(self):\n    normal_init = nn.init.normal(mean=0.0, std=0.02)\n    residual_init = nn.init.normal(mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\n    new_params = []\n    for name, module in self.named_modules():\n        if isinstance(module, nn.layers.linear.Linear):\n            if 'c_proj' in name: # residual projection\n                new_params.append((name + '.weight', residual_init(module.weight)))\n            else:\n                new_params.append((name + '.weight', normal_init(module.weight)))\n        elif isinstance(module, nn.layers.embedding.Embedding):\n            new_params.append((name + '.weight', normal_init(module.weight)))\nAfter checking if the module is a linear layer, we check if \u201cc_proj\u201d is in the name because that\u2019s how we named the residual projections. Then we can apply the special initialization. Finally, we need to initialize the biases to be zero.\n\n# method of GPT\ndef _init_parameters(self):\n    normal_init = nn.init.normal(mean=0.0, std=0.02)\n    residual_init = nn.init.normal(mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\n    new_params = []\n    for name, module in self.named_modules():\n        if isinstance(module, nn.layers.linear.Linear):\n            if 'c_proj' in name:\n                new_params.append((name + '.weight', residual_init(module.weight)))\n            else:\n                new_params.append((name + '.weight', normal_init(module.weight)))\n            if 'bias' in module:\n                new_params.append((name + '.bias', mx.zeros(module.bias.shape)))\n        elif isinstance(module, nn.layers.embedding.Embedding):\n            new_params.append((name + '.weight', normal_init(module.weight)))\n    self = self.update(utils.tree_unflatten(new_params))\nWe add another if statement under our linear branch to check if the nn.Module object has a bias attribute. If it does, we add it to the list initialized to zeros. Finally, we need to transform our list of tuples into a nested dictionary. Luckily mlx has some functions implemented for dealing with parameter dictionaries, and we can use util.tree_unflatten() to convert this list of tuples to a nested parameter dictionary. This is passed into the update method to initialize the parameters. Now we can call _init_parameters() in the constructor.", "mimetype": "text/plain", "start_char_idx": 40926, "end_char_idx": 45134, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c91aae05-2a0e-42c8-9805-10d5ff56a49a": {"__data__": {"id_": "c91aae05-2a0e-42c8-9805-10d5ff56a49a", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a77a080e-5173-4671-8834-73146464a468", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "96f005c8f2b053bfdf50e78231a20de2c457d361e22b97985ddabb111ee9fca9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9e726e5f-157b-458e-9622-ba84969f6f8e", "node_type": "1", "metadata": {}, "hash": "d248076eac20780cccf3ca67fa4aa3a02f0537fd999f16a7a4f3c8a52e0422d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If it does, we add it to the list initialized to zeros. Finally, we need to transform our list of tuples into a nested dictionary. Luckily mlx has some functions implemented for dealing with parameter dictionaries, and we can use util.tree_unflatten() to convert this list of tuples to a nested parameter dictionary. This is passed into the update method to initialize the parameters. Now we can call _init_parameters() in the constructor.\n\nclass GPT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocab_size, n_emb) # token embeddings\n        self.wpe = nn.Embedding(ctx_len, n_emb) # position embeddings\n        self.blocks = nn.Sequential(\n            *[Block() for _ in range(n_layers)],\n        ) # transformer blocks\n        self.ln_f = nn.LayerNorm(dims=n_emb) # final layernorm\n        self.lm_head = nn.Linear(n_emb, vocab_size) # output projection\n        self._init_parameters() # <-- initialize params\n        # print total number of params on initialization\n        total_params = sum([p.size for n,p in utils.tree_flatten(self.parameters())])\n        print(f\"Total params: {(total_params / 1e6):.3f}M\")\n    # Tensor shapes commented\n    def __call__(self, x):\n        B, T = x.shape # (B = batch_size, T = ctx_len)\n        tok_emb = self.wte(x) # (B, T, n_emb)\n        pos_emb = self.wpe(mx.arange(T)) # (T, n_emb)\n        x = tok_emb + pos_emb # (B, T, n_emb)\n        x = self.blocks(x) # (B, T, n_emb)\n        x = self.ln_f(x) # (B, T, b_emb)\n        logits = self.lm_head(x) # (B, T, vocab_size)\n        return logits\n    def generate(self, max_new_tokens):\n        ctx = mx.zeros((1, 1), dtype=mx.int32)\n        for _ in range(max_new_tokens):\n          logits = self(ctx[:, -ctx_len:]) # pass in last ctx_len characters\n          logits = logits[:, -1, :] # get logits for the next token\n          next_tok = mx.random.categorical(logits, num_samples=1)\n          ctx = mx.concatenate((ctx, next_tok), axis=1)\n        return ctx\n    def _init_parameters(self):\n        normal_init = nn.init.normal(mean=0.0, std=0.02)\n        residual_init = nn.init.normal(mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\n        new_params = []\n        for name, module in self.named_modules():\n            if isinstance(module, nn.layers.linear.Linear):\n                if 'c_proj' in name:\n                    new_params.append((name + '.weight', residual_init(module.weight)))\n                else:\n                    new_params.append((name + '.weight', normal_init(module.weight)))\n                if 'bias' in module:\n                    new_params.append((name + '.bias', mx.zeros(module.bias.shape)))\n            elif isinstance(module, nn.layers.embedding.Embedding):\n                new_params.append((name + '.weight', normal_init(module.weight)))\n        self = self.update(utils.tree_unflatten(new_params))\n\nWe also add 2 lines of code in the constructor to print the total number of params. Finally, we are ready to build the training loop.\n\nTraining Loop\nTo train the model we need a loss function. Since we are predicting classes (next token) we use cross-entropy loss.\n\ndef loss_fn(model, x, y):\n    logits = model(x)\n    B, T, C = logits.shape # (batch_size, seq_len, vocab_size)\n    logits = logits.reshape(B*T, C)\n    y = y.reshape(B*T)\n    loss = nn.losses.cross_entropy(logits, y, reduction='mean')\n    return loss\nFirst, we get the logits from the model. Then we reshape logits to make a list of vocab_size length arrays. We also reshape y, the correct token ids, to have the same length. Then we use the built-in cross-entropy loss function to calculate the loss for each example and average them to get a single value.\n\nmodel = GPT()\nmx.eval(model.parameters()) # Create the model params (mlx is lazy evaluation)\nloss_and_grad = nn.value_and_grad(model, loss_fn)\nlr = 0.1\noptimizer = optim.AdamW(learning_rate=lr)\nNext, we instantiate the model, but since mlx is lazy evaluation it won\u2019t allocate and create the parameters.", "mimetype": "text/plain", "start_char_idx": 44695, "end_char_idx": 48695, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9e726e5f-157b-458e-9622-ba84969f6f8e": {"__data__": {"id_": "9e726e5f-157b-458e-9622-ba84969f6f8e", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c91aae05-2a0e-42c8-9805-10d5ff56a49a", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "22ae7e8cf37690c362bd923b8e8b66133580b1d9aa14f16d718337254a44d187", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d9107d2-532d-49f5-ad5f-149f1ae99205", "node_type": "1", "metadata": {}, "hash": "17b0ac1fd5b08094642700181486f79cd221f667d48be94723c9c50ef6ccdeb8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we reshape logits to make a list of vocab_size length arrays. We also reshape y, the correct token ids, to have the same length. Then we use the built-in cross-entropy loss function to calculate the loss for each example and average them to get a single value.\n\nmodel = GPT()\nmx.eval(model.parameters()) # Create the model params (mlx is lazy evaluation)\nloss_and_grad = nn.value_and_grad(model, loss_fn)\nlr = 0.1\noptimizer = optim.AdamW(learning_rate=lr)\nNext, we instantiate the model, but since mlx is lazy evaluation it won\u2019t allocate and create the parameters. We need to call mx.eval on the parameters to ensure they get created. Then we can use nn.value_and_grad() to get a function that returns the loss and gradient of model parameters w.r.t the loss. This is all we need to optimize. Finally, we initialize an AdamW optimizer.\n\nA quick note on nn.value_and_grad(). If you are used to PyTorch you might expect us to use loss.backward() which goes through the computation graph and updates the .grad attribute of each tensor in our model. However, mlx automatic differentiation works on functions instead of computation graphs [3]. Therefore, mlx has built-ins that take in a function and return the gradient function such as nn.value_and_grad() .\n\nNow we define the training loop.\n\nnum_epochs=20\nbatch_size=32\nfor epoch in range(num_epochs):\n    model.train(True)\n    running_loss = 0\n    batch_cnt = 0\n    for input, label in get_batches(X_train, y_train, batch_size):\n        batch_cnt += 1\n        loss, grads = loss_and_grad(model, input, label)\n        optimizer.update(model, grads)\n        running_loss += loss.item()\n        # compute new parameters and optimizer state\n        mx.eval(model.parameters(), optimizer.state)\n    avg_train_loss = running_loss / batch_cnt\n    model.train(False) # set eval mode\n    running_loss = 0\n    batch_cnt = 0\n    for input, label in get_batches(X_val, y_val, batch_size):\n        batch_cnt += 1\n        loss = loss_fn(model, input, label)\n        running_loss += loss.item()\n    avg_val_loss = running_loss / batch_cnt\n    print(f\"Epoch {epoch:2} | train = {avg_train_loss:.4f} | val = {avg_val_loss:.4f}\")\nThe outer loop runs through the epochs. We first set the model to training mode because some modules have different behaviors during training and testing such as dropout. Then we use our get_batches function from earlier to loop through batches of the training data. We get the loss over the batch and the gradient using loss_and_grad . Then we pass the model and gradients to the optimizer to update the model parameters. Finally we call mx.eval (remember mlx does lazy evaluation) to ensure the parameters and optimizer state get updated. Then we calculate the average train loss over the data to print later. This is one pass through the training data. Similarly, we calculate the validation loss and then print the average train and val loss over the epoch.\n\ncompletion = decode(model.generate(1000)[0].tolist())\nprint(completion)\nwith open('completions.txt', 'w') as f:\n    f.write(completion)\nFinally, we add some code to generate from our model. Since the generation output is still in the (B, T) shape we have to index it at 0 to make it 1D and then convert it from an mlx array to a Python list. Then we can pass it to our decode function from earlier, and write it to a file.\n\nThese are the parameters we will use for training (you can play around with this):\n\nctx_len = 128\nn_emb = 128\ndropout = 0.1\nhead_size = 128\nn_heads = 4\nn_layers = 3\nnum_epochs = 20\nbatch_size = 64\nlr = 1e-3\nNow we can run the file to start training. With the settings above training took around 10 minutes on my m2 MacBook. I achieved the following training loss last epoch.\n\nEpoch 19 | train = 1.6961 | val = 1.8143\nLet\u2019s look at some output.\n\nGLOUCESTER:\nBut accomes mo move it.\n\nKING EDWARD:\nWhere our that proclaim that I curse, or I sprithe.", "mimetype": "text/plain", "start_char_idx": 48125, "end_char_idx": 52025, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4d9107d2-532d-49f5-ad5f-149f1ae99205": {"__data__": {"id_": "4d9107d2-532d-49f5-ad5f-149f1ae99205", "embedding": null, "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13", "node_type": "4", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "2187a4efee001b52656775153aab90cdc0d580feb56478d77d92d778b432b832", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9e726e5f-157b-458e-9622-ba84969f6f8e", "node_type": "1", "metadata": {"source_url": "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e", "document_index": 13}, "hash": "7aa5cce91289b4261672843204620142cbc9f06dc65fb0aae08e9fdebf6ffdf7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we can pass it to our decode function from earlier, and write it to a file.\n\nThese are the parameters we will use for training (you can play around with this):\n\nctx_len = 128\nn_emb = 128\ndropout = 0.1\nhead_size = 128\nn_heads = 4\nn_layers = 3\nnum_epochs = 20\nbatch_size = 64\nlr = 1e-3\nNow we can run the file to start training. With the settings above training took around 10 minutes on my m2 MacBook. I achieved the following training loss last epoch.\n\nEpoch 19 | train = 1.6961 | val = 1.8143\nLet\u2019s look at some output.\n\nGLOUCESTER:\nBut accomes mo move it.\n\nKING EDWARD:\nWhere our that proclaim that I curse, or I sprithe.\n\nCORIOLANUS:\nNot want:\nHis bops to thy father\nAt with hath folk; by son and fproathead:\nThe good nor may prosperson like it not,\nWhat, the beggares\nMore hath, when that made a,\nYour vainst Citizen:\nLet here are go in queen me and knife\nTo my deserved me you promise: not a fettimes,\nThat one the will not.\n\nCORIOLANUS:\nAnd been of queens,\nThou to do we best!\n\nJULIET:\nNot, brother recourable this doth our accuse\nInto fight!\nNot bad for just 10 minutes of training with a tiny model that is predicting characters! It clearly has the form of Shakespeare, although it is nonsense. The only difference between our model and the real GPT-2 now is scale! Now I encourage you to experiment \u2014 try out different settings, maybe tinker with the architecture, and see how low of a loss you can achieve.\n\nReferences\n[1] Karpathy A (2015).Tiny Shakespeare [Data set]. https://github.com/karpathy/char-rnn (MIT license)\n\n[2] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, Language Models are Unsupervised Multitask Learners (2019), OpenAI\n\n[3] Automatic Differentiation \u2014 mlx docs", "mimetype": "text/plain", "start_char_idx": 51397, "end_char_idx": 53109, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1dd85d3b-e027-46fe-874c-e21dbb04dd5c": {"__data__": {"id_": "1dd85d3b-e027-46fe-874c-e21dbb04dd5c", "embedding": null, "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14", "node_type": "4", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "9c3ef16e9fac35b4ce33748caf152737b7517a744efba3f5f88836ac594aa83a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33d9fe21-ec4b-4c55-a779-9ca87324dde4", "node_type": "1", "metadata": {}, "hash": "cffa2a2178e902f8179c5b34fb3a8a2fe0edede627a9c08c9628b5e33a6e5ef5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "My eyes felt like galaxies\u2014holding the swirling glow of countless memories\u2014as I took in our childhood home. Its siding looked like remnants of driftwood after a bonfire. I swore I smelled the smoky char of pine creep into my nostrils. It\u2019s wild how the past stays with you like that. It can feel more visceral and real than the tangible things right in front of you.\n\n\u201cJesus, it feels like just yesterday.\u201d I placed a trembling hand over my heart, struggling to steady my breath.\n\nMy brother, Perry, pulled me into a tight embrace, his strength grounding me like an anchor.\n\n\u201cThe house hasn\u2019t changed much,\u201d he said, his voice steady and comforting. \u201cBut we have.\u201d His certainty made me question, Have I really changed?\n\nBetween the two of us, Perry was as solid and stoic as a mountain range. Good thing, because I was like the wind\u2014flighty and unpredictable. Over the years, Perry had learned to handle even my harshest hurricanes.\n\nBeing his older sister\u2014even if only by four minutes\u2014I always wished I\u2019d been his protector rather than the other way around. But that demon burning deep in my belly also flashed a crooked smile, knowing that Perry would never abandon me, especially since I got sober.\n\nI hadn\u2019t had a drink in exactly seven hundred and thirty days, and although it remained unsaid, I knew Perry was terrified of leaving me to my own devices in fear I would relapse.\n\nOur sibling bond was iron-clad. After we lost our parents in the fire (my mother didn\u2019t properly butt out her 2:00 am cigarette and well, the rest is history), all Perry and I had was each other. But let\u2019s call a spade a spade; we were also as fucked up and as co-dependent as it gets. Who mutually decides to visit the catalyst of your alcohol addiction on the anniversary of your sobriety?\n\nThe house\u2019s dilapidated front door creaked as Perry gently pushed it open. The rusted metal hinges were holding it up by a thread.\n\n\u201cAfter you.\u201d Perry gestured me in, squinting from the sunlight. He was a gentleman, even in such obscurity.\n\nAs he held the door open, the shallow scar on his right cheek taunted me like some kind of schoolyard bully. His wound often pulled me in like that. Some days, I was sure I would dive right into it and drown. Other days, I prayed to God and the Devil himself to just let me fucking drown, already.\n\nThat mark became permanently etched on Perry\u2019s face on the day I quit drinking, exactly seven hundred and thirty days ago. That was the day Perry screamed bloody murder at me from the passenger seat, \u201cJackie! Stop the fucking car!\u201d But my bloodstream was far too poisoned with Bacardi Limon to listen. All I remember next was my vehicle being wrapped around a tree. I could have died that day, but what truly disturbed me in the middle of the night was the fact that I almost killed Perry.\n\nA lot can happen in seven hundred and thirty days. But I assure you, forgiving yourself isn\u2019t one of them.\n\n\u201cWell? You coming in?\u201d Perry was still holding the door ajar.\n\nI shook it off and gave my brother a knowing glance. I swear, even though we were fraternal, we had twin telepathy. I exhaled and walked in.\n\n\u201cWatch your step,\u201d I warned, my forehead tense.\n\nI imagined the rickety floorboards collapsing, crashing us into what had once been our dad\u2019s \u201cman cave\u201d. That\u2019s where he was passed out, the night of the fire.\n\n\u201cKids, stay here. Do not move,\u201d our mother demanded after getting us out of the house safely. I remember the black soot on her face and the spiderweb veins in her eyes. She shook us firmly by the forearms. \u201cI\u2019m getting your father.\u201d\n\nPerry and I held each other, shaking. The heat from the inferno felt like standing in a volcano. We never saw our parents again.\n\nTwo decades later, there we were\u2014Perry and I\u2014-making our way through the wreckage of our home. It was midday, yet the inside of the house screamed a tone of pale blue midnight. My shoulders were up to my ears, as though we were walking through a haunted house attraction.\n\nI coughed into my forearm. The ocean of dust was thick like butter. As I cleared my lungs, Perry called out from behind me.\n\n\u201cJacks, look at this! The fireplace,\u201d Perry's voice was filled with awe.\n\n\u201cUnbelievable. It\u2019s still here,\u201d I whispered, a lump forming in my throat.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4242, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "33d9fe21-ec4b-4c55-a779-9ca87324dde4": {"__data__": {"id_": "33d9fe21-ec4b-4c55-a779-9ca87324dde4", "embedding": null, "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14", "node_type": "4", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "9c3ef16e9fac35b4ce33748caf152737b7517a744efba3f5f88836ac594aa83a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1dd85d3b-e027-46fe-874c-e21dbb04dd5c", "node_type": "1", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "4be13deac1bba09a2435353110cfc49fafd767f06f1973bbaccddbc258ffe4c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "216f2a8e-6a05-47bb-8e16-b58aabc28b89", "node_type": "1", "metadata": {}, "hash": "1f46b6e185ecc6811be396310ed4fc6f722a0b7b4fcb570b58922a04d2123e7f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "She shook us firmly by the forearms. \u201cI\u2019m getting your father.\u201d\n\nPerry and I held each other, shaking. The heat from the inferno felt like standing in a volcano. We never saw our parents again.\n\nTwo decades later, there we were\u2014Perry and I\u2014-making our way through the wreckage of our home. It was midday, yet the inside of the house screamed a tone of pale blue midnight. My shoulders were up to my ears, as though we were walking through a haunted house attraction.\n\nI coughed into my forearm. The ocean of dust was thick like butter. As I cleared my lungs, Perry called out from behind me.\n\n\u201cJacks, look at this! The fireplace,\u201d Perry's voice was filled with awe.\n\n\u201cUnbelievable. It\u2019s still here,\u201d I whispered, a lump forming in my throat.\n\nIt was as though a Fairy Godmother breezed by and brought the decaying living room to life with her magical paintbrush. Kind of like in \u201cTitanic\u201d, when they showed the sunken ship underwater, versus in its prestige as it sailed across the Atlantic.\n\nWe made our way over to the fireplace and sat cross-legged on the floor.\n\n\u201cThis was our favorite spot, remember?\u201d I avoided his gaze, overwhelmed by the flood of memories.\n\n\u201cYeah,\u201d Perry murmured, his eyes softening with nostalgia.\n\nFor a moment, the taste of crispy, fire roasted marshmallows superseded the saturated stench of mildew.\n\n\u201cRemember our s\u2019mores nights?\u201d I asked.\n\n\u201cDuh. What about all our fireplace movie nights?\u201d Perry proceeded to do his best, nasally, childhood impersonation of me, \u201cBut mom! I want to watch Beauty and the Beast!! Perry always gets to pick the movie!!\u201d\n\nI punched him in the arm, \u201cFirst of all, I never sounded like that. And second. So what? I knew what I wanted.\u201d\n\nThe corners of Perry\u2019s mouth lifted. He had such a sincere sparkle about him, as though a storm cloud of confetti followed him overhead wherever he went, \u201cYou really did, kiddo.\u201d\n\nMy chest went heavy. How could Perry love me after everything I had done? After all the relationships I\u2019d ruined? All the jobs I\u2019d lost? All of his relationships I\u2019d ruined? How could he still choose me, when so often I had chosen a forty of Jack Daniels over him?\n\nHow could Perry still love me after I almost fucking killed him?\n\nPerry\u2019s gaze widened, \u201cHey! Remember when Mom would bring out those hot drinks she always made?\u201d He paused, almost as if he was searching for the right term. \u201cApple\u2026 something? Apple ssshhh\u2026\u201d\n\nI snapped my fingers, \u201cApple-Schnapple!\u201d\n\n\u201cYes!\u201d\n\n\u201cI mean, looking back it was basically just hot apple cider, but damn it was good.\u201d And it really was.\n\nOur laughs echoed throughout the abandoned asylum we once called home.\n\nPerry leaned back, holding himself up with his hands. \u201cI loved our fireplace hangs. Especially our movie nights down here. But nothing beats our movies up in the projector room.\u201d\n\nI tilted my head, \u201cWe never had a projector room.\u201d\n\nPerry playfully \u201cshoo\u2019d\u201d me away.\n\n\u201cNo. Perry. I would remember us having a projector room. Our movie nights together were our favorite thing. You even just said it yourself.\u201d\n\nThe house suddenly became pin-drop silent as Perry leaned in. \"Memories are quite something, aren\u2019t they?\" The slight shift in his tone made my skin crawl. Perry was always wistful, but this felt different, almost\u2026 clinical, \"We often remember things in ways that are\u2026 easier for us to digest.\"\n\nI was fidgety. \u201cGees Perry. You sound like Dr. Lasko.\u201d\n\nHe seemed to enjoy my little joke.\n\nDr. Lasko had been my therapist since the accident, and I would go out on a limb and say that he would not have approved of this self-inflicted exposure therapy I was subjecting myself to by visiting the house.\n\nPerry seemingly snapped out of his little therapist moment and went right back to being his sparkly confetti self. As I watched his amicable face scan the mantle above the fireplace, I felt a sickening uneasiness. Imagine you had actually fucking killed him.\n\n\u201cMan, I can still picture all our family photos up there,\u201d Perry\u2019s childlike wonder destroyed me.\n\nMy face went flush. I could feel the water rising in my eyes like the tides. How pathetic and infuriating was it that after everything I\u2019d done, I was still somehow the victim.", "mimetype": "text/plain", "start_char_idx": 3501, "end_char_idx": 7672, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "216f2a8e-6a05-47bb-8e16-b58aabc28b89": {"__data__": {"id_": "216f2a8e-6a05-47bb-8e16-b58aabc28b89", "embedding": null, "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14", "node_type": "4", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "9c3ef16e9fac35b4ce33748caf152737b7517a744efba3f5f88836ac594aa83a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33d9fe21-ec4b-4c55-a779-9ca87324dde4", "node_type": "1", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "6b422b1b15ecf040088ee4c13f8517fcc1d4d7f368b43eae66c8cb53b64d0e87", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "30f360d4-aff1-4f0d-a97d-6e9e9d966bb3", "node_type": "1", "metadata": {}, "hash": "185b964ae1a6f48366301a333fdb37d5dbb9decfb69008e983a0e92f2ae37b3e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "I was fidgety. \u201cGees Perry. You sound like Dr. Lasko.\u201d\n\nHe seemed to enjoy my little joke.\n\nDr. Lasko had been my therapist since the accident, and I would go out on a limb and say that he would not have approved of this self-inflicted exposure therapy I was subjecting myself to by visiting the house.\n\nPerry seemingly snapped out of his little therapist moment and went right back to being his sparkly confetti self. As I watched his amicable face scan the mantle above the fireplace, I felt a sickening uneasiness. Imagine you had actually fucking killed him.\n\n\u201cMan, I can still picture all our family photos up there,\u201d Perry\u2019s childlike wonder destroyed me.\n\nMy face went flush. I could feel the water rising in my eyes like the tides. How pathetic and infuriating was it that after everything I\u2019d done, I was still somehow the victim.\n\n\u201cHey.\u201d He took my hand.\n\n\u201cOh Perry,\u201d  I threw myself into him. \u201cI\u2019m so sorry.\u201d\n\nMy brother held me with his usual care that I didn\u2019t deserve.\n\n\u201cJacks, it\u2019s ok. I\u2019m still here. We\u2019re both still here.\u201d\n\nAs my chin rested on my brother\u2019s shoulder, I looked ahead of me at the remains of the house. Something felt off, and it wasn\u2019t just the overall unsettling environment. My brow furrowed. \u201cWasn\u2019t the doorway to the kitchen on the other side of the living room?\u201d\n\nI felt Perry shrug, \u201cI don\u2019t think so.\u201d\n\nI was staring into the out of place doorway like I was trying to pull a recollection towards me. And that\u2019s when I saw them in the kitchen: the translucent memory of mom and dad. Mom was getting our Apple-Schnapples ready. She was pacing, unlike Dad, who was sitting motionless at the table. His face was planted on its mahogany surface. His glass of Apple-Schnapple was empty, and so was the bottle of Jim Beam beside it.\n\nMom floated into the living room, our warm beverages in hand and a cigarette in her mouth, \u201cKids, your father\u2019s not feeling well. Let\u2019s have our Apple-Schnapples in here.\u201d\n\nOh my God. The bruise on her face.\n\nPerry jarred me back to reality with the gut punch of what he had to say next, \u201cYou\u2019re remembering the truth about mom and dad, aren\u2019t you?\u201d\n\nI pushed myself off and away from him. \u201cHow did you\u2026\u201d\n\nMy brother looked down, delicately tracing the floor with his finger, \u201cWe always put them on a pedestal after they died.\u201d\n\nI felt a shiver run down my spine, \u201cWhat are you talking about?\u201d\n\nAs Perry continued to speak, his words grew even more detached. \"Do you remember that first drink Dad ever gave you?\"\n\nMy eyes darted around the room as my jugular pulsed in my neck. As much as I tried to escape what Perry had just said, I did remember.\n\nI could hear my dad\u2019s slurring words of encouragement, \u201cCome on, Jackie. Just one drink. It\u2019ll be our special time, just you and me.\u201d\n\nThe bitterness of that first sip of beer made me squirm, but sharing a \u201cspecial time\u201d with my dad\u2014and the desperate yearning that maybe he did love me, afterall\u2014was the overwhelm of the full moon swallowing me whole. I was only a child, and much like how my mom turned a blind eye to my father\u2019s drinking, she did the exact same when it came to her daughter.\n\nI\u2019d used the death of my parents as the excuse for my alcoholism for so long, because admitting that they helped create the monster I would eventually become was like a knife to the heart. And knowing I had been too weak to conquer the addiction from my own volition just made the weapon twist in my chest.\n\nThe room was spinning. My face was blistering hot like the night of the fire. Or was that the warm heat from the fireplace when we were kids? The childhood fireplace memories ran through my mind, frame by frame, until\u2026..they eventually vaporized to nothing. I crouched over, thinking I might vomit.\n\n\u201cWe never had a fireplace.\u201d Perry was nodding, very matter-of-factly.\n\nMy fingernails dug into my thighs when I looked at the fireplace and: it was gone. Only a blank wall of faded, forest green wallpaper remained. Our house was once on fire, yes, but that was it. There was never a happy childhood fireplace. Ever.\n\nMy hands were cold and clammy. I fell back onto the wall behind me. \u201cPerry.", "mimetype": "text/plain", "start_char_idx": 6833, "end_char_idx": 10947, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "30f360d4-aff1-4f0d-a97d-6e9e9d966bb3": {"__data__": {"id_": "30f360d4-aff1-4f0d-a97d-6e9e9d966bb3", "embedding": null, "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14", "node_type": "4", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "9c3ef16e9fac35b4ce33748caf152737b7517a744efba3f5f88836ac594aa83a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "216f2a8e-6a05-47bb-8e16-b58aabc28b89", "node_type": "1", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "cd84111cfb3f23e8f39cf6712aa3c564500eb1f416ebb73ee780769ee6add05b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7241756b-c9db-4648-b80a-ae76c1f0d3fb", "node_type": "1", "metadata": {}, "hash": "c1439b33df3d56babec48491bc901c4fd1bc73b7f0de22afa110aa42d0665225", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "And knowing I had been too weak to conquer the addiction from my own volition just made the weapon twist in my chest.\n\nThe room was spinning. My face was blistering hot like the night of the fire. Or was that the warm heat from the fireplace when we were kids? The childhood fireplace memories ran through my mind, frame by frame, until\u2026..they eventually vaporized to nothing. I crouched over, thinking I might vomit.\n\n\u201cWe never had a fireplace.\u201d Perry was nodding, very matter-of-factly.\n\nMy fingernails dug into my thighs when I looked at the fireplace and: it was gone. Only a blank wall of faded, forest green wallpaper remained. Our house was once on fire, yes, but that was it. There was never a happy childhood fireplace. Ever.\n\nMy hands were cold and clammy. I fell back onto the wall behind me. \u201cPerry. Where are we?\u201d\n\nHe stood up and glided towards the staircase. One hand on the banister, his footsteps creaked, one by one, as he made his way to the second floor.\n\nMy mouth was bone dry, \u201cPerry!\u201d\n\nHe stopped and turned towards me, \u201cCome to the projector room. We love watching movies together, don\u2019t we? There\u2019s a movie I\u2019d like to show you.\u201d\n\nAs my brother disappeared from sight, I did what any classic horror movie trope would tell you to do: I went upstairs.\n\nI found Perry standing at the end of the ominous hallway. Large, empty picture frames lined the oxblood walls leading up to him. Through the doorway where Perry stood, particles in the air danced in the projector\u2019s cone-shaped light. That telltale winding of a film reel was the only sound in the deafening quiet of this house that I no longer recognized.\n\nHalf of Perry\u2019s face\u2014the one with the scar\u2014was perfectly illuminated, as though he was wearing the mask from \u201cThe Phantom of the Opera\u201d. \u201cI think you\u2019re ready to see how this movie ends, Jackie. This is the most progress you\u2019ve made since we\u2019ve been coming here.\u201d\n\nI gripped my thumbs in the palms of my hands, \u201cPerry, you\u2019re freaking the fuck out of me!\u201d\n\nI thought my knees might buckle as my brother\u2019s face glitched, like a flash of static snow on a television set. As his face settled back to normal to a deadpan gaze, he disappeared in the innocuous room. I followed, running on nothing but fumes.\n\nClutching the doorway, my mouth fell agape. Perry was gone. I darted to the middle of the room.\n\nAs I frantically searched for my brother, I shielded my eyes with the back of my hand from the projector\u2019s light. And that\u2019s when, from behind me, I heard five words that made my blood run cold, \u201cJackie! Stop the fucking car!\u201d\n\nI was convulsing yet paralyzed. Moving as slowly as cold molasses, I rotated on the spot towards my worst nightmare, shown on 35 mm. On the projector screen was Perry and me in my car, exactly seven hundred and thirty days ago, the day I almost kill\u2014\n\nOh my God.\n\nMy head pounded as fragmented memories surged. The reality of what happened began to crystallize, unrelenting.\n\nMy joints ached and my stomach churned. Clamping a hand over my mouth to stifle a scream, I stumbled down the hallway as it began caving in on itself. The picture frames were sucked into the walls. The floorboards cracked into distorted peaks and valleys. Wooden beams swung down from the ceiling like pendulums. I tried to spit out the chalky grit of disintegrating drywall that made the hallway look like a winter squall.\n\nPanting heavily, I stopped dead in my tracks at the stained glass window. My body trembled with an all-too-familiar dread. Each time I faced this, I wondered if this fall would be the one that would finally end it all.\n\nMaybe it\u2019d be better if it did.\n\nHolding my breath, I threw myself through the glass, my hands clawing the air for dear life. Free falling two stories feels like an eternity when you\u2019re watching the memory of your childhood home fall apart before your very eyes. But when the weight of my body finally made contact with the earth I\u2014\n\nI gasped. The cold air of the hospital room shocked my lungs. I sat up, ripping the suction cups from my face and body. My gown was clinging to me, soaked in sweat. Medical equipment beeped all around me like a metronome.\n\nDr.", "mimetype": "text/plain", "start_char_idx": 10136, "end_char_idx": 14279, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7241756b-c9db-4648-b80a-ae76c1f0d3fb": {"__data__": {"id_": "7241756b-c9db-4648-b80a-ae76c1f0d3fb", "embedding": null, "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14", "node_type": "4", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "9c3ef16e9fac35b4ce33748caf152737b7517a744efba3f5f88836ac594aa83a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "30f360d4-aff1-4f0d-a97d-6e9e9d966bb3", "node_type": "1", "metadata": {"source_url": "https://blog.reedsy.com/short-story/a3gstd/", "document_index": 14}, "hash": "39838077559f94a0c92ee037d6f81cf5626554c6233c5268f5787620e8694039", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Panting heavily, I stopped dead in my tracks at the stained glass window. My body trembled with an all-too-familiar dread. Each time I faced this, I wondered if this fall would be the one that would finally end it all.\n\nMaybe it\u2019d be better if it did.\n\nHolding my breath, I threw myself through the glass, my hands clawing the air for dear life. Free falling two stories feels like an eternity when you\u2019re watching the memory of your childhood home fall apart before your very eyes. But when the weight of my body finally made contact with the earth I\u2014\n\nI gasped. The cold air of the hospital room shocked my lungs. I sat up, ripping the suction cups from my face and body. My gown was clinging to me, soaked in sweat. Medical equipment beeped all around me like a metronome.\n\nDr. Lasko, my therapist since the accident, sat across the stark white room, sighing as he rubbed his forehead. He, too, was connected to a plethora of suction cups and wires. He looked a little worn out in the fluorescent overhead lighting. Ever since I was hospitalized and later incarcerated, Dr. Lasko had been helping me delve into my memories, namely the ones that were too excruciating for me to face. And as such, Dr. Lasko had been appearing in the simulations as my brother Perry, the love of my life who died in the car crash, seven hundred and thirty days prior.\n\nDisoriented, I blinked rapidly, the vividness of the memory contrasting sharply with the sterile, geometric ceiling tiles above me.\n\n\u201cI don\u2019t ever want to do that again!\u201d I was venomous.\n\n\u201cJackie,\u201d Dr. Lasko started.\n\n\u201cDon\u2019t start,\u201d I pulled up four fingers for air quotes, \u201c\u2018Jackie, don\u2019t give up. This was the closest you\u2019ve ever come to facing the truth.\u201d\n\nAs the initial burst of adrenal and cortisol left my body, I fell back on my pillow. I was depleted. Quiet rivers flowed down my cheeks.\n\nRemoving his own suction cups, Dr. Lasko approached my bedside and took a seat. He treaded lightly. \u201cJackie, I understand how challenging this is for you, but you did an incredible job today. If we continue making progress like this, there's a real possibility you'll gain your freedom sooner.\u201d\n\nI looked at the well-meaning doctor, but all I could see was Perry. Multicolored confetti fell softly around him like that first November snow. His face was the sun. His eyes reflected the whole world back to me.\n\nPerry.\n\nWith a weak grip, I took Dr. Lasko\u2019s hand. My vocal cords were like sandpaper. \u201cI\u2019ll leave this place one day, doc.\u201d A single tear dripped from my chin onto my collarbone. \u201cBut I\u2019m not sure if I\u2019ll ever be free.\u201d\n\nDr. Lasko didn\u2019t say a word, but I felt him squeeze my hand, just a little bit tighter.\n\nI licked the cracks on my lips as my eyes closed shut, imagining the oaky comfort of bourbon on my tongue. I felt myself drift, and good thing, because I needed the rest. Dr. Lasko and I would be delving into my memories again the following day.\n\nNo matter how masochistic it felt, I vowed to keep showing up for the simulations. Even if I never forgave myself for what I did, at least in my memories, I got to see Perry.", "mimetype": "text/plain", "start_char_idx": 13499, "end_char_idx": 16592, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ecfb8bd-a029-4c96-beb6-de99b381efd3": {"__data__": {"id_": "9ecfb8bd-a029-4c96-beb6-de99b381efd3", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2da65707-71d4-4760-b5bb-4607bf462478", "node_type": "1", "metadata": {}, "hash": "4935def0e46b70fe98c76a67c4b3fc62f82671eeb63857e07b756d320643788e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Space Babies\n\nOriginal Airdate: 11 May 2024\n\n[Tardis]\n(Ruby has walked into the unlocked Tardis at the end of The Church on Ruby Road.)\nRUBY: Who are you?\nDOCTOR: I'm the Doctor. You don't have to stand over there. Come and have a look. It's called the Tardis.\n(Snaps his fingers and the lighting changes.)\nRUBY: Ooo! Nice! But hold on. I can't call you Doctor. No, I want to know your name.\nDOCTOR: Yeah, that's er... that's tricky, because I was adopted, and the planet that took me in, they were kind of... they were kind of posh. They'd use titles like the Doctor, or the Bishop, or the Rani, or the Conquistador. Say Doctor for a thousand years and it becomes my name.\nRUBY: Okay. The planet. Parking that. Thousand years, double parked. So you're a doctor, but you're... the police?\nDOCTOR: Police box. No. No, no, no, no, that's a disguise.\nRUBY: Oh.\nDOCTOR: Inside, it's a Time and Space machine, but outside, it's like a chameleon, 'cos once I landed in 1963 and they used to have police boxes on street corners.\nRUBY: 1963?\nDOCTOR: Yep.\nRUBY: Okay. Ooo, jukebox. I like that.\nDOCTOR: Mmm.\nRUBY: Okay, so, back to the planet.\nDOCTOR: My world was called Gallifrey.\nRUBY: Gallifrey? And where's that?\nDOCTOR: Gone! Ruby, it's gone. It's gone. They died. There was a genocide, and they died. So the one that was adopted was the only one left. I am the last of the Time Lords. And I am so, so glad to be alive. This thing flies. Do you want to see?\n(The gravity goes off, the Tardis dematerialises, gravity back on. Never done that before.)\nDOCTOR: Let's have a random landing.\nRUBY: Whoa!\nDOCTOR: Hoo-hoo! Ooo... 150 million years in the past.\nRUBY: No!\nDOCTOR: Really.\nRUBY: No, you've got to be k... You are kidding. Don't be so ridiculous. Are there dinosaurs out there?\nDOCTOR: I don't know. Go and have a look.\nRUBY: Wait! No. Is it safe? What if I change history by stepping on a butterfly or summat?\nDOCTOR: Well, that's not going to happen, is it? Who steps on butterflies? You'd literally have to be like, \"Wait. Come 'ere, butterfly! \"Come 'ere, 'ave it!\"\n\n[Prehistoric Earth]\n\nRUBY: Oh, my God. That... that's so beautiful.\nDOCTOR: And Tardis stands for Time And Relative Dimension In Space, huh? So we've moved location as well. This will be North America. One day, this is Wyoming. A little town called Green River.\n(A boot steps on a butterfly.)\nDOCTOR: Oh!\n(Ruby is no longer a human.)\nRUBATHON: What's wrong? Did I do something wrong? Because I am Rubathon Blue of the 57th Hemisphere Hatchlings, and I do not do wrong things, Dok-tah.\nDOCTOR: But...\nRUBATHON: If you have made an incorrect accusation, I will have to kill you.\nDOCTOR: No, no, no. Just wait, wait a minute. Just...\nRUBATHON: What are you doing?\nDOCTOR: Nothing, just...\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\nRUBY: Am I missing summat?\nDOCTOR: Nothing. Let's try that again, okay?\nRUBY: Thank you.\nDOCTOR: Yeah. Yeah, yeah, yeah.\n\n[Tardis]\n\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let's go forward. Give me a number. Give me a year.\nRUBY: Er, two.\nDOCTOR: Two.\nRUBY: One.\nDOCTOR: One.\nRUBY: Five.\nDOCTOR: Five.\nRUBY: Oh.\nDOCTOR: Oh.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3232, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2da65707-71d4-4760-b5bb-4607bf462478": {"__data__": {"id_": "2da65707-71d4-4760-b5bb-4607bf462478", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ecfb8bd-a029-4c96-beb6-de99b381efd3", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "e4b1a1b7ccbd21b2b5c291248fa52f9a50cc108b3eefb20ee83f84f652c730ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73f77458-144a-43e8-a220-80e03f7131c9", "node_type": "1", "metadata": {}, "hash": "99ce8e0c86941f0c1a9d6c813b1e78169c54fff89db1655ac35e67b60034c36f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DOCTOR: No, no, no. Just wait, wait a minute. Just...\nRUBATHON: What are you doing?\nDOCTOR: Nothing, just...\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\nRUBY: Am I missing summat?\nDOCTOR: Nothing. Let's try that again, okay?\nRUBY: Thank you.\nDOCTOR: Yeah. Yeah, yeah, yeah.\n\n[Tardis]\n\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let's go forward. Give me a number. Give me a year.\nRUBY: Er, two.\nDOCTOR: Two.\nRUBY: One.\nDOCTOR: One.\nRUBY: Five.\nDOCTOR: Five.\nRUBY: Oh.\nDOCTOR: Oh.\nRUBY: Ah, six!\nDOCTOR: Six! Ah! Five numbers! I like it!\n(The Tardis travels the Vortex.)\n\n[Space station]\n\nRUBY: But we're indoors. We got through walls. Ah-ha. Is that like a matter transporter, like in Star Trek?\nDOCTOR: We've got to visit them one day.\nRUBY: Hey, but you said the Tardis was like a chameleon, but it still looks like a police box.\nDOCTOR: Oh, it's, er... it's broken. Most of the universe is knackered, babes. Okay. Come, come, come, come.\nRUBY: Oh, it stinks\nDOCTOR: Something is wrong with this place. It is a space station reaching overload. Whoa! Whoa!\nRUBY: No, you've made it worse.\n(Something snarls nearby. They both jump.)\nDOCTOR: No, that is worse.\nRUBY: Is that a monster?\nDOCTOR: No. No, don't be silly, Ruby. There's no such thing as monsters, there's just... just creatures you haven't met yet. Hi there.\n(The creature roars.)\nRUBY: Run?\nDOCTOR: Run! Run! Run!\n(They and the monster are visible on monitors as they run down passages.)\nDOCTOR: Come on! In here, in here, in here, in here.\nRUBY: But...now we're trapped! Now we're trapped! Push the button! Doctor!\nDOCTOR: Okay.\n(The tiny one-person lift takes them up. The Doctor's hand is over Ruby's eyes.)\nDOCTOR: Oh, yeah, yeah.\n(The lift abruptly arrives.)\n\n[Birth Zone 6]\n\nDOCTOR: The question is, why did I run?\nRUBY: 'Cos it was scary.\nDOCTOR: It was new. I love meeting new things, so why did it give me the shivers? I couldn't run fast enough. I was like whoosh!\nRUBY: Well, it'd help if we knew where we were.\nDOCTOR: Yet again, push the button.\n(The lights come on so they can see all the glassware, containing...)\nDOCTOR: Oh. Oh, we're on a baby farm. Ha-ha! A parthenogenesis machine. What is it with you and babies?\nRUBY: I was going to say the same thing to you.\nDOCTOR: We've gone from baby to baby. I'm not saying things are connected, and yet... things connect.\nRUBY: Well, I'm the one looking for my parents, and you've got a Time and Space machine. So this place grows babies. What for? Food?\nDOCTOR: Food? What? What?! Food? They're not tomatoes!\nRUBY: Well, excuse me. There's a big hungry thing downstairs.\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don't know, goes mad and bans kissing.\nRUBY: So these babies are human, yeah?\nDOCTOR: Yep, grown for a colony world.\nRUBY: And a colony world is not Earth?\nDOCTOR: Hey. Okay, one last time, push the button.\n(And a shield retracts to reveal that they are in orbit.)\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\nDOCTOR: Yeah.\nRUBY: How do you keep going?\nDOCTOR: For days like this, Ruby Sunday.", "mimetype": "text/plain", "start_char_idx": 2651, "end_char_idx": 5937, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73f77458-144a-43e8-a220-80e03f7131c9": {"__data__": {"id_": "73f77458-144a-43e8-a220-80e03f7131c9", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2da65707-71d4-4760-b5bb-4607bf462478", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "dd5c12416d7c4b2cb0ae127a133758cb218850ed884a408b8e3bd0223df313bd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa32a53d-c5c3-4ae9-a61c-b6e1c2672056", "node_type": "1", "metadata": {}, "hash": "824db4523b4397509353ec0be7525f39555aa816a93a4cfdb16aba7b6d067875", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DOCTOR: Food? What? What?! Food? They're not tomatoes!\nRUBY: Well, excuse me. There's a big hungry thing downstairs.\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don't know, goes mad and bans kissing.\nRUBY: So these babies are human, yeah?\nDOCTOR: Yep, grown for a colony world.\nRUBY: And a colony world is not Earth?\nDOCTOR: Hey. Okay, one last time, push the button.\n(And a shield retracts to reveal that they are in orbit.)\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\nDOCTOR: Yeah.\nRUBY: How do you keep going?\nDOCTOR: For days like this, Ruby Sunday. I don't have a people. I don't have a home. But I don't have a job, either. I don't have a boss, or taxes or rent or bills to pay. I don't have a purpose or a cause, or a mission, but I have... ..freedom. And so I keep moving on, to see the next thing, and the next, and the next. And sometimes... it looks even better through your eyes.\nRUBY: So where's this, then?\nDOCTOR: Oh, er...\n(Calls it up on a screen.)\nDOCTOR: Huh. Planet Pacifico del Rio.\nRUBY: Oh, that's in English. They speak English here? English exists?\nDOCTOR: Er, no. No, no, no. Humans all speak one language by this point. A bit like Cantonese. This is what it really looks like, but the Tardis translates. It's got a perception filter, so it helps you fit into every time and place.\nRUBY: Right, and my mum, she's long gone now.\nDOCTOR: Can I see your phone?\nRUBY: Yes.\nDOCTOR: So, my sonic screwdriver can make the distance between you and Earth 19,000 years or... one phone call.\nRUBY: What?\nDOCTOR: Carla. Phone her.\nRUBY: But...\nDOCTOR: Your mum, Ruby. Call your mum.\n\n[Ruby's home / Birth Zone 6]\n\nCARLA: Well? What is it now?\nRUBY: Mum?\nCARLA: Yes, Mum, obviously. You've just ran out the door ten seconds ago. Why are you phoning me? You went like the wind. Where are you going?\nRUBY: Yeah. Yes, I will... I'll, er... I'll catch up with you in a minute. Bye. Love you. Love you. Merry Christmas!\n\n[Birth Zone 6]\n\nRUBY: That was my mum, on Christmas Eve. On my birthday, ten minutes ago. That's the best signal ever. How much does that cost?\nDOCTOR: I want to know what the hell is wrong with this place. Do you see? It's calm up here, but underneath it is seething, just like downstairs with that creature. There's got to be a crew or a captain...\n(Enter a child in a motorised push-chair.)\nERIC: This is Eric, reporting from Birth Zone 6. I keep getting these temperature fluctuations. I've opened up safety valves 10 to 16. Tried cross-matching with the CO2 exchange, but until we get that pressure down, I can't...\nDOCTOR: Hi.\nRUBY: You all right?\nERIC: But... you. Oh. We've been waiting for an awfully long time. Mummy! Daddy!\nDOCTOR: Oh, no.\nRUBY: No, no. No, darling, we're not...\nERIC: Boys-oh-boys, I've got to tell everybody Mummy and Daddy are here.\n(Leaves the room.)\nRUBY: A baby farm. Run by babies.\nDOCTOR: Ha-ha! Space babies!\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\n\n[Control room]\n\nERIC: They're here. They came at last. Mummy and Daddy are here.\n(All the crew are in electric pushchairs.)\nBABIES: Mummy and Daddy! They came back!\nDOCTOR: Hello, space babies.\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\nDOCTOR: Oh.", "mimetype": "text/plain", "start_char_idx": 5231, "end_char_idx": 8600, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fa32a53d-c5c3-4ae9-a61c-b6e1c2672056": {"__data__": {"id_": "fa32a53d-c5c3-4ae9-a61c-b6e1c2672056", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73f77458-144a-43e8-a220-80e03f7131c9", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "c2bbaeae0e82590db2c6a4a967089c7077ef5ab8af34ad4fa4c533aeab8e7f16", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d424ab39-4918-4e46-82b9-8da1d9c193f8", "node_type": "1", "metadata": {}, "hash": "f543615631d11f95c2445fed4b23f5bc528a0fbf9f06934d1f2880932392d3d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ERIC: But... you. Oh. We've been waiting for an awfully long time. Mummy! Daddy!\nDOCTOR: Oh, no.\nRUBY: No, no. No, darling, we're not...\nERIC: Boys-oh-boys, I've got to tell everybody Mummy and Daddy are here.\n(Leaves the room.)\nRUBY: A baby farm. Run by babies.\nDOCTOR: Ha-ha! Space babies!\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\n\n[Control room]\n\nERIC: They're here. They came at last. Mummy and Daddy are here.\n(All the crew are in electric pushchairs.)\nBABIES: Mummy and Daddy! They came back!\nDOCTOR: Hello, space babies.\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\nDOCTOR: Oh.\nPOPPY: Everyone, back to work. Show Mummy and Daddy what a good job we've been doing. Make them proud.\n(The controls are jury-rigged with string and wooden pointers so the babies can activate them.)\nMARCEL?: My job is to keep the pipes clean. I'm proud of the pipes.\nADJANI?: And I keep the oxygen nice and cool. We need oxygen to breathe.\nSANDRA?: And I pull this string and that string. I'm not sure what they do, but I pull them very hard.\nERIC: And I made this for you. It's a little flower.\nRUBY: Thank you.\nPOPPY: I'm Captain Poppy and I kept the station running for Mummy and Daddy, because we knew you'd come back for us one day. We waited.\nDOCTOR: Right. You're not supposed to be running this place. This isn't Baby World. You got left behind when the adults... ..vamoosed?\nPOPPY: We took over. We were very brave.\nRUBY: Right. That's great. That's, oh, that's good. That's amazing. You've done a really great job.\nDOCTOR: I'm sorry, Poppy, I'm so sorry, but we are not your mummy and daddy. I wish we were, but we're not.\nERIC: They left us. Where did they go?\nRUBY: I don't know, darling, but... I'm Ruby and this... this is the Doctor. And we're your friends. Yeah, got you. I've got you, I've got you, I've got you, I've got you.\n(She picks up Eric from his pushchair.)\nBABIES: And me! And me! And me! And me!\nDOCTOR: Oh, gosh.\nBABIES: And me! And me!\nDOCTOR: Captain Poppy, when was the last time that you had a hug?\nPOPPY: Never.\nDOCTOR: Oh. Oh, baby, it's okay. Come here, it's okay. It's okay, it's okay. Shh-shh-shh. Aww, never had a hug.\nRUBY: Come on, you can all have a hug.\n(Later, with everyone back in their pushchairs.)\nPOPPY: Did I get things wrong, Doctor\nDOCTOR: Well, according to this, the crew went home. They abandoned ship and they left you guys behind. I don't know why, but they left the birth machine running, so you lot grew up, but you stayed the same size. Baby size. Space babies.\nPOPPY: But are we wrong?\nDOCTOR: What do you mean?\nPOPPY: We're not meant to be like this. Did we grow up wrong?\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\nPOPPY: But Mummy and Daddy left us.\nDOCTOR: That's okay. Mine did, too.\nPOPPY: What happened?\nDOCTOR: Well, I was found.\nPOPPY: Hooray!\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\nPOPPY: I don't know.\nDOCTOR: The Time Lords.\nPOPPY: Ooo.\nDOCTOR: Can you say it like me?\nPOPPY: The Time Lords.\nDOCTOR: That's it, P-P-P-P-Pop.", "mimetype": "text/plain", "start_char_idx": 7967, "end_char_idx": 11142, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d424ab39-4918-4e46-82b9-8da1d9c193f8": {"__data__": {"id_": "d424ab39-4918-4e46-82b9-8da1d9c193f8", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fa32a53d-c5c3-4ae9-a61c-b6e1c2672056", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "c60c3dafb02efadee709e96522239c01dfc577a99be13531fd84e652f556c28c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c55f8999-df3e-45ef-b669-3bcfeed68168", "node_type": "1", "metadata": {}, "hash": "7f31aaa0b92feeb041894e5406c7fdff032afd37755ed3ca1c6d7ba204e2765f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "POPPY: We're not meant to be like this. Did we grow up wrong?\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\nPOPPY: But Mummy and Daddy left us.\nDOCTOR: That's okay. Mine did, too.\nPOPPY: What happened?\nDOCTOR: Well, I was found.\nPOPPY: Hooray!\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\nPOPPY: I don't know.\nDOCTOR: The Time Lords.\nPOPPY: Ooo.\nDOCTOR: Can you say it like me?\nPOPPY: The Time Lords.\nDOCTOR: That's it, P-P-P-P-Pop. But the point is, is that it doesn't matter where I come from, because I am absolutely lovely, aren't I?\n(Poppy yawns.)\nDOCTOR: That wasn't rhetorical, Pops.\nPOPPY: Yes, you are.\nDOCTOR: And do you want to know my secret? There's no one like me in the whole wide universe. No one like me exists, and that's true of everyone.\nIt's not a problem, Captain Pops. It's a superpower. High five. Yeah.\nPOPPY: Yeah!\n(Ruby is dandling Eric, with the other babies in a semi-circle.)\nRUBY: So you're Eric. And you're Tasha. And Ruben. And then there's Saltine and Boo.\nERIC: I love you, Ruby.\nRUBY: Aw, I love you too, Eric. But how do you manage all on your own?\nERIC: We've got Nanny. Say hello, Nanny.\nNAN-E: Good afternoon, children, and welcome to our new visitors.\nDOCTOR: Oh. Nanomatrix Electroform. Nan-E. Right. Hi, Nan-E. I'm the Doctor, and this is Ruby.\nNAN-E: We have visitors, children.\nERIC: Nanny!\nNAN-E: Noses must be blown. Activate nose-blow.\nDOCTOR: Er...\nNAN-E: One, two, three and... blow.\n(Mechanical hands on the pushchairs put handkerchiefs to the babies' noses. They blow into them, then the dirty handkies are dropped into a disposal tube.)\nNAN-E: Well done, children And now, children, back to work. Nappies are changed at 1800 hours.\nRUBY: Oh, can't wait to see that.\nDOCTOR: Right. So it's you lot? It's Nan-E And downstairs, is that your pet dog?\n(Everyone screams and cries.)\nERIC: That's not a doggo.\nRUBY: What is it then, Eric?\nERIC: The Bogeyman.\nRUBY: Shush, shush, shush. Shush, shush, shush.\nDOCTOR: No. Gosh.\nERIC: We don't like the Bogeyman.\nRUBY: No, no, no. Shush, shush. I did not mean to scare you. There is no such thing as the Bogeyman. That thing was more sort of like a er...\nDOCTOR: Bogeyman!\nRUBY: No, stop it! No, stop it! Nan-E, tell them there's no such thing as the Bogeyman.\nNAN-E: Nan-E is scared of the Bogeyman.\nDOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\n(Puts it on monitor. The babies wail.)\nRUBY: Doctor, turn it off.\nDOCTOR: Okay.\nRUBY: No, listen to me. Listen to me.\nDOCTOR: I'm sorry, I'm sorry. I'm sorry, babies. Space babies. I'm sorry.\nPOPPY: Oh, Ruby...\n(The Doctor finds a headset and puts it on, then works a computer.)\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\nNAN-E: Portal 3-5-7.\nDOCTOR: Okay, what's that?", "mimetype": "text/plain", "start_char_idx": 10574, "end_char_idx": 13658, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c55f8999-df3e-45ef-b669-3bcfeed68168": {"__data__": {"id_": "c55f8999-df3e-45ef-b669-3bcfeed68168", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d424ab39-4918-4e46-82b9-8da1d9c193f8", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "169e017e898b8f227a2fa27bf6ad7040da79a10a84468244641cdd2a9a777816", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "205eded4-e2a6-414c-8c76-a86c56868495", "node_type": "1", "metadata": {}, "hash": "7260a6a83a7887c536376e2418fcf199c389f0dbdda34ee545aff17b233c59ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\n(Puts it on monitor. The babies wail.)\nRUBY: Doctor, turn it off.\nDOCTOR: Okay.\nRUBY: No, listen to me. Listen to me.\nDOCTOR: I'm sorry, I'm sorry. I'm sorry, babies. Space babies. I'm sorry.\nPOPPY: Oh, Ruby...\n(The Doctor finds a headset and puts it on, then works a computer.)\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\nNAN-E: Portal 3-5-7.\nDOCTOR: Okay, what's that?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: That's on this floor. What is it?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: Yeah, it is just a storage unit. What would I need to go there for?\nNAN-E: Oh, for God's sakes, 3-5-7. Come on!\nRUBY: Where do you think you're going?\nDOCTOR: Portal 3-5-7!\nRUBY: Right. Great. Ok. Coming!\n\n[Corridor]\n\nRUBY: So, is this what you do, Doctor? I mean, in life? You help? That's like your... purpose?\nDOCTOR: No, no, I'm just, er... helping babies - space babies. Ha! Listening to my hearts. Two hearts. Plural.\nRUBY: Okay. Two hearts. But what if helping the babies takes six weeks? Or ten years? Because my mum's still waiting for me.\nDOCTOR: Back home, on your birthday. Yeah, it's strange, your life. You were abandoned, like this lot. If things connect, then you are connecting like crazy. You don't know anything about your birth mother or your father? They didn't leave a note or a scrap of paper...?\nRUBY: Nothing. I was... I was just left.\nDOCTOR: By the church.\nRUBY: In the snow.\nDOCTOR: On Ruby Road.\n(The Doctor sees a figure point at him by the church.)\nRUBY: Doctor...\nDOCTOR: What?\nRUBY: It's snowing. Okay, what just happened? I said snow, and we've got... ..snowflakes.\nDOCTOR: It's like a memory just came through, from the day that you were born.\nRUBY: But how? Is this the sort of thing that happens with time travel?\nDOCTOR: I have been to the ends of time and back, and I have never seen anything like this before.\nRUBY: Then what does it mean?\nDOCTOR: I don't know.\n(The snow has stopped.)\nDOCTOR: Oh, I thought my birth was crazy...\nRUBY: Oh, yeah.\nDOCTOR: Oh... I wonder who she is. Your mother. The memory changed. She was pointing at me.\n(A door opens.)\nJOCELYN: I said Portal 3-5-7. Don't just stand there yapping, you pair of idiots. Get inside!\nRUBY: Who's she?\nDOCTOR: Nan-E. Ha!\nRUBY: Oh.\n\n[Portal 357]\n\nRICO [on screen]: This is Captain Rico Trieste, signing off duty from Babystation Beta, Pacifico date 56-56-22. For the record, I'm signing off under protest and wish to condemn this course of action.\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I'd like to say for the record, the company's actions are appalling. I will be launching an appeal against this as soon as we're home.\n(Jocelyn fixes a gas leak with a blow from a wrench.)\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\n(Played by Susan Twist. She keeps turning up, does this woman.)\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\nJOCELYN: It's the recession. The government closed the Babystation to save money, but the law says it's illegal to stop the birth machine.", "mimetype": "text/plain", "start_char_idx": 13003, "end_char_idx": 16331, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "205eded4-e2a6-414c-8c76-a86c56868495": {"__data__": {"id_": "205eded4-e2a6-414c-8c76-a86c56868495", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c55f8999-df3e-45ef-b669-3bcfeed68168", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4d66b79d961a25080213bd0e7e55ff525b3ad9d4895be128968cd925f6def16e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "257c13d6-1e99-4e1a-972f-7a7b59a3199b", "node_type": "1", "metadata": {}, "hash": "83533e06a0cd56c37559b6887f430f708ecaec1a28b18ac7ba0f6b51538accc5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For the record, I'm signing off under protest and wish to condemn this course of action.\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I'd like to say for the record, the company's actions are appalling. I will be launching an appeal against this as soon as we're home.\n(Jocelyn fixes a gas leak with a blow from a wrench.)\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\n(Played by Susan Twist. She keeps turning up, does this woman.)\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\nJOCELYN: It's the recession. The government closed the Babystation to save money, but the law says it's illegal to stop the birth machine.\n(Another leak, another thump with the wrench.)\nJOCELYN: But how did you arrive? Have you got a way out of here?\nDOCTOR: I've got a ship, yeah, it's er... What is your name - sorry, Nan-E?\nJOCELYN: Jocelyn, Jocelyn Sancerre. I was the on-site accountant. I don't know how this place works.\n(The Doctor plugs his sonic into the computer.)\nDOCTOR: Jocelyn, hold on, hold on, hold on. This... this can help. If you leave this to sync up, that should recalibrate the whole shebang.\nJOCELYN: Thank you. Wanna swap?\nRUBY: Hang on. So the planet down below refused to stop the babies being born... but once they're born, they don't look after them?\nJOCELYN: It's a very strange planet.\nRUBY: It's not that strange.\nDOCTOR: But you stayed behind.\nJOCELYN: I couldn't leave them. And I tried with this place. But I'm not an engineer. The machine went out of sync, I patched it back, but then the education software ran out of control. It's a mess. And I've been all on my own, watching the kids, for six years.\nDOCTOR: But I don't understand. They are gorgeous. Why would you hide?\nJOCELYN: Cos I don't want to see them die. And I don't want them to see me die. 'Cos that's how bad it is. This is a closed station. There's only so much air. There's only so much food. The last thing I'll do is give them the air out of Portal 3-5-7. But then... ..then you came along.\nRUBY: Can't you fly somewhere else?\nJOCELYN: What do you mean, fly?\nDOCTOR: Er, space station. Stationary, no engines. This great big thing can't move. It's just stuck in orbit, which is a shame, because this is a nice little system.\nJOCELYN: The fifth planet out, Mondo Caroon, that's a DuBarryDuPlessy world.\nDOCTOR: Oh, that's good. DuBarryDuPlessy is a starwide organisation. It means they can take in lots of refugees.\nRUBY: Oh. Well, can't we call them for help?\nJOCELYN: They don't go and fetch refugees. That's the fate of every refugee in the universe. You physically have to turn up on someone else's shore. And we can't move.\nDOCTOR: But now you have a ship. Plenty of room. It's called the Tardis. The trouble is, between us and the ship is the Bogeyman.\nJOCELYN: What is that thing?\nBOTH: You don't know?\nJOCELYN: It's nothing to do with me. It's not part of the manifest. It's not like anything I've ever seen.\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\nJOCELYN: Because it's terrifying.\nDOCTOR: Yeah, but I've met a million ugly bugs. I'm an ugly bug. That thing made me run, and I just wonder why.\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you've got babies, you've got a nanny, and you've got the Bogeyman.", "mimetype": "text/plain", "start_char_idx": 15626, "end_char_idx": 19038, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "257c13d6-1e99-4e1a-972f-7a7b59a3199b": {"__data__": {"id_": "257c13d6-1e99-4e1a-972f-7a7b59a3199b", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "205eded4-e2a6-414c-8c76-a86c56868495", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "b1e34d81b8ffd7ba36e1df403d65ac6eda0246eef6dcf9008669afab8bac2070", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7550c5e-9473-4711-b29d-5880713a084e", "node_type": "1", "metadata": {}, "hash": "d420583e500c865b46c427ecf5a4c6f4aacbdefee699ee92fdf7ea8010fe545b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The trouble is, between us and the ship is the Bogeyman.\nJOCELYN: What is that thing?\nBOTH: You don't know?\nJOCELYN: It's nothing to do with me. It's not part of the manifest. It's not like anything I've ever seen.\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\nJOCELYN: Because it's terrifying.\nDOCTOR: Yeah, but I've met a million ugly bugs. I'm an ugly bug. That thing made me run, and I just wonder why.\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you've got babies, you've got a nanny, and you've got the Bogeyman. You've literally got a monster living down below. It's a children's story come to life.\nDOCTOR: And every story has its hero.\n(They spot someone on the screen.)\nRUBY: That's Eric. Is that Eric?\nJOCELYN: Eric, get out of there.\n\n[Space station]\n\nNAN-E: Eric, please vacate this area.\n\n[Portal 357]\n\nDOCTOR: Oh, is that how it works?\nJOCELYN: Nan-E filter. Eric, get out now.\n\n[Space station]\n\nNAN-E: Eric will leave immediately.\nERIC: No, Nanny! I'm being brave.\n\n[Portal 357]\n\nJOCELYN: Eric, for God's sake, run!\n\n[Space station]\n\nNAN-E: Eric, invoking the deity, accelerate perambulation.\nERIC: I'm doing what Ruby said.\n\n[Portal 357]\n\nRUBY: What?\n\n[Space station]\n\nERIC: I love Ruby, and she said there's no such thing as the Bogeyman. So I'm going to find the naughty doggo and tell him off.\n(He meets the Bogeyman.)\nERIC: But I'm so scared.\n\n[Portal 357]\n\nRUBY: Oh, my God, it's my fault!\n\n[Birth Zone 6]\n\nRUBY: Eric, I'm coming! I'm coming! I'm coming! I'm coming! I'm coming! I'm coming!\n\n[Space station]\n\n(Ruby and the Doctor take the little lift down, and find Eric's pushchair fallen over.)\nRUBY: Oh.\nDOCTOR: Nan-E, where's the Bogeyman?\n\n[Portal 357]\n\nJOCELYN: It's about 400 metres north-west of you. But still no sign of Eric. I can't get a proper fix. I told you, these systems are a crock of...\n\n[Space station]\n\nNAN-E: ..waste products.\nDOCTOR: Mind your language, Nan-E.\nRUNY: Okay, Doctor, if we make a ton of noise, then the Bogeyman will come for us and leave Eric alone, yes?\nDOCTOR: Yes.\nRUBY: Okay, right.\nDOCTOR: Yes. Yes, yes.\n(They pick up things to hit the pipework with and move off.)\nRUBY: Bogeyman! Bogeyman!\nBOTH: Bogeyman! Bogeyman!\n\n[Portal 357]\n\nJOCELYN: It's moving. It's heard you.\n\n[Space station]\n\nRUBY: Okay, nice plan, but what now?\nDOCTOR: I think... if I was very, very little and I knew the Bogeyman was coming... I would need to change my nappy. 'Cos I can detect...\n(In a locker.)\nDOCTOR: Space baby! Oh, Eric.\nRUBY: We've got you, we've got you.\nDOCTOR: Oh, you poor thing. It's okay.\nRUBY: I know, I know. I know.\n\n[Portal 357]\n\nJOCELYN: Not west, I meant east.\n\n[Space station]\n\nDOCTOR: Go, go. It's all right, it's all right. It's all right, it's all right, it's all right. All right, all right. It's all right.\nRUBY: It's okay, it's okay.\nDOCTOR: All right.\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\n\n[Portal 357]\n\nJOCELYN: Don't you touch them, you...\n\n[Space station]\n\nNAN-E: ..illegitimate person.\nDOCTOR: Go! Go. It's a dead end.", "mimetype": "text/plain", "start_char_idx": 18400, "end_char_idx": 21557, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7550c5e-9473-4711-b29d-5880713a084e": {"__data__": {"id_": "f7550c5e-9473-4711-b29d-5880713a084e", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "257c13d6-1e99-4e1a-972f-7a7b59a3199b", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "095a68f6c22292d3e8f4593c6c957299de63b4901dd8a874feb66dcafc909942", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ea29a4c0-036a-4e32-885a-ffe444689ae6", "node_type": "1", "metadata": {}, "hash": "45c4f4d628f0527c36c425b995d5d06edcbe673358818f32817944c2a3e039bb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Oh, Eric.\nRUBY: We've got you, we've got you.\nDOCTOR: Oh, you poor thing. It's okay.\nRUBY: I know, I know. I know.\n\n[Portal 357]\n\nJOCELYN: Not west, I meant east.\n\n[Space station]\n\nDOCTOR: Go, go. It's all right, it's all right. It's all right, it's all right, it's all right. All right, all right. It's all right.\nRUBY: It's okay, it's okay.\nDOCTOR: All right.\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\n\n[Portal 357]\n\nJOCELYN: Don't you touch them, you...\n\n[Space station]\n\nNAN-E: ..illegitimate person.\nDOCTOR: Go! Go. It's a dead end.\n(The Bogeyman is there.)\nDOCTOR: Whoa! It's okay, it's okay. You're okay.\n(The Bogeyman is attacked by flames. It runs away.)\nPOPPY: Babies to the rescue!\nDOCTOR: Ha! Space babies!\nRUBY: Babies with a flame-thrower!\nDOCTOR: Babies, babies, babies, you did brilliant! You did so great! Space babies, you need to go, okay? Get.. get out of here.\n(He whistles up Eric's pushchair.)\nRUBY: Okay, let's get you in here, come on. Let's get you in there. Nan-E, tell them what to do.\nNAN-E: Children will return to the upper levels or have no expletive dinner.\nBABIES: Goodbye.\nDOCTOR: Okay, er, you... you go with them. I've got to stay here. Not just for the Tardis, but I've got to find out what that thing is.\nRUBY: If that's you telling me to leave you on your own, then... Oh, Doctor. Well, come on.\n(They head back through the stinky area.)\nDOCTOR: Ooo! Whew! Whew! So how did this begin, Jocelyn?\n\n[Portal 357]\n\nJOCELYN: First I knew, six years ago, it was like a rattling in the pipes. Then the howling began. By the time I got the cameras working, there it was. The Bogeyman. I don't know how it even exists.\n\n[Space station]\n\nRUBY: And that was six years ago?\nDOCTOR: Shh-shh-shh.\nRUBY: Oh. That's the same time the babies were born.\nDOCTOR: It's leaving... some sort of spoor. Man, that's a good word. Spoor.\nNAN-E: What the bleep-bleep is that?\nRUBY: Oh, Jocelyn, turn the filter off.\n\n[Portal 357]\n\nJOCELYN: What is that stuff?\nDOCTOR (on screen): If I could get this to your machine, it could analyse it.\nJOCELYN: The machine's got a vent in the basement. Follow the corridor. Left, straight ahead, left again.\n\n[Space station]\n\nDOCTOR: Into the belly of the beast. Yeah, this stuff is slippy, Rubes. Be careful.\n(She slips then gets dribbled on from a pipe outlet.)\nRUBY: Oh. Ah. Oh, my God. Oh, this is disgusting. Don't call me Rubes!\nDOCTOR: Are we almost there, Joce? This gunk stuff is sealing the whole place off. Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let's make sense of this thing. Ah, according to the machine... Oh.\nRUBY: What?\nDOCTOR: It has been right in front of us. We've been saying it all along. It's all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\nRUBY: It grew the Bogeyman.\nDOCTOR: Yes!\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\nRUBY: It's like a story. The teaching software, it told a story.", "mimetype": "text/plain", "start_char_idx": 20984, "end_char_idx": 24190, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ea29a4c0-036a-4e32-885a-ffe444689ae6": {"__data__": {"id_": "ea29a4c0-036a-4e32-885a-ffe444689ae6", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7550c5e-9473-4711-b29d-5880713a084e", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "24a3e26253cd91ba33f3522d741c8639f68ce96b7f6406227f720f4d820e148f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3f747d43-13cd-49ed-a786-1bdd7b431d7b", "node_type": "1", "metadata": {}, "hash": "2163d1f1b9948b424be374e553a1b56989dbf16f51922267566950e51bd1fcbf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let's make sense of this thing. Ah, according to the machine... Oh.\nRUBY: What?\nDOCTOR: It has been right in front of us. We've been saying it all along. It's all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\nRUBY: It grew the Bogeyman.\nDOCTOR: Yes!\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\nRUBY: It's like a story. The teaching software, it told a story.\nDOCTOR: It invented the Bogeyman.\nRUBY: For the babies.\nDOCTOR: For the space babies.\nRUBY: The machine is literal, like a computer. It literally said, \"Babies need fiction, they need stories, they need monsters.\"\nDOCTOR: Yes. That is why I'm so scared. It's all deliberate, it's infrasound. The Bogeyman is roaring at 17 hertz, that's the exact pitch designed to make you scared. It's scary because it's meant to be. The machine made it tall and big and noisy, and it built it out of... Oh.\nRUBY: What.\nDOCTOR: Oh, Ruby.\nRUBY: What?\nDOCTOR: Oh, man.\nRUBY: Tell me what it is.\nDOCTOR: I can't.\nRUBY: Doctor!\nDOCTOR: Ruby, I have travelled the universe and back and seen many, many things. Nothing... is as bad as this. A Bogeyman is made out of what?\nRUBY: I don't know.\nDOCTOR: The machine is literal, and the name is Bogeyman.\nRUBY: So?\nDOCTOR: Oh, babes. Space babes. We saw it. The nose-blowing. The machine was literal, and so it grew the Bogeyman out of bogeys.\nRUBY: What?\nDOCTOR: All of this is bogeys.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: No wonder it was shedding its skin. Doesn't everyone?\nRUBY: No, no, no, no.\nDOCTOR: It's snot.\nRUBY: It's not.\nDOCTOR: Oh, Ruby, it is a living sneeze!\nRUBY: But it's in my...\nDOCTOR: I know.\nRUBY: Oh, my God! This is the worst thing that has ever happened to anyone! Don't laugh!\nDOCTOR: Sorry. Oh, isn't the universe mad?\nRUBY: Oh yeah, it just made a monster out of snot.\nDOCTOR: Oh, Ruby Sunday, Monday, Tuesday, that is... so funny.\n(The monster is in front of them.)\nRUBY: Bogeyman.\nDOCTOR: Run. Run! Go!\n(A barrier blocks their path.)\nDOCTOR: No, no, no, no!\n\n[Portal 357]\n\nJOCELYN: Don't worry, it's me. Turn right. It's your device. It's calibrated. It's brilliant! I've got control at last. Now trust me. Turn right!\nDOCTOR [on screen]: This isn't the way to the lift!\nJOCELYN: Keep going.\n(She unlocks doors remotely.)\n\n[Space station]\n\nRUBY: Ah!\nDOCTOR: Go, go, go, go!\nRUBY: I'm coming, I'm coming!\n\n[Portal 357]\n\nJOCELYN: It's catching up!\n\n[Space station]\n\nRUBY: Coming!\n(A door slides closed between them and the Bogeyman.)\nDOCTOR: Whoa!\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\n\n[Portal 357]\n\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\nJOCELYN: You can tell me later. Once I've got rid of it. I will protect my children and blast that thing into space!\n\n[Airlock door]\n\nDOCTOR: It's an airlock.\n(The Bogeyman is hanging on for dear life.)\nDOCTOR: It is one of the children, Jocelyn!", "mimetype": "text/plain", "start_char_idx": 23486, "end_char_idx": 26717, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3f747d43-13cd-49ed-a786-1bdd7b431d7b": {"__data__": {"id_": "3f747d43-13cd-49ed-a786-1bdd7b431d7b", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ea29a4c0-036a-4e32-885a-ffe444689ae6", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "5639838f8ede9953433f9da08e96df6ab22ac3291e7c9c934b106322dfab8470", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ea2ce78e-c967-410c-b8d8-97ee3709e39d", "node_type": "1", "metadata": {}, "hash": "5ca9e1bbcb54da40d5422c10af31eb147837826b2ffcea75d3eb656336177a3e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(She unlocks doors remotely.)\n\n[Space station]\n\nRUBY: Ah!\nDOCTOR: Go, go, go, go!\nRUBY: I'm coming, I'm coming!\n\n[Portal 357]\n\nJOCELYN: It's catching up!\n\n[Space station]\n\nRUBY: Coming!\n(A door slides closed between them and the Bogeyman.)\nDOCTOR: Whoa!\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\n\n[Portal 357]\n\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\nJOCELYN: You can tell me later. Once I've got rid of it. I will protect my children and blast that thing into space!\n\n[Airlock door]\n\nDOCTOR: It's an airlock.\n(The Bogeyman is hanging on for dear life.)\nDOCTOR: It is one of the children, Jocelyn! I... She's got the sonic. Jocelyn, Jocelyn!\nCOMPUTER: Oxygen field at 10%.\nDOCTOR: Okay, okay, okay, okay. We haven't got time. Stop Jocelyn, yeah?\nRUBY: Wait...\nDOCTOR: Left, second right, next left, you'll get to the lift.\nRUBY: What about you?\nDOCTOR: Left, second right, next left!\nRUBY: Right, okay.\n(She runs off.)\n\n[Control room]\n\nCOMPUTER: Oxygen field at 9%.\nPOPPY: You're hurting him.\nERIC: Stop it, Nanny. Stop it!\nCOMPUTER: Oxygen field at 8%.\n\n[Airlock door]\n\nDOCTOR [memory]: I am the last of the Time Lords.\nRUBY [memory]: How do you keep going?\nDOCTOR [memory]: For days like this. I'm the only one of me in the whole, wide universe. No one else like me exists, and that is true of everyone.\nDOCTOR: The only one of its kind.\nCOMPUTER: Oxygen field at 7%.\n(The Doctor opens the airlock door and holds it open with his body.)\nCOMPUTER: Oxygen field at 6%.\n(Then he goes inside, hanging on, with the Bogeyman just beyond reach.)\nCOMPUTER: Oxygen field at 5%. Oxygen field at 4%.\n(Then he lets go, and lands on the hull between the open outer door and the big red button.)\nCOMPUTER: Oxygen field at 3%.\nDOCTOR: Push...the button.\nCOMPUTER: Oxygen field at 2%. Venting reverse. Venting reverse.\n\n[Portal 357]\n\n(Ruby runs in and grabs the sonic.)\nJOCELYN: No!\nRUBY: That's what you do, Jocelyn. You save them all.\nCOMPUTER: Oxygen field at 1%.\n(The outer airlock door is closed, the air stops rushing out. The Doctor and the Bogeyman drop to the floor.)\nRUBY: You save them all. Come here. It's okay, it's okay.\n(Jocelyn cries in Ruby's arms.)\n\n[Control room]\n\nDOCTOR: Attention! Calling Captain Poppy. Calling all crew. Especially you, Eric. Plus Ruby and Jocelyn Sancerre.\nERIC: Nanny was really naughty.\nJOCELYN: I know, and I'm so sorry. All of you. I was just... on my own for such a very long time.\nERIC: We still love you, Nanny.\nBABIES: Yay! We do!\nDOCTOR: But-but-but-but-but-but... your favourite monster is fine. Look. Look, look, look, look.\nBABIES: Yay!\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\nBABIES: Wow!\nDOCTOR: The world of Mondo Caroon. But... but you can't get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\nBABIES: Huh?\nDOCTOR: Huh? 'Cos the system went wrong, and that's where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\nJOCELYN: Nan-E filter.\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!", "mimetype": "text/plain", "start_char_idx": 26066, "end_char_idx": 29320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ea2ce78e-c967-410c-b8d8-97ee3709e39d": {"__data__": {"id_": "ea2ce78e-c967-410c-b8d8-97ee3709e39d", "embedding": null, "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15", "node_type": "4", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "4dbdb68efbecfd073377b8535595e3758f67d339c1066304628d14ff444102e3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f747d43-13cd-49ed-a786-1bdd7b431d7b", "node_type": "1", "metadata": {"source_url": "http://www.chakoteya.net/DoctorWho/40-1.html", "document_index": 15}, "hash": "89d6d6ce50a669269084be1374240a7e1e8dfec3781ed75e28f3e058aefaf9ca", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "BABIES: Yay!\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\nBABIES: Wow!\nDOCTOR: The world of Mondo Caroon. But... but you can't get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\nBABIES: Huh?\nDOCTOR: Huh? 'Cos the system went wrong, and that's where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\nJOCELYN: Nan-E filter.\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!\n(The waste gets vented in a massive grey cloud, and the space station gets propelled out of orbit.)\nDOCTOR: Oh, set sail for your new home. Baby World!\nRUBY: Come here now. Are you happy now, Eric?\nERIC: I'm very, very happy. I love you, Ruby.\n\n[Outside the Tardis]\n\nRUBY: So that was a normal day for you, then?\nDOCTOR: No, no. That was extra-special nuts. And you, Ruby Sunday, get this. Your very own Tardis key.\nRUBY: What for?\nDOCTOR: I have the whole universe at my fingertips, and I'm all on my own. So I'd love it if you came with me.\nRUBY: To what, just travel?\nDOCTOR: No job. No boss. Just fun.\nRUBY: We did almost die.\nDOCTOR: Yes. But we lived so much, too.\nRUBY: Yes, we did. Yes, we did. Yes, yes, we did. Yep, we did, we did. We did. Yes.\nDOCTOR: Yes?\nRUBY: Yes.\nDOCTOR: Yes?\nRUBY: Yes. Oh, my God.\nDOCTOR: Yes? Yes! Yes! Yes! Ruby Sunday said yes!\nRUBY: Come on in. Follow me.\nDOCTOR: Oh, come on.\n\n[Tardis]\n\nRUBY: Right, mate, let me tell you where we're gonna go.\nDOCTOR: Except...\nRUBY: Oh, terms and conditions.\nDOCTOR: There is one thing that I can never do, Ruby. And that's take you to that church on Ruby Road that Christmas. Absolutely never.\nRUBY: But you've got a time machine.\nDOCTOR: If you change one thing, a single snowflake, that could change your birth mother's story and then you would never meet me, none of this would ever happen, and we would fall into the deepest, darkest paradox. Ruby, trust me. I think that snow was a warning. I can't. And I won't.\nRUBY: Well, that's a pity. 'Cos I disagree. And if you let me finish... we are going to go see my mum. At Christmas. Right now. Come on.\n\n[Ruby's home]\n\nCARLA: (on phone) And Ruby phoned, she said, \"I love you,\" and ran off! No word from her since. What sort of Christmas is this? It all started with this man. He called himself the Doctor. Hold on. What's that noise?\n(The Tardis materialises, making a hole in the kitchen ceiling. Not normal Tardis behaviour, that.)\nCHERRY: What the blinking flip?\n(Tardis door opens.)\nRUBY: Hiya, Mummy.\nCARLA: But... what are you doing? And what the hell is that? What's it done to my kitchen?\n\n[Tardis]\n\nRUBY [OC]: Hey! Come and say hello!\nDOCTOR: Yes. Coming. Tell your mum not to slap me.\n(He sonicks up a quick DNA scan of Ruby Sunday.)\nDOCTOR: Yes, now, the people from my world, they use titles like the Bishop, the Pedant, the Sagi-shi. My name was...\n(He doesn't wait for the results of the scan.)", "mimetype": "text/plain", "start_char_idx": 28683, "end_char_idx": 31757, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e6c667ae-d966-4201-8291-6a610ca58d95": {"__data__": {"id_": "e6c667ae-d966-4201-8291-6a610ca58d95", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8290191e-e61d-4c09-b056-292488015dcc", "node_type": "1", "metadata": {}, "hash": "fd0e735d43e0b98a12b2b6459d405a8ba15b7d1728ae86ab46467f80b7ceb162", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Version History\n(Redirected from Version history)\nJump to navigationJump to search\nStardew Valley was released on 26 February 2016 for Windows PC after almost four years of closed development. Linux and macOS compatibility was released in a free update on 29 July 2016.\n\nFor a detailed breakdown of changes specific to console versions of the game see Console Version History.\nFor a detailed breakdown of changes specific to the mobile version of the game see Mobile Version History.\n\n1.6.8\nStardew Valley 1.6.8 was released on 28 April 2024.\n\nBug fixes\nFixes a game-breaking crash introduced in 1.6.7 where the game would crash if NPC's reach the island resort changing room.\n1.6.7\nStardew Valley 1.6.7 was released on 27 April 2024.\n\nBug fixes\nFixes a bug preventing players from giving Pierre the Missing Stock List\nFixed some machines and desert festival logic not working for Linux/MacOS players using the compatibility branch.\n1.6.6\nStardew Valley 1.6.6 was released on 26 April 2024.\n\nBalance and Gameplay changes\nBee houses now work with flowers in garden pots.\n\u201cMinecart depot\u201d alternative layout now only appears in the upper or lava mine areas.\nYou can now turn the gold clock on or off\nAdded coal -> mahogany seed trade at raccoons\n50% mastery XP now only applies to farming, as originally intended.\nTranslation changes\nReverted Chinese text to 1.6.3\nReverted Chinese default font to the original\nAdded an option to use the smooth font introduced in 1.6.4\nAdded a dialogue font size slider for Chinese\nAdded complete Russian translated movie & desert festival sprites\nAdded option for Russian to use the \u201cold\u201d font\nBug fixes\nFixed a case where Mr. raccoon could disappear during the raccoon cutscene in multiplayer\nFixed being able to trash Pierre\u2019s Missing Stocklist, or give it away at the Feast of the Winter Star.\nFixed being able to give a wilted bouquet to your spouse.\nFixed issue causing only 1 omni geode to be produced from the skull cavern chest.\nFixed crash when a save contains some invalid animal home data.\nFixed a crash when talking to Penny in French.\nFixed a malformed Willy farm event in German.\nFixed an incorrectly blocking map tile in the Forest Farm map.\nFixed some machines and some desert festival logic not working for Linux/macOS players using the compatibility branch.\nFixed a case where an area was inaccessible in the volcano dungeon\nFixed sewer event in German\nFixed cases where you\u2019d see Mayor Lewis\u2019 giftbox note again when collecting 15 parsnips from a different chest.\nFixed emily makeover event from being hard to skip\nFixed Calico Egg Rating prize edge cases for farmhands\nFixed prismatic hat effects not working in French.\nFixed being able to \u201cadvance\u201d the ready check menu by pressing Y, which lead to many issues.\nFixed island outfits not being loaded for farmhands\nMinor optimizations.\nFixes for modded players\nFixed error showing non-flavored roe items.\nFixed error if a mod sets an NPC\u2019s \u2018friends and family\u2019 data to null.\nFixed error loading a save containing enchanted weapons whose ID changed or data was removed.\nFixed soft lock when watching weather TV channel if tomorrow\u2019s weather is custom.\nFixed temporary maps that aren\u2019t part of a location not using seasonal tilesheets.\nFixed summit cutscene showing custom fish with wrong sprites.\nChanges for mod authors\nIn Data/Objects, added two new fields: CanBeGivenAsGift and CanBeTrashed. Setting CanBeGivenAsGift: false adds the not_giftable context tag automatically.\n1.6.5\nStardew Valley 1.6.5 was released on 20 April 2024.\n\nBug fixes\nFixed crash when loading dark mine levels in some cases.\nBroken villager NPCs (usually due to a removed mod) are now deleted on load. They'll respawn when they're re-added to the data.\n1.6.4\nStardew Valley 1.6.4 was released on 18 April 2024. A hotfix was applied on 19 April 2024.\n\nNew content & features\nAdded 20 new 'alternate' mine layouts, which can start appearing after reaching the bottom of the mines.\nAdded 20 new volcano mines layouts, which can appear after you've unlocked the shortcut between the caldera and the volcano entrance.\nAdded fish frenzies.\nAdded a special cutscene after you've helped your new neighbors grow their family to the max.\nAdded 4 new fairy styles.\nYou can now place 8 additional non-fish items into fish tanks.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4295, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8290191e-e61d-4c09-b056-292488015dcc": {"__data__": {"id_": "8290191e-e61d-4c09-b056-292488015dcc", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e6c667ae-d966-4201-8291-6a610ca58d95", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "0c19faba9a8534e4c52bf3fcc981297608c8458f7aab8a838afd7e2b9adaf231", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba2810cb-baaf-4743-b87d-b30bb057135e", "node_type": "1", "metadata": {}, "hash": "887c5a6176e2499c6a40f16fde789a6adcd05afd2f1ffd47dcc43affcfadbf0d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bug fixes\nFixed crash when loading dark mine levels in some cases.\nBroken villager NPCs (usually due to a removed mod) are now deleted on load. They'll respawn when they're re-added to the data.\n1.6.4\nStardew Valley 1.6.4 was released on 18 April 2024. A hotfix was applied on 19 April 2024.\n\nNew content & features\nAdded 20 new 'alternate' mine layouts, which can start appearing after reaching the bottom of the mines.\nAdded 20 new volcano mines layouts, which can appear after you've unlocked the shortcut between the caldera and the volcano entrance.\nAdded fish frenzies.\nAdded a special cutscene after you've helped your new neighbors grow their family to the max.\nAdded 4 new fairy styles.\nYou can now place 8 additional non-fish items into fish tanks.\nRaccoon shop now includes a trade for mystery boxes and golden mystery boxes.\nVinegar can now be poured onto trees to stop them from ever growing moss.\nShaving enchantment now causes tree-specific drops (fern \u2192 fiddlehead fern, mushroom \u2192 red mushroom, mahogany \u2192 hardwood).\nVisual improvements\nQi club coins now show up in the shop menu.\nVarious map edits and fixes.\nRemoved Maru's glasses from all beach portraits for consistency.\nTranslation changes\nMany edits and improvements to the Chinese version.\nEdits to the Russian, Portuguese, Hungarian, Turkish, and Korean translations.\nChanged the Chinese fonts to make them more appealing and readable.\nChanged Hungarian number spacing character from a comma to a period.\nSome improvements to Russian font.\nBalance changes\nWhen you load a save, you'll now unlock missed Steam achievements if needed (e.g. achievements gained while playing offline).\nAdded mini-shipping bin as an expensive Qi gem shop purchase.\nAdded more variety, and improvements, to Skull Cave treasure chests.\nLife elixirs now only restores health, and energy tonics now only restore energy.\nWild seed spots are now rarer, but yield more seeds.\nDoubled the Iridium Golem's chance to drop iridium.\nThe monsters in the volcano entry level are now randomized each day.\nUsing a treasure totem indoors no longer works.\nGoing down a level in the mines now makes you invulnerable for 1 second.\nIncreased raccoon mystery box reward from 4 to 5.\nFarming experience now contributes to mastery experience at a 50% rate.\nIce orb will no longer freeze a spider while it is in the air jumping.\nRemoved red snapper from winter fishing quest pool, and sardines from the summer quest pool.\nYou will no longer get calico rating points from going down the normal mines.\nGolden mystery boxes now have a small chance to yield an auto petter.\nSlightly reduced chance to find mystery boxes.\nMine barrels and coal carts will now \"refresh\" at the start of each year.\nThe order of mystery box rewards is now randomized per-player instead of per-save.\nQuality of life changes\nAdded a 1.2-second delay after dropping an item, before it's picked back up by the same player.\nNapalm rings are now non-destructive on the farm and inside the slime hutch (i.e. the explosion will only damage monsters).\nAdded ctrl + right-click as an alternate toolbar drop hotkey.\nReceiving a \"special notification\" (e.g. first geode message) will no longer cancel out player actions such as eating or warping.\nFlopping fish no longer fall back into fish ponds.\nCrab pots now have a short time period after harvesting from them during which they can't be removed (750ms).\nThe Junimo bundle menu now only highlights items that can actually be placed in the selected bundle.\nOther changes\nMinor optimizations.\nAdded two inappropriate names to the list to exclude from the name generator.\nYou can no longer give gifts to NPC's during green rain year 1 (prevents incongruous attitudes). This also prevents a portrait issue with Demetrius.\nGameplay fixes\nFishing splash zones and ore pan points are now removed overnight.\nThe prize ticket machine now consumes your ticket when you get the reward, rather than when you first press the button.\nFor the purposes of perfection, the level 100 stardrop now has a more robust way to check if it's been acquired. This solves a problem where the flag for eating the lvl 100 stardrop could be missing.\nFixed Monster Compendium not actually doubling all loot.\nFixed geodes no longer dropping on the farm in normal circumstances.\nFixed rare crash when spawning items overnight.\nFixed crash when a certain mine level is chosen (_dark_dark crash).\nFixed player colliding with stuff during event cutscenes.\nFixed pre-1.6 forged weapons having reduced stats.", "mimetype": "text/plain", "start_char_idx": 3537, "end_char_idx": 8052, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba2810cb-baaf-4743-b87d-b30bb057135e": {"__data__": {"id_": "ba2810cb-baaf-4743-b87d-b30bb057135e", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8290191e-e61d-4c09-b056-292488015dcc", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "6a28eb4a855ed541f22f817bc6d1bc3d0b5d10f08d29e26482cd658efacb83e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f144d6a5-ba9a-47d7-b4f7-56849d08b04b", "node_type": "1", "metadata": {}, "hash": "88db5e42142695b985fb27247f53b0c32406aea0478a88b3eb08e55841616e4d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "You can no longer give gifts to NPC's during green rain year 1 (prevents incongruous attitudes). This also prevents a portrait issue with Demetrius.\nGameplay fixes\nFishing splash zones and ore pan points are now removed overnight.\nThe prize ticket machine now consumes your ticket when you get the reward, rather than when you first press the button.\nFor the purposes of perfection, the level 100 stardrop now has a more robust way to check if it's been acquired. This solves a problem where the flag for eating the lvl 100 stardrop could be missing.\nFixed Monster Compendium not actually doubling all loot.\nFixed geodes no longer dropping on the farm in normal circumstances.\nFixed rare crash when spawning items overnight.\nFixed crash when a certain mine level is chosen (_dark_dark crash).\nFixed player colliding with stuff during event cutscenes.\nFixed pre-1.6 forged weapons having reduced stats.\nFixed not being able to put a torch on the sprinkler you get as a CC reward.\nFixed disappearing pets bug.\nFixed various bugs/crashes related to building a cabin.\nFixed wild seeds in garden pots putting their final crop in the top-left corner of the map instead of the pot.\nFixed \"lost and found\" chests (from night market and elsewhere) not working anymore in 1.6.\nFixed a duplication bug with the \"lost and found\" chests.\nFixed slime hutch floors reverting to the default after reloading a game.\nFixed malformed casino shop red fireworks ID.\nFixed pet adoption catch-all case only working with the animal catalogue, and only applying in year 2 specifically, rather than for any year 2 or beyond.\nFixed 'use legacy randomization' option applied inconsistently when loading a save, which caused weird issues like broken green rain days.\nFixed the case where you could permanently miss the ancient seed recipe if you grabbed the ancient seed packet but not the associated recipe, and then closed the museum rewards menu. Missing recipes will also be restored upon loading a file.\nFixed issue with duplicated animals & building interiors from pre ~1.3 saves.\nFixed end tables not being rotateable.\nFixed an issue where empty barns/coops could not be removed by Robin on old saves.\nFixed slime egg incubators letting you reclaim the egg before it hatches.\nFixed farmhouse placement bounds to match the object placement restrictions around it.\nMultiplayer fixes\nSynced some NPC Gift data in other languages.\nFixed fireworks (and possibly other sprites) drawing behind stuff in multiplayer.\nFixed \"Build a Silo\" quest not being completed for farmhands.\nFixed Raccoon quest not being removed for all players.\nFixed double trinket issue when a farmhand disconnects/reconnects.\nFixed double and/or missing derby participants sprite issue in multiplayer.\nDisplay text and localization fixes\nMany edits and fixes in translation text.\nFixed a text parsing error for Asian languages which caused them to incorrectly wrap in some cases.\nFixed spacing issues in Asian languages.\nFixed several localization issues (day time money box extra space in Chinese, missing Elliott sentence opener, Fizz name untranslated, birthday string de-hardcoded, etc).\nFixed Russian line break issue.\nFixed an issue with the perfection tracker display in Chinese, Korean, and Japanese.\nFixed events not consistently handling gender-dependent text.\nCosmetic fixes\nAdjusted basic object layer depth anchor point so it's more centered rather than on the bottom.\nPlaceable grass now offsets vertically a little if it would clip through a front-layer tile.\nFixed seasonal world map not working for non-English players.\nFixed flying monsters not being draw above things on the farm & volcano.\nFixed reward icon in completed quest menu being visually offset.\nFixed george's TV clipping with farmer during green rain.\nFixed movies not showing layered sprites (e.g. the eyeball in Mysterium).\nFixed Qi club coins drawn below the lightmap.\nFixed Qi coin overlay drawn during minigames.\nFixed crane game audio not stopping when the game is forcefully closed.\nFixed some tooltip padding issues.\nFixed movie theater display issues on the world map.\nFixed repeated dialogue selection sound if a control was plugged in but you are using a mouse.\nFixed quest reward icon input offset issue.\nFixed Joja Warehouse roof drawing above the weather (and possibly other similar cases).\nFixed various map tile issues.\nFixed a visual issue with a shadow in the farm house.\nFixed able to swap two chests of the same type.\nFixed machines sometimes wobbling when they're not processing anything.\nChanges for modded players\nImproved debug commands:\nAdded debug commands to change pet types/breeds, to allow migrating older saves (setPreferredPet and changePet). This replaces the former toggleCatPerson command.\nThe filterLoadMenu <search> command now keeps the original save slot numbers.\nCombined removeNpc and killNpc commands. The unified command removes all instances of an NPC, to help fix duplicate NPCs.", "mimetype": "text/plain", "start_char_idx": 7151, "end_char_idx": 12101, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f144d6a5-ba9a-47d7-b4f7-56849d08b04b": {"__data__": {"id_": "f144d6a5-ba9a-47d7-b4f7-56849d08b04b", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba2810cb-baaf-4743-b87d-b30bb057135e", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "f7f702c50dfc900b863b0c18aff7230e582078c870849e10a6f826d7065ce587", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f1af7701-3f3b-4b92-9695-71d10dff154a", "node_type": "1", "metadata": {}, "hash": "9ed3b215bd0fe88480b49bf34540df144db547811509976e4ae03429aa208208", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed crane game audio not stopping when the game is forcefully closed.\nFixed some tooltip padding issues.\nFixed movie theater display issues on the world map.\nFixed repeated dialogue selection sound if a control was plugged in but you are using a mouse.\nFixed quest reward icon input offset issue.\nFixed Joja Warehouse roof drawing above the weather (and possibly other similar cases).\nFixed various map tile issues.\nFixed a visual issue with a shadow in the farm house.\nFixed able to swap two chests of the same type.\nFixed machines sometimes wobbling when they're not processing anything.\nChanges for modded players\nImproved debug commands:\nAdded debug commands to change pet types/breeds, to allow migrating older saves (setPreferredPet and changePet). This replaces the former toggleCatPerson command.\nThe filterLoadMenu <search> command now keeps the original save slot numbers.\nCombined removeNpc and killNpc commands. The unified command removes all instances of an NPC, to help fix duplicate NPCs.\nChanges for mod authors\nC# mods can now hide specific animals from the animal social menu (e.g. animals owned by NPCs) via the FarmAnimal.hideFromAnimalSocialMenu field.\nIn Data/Buildings, you can now add furniture via IndoorItems.\nIn Data/FarmAnimals, added fields to set the sleep sprite and whether they eat golden crackers.\nIn Data/Locations, added fields to set effect of fish-specific bait and whether fish can be caught using a training rod.\nIn Data/Machines, added option to only let the machine complete overnight.\nIn Data/Powers, added CustomFields field.\nAdded missing Id fields in Data/FarmAnimals and Data/Pets.\nAdded a warning when a farm animal's spritesheet size is invalid, which would previously lead to the animal silently freezing.\nYou can now use tokenizable strings in event scripts and dialogue text.\nDe-hardcoded forest waterfall fish into Data/Locations.\nFixes for modded players\nFixed some wallpapers and flooring not appearing in mod item lists.\nFixed pre-1.6 farm maps having broken warps to the bus stop.\nFixed errors and crashes due to mods adding items without a name.\nFixed softlock when a warp leads to an invalid location.\nFixed crash when playing events that use the replaceWithClones command.\nFixed crash if an NPC has invalid temporary dialogue.\nFixed world map showing a glitched texture for custom farm types which don't override it.\nFixed another case of NPC duplication involving the movie theater.\nFixed crash when loading a save if a farm Junimo wasn't properly removed before saving.\nFixed crash if the lost & found contains null items.\nFixed disconnect for Steam players when using mods that send messages before a farmhand has been approved.\nFixed crash on save if shipping bin has empty slots.\nFixed riding the bus to the desert instantly warping you back if mods added warps on the desert road.\nFix multiplayer crash if some players don't have the same NPC textures.\nFixes for mod authors\nFixed farmhands' cellars not applying cellar data from Data/Locations.\nFixed crash if a farm animal has no entry in Data/FarmAnimals.\nFixed festivals ignoring year suffixes for <setup>_additionalCharacters and name fields.\nFixed issues with farm animals which have a custom home building.\nFixed hardcoded assumptions about farm animal spritesheets which could cause counter-intuitive behavior with custom animals.\nFurther changes were later released without changing the version number:\n19 April 2024 \"hotfix #1\" (Steam announcement)\nFixes issue when dropping a big chest into a small chest\nQuarry mine level can no longer be an alternate layout\nPrevents the player from running through barriers in certain transit cutscenes\nMine levels 45 and 85 are now also refreshed at the beginning of the year\n1.6.3\nStardew Valley 1.6.3 was released on 27 March 2024.\n\nNew content & features\nYou can now access Clint's shop and geode service while your tool is being upgraded.\nAdded Krobus portrait.\nAdded minecart shortcut to year 1 Spirit's Eve festival.\nYou can now paint the new cabins (at third upgrade level).\nBalance changes\nIncreased raccoon bug meat and bat wing request amount.\nHarvesting moss now grants 1 foraging exp per moss.\nThe Infinite Power achievement is now more generous with how it activates, allowing pre-1.6 saves to trigger the achievement.\nYou now have to collect (not just donate) the four prismatic shards for the \"Four Precious Stones\" Qi quest.\nThe Junimo Kart Qi quest now rewards 20 Qi gems (up from 10).\nAdult mossy green rain trees boost the moss growth rate of nearby trees.\nMoss now grows more slowly on sunny summer days, and recovers more slowly after harvest.\nReduced meteorite prismatic shard chance (100% -> 25%).", "mimetype": "text/plain", "start_char_idx": 11095, "end_char_idx": 15782, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f1af7701-3f3b-4b92-9695-71d10dff154a": {"__data__": {"id_": "f1af7701-3f3b-4b92-9695-71d10dff154a", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f144d6a5-ba9a-47d7-b4f7-56849d08b04b", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "82949cab52a8db103998b7eaf59cd35d907b043f77f8855891b251797095f6b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4eb7d804-73ff-4dbc-9008-abab68638ac8", "node_type": "1", "metadata": {}, "hash": "6d7f0054d2168b6f0ae635c9f3606984cd1e1f1240976e26b37c874f0ce814d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Added Krobus portrait.\nAdded minecart shortcut to year 1 Spirit's Eve festival.\nYou can now paint the new cabins (at third upgrade level).\nBalance changes\nIncreased raccoon bug meat and bat wing request amount.\nHarvesting moss now grants 1 foraging exp per moss.\nThe Infinite Power achievement is now more generous with how it activates, allowing pre-1.6 saves to trigger the achievement.\nYou now have to collect (not just donate) the four prismatic shards for the \"Four Precious Stones\" Qi quest.\nThe Junimo Kart Qi quest now rewards 20 Qi gems (up from 10).\nAdult mossy green rain trees boost the moss growth rate of nearby trees.\nMoss now grows more slowly on sunny summer days, and recovers more slowly after harvest.\nReduced meteorite prismatic shard chance (100% -> 25%).\nAncient seed packets can no longer be sold at the traveling cart.\nQuality of life changes\nWaterfall and some other ambient positional sounds now fade out more smoothly.\nIf you don't have a pet in year two, you can now start adopting them from Marnie's shop.\nBug fixes\nAdded the new cabin styles to the multiplayer starter layouts.\nStarter cabins now appear in the actual order intended.\nIf a journal quest title is too wide, the clock icon and the rest of the text will be shifted down to make room.\nYou can now press the Escape or menu button to \"go back\" on a shipping menu category page.\nMade berry bush state consistent overnight and on load (both at 20% plus a small new random bonus chance).\nMinor graphical fixes.\nFixed glitch where farming speed is changed depending on the player's direction.\nFixed several translation errors and missing translations.\nFixed large character sprites having a visual glitch (e.g. bear, island frog, or Clint when hammering).\nFixed a visual error in the shop menu if an item's name was longer than the width of the menu.\nFixed a crash related to the new festival.\nFixed a bug that caused excess trash to be fished.\nFixed bug preventing Emily's 10-heart mail and event from triggering.\nFixed graphics issues with the shipping menu.\nFixed several more cases of out-of-bounds spawning.\nChanges for mod authors\nFixed items able to have a null Name or DisplayName in 1.6. They now default to the qualified item ID and \"Unnamed Item (<id>)\" respectively.\nThe ${...}$ gender-switch syntax now works in events.\nThe character.EventActor flag is now synced in multiplayer.\nAdded paint masks for the new cabins style.\nThe debug whereis command now lists event actors too.\nFixed pet license name delimiter conflicting with unique string ID format.\nFixed NPC duplication bug with movie theater.\nFixed fruit trees above growth stage 4 no longer producing fruit.\nFixed current location's building interiors not being actively synced.\nFixed error processing a machine with no Data/Machines entry.\nFixed broken fruit tree sprite if it's synced from another player and has a custom texture in Data/FruitTrees.\n1.6.2\nStardew Valley 1.6.2 was released on 21 March 2024.\n\nBalance changes\nAdded scaling edibility to juice, jellies, wine, and pickles.\nVoid egg is now poisonous.\nBug fixes\nFixed an issue with Willy's rod.\nFixed for invisible tea sprites.\nFixed an error in the Luau event in Portuguese.\nFixed visual error with pre-1.6 basic wines.\nFixed a soft-lock if you charged a tool and then strafed to a warp spot, and released the tool while warping.\nFixed inedible ingredients being poisonous after turning into jelly or pickles.\nFixed Volcano dwarf bombs not matching regular dwarf bombs.\nFixed adventure guild open hours on map.\nFixed various translation issues.\n1.6.1\nStardew Valley 1.6.1 was released on 19 March 2024.\n\nBug fixes\nImproved cases where the quest title could go off the edge of the quest log.\nFixed botched German egg quest text (for new players going forward).\nFixed animal page crash when clicking on the scroll bar when there are a low number of animals.\nFixed Junimo harvester in save crash.\nFixed Meadowlands farm quest persisting if the farm icon was selected, but then another farm was started.\nFixed the telephone Robin house upgrade question being malformed.\nFixed eyebrow accessory looking weird when fishing.\nFixed errors due to clipboard being set to a null string.\nFixed crash when farmhand reconnects to town during green rain (and potentially other related crashes).\nFixed several map tile issues and places where forage could spawn out of bounds.\n1.6\nStardew Valley 1.6.0 was released on 19 March 2024.", "mimetype": "text/plain", "start_char_idx": 15005, "end_char_idx": 19443, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4eb7d804-73ff-4dbc-9008-abab68638ac8": {"__data__": {"id_": "4eb7d804-73ff-4dbc-9008-abab68638ac8", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f1af7701-3f3b-4b92-9695-71d10dff154a", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "baae45775d5944d11d51e8ef42f972402a462572eee322594d013a89ff8df17c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e47220ba-d638-477f-9941-f02ec41c6320", "node_type": "1", "metadata": {}, "hash": "f8756c8d67b067164bb271c860257b8eba81fb78a6ba30b5bf373d175c2b7db5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1.6.1\nStardew Valley 1.6.1 was released on 19 March 2024.\n\nBug fixes\nImproved cases where the quest title could go off the edge of the quest log.\nFixed botched German egg quest text (for new players going forward).\nFixed animal page crash when clicking on the scroll bar when there are a low number of animals.\nFixed Junimo harvester in save crash.\nFixed Meadowlands farm quest persisting if the farm icon was selected, but then another farm was started.\nFixed the telephone Robin house upgrade question being malformed.\nFixed eyebrow accessory looking weird when fishing.\nFixed errors due to clipboard being set to a null string.\nFixed crash when farmhand reconnects to town during green rain (and potentially other related crashes).\nFixed several map tile issues and places where forage could spawn out of bounds.\n1.6\nStardew Valley 1.6.0 was released on 19 March 2024.\n\nNew content & features\nAdded new festivals and events:\nThe Desert Festival is a three-day event in spring which can be accessed after the bus is repaired.\nTwo mini fishing festivals: Trout Derby and SquidFest.\nA new environmental \"event\" in summer.\nAdded a mastery system, accessed via a new area, which grants powerful perks and items\u2026\nAdded a new farm type: Meadowlands Farm. It has a chewy blue grass that animals love. You also start with a coop and 2 chickens.\nAdded many new NPC dialogues. That includes...\ncustom gift reactions;\ndynamic dialogues which react to things that happened;\ncustom flower dance acceptance dialogue;\nrestored missing dialogue (like Emily and Shane's flower dance custom accept-dance dialogues when married to the player, Shane's dialogue when browsing the Saloon vending machine, Lewis congratulating female farmers after their wedding, a line in Maru's 14-heart event, three dialogues from Sam related to Kent, two randomized dialogues when an NPC buys an item you sold to a shop, two speech bubbles from Marnie and Robin when you enter their shop building, and a fortune teller dialogue for your potential spouse);\nand more.\nYou can now get multiple pets (after getting max hearts with your starter pet).\nAdded a world map for Ginger Island, visible when visiting the island.\nThe world map now shows your actual position within the world in real-time (instead of showing you at a fixed point for each location). In multiplayer, you'll see other players' positions in real-time too.\nPets that love you will sometimes give you gifts.\nNPCs now have winter outfits.\nFestivals now have map and dialogue changes every second year (except the night market and desert festival).\nAdded a golden Joja parrot, which you can pay to find all remaining golden walnuts on Ginger Island.\nAdded perfection waivers, a new Joja way to bypass perfection challenges.\nAdded a prize machine in Lewis' house. You can collect prize tickets as a reward for completing quests and special orders, and from repeated egg/ice festival wins.\nA bookseller now comes to town twice a season.\nAdded mystery boxes.\nAdded a Big Tree, with a quest line which ultimately gives you some new neighbors.\nAdded four new crops (carrots, summer squash, broccoli, and powdermelon) which can't be purchased at the store, and two new giant crops.\nAdded four new home renovations: dining room, attic, expanded corner room, and cubby.\nAdded new items:\nBig Chest, which has almost double the size of a regular chest. It can also be placed \"onto\" a regular chest to upgrade it.\nDehydrator, which turns fruit into dried fruit and mushroom into dried mushrooms.\nMushroom Log, which produces mushrooms and interacts with nearby trees.\nBait Maker, which can produce fish-specific baits.\nHeavy Furnace, which can process more bars at a time, and yield bonus bars.\nFish Smoker, which produces smoked fish, doubling the value of the fish. You get one by default when starting a new riverlands farm.\nText Signs, which can be written on.\nAnvil, which allows you to re-roll trinkets.\nMini-Forge, which acts as a Dwarvish Forge.\nStatue Of Blessings, which grants a random blessing each day.\nStatue Of The Dwarf King, which allows you to select one of two mining buffs for the day.\nTent Kits, which allow you to build a tent which can be slept in for one night.\nTreasure Totems, which spawn a ring of diggable spots.\nMystic Tree Seeds, which grow a unique tree which can be tapped.\nMystic Syrup, a valuable tapper product.\nDeluxe Bait, gets fish biting faster than regular bait.", "mimetype": "text/plain", "start_char_idx": 18572, "end_char_idx": 22992, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e47220ba-d638-477f-9941-f02ec41c6320": {"__data__": {"id_": "e47220ba-d638-477f-9941-f02ec41c6320", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4eb7d804-73ff-4dbc-9008-abab68638ac8", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "a8e8034f9d9ca89e897df701bcdf123e43f74b0f2fece88b2c36f92ed8258801", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ab7ca72-264a-4759-8dea-ad741bd329df", "node_type": "1", "metadata": {}, "hash": "6b65512b04ac3b65a9d584d5af9cb4a2310b79d9c11566d9b9eb1b3fc2b505c5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Heavy Furnace, which can process more bars at a time, and yield bonus bars.\nFish Smoker, which produces smoked fish, doubling the value of the fish. You get one by default when starting a new riverlands farm.\nText Signs, which can be written on.\nAnvil, which allows you to re-roll trinkets.\nMini-Forge, which acts as a Dwarvish Forge.\nStatue Of Blessings, which grants a random blessing each day.\nStatue Of The Dwarf King, which allows you to select one of two mining buffs for the day.\nTent Kits, which allow you to build a tent which can be slept in for one night.\nTreasure Totems, which spawn a ring of diggable spots.\nMystic Tree Seeds, which grow a unique tree which can be tapped.\nMystic Syrup, a valuable tapper product.\nDeluxe Bait, gets fish biting faster than regular bait.\nChallenge Bait, which allows for up to 3 fish to be caught at once, but loses 1 each time a fish leaves the bobber bar.\nDeluxe Worm Bin, which upgrades the regular worm bin to produce deluxe bait.\n19 unique Books Of Power, which grant special perks.\nSkill Books, which grant experience in a skill.\nBook Of Stars, which grants experience in all skills.\nMoss, a new resource type which grows on old trees.\nMixed Flower Seeds.\nSonar Bobber, which shows the fish on your line before you catch it.\nRaisins, which have a special use.\nSea Jelly, River Jelly, and Cave Jelly, a new item that you can fish.\n7 Trinkets, which grant powers related to combat.\nRed, Purple, and Green Fireworks.\nStardrop Tea, which makes an excellent gift for anyone.\n25 new hats.\n280 new furnitures.\nNew unique furniture catalogues, which contain themed furniture sets.\n41 new floor styles.\n24 new wallpaper styles.\nGolden Animal Crackers.\nMannequins, which can be dressed.\nSpouse Portraits which can be purchased after reaching 14 hearts.\nButterfly Powder, which allows you to remove pets...\nBlue Grass Starter.\nMoss Soup.\nSecret items.\nAdded Goby fish.\nAdded some new remix bundles.\nYou can now place hats on cats and dogs.\nYou can now upgrade the copper pan into steel, gold, and iridium pans.\nYou can now enchant pans with Archaeologist, Generous, Fisher, and Reaching.\nAdded a \"Special Items & Powers\" tab to replace the wallet. The wallet area now tracks a selection of progress markers.\nAdded an animals tab that shows all your pets & animals.\nYou can now build pet bowls in Robin's Shop, with three variants.\nThe farmhouse and pet bowl can now be moved through Robin's menu.\nThe farm computer can now be used anywhere to see a summary of that location, instead of only the farm.\nThe mini-jukebox can now be used on the Ginger Island farm.\nAdded a new interaction with your horse.\nAdded a new side-tunnel to the Quarry Mine.\nThe Community Center fish tank now becomes an actual fish tank when you complete it.\nAdded more secrets & easter eggs.\nAdded two new cat and dog breeds.\nAdded turtle pets.\nAdded 8 new achievements.\nAdded 4 new cabin variants.\nAdded a few more accessory options in character creation.\nAdded a new bobber machine in Willy's shop, with 39 bobber styles to choose from. New styles unlock by catching new kinds of fish.\nAdded a cameo appearance to Maru's 14-heart event.\nEmily has a new rare \"socialize\" daily quest if you've completed the introduction quest.\nYou can now add anchors, treasure chests, and pearls to fish tanks.\nPierre now sells a few random items at the winter star booth (at a markup!).\nAdded a jingling sound when running with the cinderclown shoes on.\nBaby toss now has a chance to crit.\nAdded a skull cavern statue that can be used to toggle hard mode in the skull cave (after completing Qi's challenge).\nAdded additional chests to Skull Cavern levels 200 and 300.\nAdded unique skull cavern chest appearance for level 100, 200, and 300 chests.\nAdded a high note (C5) to flute block.\nAdded Meowmere from Terraria crossover\nAdded iridium golem to wilderness farm.\nSee changes for mod authors.\nVisual improvements around the valley\nAdded waterfalls.\nAdded more holiday decorations in winter.\nAdded more pathstones to various maps.\nAdded jack-o-lanterns after the Stardew Valley Fair in fall.\nAdded seasonal world map variants.\nAdded a new rare ambient critter.\nAdded some rare summer butterfly variants.\nAdded an uncommon little brown bird variant.\nRedrew the world map to better match the in-game locations and be more detailed.", "mimetype": "text/plain", "start_char_idx": 22209, "end_char_idx": 26538, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7ab7ca72-264a-4759-8dea-ad741bd329df": {"__data__": {"id_": "7ab7ca72-264a-4759-8dea-ad741bd329df", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e47220ba-d638-477f-9941-f02ec41c6320", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "881e9899561fe23b2d386b12dd1847d02ecc892a8fc309d646638e6e155c1a2c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a0c66fd-e068-4425-9120-cee9f639c13b", "node_type": "1", "metadata": {}, "hash": "097bbc2e6b067c6432e9d62d89254717c0ebf149a88e18c86afdbc4cda8c4e81", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Baby toss now has a chance to crit.\nAdded a skull cavern statue that can be used to toggle hard mode in the skull cave (after completing Qi's challenge).\nAdded additional chests to Skull Cavern levels 200 and 300.\nAdded unique skull cavern chest appearance for level 100, 200, and 300 chests.\nAdded a high note (C5) to flute block.\nAdded Meowmere from Terraria crossover\nAdded iridium golem to wilderness farm.\nSee changes for mod authors.\nVisual improvements around the valley\nAdded waterfalls.\nAdded more holiday decorations in winter.\nAdded more pathstones to various maps.\nAdded jack-o-lanterns after the Stardew Valley Fair in fall.\nAdded seasonal world map variants.\nAdded a new rare ambient critter.\nAdded some rare summer butterfly variants.\nAdded an uncommon little brown bird variant.\nRedrew the world map to better match the in-game locations and be more detailed.\nBoat journey textures are now seasonal and reflect the latest valley map.\nThe bus stop now has a wider map, though the distance to traverse it is the same. (This is to prevent black bars from appearing at the sides of the screen.)\nJelly, pickles, wines, and juices are now colored based on the ingredient item.\nMany town trees are now actual tree objects, though you can't cut them down.\nSlight adjustment to the way items pop out when dug from the ground.\nUpdated volcano gold ore node sprite.\nSome trees have a chance to lose their leaves in the fall.\nRiverbanks and lakeshores in the mountain, town, and forest areas are now less jagged in some places.\nGraphical improvements to building interiors.\nImproved the art of George & Evelyn's roof.\nIf you destroy a mines chest, it now shows some graphics debris.\nAdded special backplates to fortune teller TV show if you get a perfectly good or perfectly bad luck day.\nLighting changes:\nIt now gets dark an hour earlier in winter.\nNight tiles (e.g. town lamps) now activate an hour earlier in all seasons.\nIndoor daytime lighting now smoothly transitions to night lighting over the course of two hours.\nNight lighting in non-farmhouse indoor locations is now slightly darker.\nFarmhouse lighting on rainy days is now slightly moody, and lights stay on all day.\nTVs and trees of the Winter Star now give off light at night.\nAdded light sources to window light glows so there are no more \"dark but lit\" windows.\nMade some improvements to the intro bus drive cutscene.\nAt night, hats are now drawn at the night-time color in the game menu portraits.\nRemoved lighting quality option. It's now permanently set to ultra quality.\nThe submerged fishing bobber is now recolored automatically to match the water.\nMultiplayer changes\nYou can now have up to 8 players on PC.\nMany improvements for multiplayer performance and stability. That includes:\nSteam players will now use Steam multiplayer authentication, potentially improving connection issues significantly.\nLarge multiplayer packets are now compressed, reducing bandwidth usage and latency.\nInternal optimizations to data syncing.\nYou now need the same build number (in addition to version) to join a multiplayer server. This prevents crashes due to game changes between builds.\nAccepting a Qi challenge that increases mine difficulty now only kicks other players out of the affected mine type, not all mines.\nPurple shorts no longer show a chat message when placed into the Luau soup.\nJump down mineshaft sound now plays for all players in the level rather than just the jumper.\nBalance changes\nAdded a box with three tent kits to the Ginger Island jungle.\nWeapons found in the wild now have a chance to come with a basic \"innate enchantment\". You can re-roll \"innate enchantments\" (if the weapon could have one) at the forge using a dragon tooth.\nSlime hutches are now significantly smaller (11x6 \u2192 7x4).\nFarm animals now gain a little happiness if you close the animal door behind them at night.\nGrass now survives in the winter, though it won't spread. However, cutting grass during winter is much less effective.\nThe mushroom cave now comes with a free Dehydrator.\nChanged recipe skill requirements for:\ncharcoal kiln (foraging 4\u21922);\ncookout kit (foraging 9\u21923);\nsurvival burger (foraging level 2\u21928);\ntapper (foraging 3\u21924);\nand worm bin (fishing level 8\u21924).\nPrice changes:\nMost home renovations now cost money, which is refunded if you undo the renovation. (The game knows whether you bought it though, so refunding a pre-1.6 renovation won't give you free money.)\nReduced fairy dust sell price (500g \u2192 300g).\nReduced tea sapling sell price (500g \u2192 250g).", "mimetype": "text/plain", "start_char_idx": 25663, "end_char_idx": 30193, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3a0c66fd-e068-4425-9120-cee9f639c13b": {"__data__": {"id_": "3a0c66fd-e068-4425-9120-cee9f639c13b", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ab7ca72-264a-4759-8dea-ad741bd329df", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "a2e88a98203285ca53cf34892f9df7c455893ff541fd0137a2e77acf326e33f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1573b95-2444-47ed-9ba6-36cd7df91364", "node_type": "1", "metadata": {}, "hash": "c393ece5e7fc40f96677b7c238ea77f1e15d985224bc299ef18084b493333271", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Farm animals now gain a little happiness if you close the animal door behind them at night.\nGrass now survives in the winter, though it won't spread. However, cutting grass during winter is much less effective.\nThe mushroom cave now comes with a free Dehydrator.\nChanged recipe skill requirements for:\ncharcoal kiln (foraging 4\u21922);\ncookout kit (foraging 9\u21923);\nsurvival burger (foraging level 2\u21928);\ntapper (foraging 3\u21924);\nand worm bin (fishing level 8\u21924).\nPrice changes:\nMost home renovations now cost money, which is refunded if you undo the renovation. (The game knows whether you bought it though, so refunding a pre-1.6 renovation won't give you free money.)\nReduced fairy dust sell price (500g \u2192 300g).\nReduced tea sapling sell price (500g \u2192 250g).\nReduced life elixir sell price (500g \u2192 250g).\nBuilding cabins no longer requires materials, only the 100g price.\nRaised price of second house upgrade (50,000g \u2192 65,000g), but reduced number of hardwood needed (150 \u2192 100).\nReduced worm bin's hardwood needed (25 \u2192 15).\nIncreased cost of warp totem: farm in casino (500 \u2192 1000)\nRaised price of bombs in dwarf shop.\nRaised some hat prices from Hat Mouse.\nShop changes:\nPut limits on some casino stock.\nYou can now buy all brazier recipes in Robin's shop at once instead of in sequence.\nItem drop changes:\nChopping down a fruit tree now yields the appropriate fruit sapling. If the tree is mature (i.e. the fruit quality is > basic), it will yield a sapling with the same quality as its fruit. The higher the quality, the faster the sapling will mature.\nChopping down a tea bush now gives back a tea sapling.\nThere's now a small chance to find cosmetic items and other goodies while doing random tasks.\nSnake vertebrae are now easier to get.\nTrain cars which carry wood can now drop hardwood.\nSanta's train car can now drop gifts.\nReduced prismatic shard drop rate from iridium nodes (4% \u2192 3.5%).\nRare yellow slimes now drop money.\nBrown slimes now drop wood (doesn't affect the copper slimes in the quarry mine).\nBotanist perk now applies to items dropped from trees (e.g. coconuts).\nReduced chance of fishing void mayonnaise at the witch swamp.\nGift taste changes:\nAdjusted gift tastes for several NPCs.\nTreasure chests are now a universally liked gift... except by Linus.\nSkill XP changes:\nMushroom Logs and Mushroom Boxes now grant 5 foraging XP on harvest.\nHarvesting berry bushes now grants 1 foraging XP per berry.\nHarvesting forage crops from wild seeds now give much less foraging experience, but grant some farming experience.\nMonsters on the farm now give combat experience, but it's 1/3 of normal value. This excludes slime hutch slimes.\nAdjusted combat:\nExtended the area of effect of downward facing melee attacks (and slightly extended the side attack of daggers).\nTopaz ring now gives +1 defense, rather than the unused precision stat.\nRaised insect head's damage (10-20 \u2192 20-30).\nRaised kudgel's critical attack power (+4 \u2192 +50).\nBombs now affect terrain features (like trees and crops) within the round explosion radius rather than a square area.\nSlightly increased rate at which skeletons throw bones or shoot spells.\nAdjusted Junimo Kart:\nAdded grace jumps in Junimo Kart: when you run off the track, you can still jump for a short time to recover.\nYour score is now saved if the minigame forcibly exits while playing endless mode.\nNoxious gas emitting mushrooms no longer appear in pairs.\nReduced bubble spawn rate on whale level.\nAdjusted machines:\nWorm bins now need a lower fishing level (level 8\u21924) and produce more bait (2\u20135 \u2192 4\u20135).\nLoom now has a higher chance of double cloth when processing quality wool.\nFish ponds now have a chance to produce extra roe whenever they produce roe.\nGeode Crushers no longer require coal to operate.\nAdjusted penalties when knocked unconscious:\nYou can no longer lose the Golden Scythe, Infinity weapons, or tools.\nYou can no longer lose more than three items.\nThe amount of money lost now scales to how much you have. It's now less punishing if you don't have much money, but more punishing if you have a lot. This also raises the maximum lost from 5000g to 15000g.\nAdjusted food buffs:\nJoja cola now gives a very short speed buff.", "mimetype": "text/plain", "start_char_idx": 29441, "end_char_idx": 33633, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a1573b95-2444-47ed-9ba6-36cd7df91364": {"__data__": {"id_": "a1573b95-2444-47ed-9ba6-36cd7df91364", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a0c66fd-e068-4425-9120-cee9f639c13b", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2ae1505205529d9e9438c4e1e0e59098e79b1394a54608b0a9fec3b90f7c403b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "418ac076-a0e4-4576-89ad-4dab8cb72ae4", "node_type": "1", "metadata": {}, "hash": "aa7dc6506a3d94aa5cf067c31f3bd40a71123b74d8732fac47f73c71766df425", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Noxious gas emitting mushrooms no longer appear in pairs.\nReduced bubble spawn rate on whale level.\nAdjusted machines:\nWorm bins now need a lower fishing level (level 8\u21924) and produce more bait (2\u20135 \u2192 4\u20135).\nLoom now has a higher chance of double cloth when processing quality wool.\nFish ponds now have a chance to produce extra roe whenever they produce roe.\nGeode Crushers no longer require coal to operate.\nAdjusted penalties when knocked unconscious:\nYou can no longer lose the Golden Scythe, Infinity weapons, or tools.\nYou can no longer lose more than three items.\nThe amount of money lost now scales to how much you have. It's now less punishing if you don't have much money, but more punishing if you have a lot. This also raises the maximum lost from 5000g to 15000g.\nAdjusted food buffs:\nJoja cola now gives a very short speed buff.\nGreen tea now gives +0.5 speed.\nMine and dungeon changes:\nAdded coal nodes to the volcano dungeon.\nBarrels now spawn on skull cavern levels divisible by 5.\nReduced the maximum possible effect a bad luck day can have on finding a prismatic slime.\nReduced number of bugs to kill for monster slayer goal from 125 to 80.\nBundle changes:\nMade remixed specialty fish bundle (and analogues) reward 5 Dish O' The Sea, to make it consistent with the classic bundle.\nRiver fish bundle now gives deluxe bait.\nImproved some community center rewards.\nAdjusted crafting recipes:\nspeed gro now requires 5 Moss instead of 1 Clam .\ndeluxe speed-gro now requires 5 bone fragments instead of 1 coral.\nquality fertilizer now requires 4 sap instead of 2, but produces 2 per craft (still only requires 1 fish).\nSpouse changes:\nSpouses now have a seven-day \"honeymoon\" period after marriage which prevents them from laying in bed all day due to being upset.\nKissing your spouse, and giving them a gift on the previous day, each reduce the \"minimum heart level threshold\" for a bed-ridden day by one heart (12\u219210 if you do both).\nFriendship gain is reduced by 33% for spouses.\nRebalanced the crop fairy event: the chance no longer depends on the number of planted crops, it can no longer happen on the last day of the season (to avoid growing crops that might die overnight), and it can no longer choose dead crops to grow.\nIncreased the shaving enchantment's effect on giant crops.\nEach giant crop now has a 60% chance of dropping an extra six crops while the shaving enchantment is equipped, spread across the number of hits needed to break it. For example, a base axe which breaks the giant crop in three hits gets three 20% chances of dropping 2 crops.\nThe mushroom cave now provides mushrooms every second day. It was unintentionally changed to daily in Stardew Valley 1.5.\nYou can no longer plant trees in the beach farm tunnel.\nRandomization no longer produces simple repeating patterns in many cases (e.g. clay farming, mushroom level prediction, crab pot fish offset, etc).\n(You can enable \"Use Legacy Randomization\" in the advanced save options to use the old randomization, though some specific patterns may still change due to the underlying changes. That option is mainly intended for speedrunners; most players should keep it disabled for the intended experience.)\nSpreading weeds can no longer destroy artifact spots.\nIncreased the number of monsters that daily monster quests will ask you to slay (in some cases). Added more custom quantities, for example Dust Spirits will ask for 10-20 kills.\nTilled dirt on the island farm now decays in the same way as the regular farm.\nSlightly increased time you have to push against farm animals before passing through them.\nSlightly boosted quarry output. Daily quarry output now increases each year, up to a limit.\nYou can no longer plant trees in town.\nSecret notes are no longer created during festivals (except passive festivals like the night market and desert festival).\nAdjusted fish variety in ice fishing festival.\nQuality of life changes\nPerformance improvements.\nNPCs now shove chests out of their way instead of destroying them.\nIf Pam won't be coming to the bus for any reason, she now leaves a sign informing you and you can drive yourself to the desert.\nAudio changes:\nMade more sounds positional (mainly players, tools, and machines).\nPositional sounds now fade with distance when off-screen, instead of cutting off abruptly.\nSoftened the bomb fuse sound.\nThe music now \"ducks out\" and then resumes when certain sounds are played, instead of stopping.\nYou can now \"strafe\" while charging a watering can or hoe, allowing you to reposition your tool hit area without changing your facing direction.", "mimetype": "text/plain", "start_char_idx": 32792, "end_char_idx": 37379, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "418ac076-a0e4-4576-89ad-4dab8cb72ae4": {"__data__": {"id_": "418ac076-a0e4-4576-89ad-4dab8cb72ae4", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1573b95-2444-47ed-9ba6-36cd7df91364", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "b647ff7e0b272751a6ef26b47d39eed05dd3d82a8238ad5a34f80b1514143427", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d3d7d13-9c4a-4135-9333-3a90684e7cbf", "node_type": "1", "metadata": {}, "hash": "7deff37e71358eaa1903e213467370191f4c1d6199ed48ef18a76ad321d90e1d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Slightly boosted quarry output. Daily quarry output now increases each year, up to a limit.\nYou can no longer plant trees in town.\nSecret notes are no longer created during festivals (except passive festivals like the night market and desert festival).\nAdjusted fish variety in ice fishing festival.\nQuality of life changes\nPerformance improvements.\nNPCs now shove chests out of their way instead of destroying them.\nIf Pam won't be coming to the bus for any reason, she now leaves a sign informing you and you can drive yourself to the desert.\nAudio changes:\nMade more sounds positional (mainly players, tools, and machines).\nPositional sounds now fade with distance when off-screen, instead of cutting off abruptly.\nSoftened the bomb fuse sound.\nThe music now \"ducks out\" and then resumes when certain sounds are played, instead of stopping.\nYou can now \"strafe\" while charging a watering can or hoe, allowing you to reposition your tool hit area without changing your facing direction.\nYou can now refill slingshot ammo by right-clicking it with the same ammo. Previously that would just swap the item stacks.\nPlanting cactus seeds on the farm now fails with a message, instead of the seeds dying overnight.\nHolding a tea sapling or seed over a garden pot now shows the green/red placement tile.\nYou can no longer pick up rugs if there's something on it.\nChecking a pet bowl will now show a text bubble with the pet's name.\nAdded a new post-fishing sparkling text to indicate when you've caught something for the first time.\nTorches can now be placed on sprinklers.\nYou can now sit in chairs during festivals.\nYou can now move filled chests by hitting them twice with a heavy tool (previously only with bare hands). The chests will shift one space at a time.\nYou can now place flooring underneath most buildings.\nCrystalariums now have to be removed and replaced before a different gem can be put inside, to help avoid wasting gems accidentally.\nDaily billboard quests now have a more informative tracker notification when you make progress on them.\nAdded a small checkmark icon on special orders you've completed before (only on town special orders board).\nYou can now skip the pet adoption scene, which causes you to adopt the pet.\nReduced the amount of time you need to push against a pet before they start shaking and then let you pass through them (1.5 \u2192 .75 seconds).\nReduced time for mini-obelisk warp (750ms faster).\nMale farmers are no longer forced into wedding clothes on their wedding day, so you can choose your own outfit for the wedding.\nEmptying a fish pond with fish still in it will cause the remaining fish to flop out of the pond.\nSlime hutch changes:\nYou can now change the flooring of the slime hutch.\nYou can now remove the starter incubator in the slime hutch.\nSlime balls no longer appear on crafted flooring.\nUI improvements:\nAdded an hourglass cursor shown when you're waiting for something to load on the title screen.\nNotification messages in the bottom-left corner now last 50% longer before going away.\n\"Sound in the night\" events now show an icon on the screen to indicate that a sound is playing.\nDialogue question selectors no longer remain selected when you hover away from them, to reduce accidental selections.\nRobin's building menu now shows how many days a building will take.\nIf an item menu exits while you're holding an item, the item is now always retrieved. (Previously only some item menus like chests would do it.)\nMarnie's animal shop now centers the camera on an appropriate building when purchasing an animal.\nMarnie's animal shop now shows prices in the tooltip, in case the tooltip covers the price display.\nThe achievement menu now lists all potential achievements. Hidden achievements you haven't unlocked yet are shown as \"???\".\nThe museum reward menu now prevents picking up a reward that won't fit in your inventory.\nThe museum reward menu now lets you exit while holding a reward. It'll be added to your inventory if possible, otherwise it'll drop at your feet.\nThe save creation farm selector now has two columns instead of one, and no longer overlaps the back button on small screens.\nThe shipping menu category pages no longer take up the whole screen, as long as the screen is beyond a minimum size.\nInventory tooltips for food that gives a buff now shows the buff duration in the tooltip.\nThe map now closes when you press the map button again.\nExiting the Junimo Note menu from within the game menu now returns to where you were in the game menu rather than exit the menu.\nShops now truncate item names which would overflow the menu width.\nShops now have a slight delay before you can buy/sell items, to help avoid double-clicks doing it accidentally.\nDeleting a save on PC is now much faster.", "mimetype": "text/plain", "start_char_idx": 36391, "end_char_idx": 41150, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4d3d7d13-9c4a-4135-9333-3a90684e7cbf": {"__data__": {"id_": "4d3d7d13-9c4a-4135-9333-3a90684e7cbf", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "418ac076-a0e4-4576-89ad-4dab8cb72ae4", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "8256dff19874be812d9e71abc366dfad809905d417abb592b49577a0d2fedb0c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be192bb3-314e-4ba3-9e07-4ba3e8efa663", "node_type": "1", "metadata": {}, "hash": "2c70f58b6cbd3f84aeb07db166481d3b08935e2da7107105275983e78d040a9b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The museum reward menu now lets you exit while holding a reward. It'll be added to your inventory if possible, otherwise it'll drop at your feet.\nThe save creation farm selector now has two columns instead of one, and no longer overlaps the back button on small screens.\nThe shipping menu category pages no longer take up the whole screen, as long as the screen is beyond a minimum size.\nInventory tooltips for food that gives a buff now shows the buff duration in the tooltip.\nThe map now closes when you press the map button again.\nExiting the Junimo Note menu from within the game menu now returns to where you were in the game menu rather than exit the menu.\nShops now truncate item names which would overflow the menu width.\nShops now have a slight delay before you can buy/sell items, to help avoid double-clicks doing it accidentally.\nDeleting a save on PC is now much faster.\nSignificantly reduced save loading time when there are many custom locations.\nIf a default farm building (like the greenhouse) is somehow removed, it'll now be rebuilt next time you load the save.\n\"Menu background\" is now a drop down option, which includes \"Standard\", \"Graphical\", or \"None\".\nAttempting to put something in a machine but failing will no longer cause you to try and consume or activate the object you're holding.\nKent intro event and Robin flute block event are now skippable.\n(PC) You can now shift + right-click an item on the toolbar to throw it out of your inventory (if possible).\n(PC) You can now press the Y or N key to confirm or cancel the \"leave festival\" confirmation box.\n(PC) Holding left-shift + left-ctrl + 1 when buying from a shop will attempt to buy a stack of 999.\nOther changes\nAdventure guild now stays open until 2am, though the music will not play after midnight.\nGender-specific clothing variants can now be worn by any gender.\nIf you have 12 hearts or more with your spouse, the chance they'll say a neutral dialogue in the afternoon (which sometimes comes across as negative) is significantly lower (25% \u2192 5% chance).\nPenny's forest picnic event and Leah's forest picnic event now only happen if it's sunny.\nNPCs now try to avoid walking through trees and other terrain features.\nCabins have been combined into one entry in Robin's menu.\nReplaced pet icons on the inventory tab with the current date.\nThe \u201cOrganize\u201d button now sorts items in a more intelligent way.\nYou can now drink mayonnaise and jelly, and eat pickles.\nSome colored objects now count as their color for qi quest and dye menu.\nClam is now considered a \"fish\" just like all the other shellfish.\nAdded more descriptive titles to daily quests.\nAdded Cyrillic sprite text and some translated world pixel art text.\nAdjusted the date/time/money box in Chinese.\nThe about page now shows the build number.\nThe Skull Cavern now have a chance to also play music from the upper mines.\nChanged parrot flap sound to be different from bat flaps.\nPans now have a chance to yield bone fragments.\nMade the character randomization a little less random, and added some of the newer hairstyles and accessories to the mix.\nPan no longer yields the same thing if you pan in the same spot twice in a day.\nThe about page no longer hides the version if a tip message is shown.\nThe order that you'll get forge enchantments is now unique per player rather than per farm.\nThe Ginger Island shrine item pedestals are now normal items. Modded players can spawn them to display items decoratively (though they're not obtainable in vanilla currently).\nMap no longer closes if you click on an area of interest.\nFixed some NPC schedules that weren't previously applied:\nLewis visiting the library on winter Sundays;\nMaru and Penny hanging out on summer Sundays;\nMaru tinkering on summer Mondays;\nAfter reaching six hearts with some NPCs, they won't visit their rival love interest anymore. This affects Alex visiting Haley, Elliott visiting Leah, and Haley visiting Alex.\nGameplay fixes\nFishing fixes:\nIf you're fishing when the pirate cave changes to pirate mode, you will catch your fish.\nFixed artifacts found in fishing chests not counting for the collection tab.\nFixed fishing crash if a treasure chest appears while the player has a large number of stacked fishing buffs.\nBuff fixes:\nFixed a range of bugs like attribute drift and double-debuff.\nFixed food/drink buffs discarded if they have a balanced total of effects (e.g. +2 attack and -2 speed).\nFixed negative custom buffs shown with a double-negative (e.g. \"--2 speed\").\nFixed Squid Ink Ravioli buff not remaining active if another food buff is added later (although the buff icon was still shown).", "mimetype": "text/plain", "start_char_idx": 40267, "end_char_idx": 44889, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "be192bb3-314e-4ba3-9e07-4ba3e8efa663": {"__data__": {"id_": "be192bb3-314e-4ba3-9e07-4ba3e8efa663", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d3d7d13-9c4a-4135-9333-3a90684e7cbf", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "d01ef1143d0b6407c493658a58608b78335ca1a6c8f155d9e3c64d9b53c17a7f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c9bb97e6-cfdb-4bf1-b39d-e3ff0e0703d8", "node_type": "1", "metadata": {}, "hash": "9c364b8fc2f07405b62070034795063fb83791b5ced522953f41bb057b81625c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This affects Alex visiting Haley, Elliott visiting Leah, and Haley visiting Alex.\nGameplay fixes\nFishing fixes:\nIf you're fishing when the pirate cave changes to pirate mode, you will catch your fish.\nFixed artifacts found in fishing chests not counting for the collection tab.\nFixed fishing crash if a treasure chest appears while the player has a large number of stacked fishing buffs.\nBuff fixes:\nFixed a range of bugs like attribute drift and double-debuff.\nFixed food/drink buffs discarded if they have a balanced total of effects (e.g. +2 attack and -2 speed).\nFixed negative custom buffs shown with a double-negative (e.g. \"--2 speed\").\nFixed Squid Ink Ravioli buff not remaining active if another food buff is added later (although the buff icon was still shown).\nFixed Squid Ink Ravioli not resetting the buff duration when you eat another one, unlike other food buffs.\nFixed Squid Ink Ravioli description having an extra blank line.\nFixed Burnt not showing the -3 Attack effect.\nFestival fixes:\nFixed unable to leave the Festival of Ice until it ends.\nFixed two-second pause when entering the Stardew Valley Fair.\nItem fixes:\nFixed dropped tools not recovered if they're inside a constructed building.\nFixed potted tea bushes planted in town not being harvestable.\nFixed bee house dropping a generic \"Honey\" item when you break it, instead of the flavored honey it would produce when harvested normally.\nFixed farm computer counting fiber crops as unwatered.\nFixed geode and lost book message not shown if your first one is from a fishing chest.\nFixed magic bait disabling some fish area checks (e.g. so you could catch river fish in the forest pond).\nFixed heavy tappers not tracked correctly. That caused issues like heavy-tapped trees not ignored when creating mushroom trees in fall.\nFixed rain totem used during a storm incorrectly making the next day stormy instead of rainy.\nFixed secret note #2 not revealing Kent's gift taste if he hasn't returned yet.\nFixed wedding rings being giftable to NPCs.\nFixed watering can's water left and capacity resetting on right-click into chest.\nFixed wilted bouquet not cancelling the wedding if it hasn't happened yet.\nFixed various cases where item-received logic wasn't applied consistently.\nCombat fixes:\nYou can now kill any slime for the \"Initiation\" quest, not just green slimes.\nFixed player stuck in swimsuit if they collapse from damage while wearing it.\nFixed broken event if the player is defeated in the mines and their name contains a slash.\nFixed issue where you could clear a forest-themed mine level without finding a ladder.\nFixed Magma Sparker's debuff ignoring squid ink ravioli's protection.\nController fixes:\nPressing the trigger buttons on a gamepad while in the junimo bundle menu now snaps the cursor to the ingredients slot or back.\nImproved controller navigation on the Junimo bundle page and world map.\nFixed issue which could cause Junimo Kart to be unplayable with a controller, if you had rebound keys to certain values.\nFixed issue where viewing a letter with multiple pages and positioning the cursor directly above the skip button could cause the next viewed event to be skipped when the A button is pressed to progress text.\nUI fixes:\nFixed issue where clicking an item attached to a letter could exit the letter if your inventory was full.\nFixed items from dialogue being lost if your inventory was full. You'll now see a menu to collect them when the dialogue closes.\nFixed gates popping off when opening or closing them while the player overlaps the tile.\nFixed random seeds on Ginger Island being based on the valley's season.\nFixed exploit where you could keep temporary items like Qi Fruit by selling them to Pierre and buying them back later.\nFixed fruit trees being plantable on stone tiles outside the greenhouse.\nFixed tree stumps dropping seeds like full-grown trees.\nFixed riding an orphaned horse (e.g. spawned using debug commands) preventing you from owning or riding other horses.\nFixed some mail not received on the intended day if you don't leave the farmhouse that day.\nFixed bug where it was faster to harvest left-to-right than right-to-left.\nFixed some spots where forage could appear out-of-bounds.\nFixed spot where you could run into the water on the beach farm.\nFixed minecarts unlocked before you've seen the cutscene.\nFixed able to place things underneath the traveling merchant cart and pig.\nFixed some undiggable tiles in Ginger Island dig site.\nFixed geode crusher \"off-by-one\" bug/exploit.\nFixed speed of Taro growth when grown with agriculturist and hyper speed gro (and generally fixed issues with negative phase durations).\nFixed invisible menu preventing you from moving after closing out of the bulletin board Junimo note, if you were holding a useable object.\nNPC fixes\nDialogue fixes:\nFixed NPCs not having custom dialogue when accepting a movie invite for non-English players.", "mimetype": "text/plain", "start_char_idx": 44118, "end_char_idx": 49021, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c9bb97e6-cfdb-4bf1-b39d-e3ff0e0703d8": {"__data__": {"id_": "c9bb97e6-cfdb-4bf1-b39d-e3ff0e0703d8", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be192bb3-314e-4ba3-9e07-4ba3e8efa663", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "a43acf3754033f16921b226d0c797a13c8ac12981c54a144281df498101a3290", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "576291a0-c9bd-4c15-aa52-11f5a859c672", "node_type": "1", "metadata": {}, "hash": "6f4a6a8996a8cc06511f46f71e308cc4bc33753f70db307890cc2aade4628d11", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed some mail not received on the intended day if you don't leave the farmhouse that day.\nFixed bug where it was faster to harvest left-to-right than right-to-left.\nFixed some spots where forage could appear out-of-bounds.\nFixed spot where you could run into the water on the beach farm.\nFixed minecarts unlocked before you've seen the cutscene.\nFixed able to place things underneath the traveling merchant cart and pig.\nFixed some undiggable tiles in Ginger Island dig site.\nFixed geode crusher \"off-by-one\" bug/exploit.\nFixed speed of Taro growth when grown with agriculturist and hyper speed gro (and generally fixed issues with negative phase durations).\nFixed invisible menu preventing you from moving after closing out of the bulletin board Junimo note, if you were holding a useable object.\nNPC fixes\nDialogue fixes:\nFixed NPCs not having custom dialogue when accepting a movie invite for non-English players.\nFixed Abigail showing both default and custom item delivery dialogue.\nFixed Lewis skipping his final dialogue at the Festival of Ice on subsequent player wins.\nFixed the fortune teller nearly always showing the text for your combat skill, instead of your highest skill.\nFixed issue where an NPC who bought an iridium-quality item you sold to a shop could show a low-item-quality dialogue for it.\nFixed issue where NPC dialogue could reveal gift tastes for an invalid item.\nFixed monster grave text only shown in English.\nFixed wrong message shown when placing indoors-only furniture outside.\nFixed the Krobus vs Dwarf event able to happen on Fridays.\nFixed giving a gift not counting toward socialization quests.\nFixed invisible spouses asking to have children.\nFixed able to invite Leo to the movies before he moves to the valley.\nFixed able to interact with NPCs during the ice fishing event.\nFixed NPC spouse chores sometimes not applied on the intended day (e.g. saying they filled the pet water bowl but it's not filled).\nFixed NPC spouses watering crops that don't need it (e.g. fiber seeds or already watered), and almost never showing the crops-were-already-watered dialogue.\nFixed NPCs sometimes not reacting to dumpster diving if the horse is nearby.\nFixed Penny losing items when redecorating if they were placed on a stone slab (or a custom table without Table in the name).\nMultiplayer fixes\nMitigated potential remote code execution issue.\nPossibly fixed frequent disconnections for some players.\nFixed old/incorrect Steam display names being shown in some cases.\nFixed phantom action cursor over backwoods gravestone if the current player hasn't seen the related event yet.\nFixed copy & paste for invite codes on some Linux/macOS platforms.\nFixed issue where the mines were checking for the luck level of players in the host's current location, rather than players in the mines.\nFixed global chat info messages (like \"Abigail caught PlayerName digging through the trash\") sometimes showing text in the sender's language instead of yours.\nFixed egg festival requiring 12 eggs to win if there are 5+ players. It now applies the four-player requirement to any player count beyond that.\nFixed farmhands sometimes able to walk out of bounds at festivals.\nFixed farmhands who disconnected while fishing sometimes stuck frozen on reconnect.\nFixed farmhands who disconnected while playing a minigame (like Journey of the Prairie King) still hearing the music on the title screen.\nFixed farmhands who disconnected while in the building placement view being invisible on rejoin.\nFixed farmhands seeing spouse's outdoor area in the wrong spot on the beach farm.\nFixed farmhands experiencing latency able to click a horse, walk to a different location, then get teleported out of bounds.\nFixed farmhands able to collect multiple statues of perfection.\nFixed farmhands unable to enter a movie without all players.\nFixed farmhands' local effects sometimes based on host data (e.g. the host's equipped rings).\nFixed farmhands' prismatic shards sometimes spawning at the host's location instead.\nFixed farmhands' rings leaving lights behind when they disconnect.\nFixed farmhand crash while fishing in rare cases.\nFixed farmhand crash when they warp just as certain things happen (e.g. pet sounds).\nFixed farmhand crash if train approaches while they're mid-warp.\nFixed other players seeing a farmhand's old spouse room if they divorced and remarried in the same session.\nFixed dinos being able to hurt the host when they aren't in the same location.\nFixed monster drops for farmhands sometimes applying the host's ring effects and secret note.\nFixed various visual glitches with other players' tool/fishing animations.\nFixed crash when displaying a player status list which is missing a connected player.\nFixed dialogue being interrupted if another player starts a broadcast event; the event will now start for you when you finish the current dialogue instead.\nFixed enemy projectiles targeted at farmhands able to hit the host player in a different location.\nFixed monsters not taking damage from some hits if multiple players are attacking them at once.", "mimetype": "text/plain", "start_char_idx": 48103, "end_char_idx": 53176, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "576291a0-c9bd-4c15-aa52-11f5a859c672": {"__data__": {"id_": "576291a0-c9bd-4c15-aa52-11f5a859c672", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c9bb97e6-cfdb-4bf1-b39d-e3ff0e0703d8", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "184c42e9325eebd60ad9ed558a017252cedd91738cb2fca436ca3f4fefc8ebb2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c6ebb2a-7ac1-4af9-ad0a-a670227b21d4", "node_type": "1", "metadata": {}, "hash": "7f7de8b8fd7640dda9cc6df068c024926a9240209c923204f2671944753c54c5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed farmhand crash while fishing in rare cases.\nFixed farmhand crash when they warp just as certain things happen (e.g. pet sounds).\nFixed farmhand crash if train approaches while they're mid-warp.\nFixed other players seeing a farmhand's old spouse room if they divorced and remarried in the same session.\nFixed dinos being able to hurt the host when they aren't in the same location.\nFixed monster drops for farmhands sometimes applying the host's ring effects and secret note.\nFixed various visual glitches with other players' tool/fishing animations.\nFixed crash when displaying a player status list which is missing a connected player.\nFixed dialogue being interrupted if another player starts a broadcast event; the event will now start for you when you finish the current dialogue instead.\nFixed enemy projectiles targeted at farmhands able to hit the host player in a different location.\nFixed monsters not taking damage from some hits if multiple players are attacking them at once.\nFixed projectiles causing damage multiple times in multiplayer.\nFixed various cases where values weren't correctly synced between players.\nFixed watered dirt edges not updated for farmhands when they change overnight.\nFixed 'caught snooping' chat message not triggered when Marnie sees the player searching her trash bin.\nFixed cleared-landslide mail only sent to the main player.\nFixed watering can's water left and capacity not synced in multiplayer.\nFixed the local player's step/fishing stats being incremented by other players walking or fishing.\nFixed players sometimes seeing slightly different daily quests or crop fairy event.\nFixed issue where a farmhand donating the 60th museum artifact wouldn't grant the rusty key.\nFixed issue where reading another player's secret notes or journal scraps could lock them out of perfection.\nFixed issue where the host pausing the game while it's raining and a farmhand is moving would cause the frozen rain to slide across the screen.\nFixed exploit where a farmhand would have full energy after passing out if they disconnected while sleeping earlier in the day.\nDisplay text and localization fixes\nSpanish prices are now formatted like 15o instead of 15g to match the translated term (oro instead of gold).\nFixed unlocalized text shown for...\nthe building paint menu's region names (like \"Roof\" or \"Trim\");\nNPC names in some movie theater dialogue;\nNPC names in the spouse pregnancy question;\nProfessor Snail's name after his first event;\nLeo's name in his introductory event for some languages;\nfish names for some languages in certain cases;\nthe 'Miss' text when an attack misses.\nFixed Lewis' letter for Feast of the Winter Star saying it starts at 10am instead of 9am.\nFixed dust sprites called dust spirits in Clint's special order and the summit cutscene.\nFixed various typos, broken tokens, translations that don't match the original, etc.\nFixed NPC name translations applied to horses/pets that share a name with that NPC.\nFixed random name generator able to produce words similar to certain slurs.\nFixed world map tooltip for Pierre's shop still showing \"closed on Wednesdays\" after he extends his business hours.\nFixed some recipe names not matching the items they produce.\nFixed the hats added in 1.5 translating their internal name instead of setting the display name in some languages.\nFixed museum item descriptions not having an intended newline.\nFixed French formatting times past midnight like \"26h\" instead of \"02h\" (e.g. on the fishing TV channel).\nFixed French and Turkish showing broken dialogues about another NPC's gift tastes.\nFixed French-only display text bugs related to the ^ dialogue token.\nFixed German truncating Professor Snail's name in his intro event.\nFixed Japanese and Korean formatting buff effects inconsistently.\nFixed some broken Japanese movie reaction dialogue.\nFixed Korean credit line missing in other languages.\nFixed Russian event for Professor Snail's intro freezing.\nCosmetic fixes\nUI fixes:\nThe perfection tracker now paginates better to fit the current screen size.\nMoved \"?\" icon on dialogue question boxes.\nRemoved phantom action cursor over island farmhouse drawer.\nFixed toolbar drawn behind the time/money box.\nFixed cursor over NPCs sometimes showing a gift icon when they won't accept or react to the held item.\nFixed some in-game error messages not having an error icon.\nFixed inventory & crafting menus misaligned if you resize the window while they're open.\nFixed flashing tooltips when hovering between elements in the cooking page and collections tab.\nFixed cosmetic issues with the title & shipping screens for higher-resolution displays.\nFixed calendar tooltip when a modded festival and birthday occur on the same day.\nFixed calendar drawing child NPCs lower than intended.\nFixed the ! fish bite icon not shown when fishing in the Stardew Valley Fair and Festival of Ice.\nFixed quality fertilizer showing a green tile on sprouted crops, even though it can't be placed there.\nFixed perfection tracker not skipping the typing effect when it's paginated.\nFixed the forge preview always showing soul level one for a galaxy soul forge.", "mimetype": "text/plain", "start_char_idx": 52184, "end_char_idx": 57321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c6ebb2a-7ac1-4af9-ad0a-a670227b21d4": {"__data__": {"id_": "7c6ebb2a-7ac1-4af9-ad0a-a670227b21d4", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "576291a0-c9bd-4c15-aa52-11f5a859c672", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "a0d65607ffe10c04b4c250338dc2221c3754c07d77ad69d675d7aa6a12dd4a47", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "82d68d5c-81f3-451e-add8-f6b1880722e1", "node_type": "1", "metadata": {}, "hash": "057b13b420a52780ce22f7ddc111b7909bf64dc02b6b1a3c76d58871fd8f04e1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Removed phantom action cursor over island farmhouse drawer.\nFixed toolbar drawn behind the time/money box.\nFixed cursor over NPCs sometimes showing a gift icon when they won't accept or react to the held item.\nFixed some in-game error messages not having an error icon.\nFixed inventory & crafting menus misaligned if you resize the window while they're open.\nFixed flashing tooltips when hovering between elements in the cooking page and collections tab.\nFixed cosmetic issues with the title & shipping screens for higher-resolution displays.\nFixed calendar tooltip when a modded festival and birthday occur on the same day.\nFixed calendar drawing child NPCs lower than intended.\nFixed the ! fish bite icon not shown when fishing in the Stardew Valley Fair and Festival of Ice.\nFixed quality fertilizer showing a green tile on sprouted crops, even though it can't be placed there.\nFixed perfection tracker not skipping the typing effect when it's paginated.\nFixed the forge preview always showing soul level one for a galaxy soul forge.\nFixed advanced save option tooltips being able to extend off-screen, and not shown for some field labels.\nFixed clothing/tools sometimes showing the item-received notification on unequip.\nFixed HUD messages sometimes overlapping.\nFixed fonts sometimes having a 'thin' look.\nFixed world map tooltip for JojaMart disappearing when the movie theater is built.\nFixed stack numbers not drawn for machine output when the stack is > 1.\nFixed animal purchase menu having unnecessary padding on the right.\nFixed wiggling bottom of energy bar.\nPlaced object fixes:\nCrab pots no longer appear during the moonlight jellies.\nTub o' flowers now shows the correct sprite on the day it is placed, and now always blooms indoors.\nFixed beds or chests that were hidden for an event not reappearing afterwards.\nFixed furniture drawn over sitting players if it has no front texture.\nFixed bombs being invisible when placed on the summit.\nFixed bombs able to remove stick bugs' sticks.\nFixed colored objects not drawn correctly when placed on tables or eaten.\nFixed prismatic hats not displayed properly on alien rarecrows.\nFixed lanterns and other furniture lights not turning on after save/load if they are on a table.\nPossibly fixed clumping issue for weather debris like the spring petals.\nFixed layering issues with seagulls and Willy's house.\nFixed fruit tree leaves not rustling in winter even if they're in a non-seasonal location like the greenhouse.\nFixed barren trees having a leafy shadow.\nFixed weeds being less varied than intended in summer.\nFixed weeds able to grow on top of buildings on spring 1.\nFixed intro cutscene position not adjusted when the farmhouse is moved by a mod.\nFixed pre-built cabins sometimes placed on top of a bush or log.\nFixed many things on Ginger Island applying the valley's season or weather (including fiber seeds, seasonal decor, seasonal plants, tea bushes, and tubs o' flowers).\nFixed Elliott appearing twice during the egg hunt.\nFixed Lewis' saloon drinking animation having an incorrect frame.\nFixed bombed objects becoming tiny and sometimes showing wrong sprite index while they flash before removal.\nFixed building placement visual/sound effects playing even for players who are nowhere near it.\nFixed speech bubbles sometimes shown over invisible NPCs.\nFixed crane minigame's music sometimes continuing a few seconds after the minigame ends.\nFixed 'you received X' message & animation showing wrong item if you switch held item right as it's triggered.\nFixed some events fading in after a scene change before they're fully ready, which caused issues like NPCs visibly warping into place or mid-fade flashes.\nFixed ginger showing a watered dirt tile if you water it. This incorrectly implied that ginger needs to be watered.\nFixed missing explosion tiles in mega bomb explosions.\nFixed town festivals not showing the right version of Pam's house and community center.\nFixed an incorrect frame in Lewis' saloon drinking animation.\nFixed layering draw issue in the fishing fair minigame.\nFixes for modded players\nFestivals now only set sunny weather in their location context. (For example, a custom festival in the desert no longer changes weather in the valley.)\nMonsters no longer spawn at night by default on custom farm types.\nNon-binary NPCs can now pathfind through any gendered route (e.g. men's or women's locker room), instead of defaulting to female routes.\nFixed crashes when...\nloading a save with unknown locations or farm type, NPCs with no sprite texture, or null world objects.\nthe farm map has no grass spawn tile and you walk through crops or grass.\nthe data for an item, animal, tree, etc no longer exists.\npainting a building if its sprite changed to a smaller one since it was last painted.\nplaying audio which doesn't exist (it now logs an error and plays a default 'quiet click' sound instead).\na farmhand warps to a location which doesn't exist locally yet.", "mimetype": "text/plain", "start_char_idx": 56285, "end_char_idx": 61233, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82d68d5c-81f3-451e-add8-f6b1880722e1": {"__data__": {"id_": "82d68d5c-81f3-451e-add8-f6b1880722e1", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c6ebb2a-7ac1-4af9-ad0a-a670227b21d4", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "346cd5d2f756785734088e6c7f812a8b935e06fe2294ff40cfcc42b63f4eb031", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4e3d9e20-9c10-48fe-8766-397da5b1daef", "node_type": "1", "metadata": {}, "hash": "9beb2bd978b505628582c089e3128f0a25ddbf7881d6b0e7f1e3c19061f7f442", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixes for modded players\nFestivals now only set sunny weather in their location context. (For example, a custom festival in the desert no longer changes weather in the valley.)\nMonsters no longer spawn at night by default on custom farm types.\nNon-binary NPCs can now pathfind through any gendered route (e.g. men's or women's locker room), instead of defaulting to female routes.\nFixed crashes when...\nloading a save with unknown locations or farm type, NPCs with no sprite texture, or null world objects.\nthe farm map has no grass spawn tile and you walk through crops or grass.\nthe data for an item, animal, tree, etc no longer exists.\npainting a building if its sprite changed to a smaller one since it was last painted.\nplaying audio which doesn't exist (it now logs an error and plays a default 'quiet click' sound instead).\na farmhand warps to a location which doesn't exist locally yet.\nan NPC can't parse its dialogue (it now logs the error and defaults to \"...\" instead).\na special order's data can't be parsed.\na mini-jukebox has an invalid track selected (it now turns off instead).\na mini-shipping bin has null items.\na statue of endless fortune tries to produce a gift for an NPC whose first loved gift is a category or context tag (it now now chooses the first valid gift taste, and falls back to a non-birthday gift if none was found);\na farm animal warps home in rare cases;\nthe player's NPC spouse no longer exists (e.g. the mod which added it was removed).\nFixed calendar support for multiple events on the same day (including multiple weddings, multiple birthdays, birthdays on a festival day, etc).\nFixed horses in indoor locations or mine/volcano levels unable to return home.\nFixed event setup not allowing more than 9 players.\nFixed events not exiting correctly if they crash before the first script command.\nFixed event errors not logged to the console.\nFixed potential event crash if a custom NPC name contains 'farmer'.\nFixed save loading very slowly if it has a broken outdoors location in some cases.\nFixed some items being unremovable when spawned by players. This affects incubators, mushroom boxes, slime balls, and three unused items (locked doors and alternate wicked statues).\nFixed issue when warping to Sandy early using mods where she could give daily quests as soon as you met her, but didn't accept items until you fixed the bus.\nFixed issue where sleeping in a location where an event starts the next day would skip overnight events and soft-lock the game.\nFixed invalid game state when the day of month increases past 28 due to a mod issue. Any day past 28 is now treated as the last day of the season.\nOther bug fixes\nFixed crash when taking a screenshot on macOS if the ~/.local folder doesn't exist.\nFixed crash when removing light glows in rare cases.\nFixed window resize on character creation resetting profit margins & starting cabins, and desyncing the 'skip intro' checkbox.\nFixed able to equip a staircase as pants to obtain trimmed lucky purple shorts.\nFixed being able to place a yellow couch in a loom.\nFixed wilderness farm spawning a stone in water.\nFixed hill-top farm spawning grass inside of stumps.\nFixed Trash Bear treated as a villager (e.g. it could theoretically be picked for quests).\nFixed save folder collision if you set the save's name & seed to the same value as an existing save.\nFixed selecting small buildings in the construction menu's farm view. This fixes the gap above the shipping bin where it can't be selected, and fixes small buildings selectable by hovering three tiles above them.\nFixed the build number not set on Linux/macOS.\nFixed unable to write vanilla error logs for players with special characters in their name.\n1.5.6\nStardew Valley 1.5.6 was released on 21 December 2021. Hotfixes were applied on 22 December 2021 (twice) and 18 January 2022.\n\nQuality of life changes\nOn multi-monitor setups, the game now remembers and restores on the last used monitor.\nBug fixes\nPossibly fixed a random crash that could occur at the end of the night.\nFixed issue where some farm types' wallpapers and floors weren't applied when starting a new game.\nFixed pressing ESC to dismiss the level up screen also skipping the level up itself, causing it to reappear every night.\nFixed tilled dirt still decaying under forage items on the farm. This means that dirt under freshly grown seasonal forage seeds can no longer disappear randomly.\nFixed grass placed indoors dying when the season changes to Winter.\nFixed unable to harvest tea saplings placed in garden pots on Ginger Island.\nFixed the Z key unbindable after resetting controls to the default.\nFixed map screenshots not working on Linux.", "mimetype": "text/plain", "start_char_idx": 60339, "end_char_idx": 65006, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4e3d9e20-9c10-48fe-8766-397da5b1daef": {"__data__": {"id_": "4e3d9e20-9c10-48fe-8766-397da5b1daef", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82d68d5c-81f3-451e-add8-f6b1880722e1", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "f18828a667f86523933c29cbb88e98744b8edfd97649ff796925737564e4c4e7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58394294-6b3a-4776-856a-1fe0d7341bde", "node_type": "1", "metadata": {}, "hash": "910e34205d4ae4fcc1c9e5d072c608de7d647f3a663e7e497a7d081299f04932", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Hotfixes were applied on 22 December 2021 (twice) and 18 January 2022.\n\nQuality of life changes\nOn multi-monitor setups, the game now remembers and restores on the last used monitor.\nBug fixes\nPossibly fixed a random crash that could occur at the end of the night.\nFixed issue where some farm types' wallpapers and floors weren't applied when starting a new game.\nFixed pressing ESC to dismiss the level up screen also skipping the level up itself, causing it to reappear every night.\nFixed tilled dirt still decaying under forage items on the farm. This means that dirt under freshly grown seasonal forage seeds can no longer disappear randomly.\nFixed grass placed indoors dying when the season changes to Winter.\nFixed unable to harvest tea saplings placed in garden pots on Ginger Island.\nFixed the Z key unbindable after resetting controls to the default.\nFixed map screenshots not working on Linux.\nFixed modding issues.\nInternal changes\nUpdated Steamworks.NET to 20.0.0.\nFurther changes were later released without changing the version number:\n22 December 2021 (announcement)\nFixed crash when starting the game on the compatibility branch on macOS.\nFixed unable to move the game window from one desktop to another in some monitor configurations.\nFixed issue that prevented selecting a profession using a gamepad. You should be able to re-select any missed professions the next day.\nFixed garden pots automatically harvesting when moused over.\nFixed Emily's patio decorations being one tile above where they should be.\n22 December 2021\nFixed issue initializing Steam SDK in 1.5.6.\n18 January 2022 \"Hotfix #3\" (appended to 1.5.6 announcement)\nThe version shown on the title screen ? menu now reflects hotfixes.\nChanged how the Stardew valley logo is scaled on the title screen for resolutions with lower heights.\nRemoved the numeric hotkey displays along the top of the inventory screen menu when playing on a controller.\nFixed player/horse placement issues after triggering an event on the farm while on horseback (including an issue that could cause a farmhand to become stuck in a wall after viewing Leah's 6-heart event).\nFixed Korean/English dialogue line swapped for collapsed-in-Volcano scene.\nFixed exclusive fullscreen mode being off-center or incorrectly sized when Window's zoom isn't set to 100% on main-branch builds.\nAdded failsafe when maximizing/windowing from the title screen to clamp to the upper-right corner of the current display in fullscreen mode.\n1.5.5\nStardew Valley 1.5.5 was released to the Steam beta branch on 17 August 2021 for mod authors, announced in the forums on 07 September 2021, and released to all players on 30 November 2021. Hotfixes were applied on 3 December 2021, 5 December 2021, and 7 December 2021.\n\nArchitectural changes\nAdded support for Xbox Game Pass.\nThis migrates the game on Windows from .NET Framework 4.5.2 to .NET 5. You may need to launch the vanilla game once through Steam/GOG to install the new dependencies.\nAdded internal changes for mod authors (see mod author migration guide and completed modding wishlist items).\nQuality of life changes\nHolding Control + Shift now lets you purchase or craft stacks of 25 items at a time.\nMany in-game settings now remember their last value when you start a new save. (Some settings like zoom level, gamepad mode, and multiplayer server privacy aren't copied over.)\nYou can now build or move farm buildings onto artifact spots (which will destroy the artifact spots).\nYou can now nudge pets out of the way while building/moving a building by clicking on them.\nYou can now buy back items accidentally sold in the same shopping session.\nThe in-game time is now shown on the upper-right hand corner of the screen when playing Journey of the Prairie King in multiplayer.\nGrass placed using grass starters during winter no longer disappears when the game is reloaded (but it still won't grow or spread). Grass that's outdoors in winter now takes on the appearance of the grass found in the frost section of the mines.\nAdded /printdiag chat command which prints some diagnostic info to the chat window.\nLocalization fixes\nFixed Shane's 6-heart event soft-locking in the Hungarian translation.\nFixed incorrect '\\' characters in various events in the Hungarian localization.\nFixed typos in the French localization.\nFixed a typo in Livin' Off The Land that incorrectly states that super cucumber can be caught in Winter.\nCosmetic fixes\nAdded commas to the price display on Robin and the Wizard's building menus.\nAdjusted collisions on the desert map to avoid sorting issue on the top-left edge of raised cliffside.", "mimetype": "text/plain", "start_char_idx": 64103, "end_char_idx": 68713, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58394294-6b3a-4776-856a-1fe0d7341bde": {"__data__": {"id_": "58394294-6b3a-4776-856a-1fe0d7341bde", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e3d9e20-9c10-48fe-8766-397da5b1daef", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "04fdfec7d50be129b5fc28ee4e5a5028e7fd07a85ba4bc202542a5ee14ac503a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6c8a1732-59f0-4956-8ea2-bbf44b1b0113", "node_type": "1", "metadata": {}, "hash": "a86a5a3d580ac7d6d6bf7285e2026e321df63edb96c9a4d905153db99c936c1c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The in-game time is now shown on the upper-right hand corner of the screen when playing Journey of the Prairie King in multiplayer.\nGrass placed using grass starters during winter no longer disappears when the game is reloaded (but it still won't grow or spread). Grass that's outdoors in winter now takes on the appearance of the grass found in the frost section of the mines.\nAdded /printdiag chat command which prints some diagnostic info to the chat window.\nLocalization fixes\nFixed Shane's 6-heart event soft-locking in the Hungarian translation.\nFixed incorrect '\\' characters in various events in the Hungarian localization.\nFixed typos in the French localization.\nFixed a typo in Livin' Off The Land that incorrectly states that super cucumber can be caught in Winter.\nCosmetic fixes\nAdded commas to the price display on Robin and the Wizard's building menus.\nAdjusted collisions on the desert map to avoid sorting issue on the top-left edge of raised cliffside.\nFixed issue where Sebastian's sprite would shift into an invalid position at 1:00 PM when he's working on his bike on the farm.\nGeneral fixes\nAfter completing the Cryptic Note quest, reaching floor 100 of the Skull Cavern again will guarantee a chest.\nFixed issue where the harder Mines could become permanently enabled and unable to change back.\nFixed radioactive bars not affected by the Blacksmith profession.\nFixed explosion radius not centered when dislodging flooring and certain other types of items.\nFixed garden pots clearing their fertilizers when a crop is harvested.\nFixed placing a garden pot on Ginger Island on a rainy day not watering its dirt.\nFixed multiplayer hosts registering their lobbies before fully loading a save, causing the games not to appear in the multiplayer games list.\nFixed moving a cabin with a cellar causing the stairs to the cellar to warp the players out of bounds for the rest of the play session.\nFixed a case where entering the Farm from the south on horseback and triggering an event could cause the player to get stuck in a wall.\nFixed various invisible tiles preventing certain spots in the Mountain lake from spawning fish activity bubbles.\nFixed the tile holding the plant on Elliott's table not being passable.\nFixed some tiles on the left side of the beach farm being unbuildable.\nFurther changes were later released without changing the version number:\n3 December 2021 (announcement, release notes appended to 1.5.5 post)\nFixed widescreen and UHD displays not handled correctly.\nFixed crash in the French localization for the \"It Howls In The Rain\" movie.\nFixed GOG builds not optimized for release, which caused errors with some mods.\nFixed gamepad issues on Linux and macOS with the main 64-bit branch.\n5 December 2021\nReverted gamepad fix in the previous update, which caused crashes for some players.\n7 December 2021 (see announcement for release, revert, and re-release)\nFixed a memory leak related to sound effects.\nFixed an issue where quitting the game in exclusive fullscreen would revert to windowed borderless upon reloading the game.\nFixed an issue where the last-used volume levels weren't properly applied when starting a new game.\nFixed special orders board appearing distorted during festivals.\n(Modding) Fixed [HOURS_24_00] not properly zero padded.\n1.5.4\nStardew Valley 1.5.4 was released on 22 January 2021. A hotfix was applied on 2 June 2021.\n\nChanges\nPam no longer visits the Island resort on Sandy's birthday.\nThe Stardew Valley Fair shop no longer sells multiples of the randomly chosen items.\nThe Stardew Valley Fair shop now sells triple shot espresso instead of tea sapling.\nMultiplayer fixes\nFixed a rare crash that could occur when watching an event in multiplayer as the clock hits midnight or 1am.\nFixed the sound of fiber crops being harvested being audible when you're in another area.\nGeneral fixes\nItems related to Qi challenges and special orders are now properly removed from both Marlon's Item Recovery Service, and items requested to be recovered are now removed from the mailbox once the quest expires.\nFixed perfection check not accounting for games where the farm switched to the Joja route partway through a Community Center playthrough.\nFixed lucky rings losing their luck bonus overnight.\nFixed softlock when fishing with multiple rods in your inventory after catching a treasure and casting from a different rod. This fixes the common fishing rod softlock next to Willy's house and during the Festival of Ice.\nFixed exploit where entering the Skull Cavern would immediately unlock all 120 floors for the elevator in The Mines.\nFixed exploit where you could find lost books by storing and retrieving certain wallpapers in chests.\nFixed a rare issue where a charged hoe could dislodge a non-empty chest and destroying its contents if it was placed in a specific configuration next to other chests.", "mimetype": "text/plain", "start_char_idx": 67743, "end_char_idx": 72606, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6c8a1732-59f0-4956-8ea2-bbf44b1b0113": {"__data__": {"id_": "6c8a1732-59f0-4956-8ea2-bbf44b1b0113", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58394294-6b3a-4776-856a-1fe0d7341bde", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "38e767331f22b995292f6b73af20439b7cd423d4dafce9652ebb9b1f02d611a4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b7e7206-4792-4a7a-8219-c721bccc88e1", "node_type": "1", "metadata": {}, "hash": "17b23fbe7ab3acc37766b45b4e84f59945bcfab28c94455bcf3b04a37c89e20c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "General fixes\nItems related to Qi challenges and special orders are now properly removed from both Marlon's Item Recovery Service, and items requested to be recovered are now removed from the mailbox once the quest expires.\nFixed perfection check not accounting for games where the farm switched to the Joja route partway through a Community Center playthrough.\nFixed lucky rings losing their luck bonus overnight.\nFixed softlock when fishing with multiple rods in your inventory after catching a treasure and casting from a different rod. This fixes the common fishing rod softlock next to Willy's house and during the Festival of Ice.\nFixed exploit where entering the Skull Cavern would immediately unlock all 120 floors for the elevator in The Mines.\nFixed exploit where you could find lost books by storing and retrieving certain wallpapers in chests.\nFixed a rare issue where a charged hoe could dislodge a non-empty chest and destroying its contents if it was placed in a specific configuration next to other chests.\nFixed issue where the buttons in the CalicoJack and Calico Spin minigames wouldn't respond to controller input if the UI scale setting didn't match zoom level setting.\nFixed issue where bombing certain floor tiles in the quarry would spawn items.\nFixed palm trees in the desert producing golden coconuts.\nFixed being able to interact with objects while warping with the return scepter.\nFixed trees able to grow on top of placed furniture items.\nFixed a minor graphical inconsistency with the quality indicator on procedurally-colored objects such as flowers.\nFixed Leo's first event unable to complete when playing in the Korean localization.\nFixed the special order board being invisible during summer in the Korean localization.\nVarious localization corrections.\nFurther changes were later released without changing the version number:\n2 June 2021 (announcement)\nAdjusted the randomization of the mummified bat drop.\nFixed multiplayer issues on macOS.\nFixed text wrapping issue on the Special Orders board in the Korean localization.\nFixed some stardrops not always counted for the perfection score. Reaching max stamina now counts as having found all stardrops.\n1.5.3\nStardew Valley 1.5.3 was released on 15 January 2021. A hotfix was applied on 16 January 2021.\n\nBalance changes\nThe stone owl is now rarer.\nThe strange capsule now only spawns once per game.\nPrismatic slimes are now more common (0.8% chance to 1.2% chance), and their spawn rate is now affected by daily luck.\nFixed exploit where Qi beans/fruit weren't removed from machines/craftables after the challenge expires.\nYou can no longer catch Qi Beans when fishing during festivals.\nMinor changes\nAdjusted Leo's gift tastes.\nTweaked stone owl sprite.\nPenny's 14 heart event now places your existing bed in a chest rather than replacing it.\nFurniture is no longer visible and can no longer block movement during events that take place outside of the farm.\nMultiplayer fixes\nCrab pots now check the professions of the player who refilled them. This fixes a case in multiplayer where a player's profession (such as Mariner) would appear to not work because the crab pot was originally placed in the water by someone else.\nFixed the summit event not triggered if the player is married to another player.\nFixed the menu backgrounds option displayed incorrectly when playing in split-screen mode on a rainy day.\nFixed incorrect button mapping shown on Local Coop Join screen.\nGeneral fixes\nExperimentally fixed rendering on ultra-wide displays.\nPotentially fixed various cases where the player could get stuck or softlocked in an animation after using a tool (including the the horse flute softlock and possibly fishing softlocks).\nThe Farmer no longer blinks while charging a tool. This was causing a minor visual issue.\nFixed summit event being repeatable if its music wasn't marked as heard. The music is now saved as soon as the event is started.\nFixed issue where a character could spawn on the upper-left corner of the island map when skipping the Ginger Island departure event while the character is still pathing.\nFixed Leo using the wrong schedule on Wednesdays after his six-heart event.\nFixed issue where the quality bobber wasn't applying its bonus.\nFixed magic bait not working to catch Night Market fish in the southwest corner of the beach.\nFixed issue where you could get softlocked if you hooked a fish just as the pirate cave event begins.\nFixed some minor data entry issues on normal bundles that also appear in remixed bundles (Animal Bundle requiring a small brown egg instead of a large white egg, and normal cheese not being an option in the Artisan Bundle).\nFixed bug preventing prismatic slimes from not dropping prismatic jelly in rare cases.\nFixed bug where the strange capsule would leave a residual light glow.\nFixed overnight lost & found tool logic not checking the island farmhouse fridge.\nFixed crash that could occur if a dust sprite's stone-breaking move would cause a Qi Bean to spawn.", "mimetype": "text/plain", "start_char_idx": 71584, "end_char_idx": 76589, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9b7e7206-4792-4a7a-8219-c721bccc88e1": {"__data__": {"id_": "9b7e7206-4792-4a7a-8219-c721bccc88e1", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6c8a1732-59f0-4956-8ea2-bbf44b1b0113", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "386ac46430ddd18331f6cc3884ebd2ecfb50388c7c0e7cb11469f476a074cff4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0c926f42-462e-4e43-97eb-9fbb03f58eae", "node_type": "1", "metadata": {}, "hash": "c24d5486e320ef7130b6d6d63ac016ae6d2e747a9f3e52bf8996cd518fdbe332", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed Leo using the wrong schedule on Wednesdays after his six-heart event.\nFixed issue where the quality bobber wasn't applying its bonus.\nFixed magic bait not working to catch Night Market fish in the southwest corner of the beach.\nFixed issue where you could get softlocked if you hooked a fish just as the pirate cave event begins.\nFixed some minor data entry issues on normal bundles that also appear in remixed bundles (Animal Bundle requiring a small brown egg instead of a large white egg, and normal cheese not being an option in the Artisan Bundle).\nFixed bug preventing prismatic slimes from not dropping prismatic jelly in rare cases.\nFixed bug where the strange capsule would leave a residual light glow.\nFixed overnight lost & found tool logic not checking the island farmhouse fridge.\nFixed crash that could occur if a dust sprite's stone-breaking move would cause a Qi Bean to spawn.\nFixed a long delay after talking to Gourmand when you've got the crop he's requested growing, but it's not yet fully grown.\nFixed the daytime music from Ginger Island not being playable on the Saloon jukebox.\nFixed a crash when using a warp totem while the mermaid show is playing.\nFixed issue where you couldn't go back to sleep immediately after waking up after passing out.\nFixed item duplication glitches related to moving rings around in certain menus.\nFixed certain gemstones appearing on the daily quest board before they're actually accessible in-game.\nFixed various localization issues.\n(Modding) A randomized bundle containing an invalid item now shows a more detailed error message.\n(Modding) Fixed big craftables losing mod data when picked up.\n(Modding) Fixed issue where going from one floor to another on horseback inside the Volcano would position the player incorrectly on the next floor.\nFurther changes were later released without changing the version number:\n16 January 2021 (announcement)\nFixed exploit where Qi beans/fruit weren't removed from Marlon's item recovery service after the challenge expires.\nFixed a multiplayer fishing softlock added in 1.5.3.\n1.5.2\nStardew Valley 1.5.2 was released on 8 January 2021.\n\nFeature changes\nYou can now dismiss the level-up menu by pressing the ESC key.\nBalance changes\nQi fruit can now be grown on the farm during winter.\nTools now track the previous two enchantments applied to them so they're not reselected when you reapply an enchantment.\nCoral and other aquatic forage items are now included for the \"Botanist\" profession.\nAdded dark cowboy hat to Skull Cavern chest loot table.\nYou can no longer increase speed buffs using Qi seasoning.\nBuff durations from Qi seasoned food/drinks are now 50% longer.\nYou can no longer complete the \"Danger In The Deep\" Qi Challenge by visiting the Skull Cavern.\nReduced price when selling cookout kits from 3000g to 80g.\nReduced price when selling ducks from 4000g to 1200g.\nFixed ducks not selling for the appropriate price.\nGinger Island fixes\nAdjusted a journal scrap treasure map to better represent the in-game location.\nAdded failsafe to prevent players from warping to the upper-left corner of the southern island map.\nPassing out in Qi's secret room no longer causes you to wake up on the mainland.\nFixed Junimos not harvesting crops if you spent the night on the island or when you're not physically present.\nFixed unable to place mini-fridges in the Island farmhouse.\nFixed unable to collect honey from bee houses on the island farm in winter.\nFixed garden pots on the island farm becoming watered on days when it's raining in the valley.\nFixed forage crops disappearing overnight on the island farm on Saturdays/Sundays.\nMultiplayer fixes\nFixed most minigames appearing misaligned in split-screen mode.\nFixed a crash that could occur in the mermaid show in split-screen mode.\nFixed farmhands getting stuck if two split-screen players choose the same farmhand at the same time.\nFixed a crash when crab pots are removed by a farmhand.\nGeneral fixes\nYou can no longer sit on chairs if the game is currently pausing your character due to an animation (such as using a tool or kissing your spouse).\nYou can no longer instantly kill Fector as a zombie in Journey of the Prairie King.\nAdjusted the rendering of very wide furniture items so that they do not extend too far past an inventory slot.\nFixed issue preventing 100% perfection score in the Joja route.\nFixed graphical issues with the post-perfection event.\nFixed coral not considered red instead of pale violet red for dyes, etc.\nFixed hearts dropped during Qi's Hungry Challenge not collectable if the inventory is full.\nFixed the level-up screen's OK button positioned offscreen in some cases.\nFixed the Key to the City not allowing you into Pierre's shop if you completed the game through the Joja route.", "mimetype": "text/plain", "start_char_idx": 75690, "end_char_idx": 80464, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0c926f42-462e-4e43-97eb-9fbb03f58eae": {"__data__": {"id_": "0c926f42-462e-4e43-97eb-9fbb03f58eae", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b7e7206-4792-4a7a-8219-c721bccc88e1", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "82ca58cacda8374f83bac8d5ce612c72aa7716a4d1212f2cfab9f23caf6fd43a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8fcf933-bb27-4f37-bcb3-9fd4696d8594", "node_type": "1", "metadata": {}, "hash": "345787e8aa236a309bfa8a627cb158b44279832e9278d3fc7a3644fb12c87969", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed a crash when crab pots are removed by a farmhand.\nGeneral fixes\nYou can no longer sit on chairs if the game is currently pausing your character due to an animation (such as using a tool or kissing your spouse).\nYou can no longer instantly kill Fector as a zombie in Journey of the Prairie King.\nAdjusted the rendering of very wide furniture items so that they do not extend too far past an inventory slot.\nFixed issue preventing 100% perfection score in the Joja route.\nFixed graphical issues with the post-perfection event.\nFixed coral not considered red instead of pale violet red for dyes, etc.\nFixed hearts dropped during Qi's Hungry Challenge not collectable if the inventory is full.\nFixed the level-up screen's OK button positioned offscreen in some cases.\nFixed the Key to the City not allowing you into Pierre's shop if you completed the game through the Joja route.\nFixed issue where large amounts of beets placed in a mill wouldn't produce the proper amount of sugar.\nFixed gifting-related special order objectives not correctly checking the minimum liked value of gifted items.\nFixed special order-related items stored in Junimo chests not properly removed once the special order expires.\nFixed fruit tree saplings and seeds sold at festivals not properly reflecting the profit margins setting.\nFixed sign items no longer showing their placement indicator once a fish pond had been built on the farm.\nFixed combined rings only showing the stat buffs from their first component ring.\nFixed combined rings not properly using their localized name.\nFixed a ring duplication glitch in the dye pot menu.\nFixed a crash and other issues related to obtaining the Iridium Krobus item.\nPotentially fixed a random crash that occurs when going to bed.\nPotentially fixed a crash in the mines.\nFixed a crash when fishing from the pond on your farm using magic bait.\nFixed a bug causing cheese cauliflower to not display in the collections tab.\nFixed breaking open geodes and artifact troves incorrectly counted as two item collects in the collections tab.\nFixed a crash that could occur when clicking in the scrollbar region of a shop menu when there are less than four items available.\nFixed issue where placing a bomb and sleeping could cause the fuse sound to play indefinitely.\nFixed issue where weeds could appear as batteries.\nFixed weapon cooldown timers no longer displaying on weapons in the shop menu.\n(Modding) Fixed order/naming of tilesheets on the beach farm inconsistent with the other farm types.\nLocalization fixes\nFixed a missing event in Willy's shop from the Hungarian localization.\nFixed an issue with Leo's six-Heart event in the German localization. This fix is applied retroactively.\nFixed an issue where some weapons added in 1.5 would display an incorrect weapon name in the German localization.\nFixed crashes related to Lewis' phone call in various localizations.\nFixed various minor typos.\nVarious localization fixes.\n1.5.1\nStardew Valley 1.5.1 was released on 24 December 2020.\n\nFeature changes\nThe crystal cave puzzle now gradually gets easier after repeated misses.\nSpouses no longer stand around looking at rug-type furniture items. This fixes a case where a spouse might stare at a floor divider, which could cause them to block the player's way through a narrow hallway.\nMultiplayer fixes\nFixed exploit where you could regain stamina in bed in multiplayer even if the game was paused.\nFixed rare issue where the host player would warp to an invalid position if a farmhand had just completed a Community Center bundle.\nLocalization fixes\nVarious localization fixes and changes.\nFixed a crash when bombing the cave entrance next to the Field Office when playing in Spanish.\nFixed issues with Lewis's phone call in various localizations.\nFixed bug in the Spanish translations preventing Birdie's introduction event from completing.\nFixed bug in the German translations preventing male characters from completing Birdie's quest.\nGeneral fixes\nWhen dismissing the forge menu, items that can't fit in your inventory are now dropped downward instead of upward to avoid items being dropped into the lava.\nFixed pets sometimes warping out of bounds.\nFixed being able to place objects in some parts of the void in the farmhouse.\nFixed \"spawn monsters on the farm\" advanced game option resetting when you choose a different farm type after changing it.\nFixed redeeming a stack of items at the Stardew Valley Fair granting a single item, instead of the whole stack.\nFixed an issue related to having a child named Leo or Kent, where existing friendship points for these characters would be transferred over to your children.\nFixed some new hairstyles clipping through hats.\nFixed issue where purchasing the master slingshot would give the player a normal slingshot.\nFixed unable to select the Beach Farm on the new game screen when playing with a controller at minimum resolution.\nFixed Leo available as secret santa if he's not in town.\nFixed being able to place objects in certain tiles that block player movement such as the landslide that blocks the path to the Mines.", "mimetype": "text/plain", "start_char_idx": 79583, "end_char_idx": 84679, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8fcf933-bb27-4f37-bcb3-9fd4696d8594": {"__data__": {"id_": "d8fcf933-bb27-4f37-bcb3-9fd4696d8594", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0c926f42-462e-4e43-97eb-9fbb03f58eae", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "ac29d31835947b141b655ed35a95946cb09b6408270c9bd092f39c434f13b4b2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b2e9beca-33c1-4417-a602-a4c3ce72ec5a", "node_type": "1", "metadata": {}, "hash": "9c20ab287e98514347176137917ffb60a44d23f1f9d4ff4d33b471e534cab1d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed pets sometimes warping out of bounds.\nFixed being able to place objects in some parts of the void in the farmhouse.\nFixed \"spawn monsters on the farm\" advanced game option resetting when you choose a different farm type after changing it.\nFixed redeeming a stack of items at the Stardew Valley Fair granting a single item, instead of the whole stack.\nFixed an issue related to having a child named Leo or Kent, where existing friendship points for these characters would be transferred over to your children.\nFixed some new hairstyles clipping through hats.\nFixed issue where purchasing the master slingshot would give the player a normal slingshot.\nFixed unable to select the Beach Farm on the new game screen when playing with a controller at minimum resolution.\nFixed Leo available as secret santa if he's not in town.\nFixed being able to place objects in certain tiles that block player movement such as the landslide that blocks the path to the Mines.\nFixed issue where killing big slimes carrying hearts during Qi's Hungry Challenge, while wearing the burglar's ring, would cause the hearts to be collectable in the player's inventory.\nFixed a crash that occurs when demolishing cabins.\nFixed a crash that could occur overnight if you place the Auto-Petter anywhere that isn't a coop or a barn.\nFixed Maru standing on the wrong tile outside the farm on Saturdays if you're married to her.\nFixed hair #56 accidentally replaced.\nFixed Birdie's item trade quest removing all stacks of an item when they're given to their intended recipient.\n(Modding) Fixed the return scepter not returning to overwritten farmhouse entry positions.\n1.5\nStardew Valley 1.5.0 was released on 21 December 2020. Hotfixes were applied on 21 December 2020, 22 December 2020, and 23 December 2020.\n\nNew world area\n1.5 adds an entire new region of the world, Ginger Island in the Fern Islands:\nAdded new locations, dialogue, events, minigames, puzzles, and a quest line involving multiple NPCs.\nAdded Leo, a new NPC with his own backstory, plot line, events, etc.\nAdded new secondary NPCs: Birdie, Gourmand Frog, and Professor Snail.\nAdded a volcano dungeon which changes each time you visit it similar to the mines.\nAdded Qi challenges which unlock rare or unique items.\nAdded an unlockable island farm and farmhouse area, where you can plant crops in any season but can't construct buildings.\nAdded an unlockable resort you can open to let villagers visit the islands, including new beach attire and schedules.\nAdded hidden pages of a lost sailor's journal to uncover his story and learn about the islands.\nAdded golden walnuts hidden throughout the islands, which can be used to unlock new areas and content.\nAdded golden coconuts, which Clint can crack open to find rare island items.\nAdded secrets and puzzles to discover around the island.\nAdded new enemies:\ndwarvish sentry;\nfalse magma cap;\nhot head;\nlava lurk;\nmagma sprite;\nmagma sparker;\nmagma duggy;\nspiker;\nstick bug;\ntiger slime.\nAdded new cosmetic critters: crabs, caldera monkeys, overhead parrots, marsupial, and tropical butterflies.\nAdded new island obelisk building.\nNew farm features\nAdded a new beach farm layout.\nAdded ostrich as a farm animal.\nThe immovable dressers found in Farmhands\u2019 cabins have been removed.\nAdded home renovations, which let you further expand and adjust the farmhouse after it's fully upgraded.\nBeds are now normal furniture you can pick up, move around, and replace. (You can even have a house with no bed, but your spouse might have something to say about that.)\nOnce unlocked, the greenhouse can now be moved at Robin's shop.\nThe default shipping bin can now be moved or demolished at Robin's shop.\nAdded advanced game options, which can be used to customize a new game:\nset seed value used in randomization;\nchoose default vs randomized community center bundles;\nchoose default vs randomized mine chests;\nmake red cabbage seeds guaranteed to sell at least once at the travelling cart in year one, so it's always possible to finish the community center in the first year;\nchange profit margins and cabin-related options that were previously inaccessible when creating a single-player farm.\ncan toggle monsters spawning.\nYou can now apply cosmetic paints to the farmhouse and buildings.\nDucks can now swim in water, and certain coop animals will now follow adults around.\nSlimes now drink from slime hutch troughs in random order.\nOther new content and features\nAdded tool and weapon enchanting.\nAdded ability to combine two rings into one.\nAdded special orders, more dynamic late-game quests which let you help villagers with their personal projects through a special orders board in town.", "mimetype": "text/plain", "start_char_idx": 83717, "end_char_idx": 88390, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b2e9beca-33c1-4417-a602-a4c3ce72ec5a": {"__data__": {"id_": "b2e9beca-33c1-4417-a602-a4c3ce72ec5a", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8fcf933-bb27-4f37-bcb3-9fd4696d8594", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "5884517158909cd4b1248fa22ae32c407598eba051801f0b0e7c02840f04292d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c72fc260-06de-438a-817a-d472d58724b1", "node_type": "1", "metadata": {}, "hash": "58f33ec345de2c1970de5db19822ccbc6012643c896c9f06a7da7d342e020ad9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Added advanced game options, which can be used to customize a new game:\nset seed value used in randomization;\nchoose default vs randomized community center bundles;\nchoose default vs randomized mine chests;\nmake red cabbage seeds guaranteed to sell at least once at the travelling cart in year one, so it's always possible to finish the community center in the first year;\nchange profit margins and cabin-related options that were previously inaccessible when creating a single-player farm.\ncan toggle monsters spawning.\nYou can now apply cosmetic paints to the farmhouse and buildings.\nDucks can now swim in water, and certain coop animals will now follow adults around.\nSlimes now drink from slime hutch troughs in random order.\nOther new content and features\nAdded tool and weapon enchanting.\nAdded ability to combine two rings into one.\nAdded special orders, more dynamic late-game quests which let you help villagers with their personal projects through a special orders board in town. These can include more varied goals and rewards, temporary world changes (like new enemies for the duration of the quest), permanent changes (e.g., new shop inventory), and post-completion events.\nAdded a second community upgrade.\nAdded a more difficult version of the mines and the Skull Cavern, which includes new and more powerful monsters along with better drops. These can be accessed late-game, and can optionally be toggled permanently using the Shrine of Challenge.\nAdded new enemies which appear in the difficult mines:\nshadow sniper;\nskeleton mage;\nspider (jumps, often found near webs that can trap players and dust sprites);\nprismatic slime (quest only);\nputrid ghost (causes nauseated debuff);\nblue squid;\nroyal serpent;\nslime variants ('cool' and stacked).\nAdded new fishing TV channel.\nAdded new crops and trees:\nmahogany tree (drops hardwood)\nmahogany seed;\nfiber seeds;\nginger (forage);\nbanana;\nmango;\npineapple;\ntaro root (paddy crop);\nNew palm tree variant;\nQi fruit (available during special Qi quest).\nFestival changes:\nadded new even-numbered year dialogues for Egg Festival;\nadded shops to the Dance of the Moonlight Jellies, Feast of the Winter Star, Festival of Ice, and Luau;\nadded new items to various festival shops;\nChildren now attend festivals.\nYou can now change your name and gender in the Wizard's basement shrine.\nYou now have a perfection rating which tracks the percentage of game content you've completed. Reaching full completion lets you buy golden chickens, adds a random Golden Witch event, unlocks access to the Summit with a new event, and adds new bird critters.\nYou can now further customize sprinklers with attachments:\nenricher automatically applies loaded fertilizer while planting seeds nearby;\npressure nozzle increases watering range.\nAdded new craftable items and machines:\nauto-petter auto-pets animals in a coop or barn (this keeps your animals content, but can't replace the full benefit of human touch);\nbone mill turns bone items into fertilizer;\ncoffee maker brews a fresh cup every morning;\ncookout kit lets you cook on the go;\ndark sign displays an item without consuming it;\ndeconstructor destroys crafted items, but salvages their most valuable material;\nfarm computer scans the farm and displays useful information;\ngeode crusher consumes coal to break open geodes.\nheavy tapper works twice as fast as a normal tapper;\nhopper auto-loads items placed inside into the machine in front of it;\nJunimo chests are linked to a global shared stash;\nmini-obelisks let you warp between two obelisks when placed on the farm;\nmini-shipping bins is a smaller shipping bin that can be placed outside the farm;\nostrich incubator when placed in a barn, hatches ostrich eggs into baby ostriches;\nsolar panel slowly generates battery packs when left in the sun;\nstatue of true perfection produces a prismatic shard each day;\nstone chest is a variant of chest crafted with stone instead of wood;\ntelephone calls stores to check hours and inventory, and occasionally receive random phone calls (no effect on gameplay);\nwarp totem: island warps to the Fern Islands.\nAdded new food items:\nbug steak;\nbanana pudding;\nginger;\nginger ale;\nmango sticky rice;\npi\u00f1a colada;\npoi;\ntaro root;\ntropical curry;\nsquid ink ravioli (temporarily prevents debuffs).\nAdded new fertilizers:\ndeluxe fertilizer increases chance of higher-quality crops;\ndeluxe retaining soil always keeps soil watered overnight;\nhyper speed-gro increases growth rate by at least 33%.", "mimetype": "text/plain", "start_char_idx": 87400, "end_char_idx": 91879, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c72fc260-06de-438a-817a-d472d58724b1": {"__data__": {"id_": "c72fc260-06de-438a-817a-d472d58724b1", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b2e9beca-33c1-4417-a602-a4c3ce72ec5a", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "d109c42f9840f0076c0520ff276b0f8c88ab0a3cf32c70a5b54455926c08ced7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5b7f37d-54ac-4182-8840-f1c3923a581a", "node_type": "1", "metadata": {}, "hash": "404a8009f890d4fe2b8c66794f9cee89540e2c571cfbc58fd6603991fd09c5f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Added new food items:\nbug steak;\nbanana pudding;\nginger;\nginger ale;\nmango sticky rice;\npi\u00f1a colada;\npoi;\ntaro root;\ntropical curry;\nsquid ink ravioli (temporarily prevents debuffs).\nAdded new fertilizers:\ndeluxe fertilizer increases chance of higher-quality crops;\ndeluxe retaining soil always keeps soil watered overnight;\nhyper speed-gro increases growth rate by at least 33%.\nAdded new items:\nbone fragment;\nFossilized Skull, Spine, Tail, Legs, and Ribs and snake skull, snake vertebrae;\ncinder shard;\ndragon tooth;\ntiger slime egg;\nfairy dust can used on a machine to have it finish processing;\ngolden walnut;\nmagma cap;\nmonster musk causes more monsters to spawn;\nmummified bat and mummified frog;\nostrich egg;\nQi gem;\nQi seasoning increases quality of cooked recipes;\nradioactive ore and radioactive bar;\ntaro tuber;\nhorse flute summons your horse when outside;\nmushroom tree seed.\nAdded new fishing tackle:\ncuriosity lure increases the chance to catch rare fish;\nquality bobber increases fish quality;\nmagic bait catches fish from any season/time/weather for a given location.\nAdded new quest items:\nAdvanced TV Remote\nArctic Shard\nEctoplasm\nGourmet Tomato Salt\nPierre's Missing Stocklist\nPirate's Locket\nPrismatic Jelly\nStardew Valley Rose\nWar Momento\nWriggling Worm\nAdded new rings:\nglowstone ring provides both light and increased item collection radius;\nhot java ring increases your chance to find coffee drinks when slaying monsters;\nimmunity band reduces chance of status debuffs by 40%;\nlucky ring increases luck by +1;\nphoenix ring restores some health after being knocked out once per day.\nprotection ring keeps you invincible longer after taking damage;\nsoul sapper ring restores a bit of energy after slaying a monster;\nthorns ring damages enemies when they attack you.\nAdded new hats:\n???;\ndark cowboy hat;\ndeluxe pirate hat;\nforager's hat;\ngoggles;\ngolden helmet;\nMr. Qi's hat;\npink bow;\nQi mask (secret);\nradioactive goggles;\nstar helmet;\nsunglasses;\nswashbuckler hat;\ntiger hat;\nwarrior helmet.\nAdded new clothing:\nbanana shirt;\nginger overalls;\nhot pink shirt;\nisland bikini;\nmagenta shirt;\ntropical sunrise shirt;\nyellow suit.\nAdded new shoes:\ncinderclown shoes;\nmermaid boots;\ndragonscale boots;\ncrystal shoes.\nAdded new weapons:\ndwarf sword, dwarf hammer, and dwarf dagger;\ndragontooth cutlass, dragontooth club, and dragontooth shiv;\ninfinity blade, infinity dagger, and infinity gavel;\niridium needle;\nossified blade;\nsome previously inaccessible items have also been made accessible.\nAdded new fish:\nstingray;\nlionfish;\nblue discus;\nlegendary fish:\nGlacierfish Jr.;\nLegend II;\nMs. Angler;\nRadioactive Carp;\nSon of Crimsonfish.\nAdded new furniture:\n35 paintings (many only found in festival shops or while fishing certain locations);\n14 bed variants;\nten rugs:\nblossom rug;\nfunky rug;\nicy rug;\nlarge cottage rug;\nlarge green rug;\nlarge red rug;\nlight green rug;\nmodern rug;\noceanic rug;\nold world rug;\neight 'floor divider' rugs that can be placed between rooms to join visually different floor types;\nfive fish tanks you can put fish in (including an Easter egg involving hats);\ndecorative trash can;\ngourmand statue;\niridium krobus;\nlarge brown couch;\nplain torch and stump torch;\nsquirrel figurine;\ntropical chair.\nAdded a new 'sconce' furniture type with seven options.\nAdded new flooring:\nrustic plank floor;\nstone walkway floor.\nAdded new debuffs from enemies:\nburnt (Speed -2, Defense -3);\ndarkness (dims lighting, making it harder to see in caves);\nfrozen (speed -8);\nnauseated (prevents you from eating or drinking anything);\nweakness (-20 Attack).\nAdded 17 new hair styles.\nAdded mail from Krobus with his own stationary.\nAdded new decorations and tweaks to many maps.\nAdded new Easter eggs:\nEaster egg when you change your name at the Shrine of Illusions to include item spawn codes;\ntitle screen 'happy face' secret;\nnew lucky purple shorts secret;\nnew strange capsule secret.\nEmily now visits Sandy on her birthday.\nClicking the pigs at the Festival of Ice now plays a pig sound.\nQuality of life changes\nAdded lost & found box in Mayor Lewis' house.", "mimetype": "text/plain", "start_char_idx": 91500, "end_char_idx": 95591, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5b7f37d-54ac-4182-8840-f1c3923a581a": {"__data__": {"id_": "b5b7f37d-54ac-4182-8840-f1c3923a581a", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c72fc260-06de-438a-817a-d472d58724b1", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "358a1b65c4021e9227488adb29012004b3dad8d2b2d1233c33ed8d606ff78f35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7499a60c-6249-48ee-9f90-85a5dcc341c5", "node_type": "1", "metadata": {}, "hash": "bccf6744630087b969131cd078f0b299a1876bc73501c93c7c346cb55a7441dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Added a new 'sconce' furniture type with seven options.\nAdded new flooring:\nrustic plank floor;\nstone walkway floor.\nAdded new debuffs from enemies:\nburnt (Speed -2, Defense -3);\ndarkness (dims lighting, making it harder to see in caves);\nfrozen (speed -8);\nnauseated (prevents you from eating or drinking anything);\nweakness (-20 Attack).\nAdded 17 new hair styles.\nAdded mail from Krobus with his own stationary.\nAdded new decorations and tweaks to many maps.\nAdded new Easter eggs:\nEaster egg when you change your name at the Shrine of Illusions to include item spawn codes;\ntitle screen 'happy face' secret;\nnew lucky purple shorts secret;\nnew strange capsule secret.\nEmily now visits Sandy on her birthday.\nClicking the pigs at the Festival of Ice now plays a pig sound.\nQuality of life changes\nAdded lost & found box in Mayor Lewis' house. This can be used to retrieve items donated to failed special orders, lost quest items and tools, items from offline players, hats from children that have been turned into doves, and items left behind in the Stardew Valley Fair grange display.\nYou can now sit on chairs (both placed furniture and chairs that are part of the map).\nYou can now place most furniture outside.\nYou can now talk to people while mounted on a horse.\nYou can now donate items of different qualities for the same community bundle ingredient.\nYou can no longer plant fruit trees on tiles they won't be able to grow on.\nImproved game menus and HUD:\nThe social tab now shows whether you talked to an NPC today.\nThe cooking tab now shows the recipe for an item when you hover over it.\nThe cooking tab now fades icons for recipes you know but haven't made yet.\nThe cooking/crafting tooltips now show the number produced.\nThe inventory menu's organize button now combines partial item stacks.\nThe inventory menu for a chest now shows the Community Center button.\nThe shipment screen now shows the unit price of shipped items instead of displaying the shipped quantity twice.\nThe quest log now shows an arrow in the morning when you have pending completed quests.\nBuff icons now subtly pulse when they're close to expiring.\nImproved shop menus:\nYou can now press `ESC` or controller `B` to move the held item to your inventory (or drop it if you have no more inventory room).\nWhile holding a purchase, the inventory now highlights items you can stack it with.\nImproved sprinklers:\nSprinklers can now water slime hutch troughs.\nHoes no longer remove sprinklers.\nImproved Journey of the Prairie King:\nProgress can now be saved and resumed, so it can be completed in multiple sessions.\nYou now also replay the original difficulty even if you've already completed it. (Previously it would increase difficulty automatically, which is now a New Game+ mode.)\nImproved game options:\nadded option to choose between multiple fish-bite chime sounds;\nadded option to mute farm animals and pets;\nyou can now scale the UI independently of the view zoom;\nincreased maximum zoom from 120% to 200%.\nImproved various items:\nThe jukebox now has a \"Random\" setting.\nRemoving a crystalarium that isn't ready for harvest will now drop the gem that was placed in it.\nYou can now push chests containing items by holding the interact button on them with no tool equipped (the same way you could previously remove empty chests without using a tool).\nImproved inventory sorting:\nno longer changes tool order;\nnow sorts by quality too;\nnow sorts names in alphabetical instead of reverse alphabetical order.\nImproved museum donation interactions:\nClicking an item now grabs one instead of the whole stack.\nPressing back while placing an item now returns to the inventory instead of closing the whole UI.\nOther minor improvements.\nImproved HUD:\nAdded a notification when you enter a farm building if an incubator is ready but the building is at max capacity.\nThe \"infestation\" indicator in the mines is now drawn alongside the floor number, rather than replacing it.\nBalance changes\nCombat changes:\nImmunity now reduces the chance of status debuffs.\nChanged special move cooldowns on daggers (6\u21923 seconds) and clubs (4\u21926 seconds).\nThe dagger special attack now pins the target in place until the last stab (which then knocks them back), so dagger hits are less likely to miss.\nReduced desperado profession's damage bonus from 3x to 2x.\nSlightly improved dagger critical hit chance.\nCrafting changes:\nChanged skull brazier recipe (was 10 hardwood + solar essence + coal; now 10 bone fragments).\nRepairing a fence now restores full fence health, instead of half the health of a new fence.\nFarming changes:\nLowered the cost of ducks (2000\u2192600g).\nDoubled the value of duck feathers.\nSlightly increased the duck feather spawn rate.", "mimetype": "text/plain", "start_char_idx": 94747, "end_char_idx": 99454, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7499a60c-6249-48ee-9f90-85a5dcc341c5": {"__data__": {"id_": "7499a60c-6249-48ee-9f90-85a5dcc341c5", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5b7f37d-54ac-4182-8840-f1c3923a581a", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "0b6e0ee684a7d3d0cfbd4c4eb7ab7fef02d2714a71c5df79e3259a595269778c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ae3db91f-256b-4c92-b8ba-c00b1a4b6526", "node_type": "1", "metadata": {}, "hash": "60e356446c1447701b3ad278173ea4e6de5d86efea1b31bcfad979e5024d7d99", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The \"infestation\" indicator in the mines is now drawn alongside the floor number, rather than replacing it.\nBalance changes\nCombat changes:\nImmunity now reduces the chance of status debuffs.\nChanged special move cooldowns on daggers (6\u21923 seconds) and clubs (4\u21926 seconds).\nThe dagger special attack now pins the target in place until the last stab (which then knocks them back), so dagger hits are less likely to miss.\nReduced desperado profession's damage bonus from 3x to 2x.\nSlightly improved dagger critical hit chance.\nCrafting changes:\nChanged skull brazier recipe (was 10 hardwood + solar essence + coal; now 10 bone fragments).\nRepairing a fence now restores full fence health, instead of half the health of a new fence.\nFarming changes:\nLowered the cost of ducks (2000\u2192600g).\nDoubled the value of duck feathers.\nSlightly increased the duck feather spawn rate.\nFishing changes:\nFishing rod tackle no longer loses endurance when catching junk.\nCatching a non-fish item no longer triggers the minigame.\nReaching an effective fishing level of 15+ now increases the rod casting range by one tile.\nMining changes:\nGem nodes now provide mining XP and can drop diamonds.\nGem node drops are no longer limited by mine level.\nItem drop changes:\nStumps and hollow logs now have a 10% chance of dropping mahogany seeds.\nAny monster in the Secret Woods now has a 10% chance of dropping mahogany seeds.\nSkeletons now have 4% chance of dropping a bone sword.\nWilderness golems now drop rice shoots more often.\nSome Skull Cavern monsters now have a small chance of dropping red cabbage seeds.\nPure-white slimes now drop diamonds and refined quartz.\nSome containers now drop better items after reaching the bottom of the mines at least once.\nDifferent drops now unlock on mine levels 60/80/100 and the first level of the Skull Cavern.\nReduced chance of lead rod drops on mine levels 60\u201379 (or Skull Cavern level 40+ before the previous fix), and added chance for shadow dagger and wood mallet.\nMine wood barrels can now drop basic retaining soil instead of sap.\nMine frost barrels can now drop quality retaining soil instead of sap.\nReduced chance of frost barrels dropping aquamarine, frozen geode, hardwood, jade, or equipment from 35% to 26%.\nShop changes:\nPierre will now sell his seasonal items year-round once you complete a certain new quest.\nAdded two more items to the Stardew Valley Fair star token shop.\nCoconuts can be purchased from Sandy on Monday. This is now limited to ten per day.\nThe slingshot and master slingshot are now sold at the Adventurer's Guild.\nReduced workbench price (3000\u21922000g).\nReduced earth obelisk and water obelisk prices (1000000\u2192500000g).\nMachine changes:\nSome machines' processing time was previously affected by the time of day. These have been standardized so they're always ready when the morning starts: bee house (every 4 days), mushroom box (every day), strange capsule (3 days), Tapper (depends on input), and worm bin (every morning).\nDoubled star token rewards for the slingshot and fishing minigames at the Stardew Valley Fair.\nFertilizer in the greenhouse no longer disappears on season change in some cases.\nThe random stone owl and strange capsule night events are now much less rare.\nMultiplayer changes\nAdded local split-screen multiplayer mode.\nThe join co-op screen now remembers the last IP you entered.\nFarmhands can now move buildings through Robin's menu. The host can configure how this works (disabled, enabled, or only for a player's own cabin).\nUsing the return scepter now returns farmhands to their cabin's front door instead of the host's farmhouse.\nAdded various new chat messages when a player does something.\nWhen viewing a shared event in multiplayer (such as the Community Center event, or Morris' introduction), you are no longer forcibly warped to the event location.\nWhen the host player sees the year 3 event, Grandpa's Theme is now added to all players' jukeboxes even if they weren't in-game at the time.\nInteraction changes\nReworked slingshot controls: it now aims at the cursor position, and is fired by holding and releasing the mouse/gamepad fire button. The previous mode (where you'd hold the button and pull back on the cursor to aim) can be re-enabled in the options menu if desired.", "mimetype": "text/plain", "start_char_idx": 98587, "end_char_idx": 102847, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ae3db91f-256b-4c92-b8ba-c00b1a4b6526": {"__data__": {"id_": "ae3db91f-256b-4c92-b8ba-c00b1a4b6526", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7499a60c-6249-48ee-9f90-85a5dcc341c5", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "595eba601e121bc0667ab9ee468f3fa281e5da38c1adc93a07ef2d7334b5fb1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f031d920-4ae9-49d1-bd44-c199365df8a7", "node_type": "1", "metadata": {}, "hash": "2cd431b9f4736a814f9b114f9ffdaeff1e0ae4543cb59b223ba121e83d44623d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Farmhands can now move buildings through Robin's menu. The host can configure how this works (disabled, enabled, or only for a player's own cabin).\nUsing the return scepter now returns farmhands to their cabin's front door instead of the host's farmhouse.\nAdded various new chat messages when a player does something.\nWhen viewing a shared event in multiplayer (such as the Community Center event, or Morris' introduction), you are no longer forcibly warped to the event location.\nWhen the host player sees the year 3 event, Grandpa's Theme is now added to all players' jukeboxes even if they weren't in-game at the time.\nInteraction changes\nReworked slingshot controls: it now aims at the cursor position, and is fired by holding and releasing the mouse/gamepad fire button. The previous mode (where you'd hold the button and pull back on the cursor to aim) can be re-enabled in the options menu if desired.\nTo simplify bulk actions like harvesting, holding down a button while moving will no longer repeat weapon special attacks, open/close barn/coop doors, or interact with boulders, chests, furniture, hollow logs, meteorites, shipping bins, or scarecrows.\nConstructed shipping bins now have a click-to-ship hitbox that better matches the original map-based shipping bin's hitbox.\nFlooring can now be applied by clicking on the tile the farmer is standing on. Previously, flooring had to be applied to a tile next to the farmer.\nPurchasing recipes with a full inventory no longer shows a message that the inventory is full.\nClicking an empty tile right above an interactive element (like a machine or chest) now activates the element, similar to clicking below it in previous versions.\nTrees chopped from above or below will now take into consideration the player\u2019s horizontal position when falling to the left or right.\nClicking near the bottom-left corner of the screen no longer brings up the chat box.\nYou can no longer open the quest log by pressing the on-screen journal button if you're currently doing something.\nYou can now use the \"Y\" key to answer dialogue boxes for holes and exit ladders in the mines.\nController improvements:\nWhen buying/betting tokens in the Stardew Valley Festival with a controller, holding the number selection button now causes the amount to increase faster.\nEvents can now be skipped on the controller even if a dialogue box is on-screen.\nPressing B on a controller while on a specific quest page now returns to the quest list instead of closing the menu.\nPressing B on a controller while an item is held on the crafting menu now snaps to the trash can (similar to the inventory screen).\nOther changes\nSave names are now based on the farm name instead of the player name. (Saves originally created before 1.5 will continue using the player name.)\nPenny and the Dwarf now like artifacts, all other NPCs dislike (instead of hate) them as gifts.\nImproved dinosaur sleep sprites.\nCharacters now face you when you talk to them instead of when the dialogue box closes (in singleplayer).\nOn the final day of a tracked quest, the timer now says \"final day\" instead of \"1 day\" for clarity.\nAdded many changes for modders; see completed wishlist items and mod migration guide for details.\nCosmetic tweaks to various sprites.\nFixes for multiplayer\nFixed an issue where fences would degrade faster in Multiplayer.\nFixed issue where a farmhand crashing while completing the final bundle could permanently prevent the unlock from properly triggering. It is now unlocked the next time a character enters the area.\nFarmhands are now properly positioned under the elevator instead of the ladder when using it to navigate the mines.\nFixed an issue where other farmers\u2019 emotes would not playback properly if you were watching an event.\nFixed a minor issue where multiple players getting the free coffee gift at the Night Market at the same time could prevent anyone from receiving it.\nFixed the note from Grandpa reappearing for farmhands.\nFixed issue where cows in Haley's photoshoot event could be seen sliding around for farmhands. (Non-actor characters in events are now controlled by the host.)\nFixes for player interaction\nFixed rare controller and mouse input drops.\nFixed being unable to remount a horse after dismounting it behind a shipping bin.\nFixed issue where it would sometimes be impossible to name an animal with a controller because the onscreen keyboard would appear and disappear in the same frame.\nFixed character customization screen's hair color slider not properly updating when hair color is randomized.\nFixed some farm tiles incorrectly preventing buildings from being placed on them.\nFixes for visual or cosmetic issues\nAdjusted the sorting of item ready indicators for tappers.\nUnified when night tiles get applied to fix inconsistencies when windows change from light to dark.\nThe critters list is now cleared out overnight.", "mimetype": "text/plain", "start_char_idx": 101939, "end_char_idx": 106814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f031d920-4ae9-49d1-bd44-c199365df8a7": {"__data__": {"id_": "f031d920-4ae9-49d1-bd44-c199365df8a7", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ae3db91f-256b-4c92-b8ba-c00b1a4b6526", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "4c21f6fc9939cc1091ffb1d1c93fec36e0ababf9e4a08c8a08c979985a19ba34", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d35edacc-5c9d-41c1-bf00-1231e1ee9712", "node_type": "1", "metadata": {}, "hash": "c63629a90b704c057c0fe8ce9a317732a52d172f0e1180ad177128a0b399f48d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed the note from Grandpa reappearing for farmhands.\nFixed issue where cows in Haley's photoshoot event could be seen sliding around for farmhands. (Non-actor characters in events are now controlled by the host.)\nFixes for player interaction\nFixed rare controller and mouse input drops.\nFixed being unable to remount a horse after dismounting it behind a shipping bin.\nFixed issue where it would sometimes be impossible to name an animal with a controller because the onscreen keyboard would appear and disappear in the same frame.\nFixed character customization screen's hair color slider not properly updating when hair color is randomized.\nFixed some farm tiles incorrectly preventing buildings from being placed on them.\nFixes for visual or cosmetic issues\nAdjusted the sorting of item ready indicators for tappers.\nUnified when night tiles get applied to fix inconsistencies when windows change from light to dark.\nThe critters list is now cleared out overnight. This fixes an issue where having a Butterfly Hutch in your house and repeatedly sleeping without leaving would spawn endless butterflies in the house.\nImproved various text:\nFixed some localizations using inches for fish measurements to reference centimeters.\nFixed mill description not mentioning rice.\nFixed typos in dialogue and events.\nFixed missing characters in Chinese and Korean fonts.\nFixed credits not showing localizer names correctly if the current language's font doesn't have the needed characters.\nImproved many translations.\nFixed various cosmetic/layering issues with character shadows.\nFixed characters in events snapping to strange animation frames when skipping an event.\nFixed various instances where the camera would pan unnecessarily after changing locations.\nFixed greenhouse trees taking on seasonal appearances.\nFixed tooltip for purchasing edible but non-health-restoring items (like crocus) showing price outside of the tooltip.\nFixed a single-frame flicker in Haley\u2019s 10-heart event.\nFixed a single frame flicker of the farm when starting a new game.\nFixed stamina bar showing sweat particles when fishing during the fishing competition.\nFixed the scythe showing the weapon ability cooldown effects.\nFixed the erroneous door tile visible on the south end of the standard farm during winter.\nFixed issue where unlocking multiple community center bundles at once would make the screen pan to the same room multiple times.\nFixed various issues related to the Festival of Ice map, like being able to escape the festival bounds or prematurely end the festival from certain tiles, and minor visual fixes.\nFixed terrain features showing an \"interact\" cursor when mousing over their tiles during festivals.\nFixed options page scrollbar sometimes going past the end of the scrollbar region.\nFixed various text overflow issues on the options page.\nFixed chests spawned on certain Skull Cavern floors being shifted down by 4 tiles.\nFixed tiling of\u2026\nfloor tiles in the farmhouse so applied flooring in adjacent rooms appear contiguous instead of having hard edges;\nwall tiles in the farmhouse to fix sorting of certain objects that extend outside normal tile boundaries (e.g., grass starter).\nthe fountain so that it has a more consistent appearance throughout the seasons;\nPierre's stand at the Egg Festival to fix layering issues.\nOther bug fixes\nFixed crash when resizing game window in some cases.\nFixed rare crash on launch due to invalid game window size options.\nFixed Iridium Bat kills not counting towards Adventurer's Guild bat eradication goal.\nFixed an issue where the Mermaid Show reward was delayed incorrectly.\nFixed some events showing a dark blue screen after fading out when viewed during rainy days.\nFixed museum-related rarecrows not sold at the Night Market after being unlocked.\nFixed issue where non-wooden gates would revert to wooden gates after saving & loading a game.\nFixed being able to add staircases to the Luau.\nFixed an item duplication exploit related to chest organization.\nFixed a minor desync in character pathfinding that could happen when characters pathed to the JojaMart on modded games.\nFixed Penny walking through walls on rainy days if you've completed the community upgrade.\nFixed Penny's 4-heart event not accessible once you finish the community upgrade.\nFixed fences not collected correctly after a divorce or Penny's 14-heart event.\nFixed characters greeting you when you enter a location when they're not present.\nFixed characters you divorced still greeting you when you enter a location.\nFixed issue where an NPC spouse fails to pathfind when a player/NPC is blocking the front door when they check, causing them to stand in place instead.\nFixed crops sometimes growing a day slower than they should.\nFixed applying flooring for the first time in an upgraded house sometimes causing the flooring in the kitchen to switch to the default wooden flooring.\nFixed issue where riding a horse while travelling from one location to another diagonally would repeatedly warp back and forth between the two locations.\nFixed watered slime hutch troughs emptied when you load a save. (This mainly affects loading a mid-day save on mobile.)\nFixed the community center not properly loading the refurbished map variant on game load.", "mimetype": "text/plain", "start_char_idx": 105846, "end_char_idx": 111100, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d35edacc-5c9d-41c1-bf00-1231e1ee9712": {"__data__": {"id_": "d35edacc-5c9d-41c1-bf00-1231e1ee9712", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f031d920-4ae9-49d1-bd44-c199365df8a7", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "1274b68cb5418a02cc32237139db8c03827cca360e99ff948ec86fcaabf7f257", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9aa789f7-9e08-46c1-942b-f3ff0d62ac3b", "node_type": "1", "metadata": {}, "hash": "2dcae2766411c40aec0b2143135602b2eb806162ccd2620215b3982c71804ab8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed Penny's 4-heart event not accessible once you finish the community upgrade.\nFixed fences not collected correctly after a divorce or Penny's 14-heart event.\nFixed characters greeting you when you enter a location when they're not present.\nFixed characters you divorced still greeting you when you enter a location.\nFixed issue where an NPC spouse fails to pathfind when a player/NPC is blocking the front door when they check, causing them to stand in place instead.\nFixed crops sometimes growing a day slower than they should.\nFixed applying flooring for the first time in an upgraded house sometimes causing the flooring in the kitchen to switch to the default wooden flooring.\nFixed issue where riding a horse while travelling from one location to another diagonally would repeatedly warp back and forth between the two locations.\nFixed watered slime hutch troughs emptied when you load a save. (This mainly affects loading a mid-day save on mobile.)\nFixed the community center not properly loading the refurbished map variant on game load. This caused characters like Maru to path incorrectly in them if the player had not visited the Community Center during that playthrough.\nFixed the weekly friendship boost for giving an NPC two gifts not applied if you also gave them a third gift for their birthday.\nFixed overnight lightning not randomized correctly, so either every overnight lightning would strike or none of them would.\nFixed issue where stones, wood, and weeds could spawn on top of terrain features when a new year begins.\nFurther changes were later released without changing the version number:\n21 December 2020 (appended to 1.5.1 post)\nFixed a crash when interacting with the Junimo notes in the Community center when playing in non-English.\n22 December 2020 (appended to 1.5.1 post)\nFixed malformed item data causing the game to crash when playing in Turkish.\n23 December 2020 (appended to 1.5.1 post)\nPlayers can now choose another player's character in local multiplayer. This allows players continuing multiplayer farms in local multiplayer to resume their old farmers.\nFixed shared events in multiplayer potentially putting players out of bounds.\nFixed the am/pm display not displayed properly in non-English languages.\nVarious localization fixes and changes.\n1.4.5\nStardew Valley 1.4.5 was released on 11 February 2020.\n\nBug fixes\nFixed an issue on Windows where the game would initialize incorrectly and start without audio.\nFixed an issue where passable objects, such as torches, could block you from attacking enemies that are standing nearby.\nYou can now reclaim the ancient seed crafting recipe from Gunther if you donated an Ancient Seed artifact and collected only the seed and not the recipe.\nFixed an issue that would allow animals to walk on certain water tiles alongside some bridges.\nWallpapers can no longer be used in place of items to be processed into artisan goods.\nFixed the Lewis statue letter not granting its reward in the Simplified Chinese localization.\n1.4.4\nStardew Valley 1.4.4 was released on 31 January 2020.\n\nChanges\nAdjusted dropped item pickups so that they're more responsive for clients in multiplayer and will \"rubber band back\" to their previous locations less frequently.\nAdjusted item collection code so that machines tucked in corners can be refilled without using cursor mode.\nFixed Elliott's 14-heart not properly working in non-English languages.\nFixed a data entry issue that caused some fish ponds to use incorrect data.\nFixed the Shrimp Enthusiast Shirt applying the wrong shirt artwork.\nFixed a soft-lock when watching the 2nd Fall movie in a non-English languages.\nFixed the cursor not appearing in the level up profession selector if the Controller Style Menus option is toggled off while using a controller.\nUnsuccessfully crafting an unstackable item while already holding an item on your cursor no longer grants you credit for crafting it.\nFixed an issue where garden pots would consume seeds without planting them if they were planted from more than a tile away.\nFixed the color selector sliders on the farmhand creation screen having incorrect navigation on controller.\nFixed the logic for fruit tree obstruction checking the wrong tile.\nFixed the dagger swipe sound effect repeating an extra time in multiplayer if another player is in the same area.\nKrobus will no longer get jealous if you gift characters you're dating after he moves in.\nPenny now leaves garden pots alone in her 14 heart event.\nFixed an issue that could cause Sam's 6 heart event to soft-lock.\nThe game now re-issues the player the Qi's Challenge quest if they had previously opened the mail, but dismissed it without accepting the quest.\nItems placed in an ex's room are now collected and placed in a chest after divorce.\nYou can no longer give away quest items or non-giftable items during the Feast of the Winter Star.", "mimetype": "text/plain", "start_char_idx": 110052, "end_char_idx": 114926, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9aa789f7-9e08-46c1-942b-f3ff0d62ac3b": {"__data__": {"id_": "9aa789f7-9e08-46c1-942b-f3ff0d62ac3b", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d35edacc-5c9d-41c1-bf00-1231e1ee9712", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "33dbbc7cb2b01fce8279ffa85c04ded531efc27708f4293c32d1cc4a02b1a305", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "05438a62-53d7-4818-9a2d-43184a83fc5c", "node_type": "1", "metadata": {}, "hash": "8339df05a68fda3c001c222e74c5743c60060bfef375848d7a0e6735ec0afd1c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed an issue where garden pots would consume seeds without planting them if they were planted from more than a tile away.\nFixed the color selector sliders on the farmhand creation screen having incorrect navigation on controller.\nFixed the logic for fruit tree obstruction checking the wrong tile.\nFixed the dagger swipe sound effect repeating an extra time in multiplayer if another player is in the same area.\nKrobus will no longer get jealous if you gift characters you're dating after he moves in.\nPenny now leaves garden pots alone in her 14 heart event.\nFixed an issue that could cause Sam's 6 heart event to soft-lock.\nThe game now re-issues the player the Qi's Challenge quest if they had previously opened the mail, but dismissed it without accepting the quest.\nItems placed in an ex's room are now collected and placed in a chest after divorce.\nYou can no longer give away quest items or non-giftable items during the Feast of the Winter Star.\nAdjusted some NPC gift reactions (Vincent and Jas now hate triple shot espresso, the Dwarf now loves lemon stone, and Sam now likes concession stand Joja Cola).\nAdjusted Desert map so that crab pots placed in the water no longer render incorrectly, and objects can no longer be placed on top of the Desert Trader.\nRemoved catfish from Willy's fishing quests during Winter, as it's impossible to catch one without a rain totem.\nFixed a crash that could occur on the host when a client connects to a game that was set to Friends or Invite Only that is now being hosted on a platform that doesn't support those online modes.\nFixed incorrectly looping ambient noise in the Deep Woods at night.\nFixed an issue where the Japanese localization's dialogue for a spouse watering your crops would incorrectly show both gender variants of the text.\nFixed the Simplified Chinese localization incorrectly showing sunflower seeds as a Fall only crop.\nRemoved the \u2018<\u2018 from the Simplified Chinese localization of the \"Pet loves you\" dialogue.\nFixed an issue where Junimos would show an empty text bubble when bringing a bundle to the Junimo hut after completing a bundle in Simplified Chinese or Korean.\nFixed an issue where viewing the Junimo note before learning to read it would cause certain text to permanently display much larger in the Simplified Chinese, Japanese, and Korean localizations.\nFilled in some missing characters in the Korean fonts. This fixes some instances where an asterisk appears instead of a Korean character.\nFixed a minor typo in Grandpa's note in the Korean localization.\n1.4.3\nStardew Valley 1.4.3 was released on 13 December 2019.\n\nBug fixes\nFixed an issue where you could collect multiples of a bundles reward in the Community Center if you closed the menu without collecting them.\nFixed an issue where naming your pet the name of an NPC could have your pet appear on the calendar on that NPC\u2019s birthday.\nFixed an item duplication exploit when using the add to existing stacks button on an inventory with a full stack.\nMade some fixes to the Turkish localization.\nFixed a bug in the crafting menu that could cause extra resources to be consumed in certain situations.\nAdjusted the Four Corners farm map to fix layering issue with buildings.\nFixed a bug where you could enter the Wizard's Tower before unlocking the Community Center.\nTaking a map screenshot while the option to show menu backgrounds is on will no longer render the menu in the screenshot.\nFixed an issue causing certain wallpapers to grant a Lost Book when selected in the catalogue.\nFixed an issue where you could get your grange score immediately after asking Lewis to judge your grange during the Stardew Valley Fair.\n1.4.2\nStardew Valley 1.4.2 was released on 4 December 2019.\n\nChanges\nReverted placement rules introduced in 1.4.1 which prevented players from placing flooring or torches on their spouse's porch tiles. Instead, spouses now ignore flooring and will \"pop off\" any torches that are placed on those tiles when they move there in the morning.\nBug fixes\nFixed the crane game crashing when it loads on Mac.\nFixed workbenches not pulling items from chests that are on rugs.\nFixed Robin staying in bed if she was upgrading certain buildings on game load.\nFixed a bug where buying a magic rock candy, exiting to title, and then reloading the game would cause the candy to not re-appear in the shop.\nFixed a crash when mashing the dialogue advance buttons while transitioning between maps during an event.\nFixed another way the club smash could cause the player to get \"stuck\" holding out a weapon.\nFixed some issues where non-user-initiated mouse movements could cause changes in mouse button states to not register.\nFixed a potential soft-lock if you passed out on another player's bed.\nFixed the screen being partially faded out when Demetrius comes to ask about the farm cave.", "mimetype": "text/plain", "start_char_idx": 113971, "end_char_idx": 118800, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "05438a62-53d7-4818-9a2d-43184a83fc5c": {"__data__": {"id_": "05438a62-53d7-4818-9a2d-43184a83fc5c", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9aa789f7-9e08-46c1-942b-f3ff0d62ac3b", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "461c3b13da0b69530909192572d5460b6c81052c1e4483a65ee831842eaf4a86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f860b520-f5d3-4245-ab13-d0aa77e046f2", "node_type": "1", "metadata": {}, "hash": "015b7bf1b977e038a0a39fce245a9b93c4d708d8a01d3eb64dc94dbf617f568e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Instead, spouses now ignore flooring and will \"pop off\" any torches that are placed on those tiles when they move there in the morning.\nBug fixes\nFixed the crane game crashing when it loads on Mac.\nFixed workbenches not pulling items from chests that are on rugs.\nFixed Robin staying in bed if she was upgrading certain buildings on game load.\nFixed a bug where buying a magic rock candy, exiting to title, and then reloading the game would cause the candy to not re-appear in the shop.\nFixed a crash when mashing the dialogue advance buttons while transitioning between maps during an event.\nFixed another way the club smash could cause the player to get \"stuck\" holding out a weapon.\nFixed some issues where non-user-initiated mouse movements could cause changes in mouse button states to not register.\nFixed a potential soft-lock if you passed out on another player's bed.\nFixed the screen being partially faded out when Demetrius comes to ask about the farm cave.\nFixed an issue where characters would greet you via speech bubble even if they weren't in the same location (e.g., Elliot welcoming you into his shack even though he's standing at the beach).\nFixed being able to perform certain actions (like using a return scepter) during overnight farm events.\nFixed farmers who are knocked out while holding an item not properly showing the knocked-out animation.\nFixed an issue where the tool being upgraded at Clint's could be set to an invalid value, causing Lewis to incorrectly send you a set of tools every night.\nClicking the emoji menu toggle button on gamepad no longer shows the onscreen keyboard.\nAdjusted rumble on third-party controllers. This may not fully solve issues on certain third-party controllers, but will at least prevent states where the rumble is stuck on.\n1.4.1\nStardew Valley 1.4.1 (previously known as 1.4.0.1, but renamed for compatibility with SMAPI) was released on 2 December 2019.\n\nNew features\nAdded Gamepad Mode to the options menu. This has three values: \"auto\" (default) switches between keyboard/mouse depending on the last input; \"force on\" forces the game to use gamepad logic, similar to earlier versions of Stardew Valley; and \"force off\" disables the gamepad and can be used if you only play the game using keyboard/mouse.\nYou can now buy the museum rarecrows from the Night Market after you've unlocked them.\nSome non-spouse NPC's now have custom movie ticket acceptance dialogue (in English only).\nBalance changes\nExplosive ammo now costs 300g each in the Adventurer's Guild, won't appear until you've unlocked the crafting recipe, and now only explodes with a 2-tile radius instead of 3.\nYou can now only buy one piece of magic rock candy per Thursday at the Desert Trader.\nIridium ore abundance now increases much more slowly beyond level 100 of the Skull Cavern.\nWeapon cooldowns now only happen if game time should pass.\nOther changes\nYou can now buy recipes with a full inventory.\nPenny's 14-heart event no longer removes placed dressers. Furniture that was supposed to be placed in an occupied tile is now added to the same chests Penny puts your objects in.\nVincent now loves snails.\nAdjusted shorts easter egg to give precedence to any normal interactions with the NPCs it affects (gifting, completing a quest, etc).\nSlightly optimized debris code.\nBug fixes\nFixed farmhands' separate wallets resetting to 500g if the host was playing on Linux or Mac.\nFixed the incorrect ordering of NPC gift tastes, so tastes should now match 1.3.\nFixed trash bear appearing on festival days (which could cause a potential crash).\nFixed an issue where reclaiming the insect head, Neptune's glaive, forest sword, or carving knife from Marlon would cause Clint to appear to be upgrading that weapon, losing any tool already being upgraded.\nFixed problem harvesting crops with the golden scythe.\nFixed being able to warp into the sewer on your horse, causing you to warp into the void.\nFixed an issue allowing torches and flooring to be placed on the spouses's porch position, so they couldn't come outside.\nFixed the golden scythe still appearing on the reaper after you've already received it.\nFixed a minor issue where players who have connected to a game and are creating a character while an achievement triggers would send a message saying \"- has earned the '(Achievement Name)' achievement.\"\nFixed a hole in the refurbished saloon room, which let players walk out of the map boundaries.\nFixed an issue where a farmhand entering a freshly built cabin could cause the farmhand that owns it to spawn in the upper-left corner of the main farmer's farmhouse.\nFixed fish pond silhouettes being incorrect after clearing the pond in multiplayer.", "mimetype": "text/plain", "start_char_idx": 117833, "end_char_idx": 122517, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f860b520-f5d3-4245-ab13-d0aa77e046f2": {"__data__": {"id_": "f860b520-f5d3-4245-ab13-d0aa77e046f2", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "05438a62-53d7-4818-9a2d-43184a83fc5c", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "be9bb8a6d79f9ac5f08b45199cf80a0020243951fc5c41bf1311fa8af4779d10", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5404591-a116-4806-8023-6d2bfb98049f", "node_type": "1", "metadata": {}, "hash": "9b39070139037847c299d0a2fb04306174cfe92146b1e751020542c9defa047c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed problem harvesting crops with the golden scythe.\nFixed being able to warp into the sewer on your horse, causing you to warp into the void.\nFixed an issue allowing torches and flooring to be placed on the spouses's porch position, so they couldn't come outside.\nFixed the golden scythe still appearing on the reaper after you've already received it.\nFixed a minor issue where players who have connected to a game and are creating a character while an achievement triggers would send a message saying \"- has earned the '(Achievement Name)' achievement.\"\nFixed a hole in the refurbished saloon room, which let players walk out of the map boundaries.\nFixed an issue where a farmhand entering a freshly built cabin could cause the farmhand that owns it to spawn in the upper-left corner of the main farmer's farmhouse.\nFixed fish pond silhouettes being incorrect after clearing the pond in multiplayer.\nFixed a typo causing plant seeds being removed from the inventory when unsuccessfully attempting to plant them outside of the farm.\nFixed pre-1.4 untyped \"Honey\" items that were misnamed \"Wild Honey\"; they're now just converted to \"Wild Honey\" that stacks with other \"Wild Honey\" items.\nFixed a crash when tree fertilizer recipe is added to a save that already has it.\nFixed the dove subplot enemy leaving visual trails on the host's machine regardless of the location they were in.\nFixed non-synchronization of items recovered from Marlon at the Adventurer's Guild.\nFixed the display name of flounder in Russian being the same as halibut.\nFixed a botched after-movie dialogue from Evelyn.\nFixed the direction of the fold on the Gi clothing items.\nFixed tea saplings not being placeable on certain tiles on the farm.\nFixed a crash when checking the calendar while engaged to another farmer that is currently disconnected from the game.\nFixed problem where you could soft-lock a shop menu in an edge case scenario.\nController fixes:\nFixed some inconsistencies with cursor placement when item stowing is on.\nFixed an issue where using the trigger buttons to swap pages in the Junimo Bundle menu while holding an item would cause it to be lost.\nFixed an issue in the quest log where if you moved the cursor right from the \"back\" button when viewing a quest description on the second or higher page of the quest log, the cursor would move to an invalid position.\nHighlighting a dropdown menu option in the options screen on the controller now snaps to the drop down button, no longer obscuring the text.\nWhen a dialogue question is asked, the first selectable option is now selected by default in controller mode, regardless of whether the controller-style menus option is enabled.\nCorrected the fix for the Stardew Valley Fair festival's petting zoo area appearing incorrectly if certain post-game conditions had been unlocked.\nAdded a graceful fail state to the function that gets a wedding for the day in case there's a completely invalid farmer ID in the farmers list (potentially from a removed cabin).\nPlayers that could have missed increases to their max health, crafting recipes due to skipping combat skill levels will now earn them on level load.\nPending level-ups are now removed from characters as they are applied, instead of all at once at the end of the night. That ensures that a character who gets disconnected/crashes during a level-up can now reapply their level-ups the next time they are connected.\nAdjusted the requirements to be able to respec a skill at the Statue of Uncertainty to allow users who have \"missed levels\" to reclaim their missed perks levels using it.\nPotential fix for switching over to the scythe after using the club slam repeat quirk causing the next used tool to soft-lock the player in place.\nFixed various typos.\nFixed crash if a location no longer exists in the game, for players with residual mod data in their save file.\nFixed the /friendAll debug command granting friendships to NPCs that aren't friendable, which could possibly cause issues on any game mechanics that randomly select a friend (e.g., daily quests).\n1.4\nStardew Valley 1.4.0 was released on 26 November 2019.\n\nNew content and features\nAdded movie theater unlocked in late game, with related content and features.\nAdded 14-heart events for every spouse.\nAdded new events and dialogue (including a new heart event for Caroline).\nAdded clothing items equipped on the player (replaces former clothing appearance options).\nAdded clothes tailoring and dyeing.\nAdded 24 new hair styles, including bald heads.\nAdded Four Corners farm map (meant for co-op, divides the land into four areas with their own perks).\nAdded fish ponds to breed fish and produce items.", "mimetype": "text/plain", "start_char_idx": 121614, "end_char_idx": 126283, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e5404591-a116-4806-8023-6d2bfb98049f": {"__data__": {"id_": "e5404591-a116-4806-8023-6d2bfb98049f", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f860b520-f5d3-4245-ab13-d0aa77e046f2", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "ac1963e0dfcf02904f643ee7957f1b4b46ede45dce1f458f7a72440eeed100a4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "545a7bd1-ecba-4550-abee-dcf4d198df60", "node_type": "1", "metadata": {}, "hash": "721c1e250b96c67fe698927556d310c0415c3cefcb7a3eca4e78d415b1781ea3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed various typos.\nFixed crash if a location no longer exists in the game, for players with residual mod data in their save file.\nFixed the /friendAll debug command granting friendships to NPCs that aren't friendable, which could possibly cause issues on any game mechanics that randomly select a friend (e.g., daily quests).\n1.4\nStardew Valley 1.4.0 was released on 26 November 2019.\n\nNew content and features\nAdded movie theater unlocked in late game, with related content and features.\nAdded 14-heart events for every spouse.\nAdded new events and dialogue (including a new heart event for Caroline).\nAdded clothing items equipped on the player (replaces former clothing appearance options).\nAdded clothes tailoring and dyeing.\nAdded 24 new hair styles, including bald heads.\nAdded Four Corners farm map (meant for co-op, divides the land into four areas with their own perks).\nAdded fish ponds to breed fish and produce items.\nAdded new items:\n181 shirts;\n35 hats;\n14 pants (including dresses, skirts, and shorts);\n2 boots;\n38 decorative items obtained in various ways (e.g., new events);\n17 new flooring options;\n2 new secret notes;\ntwo fish: flounder and midnight carp;\ntwo rings: crabshell ring and napalm ring;\nartifact troves (can be broken open by Clint to yield artifacts);\ncaviar, roe, and aged roe;\ndark sword;\ndeluxe scarecrow (recipe given when you collect all rarecrows, has double the radius);\ndinosaur mayonnaise (processed from dinosaur eggs);\ngolden scythe;\ngrass starter recipe (purchased from Pierre);\nmagic rock candy;\nmini-jukebox (place anywhere on the farm or in farm buildings to play previously-heard music);\nmini-fridges (place inside to extend your fridge capacity);\nrice crop;\nseafoam pudding (fishing level 9 cooking recipe);\nshrimp cocktail (recipe learned from the Queen of Sauce episode on Winter 28 Y2);\nsquid ink;\nsunflower honey (produced by beehouses);\ntea bushes, tea leaves and green tea;\ntraining rod (easier fishing but only catches common fish);\ntree fertilizer (non-fruit trees grow more quickly);\ntriple shot espresso;\nvoid ghost pendant;\nwarp totem: desert;\nwilted bouquet (crafted from a bouquet), which lets you break up with NPCs you're dating;\nworkbench (lets you craft with ingredients in adjacent chests);\nwood chipper (breaks hardwood and driftwood into wood).\nAdded new mine content:\na quarry mineshaft dungeon with new haunted skull and sludge monsters, and a Golden Scythe;\nprehistoric floors in the Skull Cavern with a new pepper rex monster;\nrare alternative floors in the 1-120 mines after unlocking the quarry similar to the quarry mineshaft dungeon.\nAdded shed upgrade (doubles the interior size).\nAdded cat/dog breeds selectable from the new-character customisation menu or the Shrine of Illusions.\nAdded Krobus as a potential roommate if you're unmarried.\nAdded a desert trader that sells new items.\nAdded Trash Bear to clean up trash around town in year 3+.\nAdded 4 new monster eradication goals & prizes.\nAdded 4 new museum reward levels (for donating 35, 70, 80, and 90 items).\nAdded trash can upgrades purchasable from Clint (gives 15-60% of trashed items' value as money).\nAdded a new sunroom in Pierre and Caroline's house.\nAdded the ability to perform various emotes through a new menu (default key is Y).\nAdded a new farm building: desert obelisk.\nAdded winter flooring sprites.\nAdded hidden subplot if you've turned children into doves. (Spoilers: check the television on Fall 26, then visit the Witch's Hut for a recurring effect and fish on the Four Corners farm for a one-time effect.)\nAdded experimental support for letting farmhands move buildings. Use the /movebuildingpermission command to toggle between on (farmhands can move any building), owned (they can move their own cabins or buildings they've built themselves), or off (default).\nAdded a new trash bin in front of JojaMart.\nAdded map export feature (except on 32-bit Linux), accessed via a button in the options menu or the /mapscreenshot chat command. Screenshots are saved in the appdata folder on Windows, and ~/.local/share/StardewValley/Screenshots/ on Linux; click a button in the options screen to open it. When using the command, you can optionally specify a filename and percentage size like /mapscreenshot test 25.\nAdded VSync option. Disabling VSync may improve overall framerate at the expense of frame rate stability.", "mimetype": "text/plain", "start_char_idx": 125352, "end_char_idx": 129722, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "545a7bd1-ecba-4550-abee-dcf4d198df60": {"__data__": {"id_": "545a7bd1-ecba-4550-abee-dcf4d198df60", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5404591-a116-4806-8023-6d2bfb98049f", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "c26225207b605a75c4c86eefe63772a0a46a141c38999d9a12a365cd67854261", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b6c8e8d-b6e0-4bf8-8931-e18beb1fe4c2", "node_type": "1", "metadata": {}, "hash": "5a728f2a56539fe5c8d342a9f67d122cfcb84d7418ffc13d61b63a00c5b4d639", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Added experimental support for letting farmhands move buildings. Use the /movebuildingpermission command to toggle between on (farmhands can move any building), owned (they can move their own cabins or buildings they've built themselves), or off (default).\nAdded a new trash bin in front of JojaMart.\nAdded map export feature (except on 32-bit Linux), accessed via a button in the options menu or the /mapscreenshot chat command. Screenshots are saved in the appdata folder on Windows, and ~/.local/share/StardewValley/Screenshots/ on Linux; click a button in the options screen to open it. When using the command, you can optionally specify a filename and percentage size like /mapscreenshot test 25.\nAdded VSync option. Disabling VSync may improve overall framerate at the expense of frame rate stability.\nAdded an NPC gift log accessed through the social tab (tracks birthdays, their liked/disliked gifts as you discover them in-game, etc).\nAdded 'advanced crafting info' option which shows more info on the crafting menu (including number of times crafted and the number of each ingredient available).\nAdded OST files for new music tracks.\nAdded new easter egg on the title screen.\nJunimo Kart has been completely redone and is now actually fun.\nDressers can now be used to store clothing, hats, shoes, and rings.\nWhen you catch a silver or gold-quality fish, a 'perfect' catch now increases the quality by one. (This is the only way to get iridium-quality fish.)\nYou can now put hats on your children (once they can walk).\nYou can now play Elliott's piano.\nYou can now put gemstones in Junimo huts to affect the color of new Junimos.\nDivorced spouses no longer attend your wedding.\nDivorced spouses no longer treat their exes normally during Festivals.\nAuto-Grabbers now work in the coop too.\nSuccessfully parrying a slime attack now prevents the slimed debuff.\nSeaweed can now be foraged along the bottom shore of the tidal pool beach.\nThe adventurer's guild now sells any boots you already found in mine chests.\nYou can no longer load saves created in a newer version of the game than you have. (This will only affect future versions of the game.)\nMultiplayer changes\nAdded optional separate money in multiplayer.\nAdded support for private chat messages.\nAdded more multiplayer \"server messages\".\nAdded a /ping chat command which prints the current ping to the host (for farmhands) or to each farmhand (for the host).\nAdded a /kick <farmer name> chat command.\nAdded /ban and /unban chat commands. Bans are per-farm, and the command can be called with a farmer name, user ID, or IP address. in all cases it will ban the user, not the farmhand character.\nAdded multiplayer synchronization for\u2026\ndaily luck;\nbulletin board quests (in most cases);\ntrains;\nlightning bolts;\nmine fog events;\nlost book collection;\nmerchants' limited stock;\ndrum/flute blocks;\nadjustments to the fishing bobber's position while it's midair;\nthe animation when a player has a fish on the line.\nWhen creating a new multiplayer form, the Starting Cabins option now defaults to 1 instead of None.\nEach player now has a separate mailbox and spouse porch area.\nEach player can now build a separate cellar.\nWhen a player drops an item in multiplayer, other nearby players now have priority for picking it up.\nYou can now see other players' scores during certain festivals in Multiplayer.\nQuests in multiplayer now set difficulty based on the highest-level player.\nIn the Skull Cavern, mine shafts now drop players to the same level in multiplayer.\nIn multiplayer, many random checks now use the team's average luck instead of only the host's luck.\nIf connecting to a multiplayer server fails, the game will now retry internally before giving up.\nThe reward for completing the Bulletin Board bundle is now applied to all players in multiplayer.\nMoving a Shipping Bin no longer leaves behind its lid for other players on a multiplayer farm.\nQuality of life changes\nAdded ability to rearrange the museum artifacts (without donating a new one).\nAdded ability to reread received letters anytime via the collections tab.\nAdded ability to rotate the toolbar (using Tab and Ctrl+Tab by default).\nAdded ability to fill existing stacks in a chest from your inventory.\nAdded notification when a tool being upgraded is ready.\nAdded tabs to the Catalogue and Furniture Catalogue.\nAdded current Qi coin balance to Calico Jack minigame UI.\nAdded support on Linux for pasting invite codes via an onscreen button (requires xclip).\nAdded upcoming weddings to in-game calendar.\nAll events should now be skippable.", "mimetype": "text/plain", "start_char_idx": 128915, "end_char_idx": 133484, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b6c8e8d-b6e0-4bf8-8931-e18beb1fe4c2": {"__data__": {"id_": "8b6c8e8d-b6e0-4bf8-8931-e18beb1fe4c2", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "545a7bd1-ecba-4550-abee-dcf4d198df60", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "1117592e666e28f4ec600fea244bdd91518af308d474347a07dd44c4df1b36e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "927adbe4-83f6-45dd-9f54-e008b9e2bea6", "node_type": "1", "metadata": {}, "hash": "617384e4be37115d43c5ff5b89adedcf631a592758a77491361f1c7cf0d4d4a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If connecting to a multiplayer server fails, the game will now retry internally before giving up.\nThe reward for completing the Bulletin Board bundle is now applied to all players in multiplayer.\nMoving a Shipping Bin no longer leaves behind its lid for other players on a multiplayer farm.\nQuality of life changes\nAdded ability to rearrange the museum artifacts (without donating a new one).\nAdded ability to reread received letters anytime via the collections tab.\nAdded ability to rotate the toolbar (using Tab and Ctrl+Tab by default).\nAdded ability to fill existing stacks in a chest from your inventory.\nAdded notification when a tool being upgraded is ready.\nAdded tabs to the Catalogue and Furniture Catalogue.\nAdded current Qi coin balance to Calico Jack minigame UI.\nAdded support on Linux for pasting invite codes via an onscreen button (requires xclip).\nAdded upcoming weddings to in-game calendar.\nAll events should now be skippable.\nGates can now be attached to one piece of fencing (instead of needing fences on both sides), which allows for double-width gates.\nThe hallway to the spouse's room in a two-story farmhouse now matches the bedroom flooring.\nChanged interaction cursor when pointing at farm animals you haven't pet today.\nGiving datable NPCs a gift no longer makes your spouse jealous unless you're currently dating them.\nYou can now construct/move farm buildings onto tilled dirt and tree seeds.\nTrying to construct/move farm buildings onto an animal now poke them out of the way.\nCollapsing in the mines no longer makes you forget levels.\nAfter collapsing in the mines and losing items, a list of lost items is now shown and you can pay Marlon to recover one of them.\nYou can now remove horse hats (by interacting with the horse while holding another hat).\nYou can now trash copper pans and slingshots.\nYou can now buy copper pans from Willy's shop after receiving the first one.\nYou can now stack craftable items in inventories (like kegs or furnaces).\nYou can now attach baits, tackles, etc. to your fishing rods directly from a treasure chest.\nYou can now shift-click items to move them out of the toolbar.\nYou can now hold down the interact button without retriggering the eat item prompt. That lets players quickly refill rows of kegs/preserves jars without being interrupted by the prompt.\nYou can now go to sleep while holding an item.\nYou can now pause Junimo Kart by pressing Enter or P.\nYou can now play Junimo Kart entirely with the keyboard.\nYou can no longer place iridium-quality items in casks.\nMade it easier to collect milk/wool from farm animals. Animals now have a larger hitbox, and using shears/pail while facing multiple animals now finds the best match instead of the first one.\nInteracting with a Mill that only has one type of item in it now automatically collects the item instead of opening a chest menu.\nPointing at an inventory item needed for a bundle now makes the Junimo bundle button pulsate.\nPointing at an item to sell in the shop menus now shows the \"Gunther can tell you more\" text if the item hasn't been donated yet.\nMushroom tree sprouts are now distinguishable from other trees.\nWild Bait now provides a chance to catch two fish at once.\nPets no longer spawn in positions that block the farmhouse door or corridors.\nWhen exiting a Junimo bundle menu, the cursor highlights the bundle that was exited.\nFarm animals standing on crops no longer prevent the crop from being harvested.\nA message now appears when fruit tree growth is prevented by a surrounding obstruction.\nWhen an NPC walks over a chest, it will now dump its contents out instead of destroying them.\nWhen viewing a bundle, inventory items for completed slots are now grayed out.\nJumping down a mineshaft just above level 100 will no longer drop you below level 100 in the Skull Cavern.\nPlayers can now \"push\" through NPCs at festivals, to avoid getting trapped in some cases.\nQueen of Sauce reruns will now choose an already-aired recipe that a player doesn't know.\nThe animation played when finding a new lost book is now only played once per player.\nUnclaimed bundle rewards can now be picked up from a Junimo bag in the Community Center.\nWild tree seeds can now be placed in any diggable tile outside of the farm without needing to hoe it first.\nWhen you dismiss the map by clicking on it, you're now returned to the previous menu tab (if any).\nWilted trellis crops no longer block movement.\nThe Hat Mouse now sells hats you've won in festival competitions.\nMoving the cursor over a crab pot while holding the action button no longer picks it up.\nMoving the cursor over a farm animal while holding the action button no longer opens the inspection menu (so it's easier to pet animals).", "mimetype": "text/plain", "start_char_idx": 132538, "end_char_idx": 137258, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "927adbe4-83f6-45dd-9f54-e008b9e2bea6": {"__data__": {"id_": "927adbe4-83f6-45dd-9f54-e008b9e2bea6", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b6c8e8d-b6e0-4bf8-8931-e18beb1fe4c2", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "bc7f83ae7220b8e0a09659e1d02c5686c11d993e898c80553061c97627736361", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81f40d50-b18f-43de-bb9f-1f3e9a826fe4", "node_type": "1", "metadata": {}, "hash": "e216d72ff053278ec4a67608e26fa271c21c11e740a6165df09245a23df72b96", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Players can now \"push\" through NPCs at festivals, to avoid getting trapped in some cases.\nQueen of Sauce reruns will now choose an already-aired recipe that a player doesn't know.\nThe animation played when finding a new lost book is now only played once per player.\nUnclaimed bundle rewards can now be picked up from a Junimo bag in the Community Center.\nWild tree seeds can now be placed in any diggable tile outside of the farm without needing to hoe it first.\nWhen you dismiss the map by clicking on it, you're now returned to the previous menu tab (if any).\nWilted trellis crops no longer block movement.\nThe Hat Mouse now sells hats you've won in festival competitions.\nMoving the cursor over a crab pot while holding the action button no longer picks it up.\nMoving the cursor over a farm animal while holding the action button no longer opens the inspection menu (so it's easier to pet animals).\nMoving the cursor over a scarecrow while holding the action button no longer checks it (so it's easier to harvest large fields).\nImproved the 'Organize Inventory' logic. Now properly handles empty spaces on Linux, and sorts stacks from highest to lowest quantity.\nChanged processing time of tapped mushroom trees so that they're harvestable in the morning (instead of midway through the day).\nObelisks now have a 3x2 footprint instead of 3x3. (Their sprites are unaffected.)\nDropping an item when collecting rewards from Gunther now throws the item downwards instead of upwards, to prevent players without magnet rings from dropping items into out-of-reach positions.\nBalance changes\nFruit trees no longer need the surrounding tiles to be empty to increase in quality once fully grown.\nFruit trees are no longer blocked from growing by non-colliding objects (notably artifact spots).\nMushroom trees no longer drop wood (and debris chunks are now white instead of brown).\nYou can now increase friendship by talking with NPCs at festivals.\nTrains now drop more items.\nSome items no longer appear in random shop stocks: void eggs, void mayonnaise, and sweet gem berries.\nThe quarry now spawns oak & maple trees.\nCharcoal kilns now require 2 copper bars (instead of a gold bar).\nCheese now sells for more.\nCloth now drops more often from mummies.\nDressers now cost more.\nLooms can now produce multiple cloths when higher-quality items are input.\nPancakes can no longer be bought from Krobus before winter Y1.\nSturdy ring is now easier to craft.\nJourney of the Prairie King has been rebalanced.\nCalico Jack and slot machines in the casino now statistically favor the player. (Previously the player was more likely to lose.)\nThe Forester profession now causes 25% more wood to drop from trees/stumps/logs, instead of raising the value of wood by 50%.\nSpeed-gro and retaining soil can now be applied to crops anytime.\nBasic and quality fertilizers can be applied to seeds (but can't be applied once a seed has sprouted).\nRebalanced the frequency that secret notes are dropped.\nFishing tackle now sells for less once damaged, depending on its remaining durability.\nSweet gem berry can no longer be bought from the traveling cart (you can only buy the seeds).\nBean hotpot now grants max energy +30 and magnetism +32, instead of showing \"max energy +2\" but granting nothing.\nSpring onions quality is now determined at the start of the day.\nThe Legend can now only be caught once.\nMade bottom edge of fishing bobber bar slightly more generous.\nThe effect of fishing level on fish size no longer caps at 10.\nDebris now respawns at the start of spring in Cindersap Forest, Town, and the Railroad.\nReduced cases of items splashing into water when they're visually on dry land.\nLightning rods are now always harvestable immediately the day after being struck.\nWheat now has a 40% chance to also drop hay on harvest.\nWild bait can now be obtained from fishing treasure chests if you know the crafting recipe.\nFixed the burglar's ring not affecting some monster loot items (those added programmatically).\nReduced recipe prices in the Stardrop Saloon.\nImproved controller support\nAdded an on-screen keyboard to type into chat or text fields using the controller.\nAdded ability to stow an item when playing with the controller, freeing up your hands to interact with NPCs without accidentally gifting them items.\nAdded a left/right bumper hotkey in inventory menus. when the new 'add to existing stacks' button is available, pressing the hotkey will automatically snap to that button for easier inventory consolidation.\nYou can now highlight the list of required items in the Junimo bundle screen while using a controller, so you can see a tooltip with the item's description.", "mimetype": "text/plain", "start_char_idx": 136357, "end_char_idx": 141016, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "81f40d50-b18f-43de-bb9f-1f3e9a826fe4": {"__data__": {"id_": "81f40d50-b18f-43de-bb9f-1f3e9a826fe4", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "927adbe4-83f6-45dd-9f54-e008b9e2bea6", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "615549a4973b45a5bfc14087fd119f2a97f898e0319882a716ee6065b3fd4c88", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e074541d-bae1-4485-bd00-fde53ef59930", "node_type": "1", "metadata": {}, "hash": "4be2d4d1fd15ee5560d3fb3b12fbf10b610ac1beaeeed82455346fcb034fcf4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Lightning rods are now always harvestable immediately the day after being struck.\nWheat now has a 40% chance to also drop hay on harvest.\nWild bait can now be obtained from fishing treasure chests if you know the crafting recipe.\nFixed the burglar's ring not affecting some monster loot items (those added programmatically).\nReduced recipe prices in the Stardrop Saloon.\nImproved controller support\nAdded an on-screen keyboard to type into chat or text fields using the controller.\nAdded ability to stow an item when playing with the controller, freeing up your hands to interact with NPCs without accidentally gifting them items.\nAdded a left/right bumper hotkey in inventory menus. when the new 'add to existing stacks' button is available, pressing the hotkey will automatically snap to that button for easier inventory consolidation.\nYou can now highlight the list of required items in the Junimo bundle screen while using a controller, so you can see a tooltip with the item's description.\nImproved controller navigation/use in\u2026\nthe museum donation screen;\nthe Load Game and Join/Host Coop Game menus;\nthe bundle screen (no longer need to scroll all the way to the right to access the second row);\nchest and item grab screens;\ncrafting menu.\nImproved switching between keyboard/mouse and controller mode. For example, having a controller plugged in no longer snaps mouse input to buttons.\nImproved placement logic with a controller (planting seeds, placing furniture, etc).\nYou can now direct your fishing casts with a controller.\nThe buffs display tooltip is now hidden if the mouse cursor isn't visible.\nFixed cursor snapping to upper-left item when clicking the organize items buttons on the controller.\nFixed D-Pad not correctly selecting dialogue options.\nFixed an issue making the animal pregnancy disable option unselectable with a controller.\nFixed navigation of the languages menu using a controller.\nFixed an issue where rearranging artifacts in the museum didn't work with controller-style menus.\nFixed various issues related to selecting dialogue choices with a controller.\nFixed being able to move the cursor on the shipment screen after the screen is dismissed with the OK button on a controller.\nFixed cursor slightly misaligned on the skills screen when you first enter it using a controller.\nFixed various issues related to the display of the cursor in the level up screens with a controller.\nFixed some issues with controller navigation of the items in the wallet section of the skills tab.\nFixed controller navigation of dropdown lists in the options screen.\nFixed an issue where the controller's left thumbstick was moving the mouse cursor around while playing minigames.\nFixed an issue where using the face buttons to aim shots in Journey of the Prairie King on the controller would sometimes cause the shots to go in the wrong direction and cause the player to get stuck shooting.\nFixed chest color picker buttons being selectable if the color picker isn't shown.\nOther changes\nVarious copyediting, improved text, tweaked sprites, and tweaked map tiles.\nMade some optimizations that may improve performance on some machines/platforms or in some cases.\nImproved many translations and fixed missing font characters in Korean.\nChanged midnight from 12:00 to 0:00 in Japanese.\nAdded an open sprite to the fridge.\nAdjusted the mail received after collapsing to more accurately reflect timeline changes in the game.\nAdjusted a dialogue option in Penny's 2-heart event to be more considerate of George's perspective.\nRemoved the Junimo Note/Community Center Button from non-inventory screens.\nImproved Elliott's cabin interior design a bit.\nItems found in the trash now pop out of the trash instead of going directly into your inventory.\nUpdated credits.\nIn single-player, the mines now reset as soon as you leave instead of waiting for the next 10-minute update.\nNPCs now destroy trees in their path (and will trample wild tree seeds underfoot).\nNPCs now close their eyes and do a sleep pose when they go to bed.\nPlayers now close their eyes when they go to bed.\nPenny no longer randomly reveals Pam's taste for alcoholic items.\nFish sold to Willy are now resold in his own shop (fish are no longer sold at Pierre's).\nTweaked hoed dirt color on the beach in fall.\nMade David's cage look more appropriate for guinea pigs.\nReduced splash effect of small cosmetic debris to make it easier to distinguish splash of actual items.\nAdded animation when digging through trash.\nAdjusted sound made when picking up forageables, eggs, etc.\nAdded changes for modders.\nAdded log for unexpected network disconnects (in a separate DisconnectLogs folder).\nThe ordering of the items on the collections page is now consistent between languages.\nFixes for gameplay\nDismissing a letter with unclaimed items now automatically picks up the items.\nYou can no longer activate the Statue of Uncertainty if you haven't met the level requirements.\nYou no longer take damage from monsters while passing out at 2am.", "mimetype": "text/plain", "start_char_idx": 140022, "end_char_idx": 145029, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e074541d-bae1-4485-bd00-fde53ef59930": {"__data__": {"id_": "e074541d-bae1-4485-bd00-fde53ef59930", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81f40d50-b18f-43de-bb9f-1f3e9a826fe4", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "8dbf849733a2a9a387a90cf47eb4e21dd00d0f84f3aef9aff6ae211e71a909fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa3f327a-b69d-4829-9e91-8c63b826e51d", "node_type": "1", "metadata": {}, "hash": "03a0c9608a966b7017d73848199d3697c13ebef4c224789786fd35c2842cba65", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Penny no longer randomly reveals Pam's taste for alcoholic items.\nFish sold to Willy are now resold in his own shop (fish are no longer sold at Pierre's).\nTweaked hoed dirt color on the beach in fall.\nMade David's cage look more appropriate for guinea pigs.\nReduced splash effect of small cosmetic debris to make it easier to distinguish splash of actual items.\nAdded animation when digging through trash.\nAdjusted sound made when picking up forageables, eggs, etc.\nAdded changes for modders.\nAdded log for unexpected network disconnects (in a separate DisconnectLogs folder).\nThe ordering of the items on the collections page is now consistent between languages.\nFixes for gameplay\nDismissing a letter with unclaimed items now automatically picks up the items.\nYou can no longer activate the Statue of Uncertainty if you haven't met the level requirements.\nYou no longer take damage from monsters while passing out at 2am.\nFixed various exploits, including\u2026\nopening the journal while fishing paused time but still caught fish;\nopening the journal while dying skipped the death event and prevented losing items;\nyou could use an incorrect item in some cases (like using a wallpaper to obtain the galaxy sword, incubate a dinosaur egg, or when crafting);\nyou could predict the mushroom level pattern in the mines;\nyou couldn't be damaged while the eat confirmation prompt was up in multiplayer;\nthe invincibility timer after taking damage didn't decrease in multiplayer if a menu was open;\nright-clicking a fishing rod attachment in the inventory reset its durability;\nusing glitches to leave the spa while in swimming mode would result in infinite energy/health regen;\nyou could obtain up to 109 statues of perfection by storing each one in a cabin's inventory chest;\nitems of different qualities could be combined into one stack when buying from Pierre;\nyou could sell items to Pierre's at an upgraded price (e.g., salmonberries with the Bear's Knowledge perk) and buy them back at their normal price. He now resells them at the same price he paid.\nFixed players getting stuck\u2026\nif you cast a fishing rod just after opening a treasure chest in the mines;\nin the blocking pose when you use a sword's special ability in rare cases;\non top of a mine ladder if multiple ladders were spawned;\nin the traveling merchant's cart when dismounting from a horse in some cases (or getting your horse stuck that way);\non top of Abigail when playing the minigame in her two-heart event.\nFixed rare issue where no ladder would spawn on a mine floor.\nFixed monsters spawning too close to the start of a floor in the mines.\nFixed mummies dealing damage while downed.\nFixed invisible, interactable elevators on treasure floors of the Skull Cavern.\nFixed various issues where using bombs could cause items to spawn at the main player's current location instead of the location where the bomb was placed (e.g., artifacts found via secret notes, fruit tree items, giant crops, mystic rocks, hardwood, crystals, and cave grass).\nFixed issue where weeds could be spawned on the tile directly beneath the elevator in the mines.\nFixed objects on the farm sometimes skipping their daily updates, which could cause issues like crops surviving a day into Winter or batches of crops not maturing at the same rate.\nFixed various cases where an entire stack of held items was incorrectly consumed.\nFixed certain artifacts not spawning as intended.\nFixed cooking ingredients spread between your inventory and fridge not correctly counted together.\nFixed issue where leveling up would incorrectly affect the related skill for the rest of the day (i.e., common trees wouldn't drop seeds after leveling up foraging).\nFixed artifacts appearing on grass after winter turns to spring.\nFixed bug when getting a JojaMart membership shortly after completing the Community Center.\nFixed weed item obtained from breaking a mushroom seed or shaking a mushroom tree.\nFixed Livin' Off the Land announcing the start of blackberry season on the wrong date.\nFixed certain placeable items being placeable on tiles occupied by other furniture.\nFixed a few missing boundary tiles in certain areas, including in the Stardew Valley Fair.\nFixed player's fishing level and bait not taken into account for the wait time if the first nibble was missed.\nFixed Tiller profession bonus sometimes not applied to combined foraged and grown grape stacks.\nFixed Prospector profession not applied to rocks destroyed in the mines.\nFixed forage sometimes spawning out of bounds.\nFixed removing tappers from trees in certain ways making them become un-choppable.\nFixed fishing cast distance not determined when the bobber hits the water (previously set at the end of the cast).\nFixed TV weather forecast not always matching actual weather.\nFixed Queen of Sauce sometimes airing a new recipe on the Wednesday before it's scheduled on the following Sunday.\nFixed Queen of Sauce repeatedly airing the Stir Fry episode at the end of year 2 and the beginning of year 3.", "mimetype": "text/plain", "start_char_idx": 144106, "end_char_idx": 149101, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fa3f327a-b69d-4829-9e91-8c63b826e51d": {"__data__": {"id_": "fa3f327a-b69d-4829-9e91-8c63b826e51d", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e074541d-bae1-4485-bd00-fde53ef59930", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "a58671b234a763bc84e71aa670b44c5ada2baa5f508c805b5568089d6a71ee42", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e3db9384-437b-4504-a0b8-a95915f6b8c9", "node_type": "1", "metadata": {}, "hash": "c0a62051669b0fe9f144c7b35f7430de23d5781b78a1a591a544f05dbb7f2b4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed certain placeable items being placeable on tiles occupied by other furniture.\nFixed a few missing boundary tiles in certain areas, including in the Stardew Valley Fair.\nFixed player's fishing level and bait not taken into account for the wait time if the first nibble was missed.\nFixed Tiller profession bonus sometimes not applied to combined foraged and grown grape stacks.\nFixed Prospector profession not applied to rocks destroyed in the mines.\nFixed forage sometimes spawning out of bounds.\nFixed removing tappers from trees in certain ways making them become un-choppable.\nFixed fishing cast distance not determined when the bobber hits the water (previously set at the end of the cast).\nFixed TV weather forecast not always matching actual weather.\nFixed Queen of Sauce sometimes airing a new recipe on the Wednesday before it's scheduled on the following Sunday.\nFixed Queen of Sauce repeatedly airing the Stir Fry episode at the end of year 2 and the beginning of year 3.\nFixed players playing a minigame at 2am not properly quitting the minigame and passing out.\nFixed players able to continue fishing or charging tools past 2am.\nFixed giant crops growing in a noticeable pattern.\nFixed discrepancy between an item's shown health recovery and the actual recovery when consumed.\nFixed the chicken statue furniture being stackable with the chicken statue artifact.\nFixed issue where players could still take damage and die while warping with an obelisk or return scepter.\nFixed issue where ore/mineral veins destroyed with a bomb outside of the mine would only drop stone.\nFixed issue where going to bed early caused machines to process more quickly overnight. (Machines previously processed 100 minutes per hour slept; they now only do so between 2am and 6am, and the remaining time slept will be processed at the normal daytime rate of 60 mins/hour.)\nFixed issue where harvesting a tapped mushroom tree in winter would cause it to not produce again until mid-Spring, rather than Spring 1.\nFixed issue where snow yams and winter root could be dug up in the desert in winter.\nFixed lopsided bee house flower range.\nFixed some Witch Swamp and Mutant Bug Lair water tiles not correctly marked as water, causing inconsistent fish quality in those areas.\nFixed issue where entering a house the moment an NPC passes through a door would close the door on top of the NPC, causing them to get stuck.\nFixed issue where fruit trees wouldn't grow if there was a monster or other NPC near them overnight.\nFixed issue where closing a mine chest with the OK button while your inventory was full destroyed the item; instead the item is now dropped.\nFixed issue where a player at the Stardew Valley Fair would get their score calculated based on the contents of the Grange upon closing the minigame (instead of when Lewis had actually finished his judging), letting that player have a different score than intended.\nFixed minor issue where zero shots fired at the Stardew Valley Fair slingshot shooting gallery would give a large negative calculated accuracy.\nThe Cookie recipe will be sold at the Saloon if Evelyn's 4-heart event has been seen but the recipe wasn't obtained.\nFixes for player interaction\nYou can now collect lost books even if your inventory is full.\nFixed horses being unmountable if they're very close to a pet.\nFixed being able to trash items from the crafting menu even though the trash can is invisible.\nFixed answering dialogues on a small screen causing the cursor to interact with the toolbar.\nFixed interacting with objects in the world while holding an item sometimes causing both the interaction and object to be used at the same time.\nFixed interacting with a fireplace sometimes not toggling it.\nFixed interacting with objects so that objects behind the character are longer interacted when the character is facing upwards.\nFixed interacting with a trash can on horseback simultaneously dismounting the horse and searching the trash (now just dismounts).\nFixed issue where players couldn't harvest or pick up items by clicking and holding the tool button with a melee weapon or scythe in hand.\nFixed issue where attempting to charge an upgraded watering can to the left of a body of water on the farm would prevent the farmer from charging it.\nFixed unable to fill water can from the left side of the water trough in the greenhouse.\nFixed issue where depositing ore into two nearby furnaces could activate both of them.\nFixed large rotated furniture being placeable on top of tables, causing them to disappear.\nFixed issue where players could move while warping out of the Witch's Swamp.\nFixed issue where players couldn't push through farm animals in some cases if they were offset by half a tile.\nFixed issue where interactable furniture like fireplaces couldn't be picked up with left-click when standing close to them and holding a non-tool item.\nFixed issue where it was hard to click on NPCs if you went into a festival while holding a placeable item.\nFixed crawling-stage babies in the crib not being interactable.", "mimetype": "text/plain", "start_char_idx": 148115, "end_char_idx": 153166, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e3db9384-437b-4504-a0b8-a95915f6b8c9": {"__data__": {"id_": "e3db9384-437b-4504-a0b8-a95915f6b8c9", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fa3f327a-b69d-4829-9e91-8c63b826e51d", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "38b5ebe14c6a3ba10738a5a64428c5a0002da009fc2386cbe63d4e800571976d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8d174ef-185c-47a0-961b-9267c3ebc5e1", "node_type": "1", "metadata": {}, "hash": "2695d7ea7b6ce13c4cc11acb05b585a4d7fa923c6e955c73b7f8b7adc65781ef", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed issue where attempting to charge an upgraded watering can to the left of a body of water on the farm would prevent the farmer from charging it.\nFixed unable to fill water can from the left side of the water trough in the greenhouse.\nFixed issue where depositing ore into two nearby furnaces could activate both of them.\nFixed large rotated furniture being placeable on top of tables, causing them to disappear.\nFixed issue where players could move while warping out of the Witch's Swamp.\nFixed issue where players couldn't push through farm animals in some cases if they were offset by half a tile.\nFixed issue where interactable furniture like fireplaces couldn't be picked up with left-click when standing close to them and holding a non-tool item.\nFixed issue where it was hard to click on NPCs if you went into a festival while holding a placeable item.\nFixed crawling-stage babies in the crib not being interactable.\nFixed minor issue where you could cause the farmer to stop shaking during a tool charge by pressing a movement key.\nFixed being able to interact with NPCs when your farmer is set to be immobile. (For example, this prevents you from trying to gift your spouse a second gift immediately after kissing them and getting stuck in an erroneous animation frame.)\nFixed opened gates orphaned by destroying the fence post they're attached to not blocking movement.\nFixed wild tree seed placement cursor not accounting for seed-placeable rules.\nFixed crab pot placement cursor always green, even if an invalid placement tile is selected.\nFixed palm trees not shaking and dropping leaf debris when interacted in winter.\nFixed the \"Warrior\" option not being selectable during Sebastian's 6-heart event in Korean.\nFixed being able to use the dagger while bathing.\nFixed museum reward collection menu not dismissible using the exit hotkey.\nFixed museum donation screen issue where panning the camera would cause the cursor to scroll off of UI elements.\nFixed issue where watering a small tree sapling played a scythe sound.\nFixed issue where hitting a fence that has a torch on it would destroy the torch instead of dropping it.\nFixed invisible blocking tile front of Lewis's house during the Stardew Valley Fair.\nFixed blank or whitespace-only chat messages being sendable.\nFixes for festivals, events, and quests\nDismissing a quest letter no longer discards the quest. (It's now added to your quest log to avoid permanently missing out on quests.)\nYou can no longer place objects at the beach while the Night Market is occurring.\nRemoved invisible trees from festivals.\nFixed exploit where you could pause time when the Night Market submarine was ascending/descending to skip the wait time.\nFixed exploit where you could watch the Night Market Mermaid Show while time was paused (the show now pauses too).\nFixed exploit where you could fulfill the requirements for a gathering quest by taking items out of a chest one-by-one.\nFixed players getting stuck on doors or placed objects during cutscenes in some cases.\nFixed players getting stuck in Harvey's 8-heart event if it was triggered when leaving his bedroom.\nFixed players getting stuck in Harvey's 10-heart event if a train came by.\nFixed introductions quest not considering Willy done after you meet him to receive the fishing rod.\nFixed Mr. Qi's Challenge not considered complete if you fulfilled the conditions before getting his letter.\nFixed the egg in Lewis' truck not being accessible during the egg hunt.\nFixed time not passing for machines inside of farm buildings during festivals.\nFixed players getting trapped in the hospital until the festival starts if they were knocked out for the first time on a festival day.\nFixed time passing during festivals not reflecting when the player(s) started the festivals.\nFixed some out-of-season items appearing as targets for \"Help Wanted\" quests.\nRemoved strawberry from Summer quests, catfish from Winter quests, and sardine from Summer quests.\nFixed bug limiting which NPC would request gathering, slay monsters, or fishing quests.\nFixed Help Wanted quests not reflecting that they pay 3x the market value, instead of 2x.\nFixed occasional spacing issues with the messages on the daily quest board.\nFixed Robin sometimes thanking you for the wrong item when completing a billboard quest.\nFixed winning festival events not counting towards farm's total earnings.\nFixed Penny's 6-heart event not triggering after purchasing the Community Upgrade.\nFixed Sam's 8-heart event being silent if you skipped his 2-heart event.\nFixed \"A Winter Mystery\" quest not triggering if exiting the farm from the bottom tile of the exit to the bus stop.\nFixes for shops and shipping\nFixed merchants refilling limited-stock items when you reopen their shops.\nFixed traveling merchant sometimes having the same item for sale for two different prices.\nFixed items bought from shops being sellable at a different price than produced/grown versions.\nFixed issue where honey would sometimes sell for more than expected.\nFixed pressing Alt + Enter while buying from Pierre destroying the held item.\nFixed selling animals not counting towards farm's total earnings.", "mimetype": "text/plain", "start_char_idx": 152239, "end_char_idx": 157399, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8d174ef-185c-47a0-961b-9267c3ebc5e1": {"__data__": {"id_": "f8d174ef-185c-47a0-961b-9267c3ebc5e1", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e3db9384-437b-4504-a0b8-a95915f6b8c9", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "faf27df5dabb5b46708db0d7802f59913082e0197dea2e88558aa23ef146d0e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "161945f5-32ec-4696-9668-44baeeef0aa3", "node_type": "1", "metadata": {}, "hash": "74deed8065eaa5479c5507ebdc77cd0f562db4346026a4c404a2f3e9c1bcfaf8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed occasional spacing issues with the messages on the daily quest board.\nFixed Robin sometimes thanking you for the wrong item when completing a billboard quest.\nFixed winning festival events not counting towards farm's total earnings.\nFixed Penny's 6-heart event not triggering after purchasing the Community Upgrade.\nFixed Sam's 8-heart event being silent if you skipped his 2-heart event.\nFixed \"A Winter Mystery\" quest not triggering if exiting the farm from the bottom tile of the exit to the bus stop.\nFixes for shops and shipping\nFixed merchants refilling limited-stock items when you reopen their shops.\nFixed traveling merchant sometimes having the same item for sale for two different prices.\nFixed items bought from shops being sellable at a different price than produced/grown versions.\nFixed issue where honey would sometimes sell for more than expected.\nFixed pressing Alt + Enter while buying from Pierre destroying the held item.\nFixed selling animals not counting towards farm's total earnings.\nFixed issue where you couldn't buy animals while Robin was upgrading the pertinent building.\nFixes for NPCs\nFixed several cases where NPC dialogues were out of sync with the actual state of the game world (e.g., saying the wrong dialogue in bed).\nFixed issue where villagers could get stuck doing their daily schedules late into the night after a festival.\nFixed issue where Vincent could get stuck on a flower barrel during the flower dance.\nFixed issue that prevented some villagers from hanging out with one another in town on certain days.\nFixed various issues related to naming horses.\nFixed various bugs caused by giving a villager's name to a horse, pet, or child.\nFixed friendship-related achievements not properly triggering as soon as the conditions are met.\nFixed various friendship-related bugs and inconsistencies, including 10-heart events being unlockable without a bouquet.\nFixed NPCs reacting incorrectly to certain gifted items.\nFixed issue where gifts couldn't be given to the dwarf if their dialogue was exhausted for the day.\nFixed Abigail visiting the farmer on the same day as her 8-heart event.\nFixed Bouncer just saying \"Hi.\" instead of his unique line.\nFixed Bouncer not accepting the club card if you've already exhausted his dialogue for the day.\nFixed Demetrius plowing through bushes by the fountain in summer.\nFixed Dwarf always responding negatively to items it feels neutral about.\nFixed Dwarf not liking cave carrots, despite having dialogue which suggests otherwise.\nFixed Emily's four-heart event unlockable at night.\nFixed Gus offering Bread, Pizza, Salad, and Spaghetti as dish of the day (he already sells them as part of his normal shop stock).\nFixed Henchman dialogue box showing a friendship jewel.\nFixed Krobus secret note event not triggered if riding a horse.\nFixed Krobus not keeping silent on Fridays when accepting gifts.\nFixed Leah's summer schedule causing her to walk into the water and get stuck there for the rest of the day.\nFixed Penny not having her own introductory line.\nFixed Penny talking about the sound of rain on the roof of her trailer after the community upgrade is built.\nFixed Penny talking about living in a trailer after the community upgrade is built.\nFixed Pierre talking about time off after the Community Center has been restored.\nFixed Shane sending two recipes at 3 hearts. (The second is now sent at 7 hearts as intended.)\nFixed Welwick saying two different things on the same day.\nFixed free gift at the Night Market being available every ten minutes instead of once a day.\nFixed buggy interaction with Mayor Lewis when getting a Joja membership before starting the Community Center.\nFixed townsfolk sending players the wrong cooking recipes for their current friendship level.\nFixed villagers you're already dating still accepting bouquets from you.\nFixed a rare crash when attacking \"slimes in love\".\nFixed attacking a rock crab with a pickaxe not dealing damage after its shell is broken.\nFixed issue where villagers that respond differently depending on their current location will no longer say those location specific lines when talked to again later.\nFixed spouse continuing their ongoing dialogue after being interrupted with giving you a Stardrop.\nFixed most cases of crawling-stage babies waking up in the crib at the start of the day. (They'll now spend longer trying to find a non-crib position before giving up.)\nFixed NPCs sometimes detecting players rummaging through their trash or private possessions from a different location.\nFixed NPCs saying something upon entering an area (e.g., Pam entering the Saloon) doing so if you're watching an event.\nFixes for multiplayer\nFarmhands' spouses now move around, run their daily schedules, and react to their spouses like they should.\nFarmhands now return to their own porches after a festival, instead of the main farmer's porch.\nPlayers can no longer give quest items as gifts to other players.\nYou can now connect to the host via IP while they're in the process of loading the game.", "mimetype": "text/plain", "start_char_idx": 156385, "end_char_idx": 161422, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "161945f5-32ec-4696-9668-44baeeef0aa3": {"__data__": {"id_": "161945f5-32ec-4696-9668-44baeeef0aa3", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8d174ef-185c-47a0-961b-9267c3ebc5e1", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "3aae9ec57f7dc032c673c3339bd097e9757f51289090ece18745391a79a2e00e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5822c51b-ddee-4b5a-94d4-c5391a0c8a3d", "node_type": "1", "metadata": {}, "hash": "49e15f2fab44307bab9ac1f05ca60e088629508f7038fc2ce1962021e35a4f1e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed spouse continuing their ongoing dialogue after being interrupted with giving you a Stardrop.\nFixed most cases of crawling-stage babies waking up in the crib at the start of the day. (They'll now spend longer trying to find a non-crib position before giving up.)\nFixed NPCs sometimes detecting players rummaging through their trash or private possessions from a different location.\nFixed NPCs saying something upon entering an area (e.g., Pam entering the Saloon) doing so if you're watching an event.\nFixes for multiplayer\nFarmhands' spouses now move around, run their daily schedules, and react to their spouses like they should.\nFarmhands now return to their own porches after a festival, instead of the main farmer's porch.\nPlayers can no longer give quest items as gifts to other players.\nYou can now connect to the host via IP while they're in the process of loading the game.\nFixed an issue where if a server was shut down on the same day a remote player had leveled up overnight, the level up would not be applied until the following night upon save load.\nFixed rearranging the museum in multiplayer showing a message that the player donated a new item.\nFixed farmhands not seeing the notification that a train is approaching.\nFixed players stuck if a bundle is completed while they're on a tile that becomes unwalkable after the room gets renovated.\nFixed issue where a spouse could get stuck in a farmhand's cabin after divorce. Save files that already have this issue will be fixed after the first night.\nFixed bundles button visible on the inventory screen for farmhands that had missed a bundle completion cutscene.\nFixed issue where you couldn't interact with something behind another player (e.g., to talk to an NPC).\nFixed farmhands seeing bundles for completed areas when looking at the bundles menu.\nFixed farmhands unable to pick up lost books if the host has a menu open.\nFixed married NPCs saying marriage-specific lines to players who aren't their spouse while they're on their married schedules.\nFixed the door frame from Robin's construction animation not properly removed for remote clients after construction is done.\nFixed messages like the one about spreading weeds only shown for the host player.\nFixed Kent sometimes missing from clients' festivals.\nFixed players that collapse in multiplayer seeing the screen briefly flash, showing them in bed.\nFixed fishing rod cast sound affected by other players' casts.\nFixed fishing rod animation not properly synchronized when clicking and holding to recast.\nFixed issue where Lupini would only stop selling a painting if the host player was the one to buy it.\nFixed issue where horses could lose their hats in multiplayer.\nFixed issue where farmhands couldn't activate the Dark Shrine of Night Terrors.\nFixed issue where monsters wouldn't move while host was watching an event or getting knocked out.\nFixed various issues related to child placement and multiplayer synchronization.\nFixed issue where light sources from disconnected farmhands wouldn't get cleaned up.\nFixed issue where animals in barns built by farmhands in multiplayer were unable to breed.\nFixed issue where completing a Vault bundle wouldn't send a global chat message in multiplayer.\nFixed issue where the Witch event would create a void egg for each logged-in player.\nFixed issue where items shipped, minerals found, recipes cooked, fish caught, and artifacts found during a multiplayer session could be forgotten if a client disconnected before the end of the day.\nFixed several bugs relating to Mummy behavior and multiplayer sync.\nFixed sleep stamina recovery being based on the last player who went to bed (now tracked separately for each player).\nFixed baby slimes in the mines destroying rocks on contact if a non-host player killed the big slime.\nFixed various multiplayer data sync issues.\nFixed time slowing for all players when the host is in the mine (no longer slows at all in multiplayer).\nFixed missing tools in multiplayer not always being recovered.\nFixed various issues related to pets in multiplayer.\nFixed remote players not properly showing jump/jitter animations during emotes or horse mounting/dismounting.\nFixed the host player seeing flashes or feeling controller rumbles from bombs in other locations.\nFixed explosion flashes not showing up on farmhand machines.\nFixed player getting stuck on the \"Waiting for players\" check after a festival if another player joined at the same time.\nFixed Joja purchase form not reflecting upgrades bought by other players.\nFixed issue where getting killed while paused in multiplayer could leave you in a perpetual getting-knocked-unconscious state; this now unpauses instead.\nFixes for visual or cosmetic issues\nItems that come in various colors (like tulips) now show their proper color in the item received pop-up.\nThe mouse cursor is now hidden in scenes that lock user input.\nThe lighting in the Secret Woods now changes more consistently with the rest of the world as time passes through the day.\nLit furniture placed on top of tables will now properly light upon nightfall.", "mimetype": "text/plain", "start_char_idx": 160535, "end_char_idx": 165625, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5822c51b-ddee-4b5a-94d4-c5391a0c8a3d": {"__data__": {"id_": "5822c51b-ddee-4b5a-94d4-c5391a0c8a3d", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "161945f5-32ec-4696-9668-44baeeef0aa3", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "147eef47a50524c005e2290687bdf5ba6a8481a3bac1916f7022b064ce12534a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "59ffb54a-4f37-4a0d-a0cc-b5935ccfeaad", "node_type": "1", "metadata": {}, "hash": "90cb2e04a124e3c00df57bd2fca96d261241c073f122c146f4b6a9e6343c2710", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed remote players not properly showing jump/jitter animations during emotes or horse mounting/dismounting.\nFixed the host player seeing flashes or feeling controller rumbles from bombs in other locations.\nFixed explosion flashes not showing up on farmhand machines.\nFixed player getting stuck on the \"Waiting for players\" check after a festival if another player joined at the same time.\nFixed Joja purchase form not reflecting upgrades bought by other players.\nFixed issue where getting killed while paused in multiplayer could leave you in a perpetual getting-knocked-unconscious state; this now unpauses instead.\nFixes for visual or cosmetic issues\nItems that come in various colors (like tulips) now show their proper color in the item received pop-up.\nThe mouse cursor is now hidden in scenes that lock user input.\nThe lighting in the Secret Woods now changes more consistently with the rest of the world as time passes through the day.\nLit furniture placed on top of tables will now properly light upon nightfall.\nFixed various visual map issues, including\u2026\nvarious tile issues in the Mines and Skull Cavern;\nglow from certain lamps in the town interiors tilemap bleeding into adjacent tiles in the tilesheet;\nincorrect corner edge tile used inside the walls in mine level 6;\nincorrect grass tiling under the fence on the bottom of the mountain path to town, and missing tile on the tree near that location;\nincorrect tiles in the Flower Festival;\na missing stone tile under the JojaMart sign in town;\nvisual issue with the kitchen floor tile;\nvisual bugs with the eyes of the statue in the secret woods;\nvisual issues with hat mouse's house;\nartwork of the Bulletin Board in the Community Center not lining up with the walls around it;\nmismatched walls behind the plant and picture frame in the hallway between Alex and George and Evelyn's rooms;\nmismatched wall with the power outlet for George's TV;\nlook of the carpet under Sam's bed;\nincorrect shadowing on some tiles in the mines on floor 7 and 14;\nSecret Woods statue eyes staying red after activation until the season changes or you reload the save.\nFixed various text display issues, including\u2026\nvarious typos;\nvarious line wrapping issues in dialogue boxes;\nline wrapping issue when leaving the feast of the winter star;\nline wrapping issue in tooltips for boots, rings, and melee weapons with long names;\nextra space at the bottom of tooltips for edible items that don't grant any health;\nsizing issues in carpenter menu for non-English languages;\nspacing issues in bulletin board request text;\none of Haley's lines having a blank dialogue page;\ncertain items with long names causing tooltips to word wrap incorrectly;\nstardrop message easter eggs incorrectly appending the favorite thing after the special text.\nFixed various sprite issues, including\u2026\nlayering issues (e.g., when the farmer is facing upwards while using some tools, or bushes drawn over chests);\ncharacter sprite coloration issues;\nsome monsters having two shadows (affected Ghosts, Dust Sprites, and Bugs);\nBouncer trying to face the player in some cases, resulting in an invalid sprite;\nLinus starting some days slightly clipped into a wall;\nMaru reverting to her plain clothes after her event in the clinic;\nPenny's hair missing some pixels when she's sitting on the bench in town;\nplayer hat rendered incorrectly in the inventory at night time;\nplayer with an item raised above their head rendering with hands lowered in some specific cases;\nplayer sprite rendered incorrectly after collapsing while in a bathing suit;\nplayer sprite facing upwards after interacting with a child or festival NPC from above;\nplayer 'wiggling nose' animation issue when casting or reeling in a fish;\nplayer eye color drawn incorrectly when reeling in a fish;\nplayer sprite flickering to invalid animation frame when tapping a movement key while aiming the fishing rod;\nkissing your spouse in multiplayer sometimes showing an incorrect idle frame (sometimes facing the wrong direction);\nvarious issues related to animations played as part of an NPC's daily schedule;\nthe light halo overlay on outdoor lamps sorting incorrectly at some positions;\nhealth bar not fully consistent with stamina bar.\nFixed Penny washing dishes too far from the sink.\nFixed issue where rebinding keys would cause the game to display a blank options screen instead of properly prompting the player to press a key.\nFixed switching toolbars causing incorrect animations to play in multiplayer.\nFixed various issues related to the frogs that sometimes spawn on rainy days.\nFixed ancient seed not visible in inventory.\nFixed edible items that don't grant energy displaying the poisonous icon in tooltip.\nFixed being able to click title menu buttons before they're visible.\nFixed visual issues when swapping toolbars away or onto light sources.\nFixed some dialogue boxes being positioned incorrectly.\nFixed issue where hovering over the dialogue friendship jewel would show a friendship level tooltip, even if the jewel wasn't currently visible (e.g., when answering a question).\nFixed visual seams appearing in Junimo Kart.", "mimetype": "text/plain", "start_char_idx": 164603, "end_char_idx": 169720, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "59ffb54a-4f37-4a0d-a0cc-b5935ccfeaad": {"__data__": {"id_": "59ffb54a-4f37-4a0d-a0cc-b5935ccfeaad", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5822c51b-ddee-4b5a-94d4-c5391a0c8a3d", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "630b60ce64dc41f81cada2b61edc68b7a75e4ff80d0fde43222ce756c89945fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1dd22892-30b9-4fc6-8f98-20f9ee9b7dea", "node_type": "1", "metadata": {}, "hash": "2c18bc27c2f2cf22cd53caefb1df8eb5cedab2a043ca462ebb8cb6827abbc749", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed Penny washing dishes too far from the sink.\nFixed issue where rebinding keys would cause the game to display a blank options screen instead of properly prompting the player to press a key.\nFixed switching toolbars causing incorrect animations to play in multiplayer.\nFixed various issues related to the frogs that sometimes spawn on rainy days.\nFixed ancient seed not visible in inventory.\nFixed edible items that don't grant energy displaying the poisonous icon in tooltip.\nFixed being able to click title menu buttons before they're visible.\nFixed visual issues when swapping toolbars away or onto light sources.\nFixed some dialogue boxes being positioned incorrectly.\nFixed issue where hovering over the dialogue friendship jewel would show a friendship level tooltip, even if the jewel wasn't currently visible (e.g., when answering a question).\nFixed visual seams appearing in Junimo Kart.\nFixed visual bug in the character's health bar when their health is low.\nFixed screen fading out twice when using Robin's building related functions.\nFixed resizing the window below the minimum size causing black bars on screen.\nFixed resizing the window or adjusting zoom resetting the scrollbar position on the options screen.\nFixed social tab showing one gift given if you gave two gifts that week plus a birthday present.\nFixed minor visual bug when switching between the \"Host\" and \"Join\" tabs in the co-op screen.\nFixed non-centered text alignment in the header of Robin's build menu.\nFixed the host player seeing light sources from Ghosts in the mines, even while not in the mines.\nFixed purchasing stacks of player-sold items from Pierre not visibly reducing the stack available.\nFixed lighting in the mine changed as soon as you start going down a ladder, instead of after loading the next level.\nFixed screen briefly fading to black during Grandpa's evaluation.\nFixed players sometimes getting stuck on a black screen during weddings.\nFixed pulling the last piece of hay out of a hopper not making it display as empty.\nFixed several issues with weather debris displaying incorrectly.\nFixed issue where white or black customization colors would cause the HSV sliders to show invalid numbers upon using the Shrine of Illusion.\nFixed visual issues with the cutscenes while riding the bus.\nFixed issue where holding 'up' while taking the bus back from the desert would cause the camera to pan during the cutscene.\nFixed trees planted in the desert showing their snow-covered sprites in winter.\nFixed issue where player animations weren't properly looping during events.\nFixed issue where Journey of the Prairie King showed -1 lives after losing all of your lives.\nFixed issue in Robin's menu where the Deluxe Barn's description overlapped the materials list.\nFixed minigames / cutscenes not always centered when the game is zoomed out.\nFixed the order of recipes in the Collections menu and the kitchen stove menu not matching.\nFixed weather debris clumped up after playing a minigame.\nFixed alignment of several UI elements in Calico Jack minigame.\nFixed falling leaves in the Secret Woods not showing their seasonal variants in fall.\nFixed campfire lighting misaligned.\nFixed map showing the player in the mines when they're in the Skull Cavern.\nFixed menu backgrounds not shown in the Community Center bundles menu.\nFixed the map's location label partly rendered off-screen in some cases.\nFixed white borders sometimes drawn on pieces of debris/dropped items.\nFixed mouse cursor not showing gift icon when gifting items to an NPC you're meeting for the first time.\nFixed mouse cursor showing \"talk to\" when hovering over NPCs during non-interactable events.\nFixed issue where harvesting from a crab pot while your inventory was full would result in multiple 'inventory full' messages without the red 'X'.\nFixed crab pots positioned/rendered over tiles they should be being drawn behind.\nFixed issue where opening a door would briefly show a ghost door.\nFixed windows in barns, coops, and spouse rooms providing light on rainy days or when it's dark out.\nFixed inconsistent particle effect when you right-click vs left-click to sell in the shop.\nFixed digging up an artifact spot in the rain leaving a dry spot.\nFixed hoeing in the desert when it's raining elsewhere leaving a wet spot.\nFixed outdoor garden pots not showing watered sprite when it's raining.\nFixed the health bar 'bleeding' at low health values if the health bar isn't currently being drawn or if the screen is currently fading.\nFixed double cursor in the Stardew Valley Fair slingshot minigame, and disabled drawing of it when playing with controller.\nOther bug fixes\nAll mine songs now show up in the Jukebox list.\nFixed crash on startup if no audio output device is detected.\nFixed resolution issues for some players.\nFixed music not properly playing at the start of a new day.\nFixed Junimos not behaving properly after completing the community center.\nFixed issue where other players could affect the music that's playing in the mines.\nFixed various bugs caused by simultaneous buffs and debuffs.\nImproved confusing error if certain game files are missing.", "mimetype": "text/plain", "start_char_idx": 168820, "end_char_idx": 173956, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1dd22892-30b9-4fc6-8f98-20f9ee9b7dea": {"__data__": {"id_": "1dd22892-30b9-4fc6-8f98-20f9ee9b7dea", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "59ffb54a-4f37-4a0d-a0cc-b5935ccfeaad", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "752d557560c19d88d4abc40dcad95585a480e09e859c784a9769f41405b9c87a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab46cd9a-d603-48f9-a4ca-60b9ee6fe689", "node_type": "1", "metadata": {}, "hash": "7e6563a8af97133cd4c4db256aab0ab93d49b177954554861647ae9f50d476a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed digging up an artifact spot in the rain leaving a dry spot.\nFixed hoeing in the desert when it's raining elsewhere leaving a wet spot.\nFixed outdoor garden pots not showing watered sprite when it's raining.\nFixed the health bar 'bleeding' at low health values if the health bar isn't currently being drawn or if the screen is currently fading.\nFixed double cursor in the Stardew Valley Fair slingshot minigame, and disabled drawing of it when playing with controller.\nOther bug fixes\nAll mine songs now show up in the Jukebox list.\nFixed crash on startup if no audio output device is detected.\nFixed resolution issues for some players.\nFixed music not properly playing at the start of a new day.\nFixed Junimos not behaving properly after completing the community center.\nFixed issue where other players could affect the music that's playing in the mines.\nFixed various bugs caused by simultaneous buffs and debuffs.\nImproved confusing error if certain game files are missing.\nFixed issue where players wouldn't get museum achievements until the next time they donated something themselves.\nFixed Master Angler achievement awarded before catching all fish.\nFixed issue where the music in Leah's house didn't stop after leaving her house.\nFixed issue where the wallpaper and flooring would shift rooms as you upgraded your house.\nFixed skipping an event sometimes making the player wait on a black screen for a while.\nFixed placing a bomb and leaving the screen before it explodes causing a buggy sound effect.\nFixed placing a bomb that destroys weeds and leaving the area before the explosion happens still playing the weed destruction sounds.\nFixed options menu being scrollable while a dropdown list is active.\nFixed an issue where a female character's pants could have their color changed to black during a wedding ceremony.\nFixed issue where you'd need to click twice to clear the dialogue that appeared after falling down a mineshaft.\nFixed issue where hotkeys (like opening the inventory) triggered after sending a chat message.\nFixed issue where dialogue couldn't be advanced using keyboard inputs.\nFixed issue where the music would sometimes briefly play again after you had turned the volume down.\nFixed issue where rebinding the menu key closed the options menu.\nFixed Prairie King game over screen only accepting input every 1.5 seconds.\nFixed Prairie King music overlapping if you use the zombie powerup multiple times in quick succession.\nFixed mouse repositioned when clicking HUD zoom buttons, making it harder to zoom in/out multiple times.\nFixed issue where loading a save would play the furnace and fireplace sounds.\nFixed volume levels not properly applied when connecting to a game as a farmhand.\nFixed rare crash or invisible grass caused by grass sizes becoming invalid.\nFixed clicking without dragging with the slingshot consuming ammo but firing nothing.\nFixed crash after eating a Maki Roll while playing in French.\nFixed Prehistoric Tibia and Amphibian Fossil not appearing in the forest (or anywhere) while playing in Spanish.\nFixed Wild Plums listed as forage instead of fruit in non-English languages.\n1.3.36\nStardew Valley 1.3.36 was posted to the beta channel on 24 January 2019 and released on 1 March 2019.\n\nChanges\nAdded French, Korean, Italian, Hungarian, and Turkish language support\nAdded a new Credits menu to replace the \"About\" menu on the title screen, and removed the /credits chat command.\nRemoved unneeded tilesheet files under Content.\nRemoved translated map files under Content/Maps (translated tilesheets are now loaded automatically).\nCentered shed door.\nBug fixes\nFixed bug where music doesn't correctly play in the morning.\nFixed bug where giving a gift to an NPC caused the gift action to happen twice in rapid succession.\nFixed furniture rotation bug for \"stools\".\nFixed Junimos not disappearing after the final goodbye.\nBeta Versions (1.3.35\u20131.3.36)\n1.3.33\nStardew Valley 1.3.33 was posted to the beta channel on 18 December 2018 and released on 8 January 2019.\n\nChanges\nImproved performance in locations with lots of light sources (e.g., torches).\nImproved performance on farms with lots of animals.\nTweaked new \"H\" health icon.\nBug fixes\nFixed multiplayer visual glitch when another player uses a tool and then starts moving in a new direction.\nFixed \"fishing stance\" visual glitches in multiplayer.\n1.3.32\nStardew Valley 1.3.32 was released on 19 November 2018. (Versions 1.3.29\u20131.3.32 were all posted on the beta channel, and are included in 1.3.32.)\n\nChanges\nOptimised network performance.\nAdded more ways for the host to unpause the server (by pressing ESC, B, Back).\nAdded alternative way to show the chat box (press right stick button on a controller).", "mimetype": "text/plain", "start_char_idx": 172975, "end_char_idx": 177693, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ab46cd9a-d603-48f9-a4ca-60b9ee6fe689": {"__data__": {"id_": "ab46cd9a-d603-48f9-a4ca-60b9ee6fe689", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1dd22892-30b9-4fc6-8f98-20f9ee9b7dea", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "afb91b74b49c9bbef8ff8f47e99a9fc46b7a26e3bcdb1cc16b4576be704e595b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "534c6d6c-7b4b-4020-b737-b41dfb0741ed", "node_type": "1", "metadata": {}, "hash": "c5acd7b07ba44ca7740ff53a98b6cf83a2a25b23b3cdd32dc671c4ab4ebaa4aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Changes\nImproved performance in locations with lots of light sources (e.g., torches).\nImproved performance on farms with lots of animals.\nTweaked new \"H\" health icon.\nBug fixes\nFixed multiplayer visual glitch when another player uses a tool and then starts moving in a new direction.\nFixed \"fishing stance\" visual glitches in multiplayer.\n1.3.32\nStardew Valley 1.3.32 was released on 19 November 2018. (Versions 1.3.29\u20131.3.32 were all posted on the beta channel, and are included in 1.3.32.)\n\nChanges\nOptimised network performance.\nAdded more ways for the host to unpause the server (by pressing ESC, B, Back).\nAdded alternative way to show the chat box (press right stick button on a controller).\nAdded internal changes for modders (should have no effect on vanilla gameplay).\nBug fixes\nFixed slimes not pouncing correctly.\nFixed items-crafted stat being 0 after loading a file until you craft something again.\nFixed rabbit's foot not affecting the breakup scene in non-English language modes.\nFixed some rare tool-related crashes in multiplayer.\nFixed an audio-related crash often caused when using bombs.\nFixed Junimos dropping crops on the floor instead of collecting them.\nFixed NPCs walking through the saloon doors.\nFixed a few rare-ish crashes that can occur when connecting to another player's game.\nFixed eye color being reset to brown after reloading.\nFixed inability to use rod / slingshot in festival minigames.\nFixed the title menu back button being hidden behind submenus.\nFixed inability to move after receiving a gift at the Feast of the Winter Star.\nFixed crash when saving after the game adds Lewis' shorts to Marnie's house.\nFixed crash viewing the map when another player is in certain events.\nFixed \"double sound\" when using singing stone.\nFixed a Geneva Convention violation (by replacing red crosses in graphics).\nFixed clicks on the chatbox not being registered when the game is paused.\nFixed players sometimes walking off in a straight line through all terrain when they get disconnected.\nFixed babies sometimes spawning in houses that don't belong to the parents.\nFixed the potential for overnight events to cancel or skip a wedding event.\nFixed a desync that could occur if a player tried to get into the casino after a different player has removed the bouncer.\nFixed players able to simultaneously build overlapping farm buildings.\nFixed only one player being able to get the dark talisman.\nFixed the inability to place donated items on the bottom two rows of the museum.\nFixed farmhands being unable to pick up items they dropped in festivals.\nFixed Pam's upgraded house interior event not happening.\nFixed visual glitches caused by triggering a shared event simultaneously with the return scepter.\nFixed softlock caused by mistaken ability to use daggers during events.\nFixed players all receiving the same personal overnight events on the same day (e.g., spouse asking if you want a baby).\nFixed attempting to demolish cabins of abnormally disconnected farmhands causing the cabin to be destroyed after you leave the buildings menu.\nFixed farmers getting stuck in the fishing casting animation after picking up someone else's rod.\nFixed host sometimes appearing stuck using tool in shared events.\nFixed soft-lock when you play the Journey of the Prairie King past 2am.\nFixed glitched chest lid appearing when you destroy a cabin.\nFixed duplicate songs in the jukebox.\nFixed only one player's glow ring working at a time.\nFixed farmhands not being able to see each others' bundle changes.\nFixed bug causing some players to become married to two other players in 3-4 player farms.\nFixed player sometimes getting stuck in bed after another player got in and then got back out.\nBeta Versions (1.3.29\u20131.3.32)\n1.3.28\nStardew Valley 1.3.28 was posted to the beta channel on 10 August 2018 and to the main channel on 14 August 2018.\n\nFixed bug preventing buildings from being placed where there would be a path/flooring tile in front of the door.\nFixed music not playing at the Luau festival and in town.\nFixed clients occasionally crashing in rainy weather.\nFixed server crash when there are no available network adapters.\nFixed the load menu showing 'no saved games' while searching for files.\nFixed crash that occurred if you collided with a monster on the first frame you entered a new location.\nFixed Robin forgetting that she's meant to upgrade a farmhand cabin if the farmhand disconnects abnormally.\nFixed farmhands not being able to set the next day's weather with rain totems.\nFixed farmhands 'swimming' inside their cabins if they're disconnected while swimming in the spa.\nFixed swimming-related visual bugs in on farmers' faces.\nFixed furniture rotation graphical glitch.", "mimetype": "text/plain", "start_char_idx": 176996, "end_char_idx": 181704, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "534c6d6c-7b4b-4020-b737-b41dfb0741ed": {"__data__": {"id_": "534c6d6c-7b4b-4020-b737-b41dfb0741ed", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab46cd9a-d603-48f9-a4ca-60b9ee6fe689", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "76e2dd33b9e6f67a50947cc1abb76c21dd25701de76f58e6f91d6e1d15d88a4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c4875247-518c-45dd-96d8-6c5e47a5ea2d", "node_type": "1", "metadata": {}, "hash": "cf9bb18dd917d73c57630d61923365a8dbcd00d72dbc6eedb1f29da3897d5fba", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed bug preventing buildings from being placed where there would be a path/flooring tile in front of the door.\nFixed music not playing at the Luau festival and in town.\nFixed clients occasionally crashing in rainy weather.\nFixed server crash when there are no available network adapters.\nFixed the load menu showing 'no saved games' while searching for files.\nFixed crash that occurred if you collided with a monster on the first frame you entered a new location.\nFixed Robin forgetting that she's meant to upgrade a farmhand cabin if the farmhand disconnects abnormally.\nFixed farmhands not being able to set the next day's weather with rain totems.\nFixed farmhands 'swimming' inside their cabins if they're disconnected while swimming in the spa.\nFixed swimming-related visual bugs in on farmers' faces.\nFixed furniture rotation graphical glitch.\nFixed a crash that occurs if you try to copy an invite code while remotely logged into the machine the game is running on.\nFixed a German localization issue with '%Farm' appearing in text instead of the farm's name.\nFixed spouse NPCs not kissing farmers.\nVarious internal changes requested on the modding wishlist.\n1.3.27\nStardew Valley 1.3.27 was released on 1 August 2018. (Versions 1.3.3\u20131.3.26 were only posted on the beta channel, and are included in 1.3.27.)\n\nNew content\nAdded multiplayer over GOG, Steam, or LAN. This includes chat with custom emotes, and new cabin buildings.\nAdded Night Market event.\nAdded Community Upgrade to carpenter's shop.\nAdded buildable shipping bins to Carpenter's Shop.\nAdded Abigail encounter at level 20 in the mines.\nAdded new heart events for Jas, Linus, Pam, Vincent, and Willy.\nAdded new heart events when player has given a bouquet to all bachelors or bachelorettes.\nAdded rare treasure chest rooms in Skull Cavern.\nAdded new monsters in the Skull Cavern: carbon ghost, iridium bat, and iridium crab.\nAdded secret notes and related quests.\nAdded new items: auto-grabber, cactus seeds, garden pot, wood sign and stone sign, solid gold Lewis statue, pearl, wedding ring, new paintings, and decorative items sold at shops and festivals throughout the year.\nAdded bear's knowledge, special charm, spring onion mastery.\nAdded Statue Of Uncertainty to change professions.\nAdded different stationery for letters from Sandy and the Wizard.\nAdded horse hats.\nBalance changes\nIncreased purchase price of wood, stone, ores, and coal in the year 2+. The gold received for selling them is unchanged.\nReduced price of tub o' flowers from 1000g to 250g, and recipe from 2000g to 1000g.\nBreaking small tree stumps now provides +1 foraging XP.\nOnce the player reaches the mine bottom...\nprismatic shards and diamonds may rarely drop from any monster;\ngems and purple mushrooms may be found when searching trash bins;\ngems and purple mushrooms may be requested in NPC quests;\nsome monsters will be stronger.\nOther changes\nOnce the player reaches the mine bottom, the Dwarf will attend weddings.\nGolden pumpkin is now a universal love (instead of universal hate).\nTweaked several seed packet sprites.\nTweaked Mr. Qi dialogue portrait.\nYou can now add Mayor Lewis' shorts to the Luau soup.\nYou can now put fire quartz in the furnace to produce refined quartz.\nYou can now refill a Watering Can at the kitchen sink.\nFireplaces are now furniture, so you can move them around and buy different fireplaces.\nFruit Trees cannot be planted on top of decorations in the greenhouse border, or in the corners of the Greenhouse.\nReplaced gold display on player menu from \"g\" to \"\u91d1\" in Chinese.\nImprove Chinese translations:\n\nItem name changes\nItem description changes:\n\nItems Changed\nBug fixes\nFixed crops harvested with a scythe not giving XP.\nFixed bee houses always giving wild honey when used on custom farms.\nFixed seeds planted out of season disappearing.\nFixed player collapse being cancelled when they open the journal.\nFixed animal mood & happiness bugs.\nFixed crystalarium item swap exploit.\nFixed furniture being usable to complete bundles.\nFixed some recipes allowing Milk, but not Large Milk.\nFixed crash that occurred after 596 hours of gameplay.\nFixed staircase being spawned on mine level 120 when a placed object is destroyed.\nSeveral grammar/spelling fixes.\nFixed wheat seeds and bok choy seeds descriptions in Brazilian-Portugese.\nFixed spring sign on bathhouse in Chinese.\nBeta Versions (1.3.0\u20131.3.27)\n1.2.33\nStardew Valley 1.2.33 was a small bugfix patch released on 10 July 2017.", "mimetype": "text/plain", "start_char_idx": 180854, "end_char_idx": 185319, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4875247-518c-45dd-96d8-6c5e47a5ea2d": {"__data__": {"id_": "c4875247-518c-45dd-96d8-6c5e47a5ea2d", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "534c6d6c-7b4b-4020-b737-b41dfb0741ed", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "e6b1af8c0806ad4390aecddcc0a98e6ca2ecfa61859292a768c72a503977c2b6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67ef8885-8b92-4259-8e64-0a7606df6c57", "node_type": "1", "metadata": {}, "hash": "1115f21c4e7806f695fd622241400b897c61356929d37d4d425845bee23d4200", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed bee houses always giving wild honey when used on custom farms.\nFixed seeds planted out of season disappearing.\nFixed player collapse being cancelled when they open the journal.\nFixed animal mood & happiness bugs.\nFixed crystalarium item swap exploit.\nFixed furniture being usable to complete bundles.\nFixed some recipes allowing Milk, but not Large Milk.\nFixed crash that occurred after 596 hours of gameplay.\nFixed staircase being spawned on mine level 120 when a placed object is destroyed.\nSeveral grammar/spelling fixes.\nFixed wheat seeds and bok choy seeds descriptions in Brazilian-Portugese.\nFixed spring sign on bathhouse in Chinese.\nBeta Versions (1.3.0\u20131.3.27)\n1.2.33\nStardew Valley 1.2.33 was a small bugfix patch released on 10 July 2017.\n\nChanges\nFixed Linux/Mac builds distributing with MonoGame-built content instead of XNA-built content (which made modding more difficult).\n1.2.32\nStardew Valley 1.2.32 was a small bugfix patch released on 10 July 2017.\n\nBug fixes\nFixed Linux install failing due to broken symlink in 1.2.31.\nFixed save files potentially getting overwritten if you start a new file after using exit to title.\n1.2.31\nStardew Valley 1.2.31 was a small bugfix patch released on 7 July 2017.\n\nBug fixes\nFixed crashes related to use of slot machines.\nFixed some potential sources of unnecessarily increased memory usage.\nFixed some options in dialogue not being usable with a controller.\nLocalization fixes\nFixed the 'loading...' message on loading screens wrapping incorrectly in some languages.\nEnglish: fixed grammar in Luau community soup text.\nPortuguese: fixed some dialogue options in Linus' 0 heart event being missing.\nPortuguese: fixed the cut-off 'level up' title.\nRussian: added more space for the '(single)' text on the social page.\n1.2.30\nStardew Valley 1.2.30 was released on 12 May 2017.\n\nChanges\nThe window mode preference is now shared between all save files.\nBug fixes\nFixed crash when the game switches window mode while loading a save.\n1.2.29\nStardew Valley 1.2.29 was released on 02 May 2017. (Versions 1.2.27\u20131.2.28 were only posted to the Steam beta channel, and are included in 1.2.29.)\n\nBug fixes\nFixed crashes while loading save files.\nFixed crashes when going fullscreen.\nFixed crashes while saving due to slay-monster quest.\n1.2.26\nStardew Valley 1.2.26 was released on 24 April 2017 with in-game support for six new languages. Beta versions were posted to the Steam beta channel starting 07 February 2017.\n\nChanges\nTranslations for German, Spanish, Brazilian Portuguese, Russian, Japanese and Simplified Chinese.\nWhen using a controller, the cursor will snap between menu buttons by default. If you disable that, the cursor will instead accelerate while moving.\nWhen using a controller, pressing the back button will skip events that are skippable.\n\"Show sharper digits\" on Options menu removed.\nExit to Title has returned.\nAdded panda hat (TGP only).\nBug fixes\nFixed lighting shader not covering the whole screen on Mac and Linux.\nSwitching from \"Windowed Borderless\" to \"Fullscreen\" should now go straight to fullscreen instead of Windowed mode.\nWallpapers and floors no longer have a tile placement indicator showing a random object.\nIncreased stability of preference-saving code. This should fix infrequent crashes that require the player to delete startup_preferences.\nFixed a crash that can happen when a pig tries to spawn a truffle but there\u2019s no space for it.\nFixed a couple of rare crashes that could have occurred at any time during the game.\nFixed a typo of the word \u2018pronounce\u2019 in the marriage event.\nFixed the player not getting the recipe for Cookies if they skip Evelyn's event.\nFixed farm animals not producing goods at high happiness.\nFarming level now affects crop yield prior to level 10.\nBeta Versions (1.2.0\u20131.2.25)\n1.11\nStardew Valley 1.11 was released 06 October 2016, with a beta posted to the Steam beta channel on 05 October 2016.\n\nMinor changes\nAll the new farms now provide some kind of fishing opportunity, although the riverland farm is still superior.\nThe riverland farm now has the potential to spawn splashing fish nodes and ore panning nodes.\nYou can place buildings on most grass areas.\nOn the riverland and forest farm maps, some bushes can be destroyed with an upgraded axe.", "mimetype": "text/plain", "start_char_idx": 184563, "end_char_idx": 188839, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67ef8885-8b92-4259-8e64-0a7606df6c57": {"__data__": {"id_": "67ef8885-8b92-4259-8e64-0a7606df6c57", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4875247-518c-45dd-96d8-6c5e47a5ea2d", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "ceda279ea86d2b0b69aef15193ec36d48387dae8f68f9be18aa96d75231cb69d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49d65a3e-9d6d-437e-ab3c-20f9fa4b5437", "node_type": "1", "metadata": {}, "hash": "6dc7d80903cabeb57d32f6e6b5cbb4fa5c4629e6b934b15f6d9e6d0fb0b6ed21", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fixed a couple of rare crashes that could have occurred at any time during the game.\nFixed a typo of the word \u2018pronounce\u2019 in the marriage event.\nFixed the player not getting the recipe for Cookies if they skip Evelyn's event.\nFixed farm animals not producing goods at high happiness.\nFarming level now affects crop yield prior to level 10.\nBeta Versions (1.2.0\u20131.2.25)\n1.11\nStardew Valley 1.11 was released 06 October 2016, with a beta posted to the Steam beta channel on 05 October 2016.\n\nMinor changes\nAll the new farms now provide some kind of fishing opportunity, although the riverland farm is still superior.\nThe riverland farm now has the potential to spawn splashing fish nodes and ore panning nodes.\nYou can place buildings on most grass areas.\nOn the riverland and forest farm maps, some bushes can be destroyed with an upgraded axe.\nDigging spots now appear on the farm, although less frequent as elsewhere. The hill-top quarry also has a chance of spawning them.\nThe forage berry bushes are now affected by the Botanist perk.\nSlime egg prices increased.\nPlacing a wicked statue in a slime hutch prevents the witch from visiting it.\nOn the forest farm map, forage items have a chance to spawn on any grassy area, not just in the west.\nSpouses will now speak to you when they come home on Friday nights.\nBug fixes\nPrice of galaxy dagger has been corrected to 35,000g (it was at 350,000g).\nThe Artisan Perk description has been corrected to reflect the actual bonus (it's 40% now, but the description still says 50%).\nWeeds in the Mutant Bug Lair no longer change with the season (and no longer turn to battery packs in the winter).\nThe Mutant Bug Lair now replenishes itself a bit each day.\nMonsters in the Mutant Bug Lair will now always be mutant... not revert to the standard grub/fly after saving and reloading.\nMeteorites can no longer land on top of stumps or boulders.\nYou can once again place buildings in the little-shaded strip right below cliffs.\nFixed some tiles on the farm maps.\nFixed problem with forage spawning under stumps.\nSpring onions can be iridium quality with the botanist perk.\nTruffles should no longer spawn in the water.\nPets should no longer be able to walk down the cellar stairs into the void.\nThe Outlaw boss in Journey of the Prairie King will warp back to the center of the map if he happens to run too far off screen in either direction.\nCoop animals can now actually produce higher quality produce like they were supposed to.\nCan no longer fill your watering can at a well that isn't fully constructed or in construction.\nTrees can no longer spread off the map into the void, causing the game to start getting slower with each day. The new patch will retroactively remove these problem trees as well.\nYou should now properly see the final Joja cutscene, even if you switched to JojaMart after completing most of the Community Center.\nForage items shouldn't spawn in inaccessible places anymore.\nFixed issue where lightning that struck an object on the farm would cause that object to \"pop\" into the current map when the current map was not the farm.\nWhen you reach level 5 or 10 in a skill, but haven't slept yet, it no longer shows your new profession as \"Desperado\".\nMinor convenience adjustments and bug fixes.\n1.1\nStardew Valley 1.1 was released 3 October 2016, with a beta posted to the Steam beta branch on 29 September 2016.\n\nMarriage candidates\nMarriage candidates now have an outdoor area on the farm that is unique for most spouses, and sometimes spend time out there, usually doing a unique behavior.\nSam has a little halfpipe and he does skateboard tricks.\nMaru has a little gadget that she works on.\nAbigail plays her flute.\nLeah has a sculpture to carve.\nSebastian works on his bike.\nAlex lifts weights.\nPenny, Harvey, and Elliott read a book in a little potted plant garden.\nEmily meditates in a crystal garden.\nHaley takes pictures between two potted palm trees.\nShane has a little chicken hutch, and he stands by it holding his chicken \"Charlie\".\nShane can be married and has new dialogue, scheduling and heart events. There's a new door for Shane in Marnie's shop which is locked. Shane's \"spouse room\" is a mess, with a mini-fridge and a muddy path of footprints leading up to it.\nEmily can be married and has new dialogue, scheduling and heart events.\nBuildings\nRobin has a few new buildings available for sale.", "mimetype": "text/plain", "start_char_idx": 187996, "end_char_idx": 192373, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "49d65a3e-9d6d-437e-ab3c-20f9fa4b5437": {"__data__": {"id_": "49d65a3e-9d6d-437e-ab3c-20f9fa4b5437", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67ef8885-8b92-4259-8e64-0a7606df6c57", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "20968a68c2e07df70b1317647cc14ab2c3efcd66b27e11d1556199d741da795c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a06e2f94-aaf6-4a32-815b-de55f5e68210", "node_type": "1", "metadata": {}, "hash": "1de5f5b1ba7cc5257e4727bb2c6f099b73cb0db70ddb69db41846629a49012f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Sam has a little halfpipe and he does skateboard tricks.\nMaru has a little gadget that she works on.\nAbigail plays her flute.\nLeah has a sculpture to carve.\nSebastian works on his bike.\nAlex lifts weights.\nPenny, Harvey, and Elliott read a book in a little potted plant garden.\nEmily meditates in a crystal garden.\nHaley takes pictures between two potted palm trees.\nShane has a little chicken hutch, and he stands by it holding his chicken \"Charlie\".\nShane can be married and has new dialogue, scheduling and heart events. There's a new door for Shane in Marnie's shop which is locked. Shane's \"spouse room\" is a mess, with a mini-fridge and a muddy path of footprints leading up to it.\nEmily can be married and has new dialogue, scheduling and heart events.\nBuildings\nRobin has a few new buildings available for sale.\nshed: an empty room which players can do whatever they like with. They can decorate it the same way as their house.\nmill: lets players place wheat in it to make flour, or beets to make sugar. One wheat makes one flour. One beet makes 3 sugars. When they place wheat or beets inside, the flour or sugar will be ready the next morning. The little box on the right side of the mill acts like a chest and it will contain any product that has been milled the previous day.\nThe wizard now offers new farm buildings after completing a quest line. These buildings are very expensive and intended for end-game. They'll appear instantly after purchase, unlike Robin's buildings which require construction.\nJunimo hut: Junimos will come out to harvest any mature crops within a certain distance of the hut. The Junimos will place the crops they harvest in the hut for players to grab at their leisure.\nWater obelisk: when interacted with, it warps players to the beach, exactly like the beach warp totem. It's basically an infinite totem that lives on the farm.\nEarth obelisk: just like the water obelisk except it warps players to the mountains.\nGold clock: prevents debris from appearing on your farm. Keeps fences from decaying.\nFarm maps\nThere are now five farm maps to choose from when starting a new game. The basic map that exists currently, as well as a new map themed around each \"skill\". Each special map has a feature that makes it a little different, and each map also comes with unique decorations inside the players house.\nRiverlands: lots of water on this map... limiting your farm space. Looks nice. Fishing is actually viable on this farm... In fact, players can catch the same fish that are available in town.\nForest: the forest encroaches on the land, limiting farming space. However, there are renewable stumps on the east edge of the map, and seasonal forage items spawn there as well. Also, there is a new type of \"weed\" that spawns on the farm, which looks unique and will always drop mixed seeds when cut.\nHill-top: lots of cliffs... and there is a special mining area in the southwest where ore will spawn, as well as unique geode-bearing stones.\nWilderness: lots of space to farm, looks a little more interesting than the basic farm with a large lake in the southwest corner, and a cliff along the east and south. On this map, bats and golems will come out at night. There is a new monster called a wilderness golem which is unique to this map. It behaves just like the stone golem, but has different drops. Its stats scale with player combat level.\nFarm\nAdded coffee beans, which can be used to brew coffee.\nAdded a new farmhouse upgrade which adds a cellar.\nAdded casks, which can be used to age alcohol and cheese to higher quality and value. This includes a new iridium quality, which doubles the value of the base item.\nFruit trees can now produce iridium-quality fruit. The fruit trees increase quality by 1 star per year of age after reaching maturity.\nDivorce\nPlayers can now divorce their spouse by filing in a little book inside the mayor's house.\nAfter divorce, your spouse moves out and returns to their old life, but any children will stay.\nAfter divorce, ex-spouses are less friendly toward the player and have unique 'rejected' dialogue.\nUsing the Dark Shrine of Memory in the Witch's Hut will erase the ex-spouses memory, making it seem like you had never been married.\nOther new content\nReturn scepter now sold by Krobus in the sewer for 2,000,000g. This item acts like a permanent warp totem to the farm.", "mimetype": "text/plain", "start_char_idx": 191554, "end_char_idx": 195911, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a06e2f94-aaf6-4a32-815b-de55f5e68210": {"__data__": {"id_": "a06e2f94-aaf6-4a32-815b-de55f5e68210", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49d65a3e-9d6d-437e-ab3c-20f9fa4b5437", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "faa9f9984a6c6d57e23f4e44a6c28845c472b04cf3d97331228aa40ce094b9d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6e6168c9-0387-4978-a29f-700673aa1fb7", "node_type": "1", "metadata": {}, "hash": "1904b2bde40b140137e0c62d17800ba8156b557f19b37ad36e10b3656f573fa9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Added casks, which can be used to age alcohol and cheese to higher quality and value. This includes a new iridium quality, which doubles the value of the base item.\nFruit trees can now produce iridium-quality fruit. The fruit trees increase quality by 1 star per year of age after reaching maturity.\nDivorce\nPlayers can now divorce their spouse by filing in a little book inside the mayor's house.\nAfter divorce, your spouse moves out and returns to their old life, but any children will stay.\nAfter divorce, ex-spouses are less friendly toward the player and have unique 'rejected' dialogue.\nUsing the Dark Shrine of Memory in the Witch's Hut will erase the ex-spouses memory, making it seem like you had never been married.\nOther new content\nReturn scepter now sold by Krobus in the sewer for 2,000,000g. This item acts like a permanent warp totem to the farm. You can use it any time to warp back to the farm.\nTwo new fish can be caught in the wild: slimejack (Mutant Bug Lair) and void salmon (Witch's Swamp).\nInside a new building, the Witch's Hut there are three new shrines:\nDark Shrine of Memory - Will erase a divorced spouse's memory, making it seem like you had never been married.\nDark Shrine of Selfishness - Allows you to turn your children into doves (Gets rid of them) in exchange for a prismatic shard.\nDark Shrine of Night Terrors - Allows you to toggle having monsters spawn on your farm in exchange for a strange bun.\nThere are two new quests available which unlock the new Wizard farm buildings (available after completing either the Community Center or JojaMart goals).\nDark Talisman - Sends the player to a new area, the Mutant Bug Lair to retrieve a powerful magical artifact.\nGoblin Problem - Sends the player to a new area, the Witch's Swamp.\nhoney can now be placed inside kegs to make mead.\ncasks can now be crafted to age alcohol and cheese which increases quality.\nvoid mayonnaise can now be crafted from void eggs.\ncatalogue - Sold by Pierre, this expensive furniture piece allows players to purchase wallpaper and flooring from their home.\nfurniture catalogue - Sold by Robin. Like the catalogue, this can be placed at the farm and players can interact with it to purchase furniture.\nNew furniture - anchor, bamboo mat, boarded window, bonsai tree, burlap rug, candle lamp, carved window, ceiling flags, decorative lantern, floor TV, green cottage rug, hanging shield, Junimo plush, l. light string, metal window, miner's crest, monster danglers, monster rug, mystic rug, nautical rug, ornate lamp, ornate window, porthole window, s. pine, small crystal, tree column, woodcut rug, world map.\nGalaxy swords, galaxy daggers and galaxy hammers are now purchasable from Marlon once you have obtained a galaxy sword.\nMinor changes\nNew mail messages after the player passes out from exhaustion or dies. They'll sometimes end up at Harvey's clinic after passing out.\nStrange bun had its price and cooking ingredients adjusted.\nGiving someone a gift on their birthday will never make your spouse jealous.\nYou can now wallpaper the little hallways in your upgraded house.\nWhen you beat Journey of the Prairie King, you can now start over in a harder mode, keeping your upgrades and coins.\n2 new \"Lost Books\" to collect for the library.\nYou can now choose to color your chests with one of 20 color options.\nNPC's now appreciate quality level in gifts, but it only has an effect on gifts they \"like\" or \"love\".\nYou can now move your buildings via Robin's construction menu.\nKrobus now sells void eggs.\nSlime balls now have a chance to drop petrified slime.\nWhen paused, the time now blinks from black to gray, to black.\nAdded a graphics option to display \"sharper\" stack number digits.\nKegs no longer require clay to craft.\nYou can once again plant fruit trees around the edge of the greenhouse interior.\nAfter seeing Shane's 8-heart event, each chicken you purchase from Marnie has a 25% chance of being blue. Aside from appearance, the blue chicken is identical to the white chicken.\nSunflower seeds can now be purchased and planted in summer in addition to fall.", "mimetype": "text/plain", "start_char_idx": 195049, "end_char_idx": 199135, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6e6168c9-0387-4978-a29f-700673aa1fb7": {"__data__": {"id_": "6e6168c9-0387-4978-a29f-700673aa1fb7", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a06e2f94-aaf6-4a32-815b-de55f5e68210", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "a6e58efad913257ac2148eb1b983c5bea95bfb69ddfc27cfbcd1a5d101dcfaf3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a5b3c2d-bbfb-4021-af7a-da9e63a32e2c", "node_type": "1", "metadata": {}, "hash": "f7a5d1ac87f1b7e40e9133a734bfcdd98a23bd8632461a559d23e49d2068f56e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "You can now choose to color your chests with one of 20 color options.\nNPC's now appreciate quality level in gifts, but it only has an effect on gifts they \"like\" or \"love\".\nYou can now move your buildings via Robin's construction menu.\nKrobus now sells void eggs.\nSlime balls now have a chance to drop petrified slime.\nWhen paused, the time now blinks from black to gray, to black.\nAdded a graphics option to display \"sharper\" stack number digits.\nKegs no longer require clay to craft.\nYou can once again plant fruit trees around the edge of the greenhouse interior.\nAfter seeing Shane's 8-heart event, each chicken you purchase from Marnie has a 25% chance of being blue. Aside from appearance, the blue chicken is identical to the white chicken.\nSunflower seeds can now be purchased and planted in summer in addition to fall.\nBalance changes\nAll animal products are increased in value by 25% (rounded up to the nearest 5g)\nThe Rancher profession now increases the value of animal products by 20%, up from 10%\nThe Artisan profession now increases the value of Artisan goods by 40%, down from 50%\nThe Blacksmith profession now increases the value of metal bars by 50%, up from 25%\nThe value of blueberry is now 50g, down from 80g\nThe value of starfruit is now 750g, down from 800g\nThe value of cranberry is now 75g, down from 130g\nThe value of ancient fruit is now 550g, down from 750g\nCranberry sauce has had its value reduced to 120g\nStuffing has had its value reduced to 165g\nCranberry candy has had its value reduced to 175g\nBlueberry tart has had its value reduced to 150g\nFruit salad has had its value reduced to 450g\nReduced sell price of cranberry seeds to 60g\nBug fixes\nWild plums are now labeled as fruit.\nGrandpa's Shrine should now always properly give the reward for reaching 4 candles.\nFixed issue where gathering an item with the \"botanist\" profession would fail if the inventory was full, even though the gold-level item was present in the inventory.\nSlime charmer ring should now protect against giant slimes.\nYou can no longer tap a stump.\nFixed Joja Warehouse graphic issue in winter.\n\"Check action\"-mapped keys should now work to attach bait to a rod.\nRain ambient sound should no longer play in Sandy's Oasis under any conditions.\nYour baby should now be properly born, even if you pass out in the mines on the eve of the birth.\nMoonlight Jellies engagement crash.\nGalaxy sword should now be truly unloseable.\nYou can no longer lose hay to a hopper because you have no silo.\nYou can no longer plant fruit trees off the farm.\nTypo fixes\n1.07a\nStardew Valley 1.07a was released on 29 July 2016.\n\nChanges\nAdded Mac OSX and Linux compatibility.\n1.07\nStardew Valley 1.07 was released 04 April 2016, with a beta posted to the Steam beta channel on 31 March 2016.\n\nGameplay\nSpouses now say unique dialogues during festivals (most of the time), rather than the generic handful of dialogues.\nSpouse stands next to you at the Dance of the Moonlight Jellies.\nIn-law dialogue... when you marry someone, their parents/relatives dialogues will change slightly to account for the change.\nSam, Sebastian, and Abigail now go to the saloon on Fridays after you marry them.\nSpouses won't leave on rainy days, unless they have to go to work.\nFruit trees produce higher quality fruit as they age. (once per year, up to gold star).\nFruit tree harvesting now involves shaking the tree to drop the fruit.\nLightning strikes now have a unique effect on fruit trees.\nLightning is more likely to strike trees and crops, but lightning rods now have a very good chance of intercepting lightning strikes (if they aren't already processing a lightning bolt).\nCharcoal kiln now requires 10 wood to produce 1 coal, down from 20.\nMaxed-out friendship levels will no longer decay.\nAdded another digit to the shipping menu money counters.\nDying in the mines is less harsh: money lost caps at 5000g, rate of item loss reduced, can't lose rings or the galaxy sword.\nYour assigned movement keys are now used within Journey of the Prairie King.\nYou can now retrieve powerups and coins that drop on the edge of the map in Journey of the Prairie King.", "mimetype": "text/plain", "start_char_idx": 198308, "end_char_idx": 202437, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3a5b3c2d-bbfb-4021-af7a-da9e63a32e2c": {"__data__": {"id_": "3a5b3c2d-bbfb-4021-af7a-da9e63a32e2c", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6e6168c9-0387-4978-a29f-700673aa1fb7", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "964fa159674edc9ca6ee47267f76c8f87c7c09bb19f7a1cf07ceb2b0dc2f2489", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad545ae1-7067-4e8c-8162-3578b9cca697", "node_type": "1", "metadata": {}, "hash": "1fc624a38589d36b9d41eb56f07b531fb32e99d30de82f8de72ad2cff3b9c71d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fruit trees produce higher quality fruit as they age. (once per year, up to gold star).\nFruit tree harvesting now involves shaking the tree to drop the fruit.\nLightning strikes now have a unique effect on fruit trees.\nLightning is more likely to strike trees and crops, but lightning rods now have a very good chance of intercepting lightning strikes (if they aren't already processing a lightning bolt).\nCharcoal kiln now requires 10 wood to produce 1 coal, down from 20.\nMaxed-out friendship levels will no longer decay.\nAdded another digit to the shipping menu money counters.\nDying in the mines is less harsh: money lost caps at 5000g, rate of item loss reduced, can't lose rings or the galaxy sword.\nYour assigned movement keys are now used within Journey of the Prairie King.\nYou can now retrieve powerups and coins that drop on the edge of the map in Journey of the Prairie King.\nThe last two hearts are now greyed-out for marriage candidates until you give them the bouquet.\nWilly now likes most fish dishes.\nAdventurer's Guild now sells monster slayer rewards after you've unlocked them (you still get the free reward).\nHardware mouse cursor option.\nBug fixes\nTools left in chests within farm buildings won't count as \"missing\".\nPoppy properly consumed in poppyseed muffin recipe.\nCan no longer incorrectly \"consume\" trap bobbers (click to make them disappear with strange sound).\nAgriculturist profession no longer causes an extra 25% growth rate when speed-gro isn't present. Speed increase effects should now properly apply to very slow-growing crops.\nFixed sunflower seed price at JojaMart.\nChests should no longer appear on top of your in bed after upgrading your house.\nItem placement with the gamepad improved, and there is now an option to show an item placement indicator.\nSnow yams shouldn't appear in the desert anymore.\nSea cucumber should properly appear in the fishing tab of the Shipping menu.\nFarm animals should no longer get stuck on fences placed directly to the right of the barn door.\nVarious minor bug fixes.\nMinor changes/fixes to dialogue.\n1.06\nStardew Valley 1.06 was released 20 March 2016.\n\nChanges\nAdded unique dialogues for all spouses.\nSpouses now leave the house on Mondays.\nValue of most animal products increased.\nHolly is now poisonous.\nMissing events problem shouldn't happen anymore.\nMinor bug/grammar/graphics fixes.\n1.051b\nStardew Valley 1.051b was released 17 March 2016.\n\nChanges\nFixed disappearing item problem. (items can still be destroyed by farm debris).\nKegs now require oak resin to craft.\nBee houses now require maple syrup to craft.\nTortilla price changed from 75g to 50g.\nNautilus shell (artifact) renamed to nautilus fossil.\n1.051\nStardew Valley 1.051 was released 12 March 2016.\n\nChanges\nFixed weird rectangle lighting problem.\nFlooring can now be removed by bombs.\nYou can press a \"menu\" button (Esc or E by default) to close out of yes/no dialogues.\nIf no other function is mapped to it, the Y key will choose \"yes\" in a yes/no dialogue.\nYou can use the trigger buttons on a gamepad to navigate through the Community Center menu.\nMinor fixes.\nMore secrets.\n1.05\nStardew Valley 1.05 was released 9 March 2016, with a beta posted to the Steam beta channel on 4 March 2016.\n\nGameplay changes\nOnly read if you've gotten to year 3: Grandpa's had a change of heart... he feels he's been a little too harsh with his judgements. He no longer mentions \"great honors\", and his dialogue is a lot softer. If he's already visited you, check his shrine for a new opportunity...\nRestored a \"lost\" Shane event.\nChanged earthquake to Summer 3rd... to make it clear that it's the season change that kills crops.\nIncreased opportunities for iridium. The chance to find iridium in the Skull Cavern increases significantly every ten levels.\nAdded a zoom in/out feature to the options tab.\nAdded volume sliders for ambient sounds and footstep sounds.\nAdded snow transparency slider.\nAdded option to turn off flash effects.\nAdded lighting quality option.\nAdded quest (Rat Problem) to make it clearer that you have to investigate the Community Center.\nBug fixes\nLeah's schedule has been fixed.\nSpouses who have jobs won't get stuck in the bus area anymore.\nUpgrading a house with crafted flooring should no longer cause a mess.\nRestored more advanced NPC end-point behavior.\n\"Secret\" NPC's should no longer show up on calendar until you meet them.", "mimetype": "text/plain", "start_char_idx": 201551, "end_char_idx": 205937, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad545ae1-7067-4e8c-8162-3578b9cca697": {"__data__": {"id_": "ad545ae1-7067-4e8c-8162-3578b9cca697", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a5b3c2d-bbfb-4021-af7a-da9e63a32e2c", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "17935dce0019a821feb4f52d5cebfce0a691d8fcf0dbed14102dba78ee65c62f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9553a3a8-55b2-43c7-a0f8-b606f8a19027", "node_type": "1", "metadata": {}, "hash": "87badfa4bee32006ea2846b8a800b749ef5462877ecc257a935c70050a08c805", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If he's already visited you, check his shrine for a new opportunity...\nRestored a \"lost\" Shane event.\nChanged earthquake to Summer 3rd... to make it clear that it's the season change that kills crops.\nIncreased opportunities for iridium. The chance to find iridium in the Skull Cavern increases significantly every ten levels.\nAdded a zoom in/out feature to the options tab.\nAdded volume sliders for ambient sounds and footstep sounds.\nAdded snow transparency slider.\nAdded option to turn off flash effects.\nAdded lighting quality option.\nAdded quest (Rat Problem) to make it clearer that you have to investigate the Community Center.\nBug fixes\nLeah's schedule has been fixed.\nSpouses who have jobs won't get stuck in the bus area anymore.\nUpgrading a house with crafted flooring should no longer cause a mess.\nRestored more advanced NPC end-point behavior.\n\"Secret\" NPC's should no longer show up on calendar until you meet them.\nEscargot, chowder, etc. should now properly give fishing buff.\nYou now truly cannot pass the bouncer.\nYou can no longer get stuck trying to board the bus.\nFixed issue with invisible trees preventing interaction with tiles.\nDead flowers no longer affect honey.\nYou can now dance with your spouse at the Flower Dance.\nGame should now properly pause when steam overlay is active.\nFixed issue where inactive window was still responding to input.\nFixed fertilizer prices in Pierre's shop.\nFixed Fector's Challenge.\nYou can now press the toolbar shortcut keys (1, 2, 3, etc. by default) to change the active slot while the inventory menu is up.\nIron ore nodes can no longer be removed, only destroyed.\nThe dog or cat should no longer sit on chests...\nSpouses less likely to run away into the dark abyss.\nNaming your child after an NPC should no longer cause issues.\nFixed issue where recipes would sometimes consume more ingredients than they should.\nFixed crashes in certain cutscenes, when certain dialogue options were chosen.\nMany small bug and typo fixes.\n1.04\nStardew Valley 1.04 was released 1 March 2016.\n\nGameplay changes\nAdded a randomize character button to the character creation screen.\nRobin now sells crafting recipes for wood floor, stone floor, and stepping stone path.\nAdded a secret new way to modify a rare item.\nIncreased grass growth rate.\nIncreased forage spawn possibilities, and made it much less likely for forage to spawn behind trees.\nReduced value of honey from 200g to 100g.\nRaised Clint's ore prices.\nInventory menus now indicate which slot is the \"active slot\".\nMade the meteorite look snazzier.\nBug fixes\nFixed problem with swinging sword while riding a horse.\nFixed strange lighting behavior when holding torches.\nFixed problem where stone fence was spawning debris.\nSpouse should no longer get stuck on their way to town.\nWild seeds now produce the proper produce when in the greenhouse.\nSecret gift exchange should now work properly.\nAll scarecrows now give reports on their crow-scaring activity.\nBouncer is now truly impassable.\nTrees no longer grow directly in front of warp statues.\nWilly's shop no longer counts as water.\nThe meteorite should no longer appear in the pond or buildings.\nIf an object is ever directly underneath you, preventing you from moving, right click to remove it.\nMariner and Luremaster professions should now work properly.\nTappers are now properly destroyed by bombs.\nFixed bathing hairstyle inconsistency.\nFixed various item duplication and stacking issues.\nPoppyseed muffin now actually looks like a muffin.\nQuest items should no longer disappear when you die.\nYou can no longer give quest items to the wrong person.\nThe Skull Cavern quest can no longer be completed before receiving the actual journal entry.\n1.03\nStardew Valley 1.03 was released 28 February 2016.\n\nGameplay changes\nThe cooking menu now looks for items in your refrigerator as well as your inventory.\nScarecrow range reduced to an 8 tiles radius.\nThe price of mayonnaise and other artisan animal products now increased by the rancher profession.\nOnce you befriend someone to 2 hearts, their room is permanently unlocked, even if you go below 2 hearts again.\nThe 'auto run' option is now enabled by default.\nBug fixes\nFixed duplicate item issue in the mines.\nLadders should no longer spawn underneath the player, locking them in place.\nFixed problems with the Community Center menu. You can now throw items down and delete them (Delete key) in the Community Center menu.\nFixed item quality exploit.\nYou can now throw items down while in the crafting menu.\nIf you destroy the stable, you can now rebuild it.\nSpa won't recharge you while the game is paused (e.g., steam overlay up).\nFixed problems with the Stardew Valley Fair fishing game.\nVarious stability fixes.", "mimetype": "text/plain", "start_char_idx": 205007, "end_char_idx": 209729, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9553a3a8-55b2-43c7-a0f8-b606f8a19027": {"__data__": {"id_": "9553a3a8-55b2-43c7-a0f8-b606f8a19027", "embedding": null, "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16", "node_type": "4", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "2f861d850d5462c14c252ae17b534c985d14c2a0bc1077a77463ca3d20f78102", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad545ae1-7067-4e8c-8162-3578b9cca697", "node_type": "1", "metadata": {"source_url": "https://stardewvalleywiki.com/Version_History", "document_index": 16}, "hash": "5e4877f80c35c22a93996d3bfa07cbc4a4636e344cf41665f73048ccdd78c920", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Scarecrow range reduced to an 8 tiles radius.\nThe price of mayonnaise and other artisan animal products now increased by the rancher profession.\nOnce you befriend someone to 2 hearts, their room is permanently unlocked, even if you go below 2 hearts again.\nThe 'auto run' option is now enabled by default.\nBug fixes\nFixed duplicate item issue in the mines.\nLadders should no longer spawn underneath the player, locking them in place.\nFixed problems with the Community Center menu. You can now throw items down and delete them (Delete key) in the Community Center menu.\nFixed item quality exploit.\nYou can now throw items down while in the crafting menu.\nIf you destroy the stable, you can now rebuild it.\nSpa won't recharge you while the game is paused (e.g., steam overlay up).\nFixed problems with the Stardew Valley Fair fishing game.\nVarious stability fixes.\n1.02\nStardew Valley 1.02 was released 27 February 2016.\n\nChanges\nIf you never received your pet, you will now have another opportunity.\nWhen you go to sleep, the game now checks if any of your essential tools are missing. If so, they will appear next to your bed in the morning.\nThe game now properly saves on level-up nights.\nEating skill food and then going to bed on a level-up night works properly now.\nFixed problem where completing the Crafts Room while standing in certain locations causes your character to get stuck.\nPlayer character should now walk correctly while in a cutscene after drinking coffee.\nRemoved an item duplication exploit.\nForage items should no longer spawn in the woods above the beach.\nFixed crab pot problem (again).\nFixed exploding armchair bug.\nRelaxing in the spa with your menu up no longer restores energy.\nRemoved Leah's doppelganger.\nDebris should no longer spawn in the pathway between farm & forest.\nFixed disappearing tapper problem.\nFixed a few minor graphics problems & dialogue typos.\nOther minor issues (spoilers).\nTools being upgraded no longer erroneously considered \"missing\".\nClay duplication bug fixed.\nPet cutscene won't refer to the \"cat\" as a \"dog\" anymore.\nLeah's 10-heart event fixed.\nPepper Popper recipe now requires cheese.\n1.01\nStardew Valley 1.01 was released 26 February 2016.\n\nChanges\nFixed random crash when going to sleep after getting your pet.\nSound effect volume now properly applied on load.\nThe error item should no longer appear for sale in the saloon.\nZ key is now bind-able.\nNo longer possible to exit the Community Center menus while holding an item.\nFinding your first artifact from a geode no longer destroys remaining held geodes.\nMature wild crops no longer disappear on day of load.\nCrab pots can now be placed and removed without issue.\nFixed crash when inspecting chests in the mines.\nYou can no longer place chests in the mines.\nTree seeds no longer incorrectly show a \"Wrong Season\" message.\nFixed some map issues.\n1.0\nStardew Valley 1.0 was released on 26 February 2016.", "mimetype": "text/plain", "start_char_idx": 208868, "end_char_idx": 211782, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9b1fd7a4-5597-4b87-9cbc-f4b793956967": {"__data__": {"id_": "9b1fd7a4-5597-4b87-9cbc-f4b793956967", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e2c2ab1d-d9fe-429f-ad9b-d23477f25035", "node_type": "1", "metadata": {}, "hash": "ac41663e6a570a55bb4032ceb87b1fe01453f92ca117a39d833eeb069c8c908e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n\"This story... is a monster. And monsters wear many faces.\"\n\u2015 Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010's Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in \"The Final Draft\" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game's story. \"The Final Draft\" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson\u2019s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon\u2014and their safe haven \u2014 against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n\u2015 Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake's American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the \"Cult of the Tree\". In addition to Nightingale's corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga's daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale's corpse, but it suddenly reanimates, in search of the \"Clicker\", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4187, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2c2ab1d-d9fe-429f-ad9b-d23477f25035": {"__data__": {"id_": "e2c2ab1d-d9fe-429f-ad9b-d23477f25035", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b1fd7a4-5597-4b87-9cbc-f4b793956967", "node_type": "1", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "c07ed4fff2d1b4fa278da628a2dbceaf315ba8311fc1b7095b231bc96a73ef90", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48ee0318-2226-4696-8169-5b3a411ead7f", "node_type": "1", "metadata": {}, "hash": "fb45a9bd605e4a0d6841b79399bc02f94777a264d2a484c88f2be9c2c766a707", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is believed he was murdered by a group calling themselves the \"Cult of the Tree\". In addition to Nightingale's corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga's daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale's corpse, but it suddenly reanimates, in search of the \"Clicker\", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a \"Taken\", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called \"In Between With Mr. Door\", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey's investigation of the \"Cult of the Word\" led by Alan's evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, \"Return\", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that \"Return\" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality \"Return\" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.", "mimetype": "text/plain", "start_char_idx": 3345, "end_char_idx": 7955, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "48ee0318-2226-4696-8169-5b3a411ead7f": {"__data__": {"id_": "48ee0318-2226-4696-8169-5b3a411ead7f", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2c2ab1d-d9fe-429f-ad9b-d23477f25035", "node_type": "1", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "abf558a966394d54e1be532a6a5d16df8ee9aa817ba8f68b44ec0a047f91746e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3b8e7d2c-aa69-4ce5-a916-3ce0b5b9ae61", "node_type": "1", "metadata": {}, "hash": "3e40830612cab874549d2b3b8f144616935bb4b1760d43c38e00593fbd44d64c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "With no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality \"Return\" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch's ending of \"Return\", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice's death. Scratch arrives at the summoning site and Saga is able to banish him from Alan's body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for \"Return\". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence's attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga's missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door's actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey's body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through \"ascension.\" Alan then revives from his gunshot wound and says, \"It's not a loop, it's a spiral.\"\n\nIn the \"Final Draft\" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelg\u00e4nger for good while finishing the spiral and freeing Alan from the loop. Saga's call connects, confirming Logan's survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.", "mimetype": "text/plain", "start_char_idx": 7033, "end_char_idx": 11408, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3b8e7d2c-aa69-4ce5-a916-3ce0b5b9ae61": {"__data__": {"id_": "3b8e7d2c-aa69-4ce5-a916-3ce0b5b9ae61", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48ee0318-2226-4696-8169-5b3a411ead7f", "node_type": "1", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "57bf4146f336d425f385631f1c3be9b9937c32fdee8084e6ea99bd4d5cad7c5d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c392767-e9bc-4c9d-b82a-ba4a9e400eb1", "node_type": "1", "metadata": {}, "hash": "718c80d03f4c9ed0ab488823694257e63275ba9c6b422531c2c614c558b500e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through \"ascension.\" Alan then revives from his gunshot wound and says, \"It's not a loop, it's a spiral.\"\n\nIn the \"Final Draft\" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelg\u00e4nger for good while finishing the spiral and freeing Alan from the loop. Saga's call connects, confirming Logan's survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga's chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane's Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named \"The Final Draft\".\n\nExpansion 1: Night Springs\nSet as \"episodes\" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a \"critical state.\" Players also encounter various puzzles and locked boxes that they'll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga\u2019s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan's story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga's story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own \"mind palaces\" to help progress their stories, with Alan having his Writer's Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake.", "mimetype": "text/plain", "start_char_idx": 10485, "end_char_idx": 14825, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c392767-e9bc-4c9d-b82a-ba4a9e400eb1": {"__data__": {"id_": "5c392767-e9bc-4c9d-b82a-ba4a9e400eb1", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3b8e7d2c-aa69-4ce5-a916-3ce0b5b9ae61", "node_type": "1", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "e67edc9015e5defe95bb4b7f911306102307d9d4416ab7e50edee5f6296cf574", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7ec8827-2b78-4836-83ef-197794a92c95", "node_type": "1", "metadata": {}, "hash": "5eaad1b182bf738ee4086fb6e482223357b123a6545bc30c1d5213574836ec90", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga's story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own \"mind palaces\" to help progress their stories, with Alan having his Writer's Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when \"Alan Wake 2\" was shown on the Artist Althea Suarez Gata's CV, only for it to be removed on the very same day. Whilst Alan Wake's American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake's American Nightmare, the credits to the game also then indicated that \"Alan Wake's journey through the night will continue\".\n\nAlso in 2012, Sam Lake tweeted a link to a \"Blogspot\" called \"This House of Dreams.\" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man \"wearing a funny jacket with old-fashioned elbow patches\" and that he wanted \"to turn all the lights on.\" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain \"alanwake2.com\" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn't revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn't announced. He revealed that the time just wasn't right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake's American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, \"It's hard to guess,\" but that he would \"love to do that\".\n\nRemedy Connected Universe\nEaster eggs in Remedy's 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan's experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an \"Altered World Event\" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for \"Altered World Event,\" they also resemble Alan's own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, \"Through AWE you\u2019ll learn more about the Bureau\u2019s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,\u201d Lake said. \u201cWe\u2019re really happy to give fans of the original game a bit more of Alan Wake-related content.\"[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.", "mimetype": "text/plain", "start_char_idx": 13932, "end_char_idx": 18520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d7ec8827-2b78-4836-83ef-197794a92c95": {"__data__": {"id_": "d7ec8827-2b78-4836-83ef-197794a92c95", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c392767-e9bc-4c9d-b82a-ba4a9e400eb1", "node_type": "1", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "53378500d243dfed5a4cf16468def4ff89b081a7189eedb830d6ff6bbc18c7f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66a6b60d-bc5e-4374-b69d-cb01dfd634f4", "node_type": "1", "metadata": {}, "hash": "55c0ea9f7e47b4f519eabbd129e09351cedc9741b64b4d13426a7ee308226265", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for \"Altered World Event,\" they also resemble Alan's own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, \"Through AWE you\u2019ll learn more about the Bureau\u2019s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,\u201d Lake said. \u201cWe\u2019re really happy to give fans of the original game a bit more of Alan Wake-related content.\"[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan's narration, seemed to indicate Remedy's next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic's new publishing initiative. The games were said to be part of \"the same franchise\". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that \"I've heard that Remedy is going to be making Alan Wake 2,\" as part of the Remedy-Epic deal. Grubb went on to say that the game \"should kind of be the follow-up that fans of that series want,\" but that there's little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy's first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga's campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake's side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic's Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game.", "mimetype": "text/plain", "start_char_idx": 17661, "end_char_idx": 21972, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "66a6b60d-bc5e-4374-b69d-cb01dfd634f4": {"__data__": {"id_": "66a6b60d-bc5e-4374-b69d-cb01dfd634f4", "embedding": null, "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "17", "node_type": "4", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "21d752d8a3dc6337e0cc7f2ec9b7dfd3d8e654387a5785734d26a27eb9396016", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7ec8827-2b78-4836-83ef-197794a92c95", "node_type": "1", "metadata": {"source_url": "https://alanwake.fandom.com/wiki/Alan_Wake_2", "document_index": 17}, "hash": "88041c42f0f1d841f82f266ff46682797e986600e4db2b378d21d4b602fe0c82", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Reception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic's Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector's edition were announced.\nThe second entry in Remedy's Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).", "mimetype": "text/plain", "start_char_idx": 21240, "end_char_idx": 22984, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ab260da2-406f-4758-b0d6-f86f8268504b": {"__data__": {"id_": "ab260da2-406f-4758-b0d6-f86f8268504b", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8031be7e-a256-4d0f-b8dd-6f0529204353", "node_type": "1", "metadata": {}, "hash": "35f469abceb4d82b756837a777beafba43f89f365ac785c0e3132f2e15aca507", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The best sci-fi and fantasy books of 2023\nIt\u2019s been a stellar year in speculative fiction\n\nBy Nicole Clark, Sadie Gennis, and Polygon Staff  Updated Dec 8, 2023, 10:00am EST  34 Comments / 34 New\nIf you buy something from a Polygon link, Vox Media may earn a commission. See our ethics statement.\n\nIt\u2019s been another banner year for science fiction and fantasy books. Many of our favorites once again blur the line between sci-fi and fantasy, but this year was a particular standout for books blurring the line between SFF and other genres. This includes everything from historical fiction \u2014 both speculative histories and Westerns \u2014 to fable retellings to intergenerational sagas in translation.\n\nThough we seem to have crested the wave of pandemic novels, that sense of dread and discoloration has lingered, written into novels of new forms. There\u2019s a preponderance of post-post-apocalyptic science fiction unpacking lofty ideas like sentience and humanity, often set on different planets or among the stars. It has also been a standout year for supernatural horrors and thrillers, particularly ones that mix queer longing with a dose of body horror. Last but not least, it\u2019s been a great year for kissing books set in fantastical worlds.\n\nRELATED\n\nLooking for more recs? Here are our favorite books of 2022\nSo jump in and take your pick. Whichever direction you head in, it will be sure to grip you \u2014 and make you think. This list is in reverse chronological order, so the newest releases are listed first. We updated this list throughout 2023, sometimes retroactively adding in entries that we missed from earlier in the year. We\u2019ve also included our favorite runners-up.\n\nHONORABLE MENTIONS\nEmily Wilde\u2019s Encyclopaedia of Faeries by Heather Fawcett, Victory City by Salman Rushdie, The Crane Husband by Kelly Barnhill, The Mimicking of Known Successes by Malka Older, Monstrilio by Gerardo S\u00e1mano C\u00f3rdova, White Cat, Black Dog by Kelly Link, Divine Rivals by Rebecca Ross, Our Hideous Progeny by C.E. McGill, The Cheat Code (Wisdom Revolution #3) by Misba, The Deep Sky by Yume Kitasei, Silver Nitrate by Silvia Moreno-Garcia, Vampires of El Norte by Isabel Ca\u00f1as, Prophet by Sin Blach\u00e9 and Helen Macdonald, Terrace Story by Hilary Leichter, Her Radiant Curse by Elizabeth Lim, Starling House by Alix E. Harrow, System Collapse (The Murderbot Diaries #7) by Martha Wells, Dark Heir (Dark Rise #2) by C.S. Pacat\n\nCover image for Ed Park\u2019s Same Bed Different Dreams, a split image between what looks like Earth and Mars.\nImage: Random House\nSAME BED DIFFERENT DREAMS BY ED PARK\nSame Bed Different Dreams is a remarkable achievement, and not for the faint of heart. Through three storylines, the book creates a kind of speculative history of Korea, with an emphasis on World War II and Japan\u2019s colonial rule and aftermath (and, crucially, the United States\u2019 involvement). One story thread builds out a hefty alternative history of the Korean Provisional Government\u2019s role and reach. Another story thread focuses on a Black Korean War vet who wrote a sci-fi epic series called 2333, which is later adapted into a video game. And yet another story thread has a more futuristic flavor, focusing on a has-been writer who now works for a tech company called GLOAT. These threads periodically intersect \u2014 for example, GLOAT ends up owning the rights to 2333, and turns it into a kind of edutainment.\n\nIf it sounds like there\u2019s a lot going on, it\u2019s because there is. And it\u2019s made even denser by the author\u2019s Pynchonian sense of humor. Some of its best moments are utterly weird or feel like the writer was smirking \u2014 like a character\u2019s dog who can\u2019t stop \u201carchiving\u201d by burying found manuscript pages, the fact that GLOAT employees truly don\u2019t know what the acronym stands for, or the idea that Marilyn Monroe is a member of the Korean Provisional Government. These absurd bits only make it harder to comb apart what\u2019s real and what\u2019s Ed Park\u2019s \u201calternate history\u201d in sections with realistic-sounding combinations of fact and fiction.\n\nIt\u2019s got the same ambitious patchwork as Jennifer Egan\u2019s The Candy House and Namwali Serpell\u2019s The Old Drift.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4140, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8031be7e-a256-4d0f-b8dd-6f0529204353": {"__data__": {"id_": "8031be7e-a256-4d0f-b8dd-6f0529204353", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab260da2-406f-4758-b0d6-f86f8268504b", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "be33045afd455914eeb84ed605851188aec7472961e81038dcaf45a3a127f403", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1b5f2a4-dd42-42e2-9668-5dffecb2364e", "node_type": "1", "metadata": {}, "hash": "fece3e311774af06f4951825aa6e029f07585f02311f979aafd15e9aed9907f5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If it sounds like there\u2019s a lot going on, it\u2019s because there is. And it\u2019s made even denser by the author\u2019s Pynchonian sense of humor. Some of its best moments are utterly weird or feel like the writer was smirking \u2014 like a character\u2019s dog who can\u2019t stop \u201carchiving\u201d by burying found manuscript pages, the fact that GLOAT employees truly don\u2019t know what the acronym stands for, or the idea that Marilyn Monroe is a member of the Korean Provisional Government. These absurd bits only make it harder to comb apart what\u2019s real and what\u2019s Ed Park\u2019s \u201calternate history\u201d in sections with realistic-sounding combinations of fact and fiction.\n\nIt\u2019s got the same ambitious patchwork as Jennifer Egan\u2019s The Candy House and Namwali Serpell\u2019s The Old Drift. Critics have compared it to everything from David Mitchell\u2019s Cloud Atlas to David Foster Wallace\u2019s Infinite Jest. There\u2019s also, of course, books within the book. It\u2019s a fever dream of a thing, and one I\u2019d heartily recommend, but perhaps with a notebook in hand or some sticky notes to help track the references. (Or perhaps, as I did, just letting the wave of information roll over you, until you\u2019re left with a vast impression and a desire to reread.) \u2014Nicole Clark\n\nCover image for Kylie Lee Baker\u2019s The Scarlet Alchemist, featuring a woman in a red outfit with a large crown set against a dark skyline.\nImage: Inkyard Press\nTHE SCARLET ALCHEMIST (THE SCARLET ALCHEMIST #1) BY KYLIE LEE BAKER\nDo not go into The Scarlet Alchemist expecting typical YA fare. What Kylie Lee Baker delivers is a story of visceral brutality, interlaced with elements of Chinese history and thoughtful meditations on family, race, and belonging. It\u2019s a book that can turn your stomach as easily as it can break your heart.\n\nSet in an alternate Tang dynasty, the novel follows Zilan, a profoundly talented young alchemist who travels to the capital in hopes of landing a coveted position in the royal service. But being a poor, half Scotian girl means the odds are stacked inordinately high against her in the imperial service exams \u2014 and that\u2019s before her skills with the illegal art of resurrection catch the prince\u2019s attention and pull her into a dangerous political game. While the premise seems familiar (underdog competes in trials, falls into star-crossed romance), Baker\u2019s skills with immersive world-building, knotty characters, and genuinely gruesome horror make The Scarlet Alchemist a dazzling and singular tale that left me rushing to read her back catalog. \u2014Sadie Gennis\n\nCover image of C Pam Zhang\u2019s Land of Milk and Honey, featuring rollicking hills of white, blue, and yellow.\nImage: Riverhead\nLAND OF MILK AND HONEY BY C PAM ZHANG\nAfter I read How Much of These Hills is Gold in 2020, C Pam Zhang became an instant must-read author in my household. Land of Milk and Honey is entirely unlike her debut \u2014 where her debut\u2019s language was sparse and pointed, this book is florid and indulgent \u2014 though similar in the extent to which it transported me somewhere entirely new, and more than a little threatening.\n\nIn Land of Milk and Honey the climate apocalypse has rendered fresh produce, at scale, a thing of the past \u2014 which is to say a provision of the extremely rich. The protagonist, listless and hungry, applies for a job as a private chef for a mysterious family in the Italian Alps (those who live around it call it \u201c\u200b\u200bla terra di latte e miele\u201d). While there, she unravels the family\u2019s true intentions, while making them delicious meals from rare ingredients.\n\nZhang sensuously describes all pleasures of the tongue, moving from descriptions of lapping of culinary delicacies to the folds of the flesh. Food feels hyperreal, with an emphasis on the texture and taste of every ingredient \u2014 and sometimes the cruelty of that ingredient\u2019s procurement. The same can be said of its scenes depicting queer intimacy; that texture and taste take precedent, and the cruelties of human emotion, too. Even after I finished, I was hungry for more. \u2014N. Clark\n\nCover image for Megan Kamalei Kakimoto\u2019s Every Drop is a Man\u2019s Nightmare, featuring a red and yellow flower against a painted backdrop.\nImage: Bloomsbury\nEVERY DROP IS A MAN\u2019S NIGHTMARE BY MEGAN KAMALEI KAKIMOTO\nThis short story collection initially caught my attention with its cover, which depicts a woman springing up from the center of a corpse flower, like a stalk standing against the wind.", "mimetype": "text/plain", "start_char_idx": 3396, "end_char_idx": 7785, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c1b5f2a4-dd42-42e2-9668-5dffecb2364e": {"__data__": {"id_": "c1b5f2a4-dd42-42e2-9668-5dffecb2364e", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8031be7e-a256-4d0f-b8dd-6f0529204353", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "354ca3c9a233b64346f787faa4cc673293fe043c3492696acbafc556531c95d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f665aa08-b4b1-4885-b271-4e769afd80f9", "node_type": "1", "metadata": {}, "hash": "6ae03aab6d8d2420caeb445861f0d2dfeb7086815eafad86579947f9281f178d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Zhang sensuously describes all pleasures of the tongue, moving from descriptions of lapping of culinary delicacies to the folds of the flesh. Food feels hyperreal, with an emphasis on the texture and taste of every ingredient \u2014 and sometimes the cruelty of that ingredient\u2019s procurement. The same can be said of its scenes depicting queer intimacy; that texture and taste take precedent, and the cruelties of human emotion, too. Even after I finished, I was hungry for more. \u2014N. Clark\n\nCover image for Megan Kamalei Kakimoto\u2019s Every Drop is a Man\u2019s Nightmare, featuring a red and yellow flower against a painted backdrop.\nImage: Bloomsbury\nEVERY DROP IS A MAN\u2019S NIGHTMARE BY MEGAN KAMALEI KAKIMOTO\nThis short story collection initially caught my attention with its cover, which depicts a woman springing up from the center of a corpse flower, like a stalk standing against the wind. Each story weaves together Hawaiian mythology and the everyday lives of the Hawaiian and mixed-race Japanese women who live there.\n\nThese stories range from fabulism to science fiction, all speculative fiction in their own way. In one story, a woman\u2019s encounter with a wild pig ends up foreshadowing a complicated pregnancy later in her life. In another story, a Brazilian waxing company allows people to pay for hairless skin by giving up personality traits. In another story, the narrator falls for a woman who lives with her family \u2014 in one of numerous queer stories in the collection \u2014 but has to cope with that woman\u2019s decision to return to \u201cwhat remains of Kaua\u2019i\u201d and join their protests.\n\nThe author\u2019s own words, published in The Guardian, sum it up best: \u201cThere is a mythical idealisation of the islands of Hawaii as paradise, peace in the tropics; some even call it a modern utopia. Yet this flattening of Hawaii to a postcard image divests our homeland of its culture and colour, reducing us to a place and history that is easily digestible. But we are not easily digestible, and our stories are not meant to be easy for you.\u201d \u2014N. Clark\n\nCover image for Shelley Parker-Chan\u2019s He Who Drowned the World, a painted image of ships on a yellow sea, with the moon looming over them.\nImage: Tor\nHE WHO DROWNED THE WORLD (THE RADIANT EMPEROR #2) BY SHELLEY PARKER-CHAN\nAn alternate history of the founding of the Ming dynasty, He Who Drowned the World shifts between four tragically ambitious figures willing to pay any price to materialize their destiny, whether that\u2019s revenge on the empire or crowning themselves the ruler of it. They pursue these goals with unshakeable inertia, doing endlessly cruel and sadistic actions with only the occasional doubts as to whether happiness could be possible if they chose a different path.\n\nThis is a relentlessly brutal sequel, and there\u2019s a hopelessness that weighs heavy throughout the book. But Parker-Chan\u2019s penetrating ability to bring empathy and nuance into even the darkest corners of humanity sparks an undeniable connection with these characters, whose self-destructive natures would otherwise be too hard to bear witness to. He Who Drowned the World is a dark and difficult read, yet Parker-Chan\u2019s prose is so brilliant, her character work so complex, that I still found myself sad to leave this world behind. \u2014SG\n\nCover image for M.A. Carricks\u2019s Labyrinth\u2019s Heart, featuring a mask-wearing figure with purple wings sprouting out of the top of the mask.\nImage: Orbit\nLABYRINTH\u2019S HEART (ROOK & ROSE #3) BY M.A. CARRICK\nOne of my favorite fantasy series of the past five years, Rook & Rose is an intricately layered trilogy where there are so many secrets, schemes, and conspiracies that at times it\u2019s admittedly difficult to keep track of them all. Because of that, there were a lot of loose ends to tie up in the anticipated conclusion, Labyrinth\u2019s Heart. (Ren alone was juggling four different identities at the novel\u2019s start.) So imagine my surprise when I discovered M.A. Carrick not only managed to leave no question unanswered by the series\u2019 end, but wrapped up even the most complicated storylines in big, bright bows.\n\nThere are elements of Labyrinth\u2019s Heart that feel like they were precisely crafted to cater to fans, but here\u2019s the thing: I don\u2019t really care. Carrick created such a lush world populated by lovable characters, an interesting magic system, and a lived-in cultural history that I was just happy to be back in Nade\u017era after a two-year wait.", "mimetype": "text/plain", "start_char_idx": 6903, "end_char_idx": 11307, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f665aa08-b4b1-4885-b271-4e769afd80f9": {"__data__": {"id_": "f665aa08-b4b1-4885-b271-4e769afd80f9", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1b5f2a4-dd42-42e2-9668-5dffecb2364e", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "5cd4127263adbafec132df2229c062f1147b0b20c38e93e9c8c01cb4bf980831", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b2a57ef-4ca2-4f53-aa0a-037eff2ef072", "node_type": "1", "metadata": {}, "hash": "4d887de29b44908655cffae887c7367b65b289b3ad039e03048774b241cabe46", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Because of that, there were a lot of loose ends to tie up in the anticipated conclusion, Labyrinth\u2019s Heart. (Ren alone was juggling four different identities at the novel\u2019s start.) So imagine my surprise when I discovered M.A. Carrick not only managed to leave no question unanswered by the series\u2019 end, but wrapped up even the most complicated storylines in big, bright bows.\n\nThere are elements of Labyrinth\u2019s Heart that feel like they were precisely crafted to cater to fans, but here\u2019s the thing: I don\u2019t really care. Carrick created such a lush world populated by lovable characters, an interesting magic system, and a lived-in cultural history that I was just happy to be back in Nade\u017era after a two-year wait. While things may have been tied up a bit too neatly for my usual tastes, that didn\u2019t stop me from whipping through pages and smiling the whole way through. Sometimes it\u2019s nice to simply soak in a happy ending rather than bathe in the bittersweet. \u2014SG\n\nCover art for Kiersten White\u2019s Mister Magic, which features a melting television against a pink background.\nImage: Del Rey Books\nMISTER MAGIC BY KIERSTEN WHITE\nThe latest fantasy-with-an-irresistible-pop-premise from the author of Hide, Mister Magic revolves around a children\u2019s TV show no viewer can forget \u2026 or prove it ever existed in the first place. There are no official records of it, no YouTube videos or merchandise or passed-around VHS tapes, and any discussion of it on the internet rapidly disappears. But the people who remember seeing it are convinced the special effects were remarkably vivid and realistic. They agree the central concept is unnerving: a creepy magician-figure leading a group of children in imagination-games aimed at teaching some decidedly non-standard lessons about embracing conformity and meekness. And they\u2019re all sure that something horrible happened while they were watching, though they can\u2019t agree on what.\n\nA reunion between five of the former child cast members, taking place 30 years after the show ended, slowly unravels its mysteries, which are even weirder than the description above suggests. Mister Magic is a startling dark fantasy with a lot of foreboding, foreshadowing, and eerie twists. At heart, though, it\u2019s also an incisive story about the kinds of people who revel in control over other people\u2019s lives, and about what an act of rebellion imagination can be. \u2014Tasha Robinson\n\nCover image for Rebekah Bergman\u2019s The Museum of Human History, featuring a painted image of a naked figure with a red cloud over the top of their head.\nImage: Tin House\nTHE MUSEUM OF HUMAN HISTORY BY REBEKAH BERGMAN\nA poetic reflection on memory, loss, and connection, The Museum of Human History is a stunning debut reminiscent of the work of Emily St. John Mandel. Slipping backward and forward in time, this introspective mosaic weaves between an identical twin whose sister fell asleep at age 8 and has never aged in the 25 years since, a museum director who questions his place within the family legacy, a widower who lost his most cherished memories as a result of an anti-aging treatment, and others equally struggling with the passage of time. There is a lyrical detachment in Bergman\u2019s prose that leaves you feeling like you\u2019re watching events unfold through a pane of thick glass, never fully able to connect with the characters, yet you remain helplessly transfixed by the haunting cycle they\u2019re caught in. It\u2019s an incredibly melancholy book, but the kind of aching sadness you\u2019re happy to sink into. \u2014SG\n\nCover image for Sara Hashem\u2019s The Jasad Heir, featuring what looks like statues of a snake,, a bull, and a griffin.\nImage: Orbit Books\nTHE JASAD HEIR (THE SCORCHED THRONE #1) BY SARA HASHEM\n\u201cArin of Nizahl was maddeningly elegant. I wanted to cut him open and compare our bones to understand why his gave him grace and mine gave me back pain.\u201d This was the line that absolutely sold me on The Jasad Heir, an irresistible enemies-to-lovers fantasy that reminded me why I\u2019ll never quit this genre.\n\nHeadstrong Sylvia is the presumed dead heir of Jasad, a kingdom that was destroyed by the neighboring Nizahl and saw its citizens\u2019 innate magic outlawed. Sylvia managed to carve out a relatively normal life for herself as a chemist\u2019s apprentice, but everything falls apart after she accidentally reveals her magic to the heir of Nizahl.", "mimetype": "text/plain", "start_char_idx": 10591, "end_char_idx": 14945, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b2a57ef-4ca2-4f53-aa0a-037eff2ef072": {"__data__": {"id_": "8b2a57ef-4ca2-4f53-aa0a-037eff2ef072", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f665aa08-b4b1-4885-b271-4e769afd80f9", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "64140fd3b1def477fd008b1dbbac6672533389dbd45342da597fa2d27646a3a5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4dd0f0ef-51d0-4ba6-ab8c-0da8474bb192", "node_type": "1", "metadata": {}, "hash": "500827edb21b0f85ff2bfd8a01dec8f5340189a5f4eeee6edf8dea71712440ff", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Image: Orbit Books\nTHE JASAD HEIR (THE SCORCHED THRONE #1) BY SARA HASHEM\n\u201cArin of Nizahl was maddeningly elegant. I wanted to cut him open and compare our bones to understand why his gave him grace and mine gave me back pain.\u201d This was the line that absolutely sold me on The Jasad Heir, an irresistible enemies-to-lovers fantasy that reminded me why I\u2019ll never quit this genre.\n\nHeadstrong Sylvia is the presumed dead heir of Jasad, a kingdom that was destroyed by the neighboring Nizahl and saw its citizens\u2019 innate magic outlawed. Sylvia managed to carve out a relatively normal life for herself as a chemist\u2019s apprentice, but everything falls apart after she accidentally reveals her magic to the heir of Nizahl. Using her life as leverage, the calculating Arin strikes a deal with Sylvia to help him capture a group of Jasadi rebels and act as his champion in a series of deadly trials. It\u2019s a familiar setup, but one impeccably done by Hashem, who delivers sharp political intrigue, sparkling banter, and touching friendships on top of Sylvia and Arin\u2019s simmering romance. \u2014SG\n\nCover image for Kritika H. Rao\u2019s The Surviving Sky, featuring a floating island overgrowing with buildings and plant life, above a stormy planet.\nImage: Titan Books\nTHE SURVIVING SKY (THE RAGES TRILOGY #1) BY KRITIKA H. RAO\nAfter I finished The Surviving Sky, I wouldn\u2019t shut up about it and tried (not always successfully) to get everyone I know to read it. So let me try once more, and maybe with less yelling this time:\n\nWith the planet\u2019s surface made unlivable by catastrophic storms, the remains of humanity survive on floating cities constructed of and powered by plants that only a select group of people, known as architects, can control. An archeologist without the ability to traject plants, Ahilya has dedicated her life to finding a way to unshackle humanity\u2019s survival from the architects\u2019 powers and return to the surface. It\u2019s not hard to see why this mission causes friction in her marriage to Iravan, one of the most powerful architects in their city, and one with an arrogance to match his revered status. Though estranged, Ahilya and Iravan come together to help clear his name after he\u2019s accused of pushing his powers dangerously far, an accusation, which if proved true, carries dire consequences for the architect.\n\nBut the deeper they look into trajection and its risks, the more Ahilya and Iravan realize they don\u2019t actually know much about where their people \u2013 and their powers \u2013 came from. And as the floating cities begin to sink toward the earthrages below, the race to save their civilization may also be the end of society as it stands, as Ahilya and Iravan uncover long-buried truths that previous generations worked hard to keep hidden.\n\nSo did I do it? Did I convince you to read this Hindu philosophy-inspired debut with some of the most inventive world-building and one of the most complex romances I\u2019ve read in years? Please say yes. You\u2019ll be doing us both a favor. \u2014SG\n\nCover image for Alexander Darwin\u2019s The Combat Codes, which features a metallic dragon against a black background.\nImage: Orbit\nTHE COMBAT CODES AND GRIEVAR\u2019S BLOOD (THE COMBAT CODES SAGA #1-2) BY ALEXANDER DARWIN\nIn the world of The Combat Codes, war no longer exists as it used to. Neither does justice \u2014 both concepts have been replaced by proxies who fight on behalf of nations or individuals, solving disputes with their fists.\n\nAlexander Darwin\u2019s debut novel effectively builds a world around this core concept, bringing it to life with compelling characters and locations (including a classic \u201cmagical school for gifted youngsters\u201d situation). The Combat Codes follows Cego, a young abandoned boy skilled at fighting, and Murray, a washed-up former fighter now tasked with scouting the next generation of combatants, whose discovery of Cego changes his entire world.\n\nDarwin is also a Brazilian jiu-jitsu practitioner and teacher, and uses that experience in the books\u2019 excellent fight sequences. His evocative and visceral descriptions not only deliver excitement and suspense in this underdog story; they build your understanding of the characters through how they fight. The Combat Codes and its equally fun sequel, Grievar\u2019s Blood, which adds new exciting characters and points-of-view, are the first two parts of a planned trilogy, and I can\u2019t wait for the conclusion next year.", "mimetype": "text/plain", "start_char_idx": 14228, "end_char_idx": 18610, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4dd0f0ef-51d0-4ba6-ab8c-0da8474bb192": {"__data__": {"id_": "4dd0f0ef-51d0-4ba6-ab8c-0da8474bb192", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b2a57ef-4ca2-4f53-aa0a-037eff2ef072", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "8431572f8bbce6740914a7ab8f47d1027a7827a8777f0e20edad28daead2aa5f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "265c159b-54ab-493d-b7ce-582a12f6e683", "node_type": "1", "metadata": {}, "hash": "fac5c5665b61f91494f425e311b236a231df0521b2a7070b85fb9e792bf42bce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Alexander Darwin\u2019s debut novel effectively builds a world around this core concept, bringing it to life with compelling characters and locations (including a classic \u201cmagical school for gifted youngsters\u201d situation). The Combat Codes follows Cego, a young abandoned boy skilled at fighting, and Murray, a washed-up former fighter now tasked with scouting the next generation of combatants, whose discovery of Cego changes his entire world.\n\nDarwin is also a Brazilian jiu-jitsu practitioner and teacher, and uses that experience in the books\u2019 excellent fight sequences. His evocative and visceral descriptions not only deliver excitement and suspense in this underdog story; they build your understanding of the characters through how they fight. The Combat Codes and its equally fun sequel, Grievar\u2019s Blood, which adds new exciting characters and points-of-view, are the first two parts of a planned trilogy, and I can\u2019t wait for the conclusion next year. \u2014Pete Volk\n\nCover image for Katie Williams\u2019 My Murder, showing a woman\u2019s face peering outside of red vertical lines.\nImage: Riverhead Books\nMY MURDER BY KATIE WILLIAMS\nFans of Sarah Gailey\u2019s The Echo Wife won\u2019t want to miss My Murder, which shares some key elements and themes with Gailey\u2019s novel while also taking them in a unique direction. In a near-future with only a few light sci-fi elements, Lou has been resurrected along with a handful of other women murdered by a single serial killer. The politics of resurrection in her world are complicated, and few people qualify. That leaves her and her fellow victims (whose therapy circle recalls Grady Hendrix\u2019s The Final Girl Support Group) a bit at sea as they try to come to terms with their deaths, which none of them can recall, and their new lives as celebrities for all the wrong reasons.\n\nLike The Echo Wife, My Murder ends up thoughtfully exploring issues around women subjected to violent men \u2014 not just the personal and internal response, but the society that shapes that violence, and responds to it in ways that raise endless questions. The victims all respond to their deaths differently, questioning their culpability and the possible failures that might have made them targets, and navigating their families\u2019 unpredictable responses to their revival. There\u2019s one big mystery at the heart of My Murder, and a whole lot of abrupt and compelling surprises. But at the core, it\u2019s a sci-fi twist on the survivor story, letting some very different people explore what it means to be victimized, and how to reclaim the lives that have been abruptly handed back to them. \u2014TR\n\nCover image for Ann Leckie\u2019s Translation State, a minimalist drawing with red, orange, and green, a silhouette of a person, and circular lines.\nImage: Orbit\nTRANSLATION STATE BY ANN LECKIE\nSet in the same universe as Leckie\u2019s Imperial Radch trilogy, Translation State follows Enae, who leaves hir long-standing isolation for what was supposed to be an interstellar goose chase. After hir demanding grandmaman dies, Enae is given a diplomat title and assigned to investigate a missing Presgr translator no one expects to be found (but that the government still wants the goodwill for pretending to look for). Only, Enae doesn\u2019t just pretend to look; sie discovers sie has quite the knack for investigating the 200-year-old cold case.\n\nThis is how hir path crosses that of Reet, an adopted maintenance worker whose mysterious origins and unsettling impulses might be explained by being the child of the fugitive translator, if you ask Enae, or the last descendant of a lost sovereign line, if you ask one particularly zealous diaspora social group. Rounding out the POV characters is Qven, a young Presgr terrified of their species\u2019 ritual of merging with an elder, a rite of passage which will see Qven\u2019s selfhood entirely dissolved. Enae, Reet, and Qven\u2019s explorations of their own identities wind up having interplanetary consequences, but it\u2019s the way Leckie gives weight to the small moments, both personal and shared, that make this book sing.\n\nThough I\u2019m sure there are layers that only those familiar with the Imperial Radch trilogy will notice and appreciate, the standalone Translation State and its rich exploration of self-identification and personhood serve as a fantastic introduction to Leckie\u2019s world. So don\u2019t hesitate to jump into Translation State if you\u2019re \u2013 like me \u2013 new to Radch and simply drawn to a thrilling mystery where the most intimate emotions can fuel a universal upheaval. \u2014SG\n\nCover image for Rita Chang-Eppig\u2019s Deep as the Sky, Red as the Sea, with facial features set against a crashing wave.", "mimetype": "text/plain", "start_char_idx": 17654, "end_char_idx": 22273, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "265c159b-54ab-493d-b7ce-582a12f6e683": {"__data__": {"id_": "265c159b-54ab-493d-b7ce-582a12f6e683", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4dd0f0ef-51d0-4ba6-ab8c-0da8474bb192", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "e7023ba699f7871d825ca1917f9d900f0266d656235790ec0ad30a042731b563", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73f09848-129b-4388-bf94-3a9b490cc915", "node_type": "1", "metadata": {}, "hash": "0c515c9d3669a46687418bfa5c0a6e40d8d7b496820d532b56d9816abf5f4738", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Enae, Reet, and Qven\u2019s explorations of their own identities wind up having interplanetary consequences, but it\u2019s the way Leckie gives weight to the small moments, both personal and shared, that make this book sing.\n\nThough I\u2019m sure there are layers that only those familiar with the Imperial Radch trilogy will notice and appreciate, the standalone Translation State and its rich exploration of self-identification and personhood serve as a fantastic introduction to Leckie\u2019s world. So don\u2019t hesitate to jump into Translation State if you\u2019re \u2013 like me \u2013 new to Radch and simply drawn to a thrilling mystery where the most intimate emotions can fuel a universal upheaval. \u2014SG\n\nCover image for Rita Chang-Eppig\u2019s Deep as the Sky, Red as the Sea, with facial features set against a crashing wave.\nImage: Bloomsbury Publishing\nDEEP AS THE SKY, RED AS THE SEA BY RITA CHANG-EPPIG\nI still remember standing in my local bookstore, struck by the cover of this book, and reading the summary. It had me at \u201cChinese pirate queen.\u201d\n\nIn Deep as the Sky, Red as the Sea, Chang-Eppig writes a historical fantasy about Shek Yeung, a fearsome Chinese pirate who must navigate her fleet after the death of her powerful husband. She marries her late husband\u2019s second-in-command, with the promise of bearing an heir, in order to retain power over the fleet \u2014 and stay a major player as the Chinese Emperor seeks to rid the waters of piracy.\n\nThe book isn\u2019t paced like a thriller, so don\u2019t make the mistake of assuming so when you start it. It\u2019s equal parts historical exposition, strategy, and warfare \u2014 and it especially excels in its characterization of a complicated woman forced to make difficult decisions and sacrifices in order to protect her power. Fantasy can put its villains and heroes on pedestals, but Deep as the Sky, Red as the Sea never errs in its very human portrayal of Shek Yeung, and how deftly she must play this game of political chess for survival. I was riveted. \u2014N. Clark\n\nCover art for Emma T\u00f6rzs\u2019 Ink Blood Sister Scribe, featuring a dripping pen growing out of the bottom of a tree against a purple background.\nImage: William Morrow\nINK BLOOD SISTER SCRIBE BY EMMA T\u00d6RZS\nThere\u2019s nothing cozier than a magical book about the magic of books \u2014 though this tale bends a little darker, and tells a story about witchcraft and complicated family dynamics. In Ink Blood Sister Scribe, two estranged sisters come together to solve the mystery of their family, and prevent further tragedies. In this world, blood can be concocted into ink \u2014 wielded by scribes for the creation of books with arcane powers \u2014 though the creation of such books drains a scribe\u2019s health. When others read these books, they create magic; willing flowers to bloom, or making magical carpets that can fly in the air.\n\nInk Blood Sister Scribe is the perfect sister thriller to read in one sitting. It doesn\u2019t reinvent the wheel, but it doesn\u2019t need to \u2014 it simply delivers on a wonderfully entertaining premise. \u2014N. Clark\n\nCover art for Martha Wells\u2019 Witch King, featuring a person running across the cover while wearing a cloak and dress fitting for a fantasy setting.\nImage: Tor\nWITCH KING BY MARTHA WELLS\nIn an era where a lot of fantasy fans value quick or cozy reads, Martha Wells\u2019 Witch King feels like a gauntlet thrown at readers\u2019 feet. It\u2019s a complex, meaty fantasy that opens well into what a more linear book would consider the third act, as Kai, the witch king of the title, is exhumed from a watery grave and starts exploring who betrayed him and trapped him there. Readers have to learn everything about Kai\u2019s world as his story unfolds in multiple intertwined timelines. That includes figuring out what a \u201cwitch king\u201d is, unwrapping the layers of what Kai actually is and why it matters. It also means being introduced to a wide variety of allies and enemies while alternately flashing back to how he met them, and slowly coming to understand the dense political machinations that shaped all their lives in the past and present.\n\nAs with Wells\u2019 Murderbot books and her Books of the Raksura series in particular, part of the draw here is a powerful, skilled protagonist whose biggest struggles are often internal. Kai has a lot of intense emotional responses to the world, but lacks the tools to understand what to do with those feelings, or who to trust with them.", "mimetype": "text/plain", "start_char_idx": 21480, "end_char_idx": 25833, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73f09848-129b-4388-bf94-3a9b490cc915": {"__data__": {"id_": "73f09848-129b-4388-bf94-3a9b490cc915", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "265c159b-54ab-493d-b7ce-582a12f6e683", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "f334e2421ef007063dc55249b60cc393070a4c79d6a0eb1ea187e98f855f6765", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3e885ba5-cbc1-4dc4-a3cf-48db7e2ecc6a", "node_type": "1", "metadata": {}, "hash": "6a4ecf011b100061eb0a677343a2a21e2e732d1665e35794725cf89b630762ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Readers have to learn everything about Kai\u2019s world as his story unfolds in multiple intertwined timelines. That includes figuring out what a \u201cwitch king\u201d is, unwrapping the layers of what Kai actually is and why it matters. It also means being introduced to a wide variety of allies and enemies while alternately flashing back to how he met them, and slowly coming to understand the dense political machinations that shaped all their lives in the past and present.\n\nAs with Wells\u2019 Murderbot books and her Books of the Raksura series in particular, part of the draw here is a powerful, skilled protagonist whose biggest struggles are often internal. Kai has a lot of intense emotional responses to the world, but lacks the tools to understand what to do with those feelings, or who to trust with them. Wells packs Witch King with a lot of audacious, expansive world-building for a standalone novel (albeit one that could easily invite sequels or prequels), but what makes Witch King an enjoyable read instead of a frustrating one is the way all the book\u2019s complications and surprises are filtered through Kai\u2019s vivid inner life, giving readers something to hold onto as they\u2019re untangling the puzzlebox aspects of this cleverly structured novel. \u2014TR\n\nCover image for Justin Lee Anderson\u2019s The Lost War, featuring five figures walking through white grass after emerging from a dark green forest. Three of the figures wear green cloaks, while two wear white.\nImage: Orbit\nTHE LOST WAR (THE EIDYN SAGA #1) BY JUSTIN LEE ANDERSON\nOriginally self-published in 2019, The Lost War is a traditional fantasy adventure that follows a rag-tag group of strangers on a mission across a war-torn country, fighting monsters and uncovering mysteries along the way. Despite the strong buzz leading up to the novel\u2019s expanded publication by Orbit this year, I found myself hesitant to pick it up since it seemed so similar to many books I\u2019ve read before. But while it\u2019s true The Lost War doesn\u2019t rewrite the genre \u2013 it\u2019s filled with well-worn tropes and classic adventurer archetypes \u2013 Anderson\u2019s skillful execution left me completely charmed. There is a real Dungeons and Dragons feel to The Lost War, and though the characters are familiar (the honorable paladin, the hard-drinking haunted soldier), Anderson does a fantastic job developing unique dynamics between the party members that vault the book beyond the sum of its parts. And it all builds up to a massive twist at the end that completely upends your understanding of what you\u2019ve read and any previous expectations for where the second book will go. The delightfully unexpected ending once again has the fantasy community buzzing ahead of Anderson\u2019s next release \u2013 only this time I\u2019m right there with them. \u2014SG\n\nCover image for Moniquill Blackgoose\u2019s To Shape a Dragon\u2019s Breath, a red cover with flowers and a dragon\u2019s head/mask on it.\nImage: Del Rey\nTO SHAPE A DRAGON\u2019S BREATH (NAMPESHIWEISIT #1) BY MONIQUILL BLACKGOOSE\nTo Shape a Dragon\u2019s Breath\u2019s description hooked me immediately: It\u2019s got dragons, a magic school, and a strong teenage main character. Moniquill Blackgoose has taken several different fantasy tropes and created a fantasy novel that\u2019s unlike anything I\u2019ve read; To Shape a Dragon\u2019s Breath is set in an evolving steampunk world as Anglish settlers push the Indigenous Masquapaug people out of their land and onto a remote island. Dragons had long been important cultural touchstones to the Indigenous people, but colonization has, too, pushed them away. To Shape a Dragon\u2019s Breath begins as 15-year-old Anequs finds a dragon egg \u2014 the first to be spotted in the area in generations. Anequs is named a Nampeshiweisit, or a dragon rider, as the community helps raise and hatch the dragon\u2019s egg.\n\nThe colonizing nation quickly finds out and forces Anequs and her dragon into the Anglish dragon school; if she resists, the dragon will be eliminated. To Shape a Dragon\u2019s Breath is about the growing relationship between her and her dragon Kasaqua, but also about her resistance to the Anglish traditions relating to dragons. The Anglish treat dragons as something to be conquered \u2014 they use them as tools and weapons, whereas the Indigenous people have historically partnered with dragons for a relationship built on both tradition and respect.\n\nThat partnership means Anequs now has the power to take on colonialism and racism in a new way.", "mimetype": "text/plain", "start_char_idx": 25033, "end_char_idx": 29432, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3e885ba5-cbc1-4dc4-a3cf-48db7e2ecc6a": {"__data__": {"id_": "3e885ba5-cbc1-4dc4-a3cf-48db7e2ecc6a", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73f09848-129b-4388-bf94-3a9b490cc915", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "b887d599344fe006a36befdd5de7af18eb434af7830f9eb2406dd153a6c0210e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8611171f-9472-4f03-9a4f-ca31d3fd1998", "node_type": "1", "metadata": {}, "hash": "3e09db22d7fcddb943b51d78f3955a6d0b19c9394645919005384d62e8bbcb0d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To Shape a Dragon\u2019s Breath begins as 15-year-old Anequs finds a dragon egg \u2014 the first to be spotted in the area in generations. Anequs is named a Nampeshiweisit, or a dragon rider, as the community helps raise and hatch the dragon\u2019s egg.\n\nThe colonizing nation quickly finds out and forces Anequs and her dragon into the Anglish dragon school; if she resists, the dragon will be eliminated. To Shape a Dragon\u2019s Breath is about the growing relationship between her and her dragon Kasaqua, but also about her resistance to the Anglish traditions relating to dragons. The Anglish treat dragons as something to be conquered \u2014 they use them as tools and weapons, whereas the Indigenous people have historically partnered with dragons for a relationship built on both tradition and respect.\n\nThat partnership means Anequs now has the power to take on colonialism and racism in a new way. Where To Shape a Dragon\u2019s Breath really shines is in that growing relationship between Anequs and Kasaqua; the partnership \u2014 and power for both that comes with it \u2014 is in stark contrast to the Anglish ways. Bonus: To Shape a Dragon\u2019s Breath has well-written, complex bisexual and neurodivergent characters, too. \u2014Nicole Carpenter\n\nCover image for Melvin Burgess\u2019s Loki, a black cover with a black snake wrapped around gold letters with the title.\nImage: Pegasus\nLOKI BY MELVIN BURGESS\nMelvin Burgess has spent a career writing confrontationally frank children\u2019s literature like Junk, his 1990s book about heroin-addicted teenagers. His first adult book, published at age 69, is a blistering, transgressive, and hugely entertaining reframing of the Norse myths, as told by the most unreliable narrator imaginable: Loki himself, the god of tricks, inventions, and political intrigue. But what does reliable mean, anyway, in the mutable world of myth? Burgess paints Loki (or rather, has him paint himself, as he addresses the reader directly in first person) as an eternal outsider, shaking his head sagely at the follies of the gods, and challenging their might-is-right order. But of course, that\u2019s what he\u2019d want us to think. Burgess\u2019 best trick, though, is the way he rolls together the deeply weird, muddy, shape-shifting mystery of the tales themselves with a bracing modernity in characterization and language, somehow without one clashing with the other. In doing so he brings the wild, ancient power of the Norse myths to vivid life. \u2014Oli Welsh\n\nCover image for Nana Kwame Adjei-Brenyah\u2019s Chain-Gang All-Stars, featuring a scythe chopping through the words with a bright yellow background.\nImage: Pantheon Books\nCHAIN-GANG ALL-STARS BY NANA KWAME ADJEI-BRENYAH\nIn Chain-Gang All-Stars, prison inmates fight to the death in a series of gladiatorial matches \u2014 and all of it is televised to a hungry audience. It\u2019s a program called CAPE, the Criminal Action Penal Entertainment, which promises freedom to inmates who survive three years of its brutality. The average life expectancy for anyone who enters is three months. Within this system, Loretta Thurwar and Hammara Stacker (called Hurricane Staxxx by her fans) emerge as two frontrunners.\n\nThis National Book Award finalist takes on the viciousness of the carceral system, with more than a bit of The Hunger Games\u2019 DNA sprinkled in. \u201cHard action\u201d fans salivate over matches, a self-obsessed announcer resents the fact that contestants don\u2019t offer more banter, and the women who top the leaderboards become sex symbols in pop culture. But where other fight-to-the-death dystopias \u2014 among the greats, like Battle Royale or Lord of the Flies \u2014 spin a more fantastical yarn, Chain-Gang All-Stars is aimed right at the heart of the all-too-real cruelties of our existing for-profit penal system.\n\nEarly in the book, Thurwar kills a 16-year-old boy in a gladiator match. Fans in the stands lament not the death of the boy, but the idea that the fight wasn\u2019t entertaining because it wasn\u2019t a fair matchup. In a footnote, Adjei-Brenyah writes of George Stinney Jr., a 14-year-old Black boy who was convicted for murder and executed in 1944. Chain-Gang All-Stars also illustrates the ways in which imprisonment is simply \u201cslavery by another name,\u201d showing all manner of menial labor the contestants are forced to perform.", "mimetype": "text/plain", "start_char_idx": 28550, "end_char_idx": 32804, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8611171f-9472-4f03-9a4f-ca31d3fd1998": {"__data__": {"id_": "8611171f-9472-4f03-9a4f-ca31d3fd1998", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e885ba5-cbc1-4dc4-a3cf-48db7e2ecc6a", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "79693a6d761025bca491e55e344de3a0ca1368dead09dfd88720376e11945aef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09be979f-2d00-4c4b-9940-802f4c9d0d62", "node_type": "1", "metadata": {}, "hash": "53ed90c7de235b7b742267d307357b83e2416b905cc72b05bcc1ceb288df8b59", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "But where other fight-to-the-death dystopias \u2014 among the greats, like Battle Royale or Lord of the Flies \u2014 spin a more fantastical yarn, Chain-Gang All-Stars is aimed right at the heart of the all-too-real cruelties of our existing for-profit penal system.\n\nEarly in the book, Thurwar kills a 16-year-old boy in a gladiator match. Fans in the stands lament not the death of the boy, but the idea that the fight wasn\u2019t entertaining because it wasn\u2019t a fair matchup. In a footnote, Adjei-Brenyah writes of George Stinney Jr., a 14-year-old Black boy who was convicted for murder and executed in 1944. Chain-Gang All-Stars also illustrates the ways in which imprisonment is simply \u201cslavery by another name,\u201d showing all manner of menial labor the contestants are forced to perform. In 2022, the ACLU reported that inmates made between 13 and 52 cents an hour, and sometimes nothing.\n\nCritics have said this book is an \u201cact of protest\u201d but that it doesn\u2019t \u201cstraightforwardly preach,\u201d or that it\u2019s more entertaining than \u201can attempt to convince its readers of the case for prison abolition has any right to be.\u201d I understand why you\u2019d want to say this book is \u201cfun\u201d despite an abolitionist message, especially in a political climate where radical writing is often appreciated only as a teaching tool. But I think that kind of delineation undercuts Adjei-Brenyah\u2019s talent as a novelist, and his skill in heightening the real as a form of storytelling. I\u2019d call it thrilling, over calling it fun. And the fact that it is thrilling is inextricable from its openly abolitionist values \u2014 it\u2019s the very knowledge of real life that Adjei-Brenyah wields to craft suspense. \u2014N. Clark\n\nCover image for Rebecca Yarros\u2019 Fourth Wing, which features a circle image behind black text, with clouds and some flying creatures.\nImage: Entangled\nFOURTH WING BY REBECCA YARROS\nThis action-packed, fantasy romance feels like a grown up version of all of my favorite young adult books. It\u2019s got all of the fun nostalgic tropes \u2014 a magical school, deadly trials, dragon riding, and a love triangle between the main character, a golden retriever love interest, and a misunderstood emo rival \u2014 but it\u2019s also extremely horny, as all fun fantasy romance must be.\n\nViolet Sorrengail is thrown into a series of trials in order to prove whether she can be a dragon rider. There are a few problems with this: she trained as a scribe, never thought she\u2019d be thrust into danger, and she also must deal with Xaden Riorson, her sworn enemy (wink). She also manages a joint condition, which leaves her in chronic pain \u2014 a fact the book handles gracefully. In one of my favorite climactic moments of the book, Violet is given a mobility device to help her with her trials; those close to her remind her that it doesn\u2019t diminish her power, but is a tool like any other, and one that allows her to flourish. I\u2019m thrilled to read the next installment, when it comes out in November. \u2014N. Clark\n\nCover art for Adrian Tchaikovsky\u2019s Lords of Uncreation, which shows a spaceship approaching what looks like a space battle next to a planet, with exploding orbs in space and a lot of spaceships in the distance.\nImage: Orbit\nLORDS OF UNCREATION (THE FINAL ARCHITECTURE #3) BY ADRIAN TCHAIKOVSKY\nReading the Final Architecture series, I had to accept long ago that I would never fully grasp the nuances of some of its central concepts, even if I understood them on an instinctual level.\n\nThis acceptance set me up well for Lords of Uncreation, which revolves around concepts that even the characters find impossible to understand, and whose minds may literally break if they try to. Like looking directly into the sun, confronting the blurred space between the real and unreal (as well as the eldritch terrors that lurk within) poses a grave threat to those doing so head-on \u2013 at least to anyone other than weary intermediary Idris Tellemier, whose risk is merely reduced rather than eliminated. But the characters Adrian Tchaikovsky has populated this world with are so grounded, so emotionally rich, and so vibrant that the details of the brain-bending threats lurking within unspace become secondary to their impact on the lives of and relationships between the Vulture God\u2019s crew.", "mimetype": "text/plain", "start_char_idx": 32026, "end_char_idx": 36256, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "09be979f-2d00-4c4b-9940-802f4c9d0d62": {"__data__": {"id_": "09be979f-2d00-4c4b-9940-802f4c9d0d62", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8611171f-9472-4f03-9a4f-ca31d3fd1998", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "c919f3b2b0c9283037f4cfe1326ccc1eb05bdfe0ac1b6f2af8433d0611f39de6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b0b11e00-37df-45b8-8eb6-dbdc64381a81", "node_type": "1", "metadata": {}, "hash": "7e05e0a7748a3e7dba1012adffbc317596559246e41f25330d69b2b386977e07", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This acceptance set me up well for Lords of Uncreation, which revolves around concepts that even the characters find impossible to understand, and whose minds may literally break if they try to. Like looking directly into the sun, confronting the blurred space between the real and unreal (as well as the eldritch terrors that lurk within) poses a grave threat to those doing so head-on \u2013 at least to anyone other than weary intermediary Idris Tellemier, whose risk is merely reduced rather than eliminated. But the characters Adrian Tchaikovsky has populated this world with are so grounded, so emotionally rich, and so vibrant that the details of the brain-bending threats lurking within unspace become secondary to their impact on the lives of and relationships between the Vulture God\u2019s crew.\n\nThis is not to say that Tchaikovsky does not deliver an incredibly satisfying conclusion to the mysteries of unspace (he does!). But what I\u2019ll remember most is how he crafted the perfect emotional resolution to this intellectually intricate tale that left me in tears and has stayed with me since. \u2014SG\n\nLead art for Justin Cronin\u2019s The Ferryman, which pictures a cloudy sky over the horizon, as a single sail boat sits on the water.\nImage: Ballantine Books\nTHE FERRYMAN BY JUSTIN CRONIN\nProctor Bennett is a ferryman, whose duty is to guide unhappy citizens from the utopian Propersa to the Nursery, where they retire their old selves before returning in younger bodies with no memories of their former lives. But when Proctor is assigned to retire his own father, the troubling encounter sends him careening off the path of conformity. He begins questioning prescribed truths and confronting the darker side of Prospera, which runs off the work of a disenfranchised support staff whose discontent is building towards a revolution that pulls Proctor into its orbit.\n\nThough this premise may feel familiar, The Ferryman is anything but. This tightly-wound, atmospheric thriller weaves together layers of knotted mystery with Proctor\u2019s haunting POV as he grapples with his relationship to grief, happiness, family, and identity. It\u2019s a sharply complex mystery with a cinematic quality to it. Throughout reading, I couldn\u2019t help but fan-cast who would star in a Christopher Nolan adaptation of it. But even if you aren\u2019t an Inception fan, it\u2019ll be easy to become immersed in The Ferryman\u2019s distinct dystopian world. \u2014SG\n\nCover image for Emily Tesh\u2019s Some Desperate Glory, featuring a woman walking confidently in front of a wall opening to reveal a planetary body.\nImage: Tor\nSOME DESPERATE GLORY BY EMILY TESH\nAround September, as the pile of unpainted plastic miniatures here in my home office began to get particularly deep, I suddenly ran out of Warhammer 40,000 Black Library audiobooks by Games Workshop that I was the least bit interested in listening to. That\u2019s when I stumbled upon Some Desperate Glory by Emily Tesh. Billed as a space opera told from the perspective of one of humanity\u2019s last genetically engineered super soldiers, I fell for the premise hook, line, and sinker. Then, about 50 pages in, I let it sucker-punch me right in the gut.\n\nWith Some Desperate Glory, Tesh has envisioned a deeply affecting reality where the children of a subjugated, war-torn race slowly come to realize that they have been lied to \u2014 manipulated into an amoral war of vengeance without end. Tesh shows incredible restraint throughout, reeling out a thick and binding thread of painful realizations from deep within the main character, Kyr. After grappling with my personal love for the grim darkness of the far future for quite a few years now, this book helped me come to terms with how much I despise those tropes even as I find myself drawn toward them time and time again.\n\nSome Desperate Glory is, in my opinion, required reading for anyone who has ever painted a Space Marine in earnest \u2013 and a new fixture in the canon of queer science fiction. \u2014Charlie Hall\n\nCover image for Jade Song\u2019s Chlorine, featuring a large fin in the ocean waves.\nImage: William Morrow & Company\nCHLORINE BY JADE SONG\nI think I have been waiting my whole life for this book \u2014 for someone to write adolescence like the body horror it is, with all of the cultural specificity of being a Chinese American girl, simply bursting at the seams with sapphic longing. Chlorine stars Ren Yu, a swimmer who believes that she is a mermaid.", "mimetype": "text/plain", "start_char_idx": 35460, "end_char_idx": 39866, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b0b11e00-37df-45b8-8eb6-dbdc64381a81": {"__data__": {"id_": "b0b11e00-37df-45b8-8eb6-dbdc64381a81", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09be979f-2d00-4c4b-9940-802f4c9d0d62", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "73a44356cc51d335ba43cacb26cb0aa7180e1ed625e7fb44bd3073dfeca9f513", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3f99cd34-1307-4339-9c23-2ab4dd6cc4a7", "node_type": "1", "metadata": {}, "hash": "417cb9fd927c4800f818fab713d866b34c32778a5cc116336caf9af67650319c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "After grappling with my personal love for the grim darkness of the far future for quite a few years now, this book helped me come to terms with how much I despise those tropes even as I find myself drawn toward them time and time again.\n\nSome Desperate Glory is, in my opinion, required reading for anyone who has ever painted a Space Marine in earnest \u2013 and a new fixture in the canon of queer science fiction. \u2014Charlie Hall\n\nCover image for Jade Song\u2019s Chlorine, featuring a large fin in the ocean waves.\nImage: William Morrow & Company\nCHLORINE BY JADE SONG\nI think I have been waiting my whole life for this book \u2014 for someone to write adolescence like the body horror it is, with all of the cultural specificity of being a Chinese American girl, simply bursting at the seams with sapphic longing. Chlorine stars Ren Yu, a swimmer who believes that she is a mermaid. But she is tethered to land by her human ambition: By the parents who constantly push her to achieve, and by a swim coach who pays inappropriate attention to her \u2014 pushing her to swim faster times, while also making her feel uncomfortable in her skin.\n\nRen\u2019s steadfast belief in being a mermaid feels both like a flight of fancy, and increasingly like a means of dissociating from the horrors of everyday life. Being a young girl is hard enough without having to contend with the high expectations of parents, the predation of adult men, and the casual racism of peers. Jade Song\u2019s writing is gruesomely lyrical, contrasting the sublime with the deeply disturbing. There were several points where this book almost made me throw up, and I mean that as a high compliment. \u2014N. Clark\n\nA Black woman stands alone in a field, her face covered by shadow, in the cover art for Lone Women by Victor LaValle.\nImage: One World\nLONE WOMEN BY VICTOR LAVALLE\nAdelaide Henry is traveling to Montana, where she plans on making a new life as a homesteader \u2014 leaving the flames of her California home, and the bodies of her parents, behind. But she has a heavy weight to carry. She lugs an enormous steam trunk wherever she goes; whenever the trunk opens, people around her die. In 1915, Montana is in the middle of a homestead boom, and though Adelaide aims to make a new start, not everyone is welcoming to a Black woman traveling alone.\n\nVictor LaValle mixes horror and fantasy in this expertly paced tale. It\u2019s satisfyingly bloody, while making incisive commentary on the price of being an outsider. The Western genre has long fixated on the white imagination, perhaps occasionally making space for the early struggle of the suffragettes. But LaValle\u2019s vision of history emphasizes just how powerful white women are in upholding the interests of their white husbands, and how far these women will go to protect the societal structures that put them in proximity to power. Lone Women also examines how shame, and the family unit, ultimately uphold these unspoken rules \u2014 ostracizing those who might otherwise find community support.\n\nThis book was so good that I am now reading my way through every interview LaValle has given on the Lone Women press circuit, too, and then reading every book he references. What a gift! \u2014N. Clark\n\nCover image of Nathan Ballingrud\u2019s The Strange, depicting a diner on Mars.\nImage: Gallery/Saga Press\nTHE STRANGE BY NATHAN BALLINGRUD\nNathan Ballingrud\u2019s debut novel was added to my TBR pile after seeing it marketed as a blend of Ray Bradbury\u2019s The Martian Chronicles and Charles Portis\u2019 True Grit. I\u2019m always dubious about marketing comparisons, but was thrilled when The Strange delivered on this high promise.\n\nIn an alternate history where humanity colonized Mars in the early 1900s, the red planet has lost all communication with Earth, leaving the fate of 14-year-old Annabelle Crisp\u2019s mother unknown. When a thief steals Annabelle\u2019s sole voice recording of her mom, she and her beloved Kitchen Engine, Watson, set off into the desert to retrieve what\u2019s hers and see justice served. The longer Annabelle\u2019s adventure goes on, the more she loses perspective and drifts away from righteousness in dogged pursuit of her own selfish desires. Struggling to comprehend that the world can\u2019t be divided into binaries like right or wrong and black or white, Annabelle converts her fear into anger, lashing out and harming those around her, including those providing aid.", "mimetype": "text/plain", "start_char_idx": 38996, "end_char_idx": 43350, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3f99cd34-1307-4339-9c23-2ab4dd6cc4a7": {"__data__": {"id_": "3f99cd34-1307-4339-9c23-2ab4dd6cc4a7", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b0b11e00-37df-45b8-8eb6-dbdc64381a81", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "84b11322a27c68d44db7c9b2e64924a529b11b6f34fa8e99d3c4509b7f656953", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f04bb2ac-06e7-466f-b399-4895884230a5", "node_type": "1", "metadata": {}, "hash": "f4c378f8642af1952c4af90d4b3c33f79a924be672004a643685282c33d22acd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "I\u2019m always dubious about marketing comparisons, but was thrilled when The Strange delivered on this high promise.\n\nIn an alternate history where humanity colonized Mars in the early 1900s, the red planet has lost all communication with Earth, leaving the fate of 14-year-old Annabelle Crisp\u2019s mother unknown. When a thief steals Annabelle\u2019s sole voice recording of her mom, she and her beloved Kitchen Engine, Watson, set off into the desert to retrieve what\u2019s hers and see justice served. The longer Annabelle\u2019s adventure goes on, the more she loses perspective and drifts away from righteousness in dogged pursuit of her own selfish desires. Struggling to comprehend that the world can\u2019t be divided into binaries like right or wrong and black or white, Annabelle converts her fear into anger, lashing out and harming those around her, including those providing aid.\n\nAnnabelle can be vengeful and cruel, and though I often disagreed with her choices, Ballingrud makes it impossible not to understand and empathize with her. Annabelle Crisp isn\u2019t a hero and she isn\u2019t a villain, but she is an outstanding protagonist in a wonderfully original sci-fi tale. \u2014SG\n\nCover image for Moses Ose Utomi\u2019s The Lies of the Ajungo, featuring a figure walking upside down on mounds of sand as a castle lurks in front.\nImage: Tor\nTHE LIES OF THE AJUNGO (THE FOREVER DESERT #1) BY MOSES OSE UTOMI\nIn his debut novella, Moses Ose Utomi wields his precise prose to tell a dark, visceral fable about a young boy from the City of Lies, a metropolis reliant on the brutal Ajungo Empire for their supply of water. But the cost of this trade is high: At 13, every child of the City of Lies has their tongue cut out and sent to the Ajungo.\n\nEven with this gruesome tithe, the Ajungo send barely enough water for the population to survive, and far from what they\u2019d need to do so comfortably, let alone thrive. Shortly before his thirteenth birthday, the brave Tutu sets out on a dangerous journey to save his mother and the city by finding their own water supply. As Tutu explores the outside world for the first time, his perception of truth and history is challenged, and he comes to understand how the decisions and deceptions of those in power rewrite the past and shape the future to uphold those with privilege and foster compliance in those who don\u2019t. \u2014SG\n\nCover image for Edward Ashton\u2019s Antimatter Blues, A Mickey7 Novel. It features an astronaut from behind on a rocky planet, looking out at another planet in the distance.\nImage: St. Martin\u2019s Press\nANTIMATTER BLUES BY EDWARD ASHTON\nEdward Ashton\u2019s sequel to Mickey 7, the 2022 novel Parasite director Bong Joon-ho is adapting as a movie starring Robert Pattinson, takes up two years after the first book left off, with \u201cExpendable\u201d-status planetary colonist Mickey still on the outs with the leadership of his struggling colony after a gutsy bluff he made to ensure his own survival. The sixth clone of the original Mickey, who accepted life as a disposable body for suicide missions in exchange for a ticket to space, Mickey 7 has walked off that job. His ongoing draw on the colony\u2019s resources is only tolerated because he\u2019s exaggerated his diplomatic connections with the local aliens. Then the base commander orders him to do something impossible, or the entire colony will die.\n\nAntimatter Blues is knottier than the first book in the series, with more to take in about the ethics of survival and humanity\u2019s predisposition toward xenophobia and selfish, self-serving behavior. It sure isn\u2019t a pleasant book to read: A lot of Mickey\u2019s co-colonists are bigots, most of them are indifferent to anyone else\u2019s suffering, and at times, the book reads as though Earth deliberately sent all the worst people into space, the better to be free of them. Even Mickey himself is, at absolute minimum, generally more focused on his own safety and comfort than on the horrific results of some of his choices. But as soon as he\u2019s placed in what seems like an unsurvivable situation, that dynamic leads to high drama, and Antimatter Blues becomes a breathless book rocketing to a surprising conclusion. Prepare to feel sorry for various alien races who have to deal with icky humanity.", "mimetype": "text/plain", "start_char_idx": 42483, "end_char_idx": 46694, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f04bb2ac-06e7-466f-b399-4895884230a5": {"__data__": {"id_": "f04bb2ac-06e7-466f-b399-4895884230a5", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f99cd34-1307-4339-9c23-2ab4dd6cc4a7", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "ef51a73d25ac01811072bcbae408e826f9caa429aa95ccb4543746bf8e38b4b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1637c3af-ad01-4d2c-b1e0-3952f8bd9460", "node_type": "1", "metadata": {}, "hash": "f41d6a1a84a8d8dc9d539a7f46b03f89f4cf0bbb9b416e3697a5120271f15efe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Antimatter Blues is knottier than the first book in the series, with more to take in about the ethics of survival and humanity\u2019s predisposition toward xenophobia and selfish, self-serving behavior. It sure isn\u2019t a pleasant book to read: A lot of Mickey\u2019s co-colonists are bigots, most of them are indifferent to anyone else\u2019s suffering, and at times, the book reads as though Earth deliberately sent all the worst people into space, the better to be free of them. Even Mickey himself is, at absolute minimum, generally more focused on his own safety and comfort than on the horrific results of some of his choices. But as soon as he\u2019s placed in what seems like an unsurvivable situation, that dynamic leads to high drama, and Antimatter Blues becomes a breathless book rocketing to a surprising conclusion. Prepare to feel sorry for various alien races who have to deal with icky humanity. \u2014TR\n\nCover image for Samantha Shannon\u2019s A Day of Fallen Night, a colorful image with a a dragon swirling around it\nImage: Bloomsbury\nA DAY OF FALLEN NIGHT (THE ROOTS OF CHAOS #0) BY SAMANTHA SHANNON\nSamantha Shannon\u2019s A Day of Fallen Night is her second book in the Roots of Chaos series, but a prequel to The Priory of the Orange Tree. Like The Priory of the Orange Tree, A Day of Fallen Night is an epic, far-flung fantasy novel set in a world of magic and dragons. A Day of Fallen Night is set hundreds of years before The Priory of the Orange Tree, and follows several of the original book\u2019s ancestors as the world fears the return of an evil wyrm, the Nameless One. You don\u2019t have to have read The Priory of the Orange Tree to enjoy A Day of Fallen Night; in fact, it\u2019s likely a good place to start if you\u2019ve been interested in reading Shannon\u2019s original, massive fantasy book. Of course, this is a slow-burn 800-page book that precedes another 800-page book, so it\u2019s definitely a time investment regardless of the path.\n\nThough A Day of Fallen Night deals with a world-shaping, cataclysmic threat and widespread political machinations, the book is rooted within four characters from around the book\u2019s world: Sabran, Glorian, Dumai, and Tunuva Melim. The stories of these characters intertwine as their regional beliefs tied to wyrms and dragons conflict, muddying up the necessary collaboration in fighting off the looming threat. In between all that catastrophe, Shannon gives the women of the book rich stories of personal relationships, sacrifice, and conflicting feelings. Motherhood and bodily autonomy are also strong themes throughout the book; both Sabran and Glorian (mother and daughter) have their bodily autonomy tied to the fate of their region.\n\nIt\u2019s not easy to describe A Day of Fallen Night in a short blurb \u2014 it does so many things and goes so many places. Shannon\u2019s created a series that has the scale of The Lord of the Rings, wrapped up in a world of queer, female power. The Roots of Chaos, as a whole, is one of my favorite fantasy series ever. \u2014N. Carpenter\n\nCover image for Mariana Enriquez\u2019s Our Share of Night, featuring a red hand with long yellow fingernails.\nImage: Hogarth Press\nOUR SHARE OF NIGHT BY MARIANA ENR\u00cdQUEZ\nThis literary tome defies categorization, so I\u2019ll paint a scene instead: A father (Juan) whisks his son (Gaspar) away on a trip. Juan is mercurial; at turns terrifying and violent, at turns bewilderingly tender, nearly infinite in love. But he is a closed book. And if you think you\u2019ve seen his hands elongate, spindly fingers yielding to piercing claws \u2014 well no, you didn\u2019t.\n\nSlow, dreadful, and razor-sharp, Our Share of Night charts a family\u2019s desperate attempt at escaping the clutches of a death cult in Argentina. Its members seek the secrets of immortality, and many are willing to pay any price to obtain it. Set in 1981, the novel\u2019s supernatural terrors intertwine with those of the Dirty War, the authoritarian violence offering cover for the cult to operate uninhibited.\n\nI will read anything Mariana Enr\u00edquez writes next, it\u2019s an absolute joy to experience her work. \u2014N. Clark\n\nCover image for Annalee Newitz\u2019s The Terraformers, which features a futuristic cityscape with lush greenery.", "mimetype": "text/plain", "start_char_idx": 45805, "end_char_idx": 49949, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1637c3af-ad01-4d2c-b1e0-3952f8bd9460": {"__data__": {"id_": "1637c3af-ad01-4d2c-b1e0-3952f8bd9460", "embedding": null, "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18", "node_type": "4", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "346b8de72e8442b9d07ff42a7a5e4e7963ca3c94cfac52555134d236283c77ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f04bb2ac-06e7-466f-b399-4895884230a5", "node_type": "1", "metadata": {"source_url": "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023", "document_index": 18}, "hash": "c56333318ed7a983d32e8f0681da9dc76b606d9b7e129d273e154648853e0e5a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "But he is a closed book. And if you think you\u2019ve seen his hands elongate, spindly fingers yielding to piercing claws \u2014 well no, you didn\u2019t.\n\nSlow, dreadful, and razor-sharp, Our Share of Night charts a family\u2019s desperate attempt at escaping the clutches of a death cult in Argentina. Its members seek the secrets of immortality, and many are willing to pay any price to obtain it. Set in 1981, the novel\u2019s supernatural terrors intertwine with those of the Dirty War, the authoritarian violence offering cover for the cult to operate uninhibited.\n\nI will read anything Mariana Enr\u00edquez writes next, it\u2019s an absolute joy to experience her work. \u2014N. Clark\n\nCover image for Annalee Newitz\u2019s The Terraformers, which features a futuristic cityscape with lush greenery.\nImage: Tor Books\nTHE TERRAFORMERS BY ANNALEE NEWITZ\nThe Terraformers concerns itself with one question: As a species evolves, what behaviors stick around? Set more than 50,000 years in the future (yes, you read that number right), The Terraformers details the process of terraforming and developing a privatized planet into a tourism joint for the super rich. Technology has advanced in barely fathomable ways, allowing, for instance, the extension of human-level intelligence to animals and robots. But some aspects of society might seem familiar: Real estate developers who jack up rent with no warning? Local governments that abhor public transit? That every video call still has one person who can\u2019t get the camera to work?\n\nEqual parts prescient and absurd, The Terraformers splits its story over three novellas, each 700 years apart. One of those stars a sentient train who teams up with an investigative journalist ... who also happens to be a cat ... who\u2019s also trying to prove this ostensibly privatized planet is in fact public land. Written by a leading science journalist of our era (author Annalee Newitz is the founder of io9 and has written for basically every major science publication under our sun), The Terraformers is unexpectedly one of the most accurate representations of the journalistic process I\u2019ve ever read. And it all culminates in an undeniable stance: That capitalistic power must still be held in check by the truth. Even 50,000 years in the future, a free press is among society\u2019s most essential facets. The more things change... \u2014Ari Notis\n\nThe cover image of Adrian Tchaikovsky\u2019s Children of Memory, which depicts a spaceship approaching a large orange planet.\nImage: Orbit\nCHILDREN OF MEMORY (CHILDREN OF TIME #3) BY ADRIAN TCHAIKOVSKY\nAdrian Tchaikovsky\u2019s highly anticipated third book in the Children of Time trilogy once again delves into some of science fiction\u2019s headiest topics. There are parallels to earlier installments \u2014 Tchaikovsky once again uses another hyper-intelligent animal species to examine the idea of what being \u201calive\u201d really means. But he also takes readers somewhere completely and utterly new, outside the scope of the previous titles, and incredibly difficult to describe without spoiling the premise entirely.\n\nAll I can say is hold on for the ride. This is an author who dives head first into Asimov-esque ideas, and who is willing to take the plot in fanciful directions. I still can\u2019t believe that I have recommended a book about sentient spider colonies to so many friends, but here we are. This finale is worth your time. \u2014N. Clark", "mimetype": "text/plain", "start_char_idx": 49187, "end_char_idx": 52550, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "252110de-689e-4281-8bc0-dbfb5bd4e2a6": {"__data__": {"id_": "252110de-689e-4281-8bc0-dbfb5bd4e2a6", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0126db65-46d9-407e-bab2-34645eb23bc4", "node_type": "1", "metadata": {}, "hash": "476617175f44fb0eb149d69dabf227a8787fa005b6bdec9e6242eff7f9d434d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A Survey on Retrieval-Augmented Text Generation for Large Language\nModels\nYizheng Huang\nYork University\nhyz@yorku.ca\nJimmy X. Huang\nYork University\njhuang@yorku.ca\nAbstract\nRetrieval-Augmented Generation (RAG)\nmerges retrieval methods with deep learning\nadvancements to address the static limitations\nof large language models (LLMs) by enabling\nthe dynamic integration of up-to-date external\ninformation. This methodology, focusing\nprimarily on the text domain, provides a\ncost-effective solution to the generation of\nplausible but incorrect responses by LLMs,\nthereby enhancing the accuracy and reliability\nof their outputs through the use of real-world\ndata. As RAG grows in complexity and\nincorporates multiple concepts that can\ninfluence its performance, this paper organizes\nthe RAG paradigm into four categories:\npre-retrieval, retrieval, post-retrieval, and\ngeneration, offering a detailed perspective\nfrom the retrieval viewpoint. It outlines\nRAG\u2019s evolution and discusses the field\u2019s\nprogression through the analysis of significant\nstudies. Additionally, the paper introduces\nevaluation methods for RAG, addressing\nthe challenges faced and proposing future\nresearch directions. By offering an organized\nframework and categorization, the study\naims to consolidate existing research on\nRAG, clarify its technological underpinnings,\nand highlight its potential to broaden the\nadaptability and applications of LLMs.\n1 Introduction\nThe advent of ChatGPT has significantly impacted\nboth academia and industry due to its interactive\ncapabilities and widespread application, establishing itself as a leading artificial intelligence tool\n(Laskar et al., 2023; Jahan et al., 2023; Huang\nand Huang, 2024). At the core of ChatGPT is the\nlarge language model (LLM) GPT-4, as detailed by\n(OpenAI et al., 2023), which has seen numerous\nenhancements to its predecessors, showcasing exceptional abilities in a variety of Natural Language\nProcessing (NLP) tasks (Laskar et al., 2020). Despite these advancements, the adoption of LLMs\nFigure 1: An example of RAG benefits ChatGPT resolves questions that cannot be answered beyond the\nscope of the training data and generates correct results.\nhas highlighted several critical issues primarily due\nto their reliance on extensive datasets. This reliance\nrestricts their ability to incorporate new information post-training, leading to three primary challenges. First, the focus on broad and general data\nto maximize accessibility and applicability results\nin subpar performance in specialized areas. Second,\nthe rapid creation of online data, combined with the\nsignificant resources required for data annotation\nand model training, hinders LLMs\u2019 ability to stay\nupdated. Third, LLMs are susceptible to generating convincing yet inaccurate responses, known as\n\u201challucinations\u201d, which can mislead users.\nAddressing these challenges is crucial for LLMs\nto be effectively utilized across various domains. A\npromising solution is the integration of RetrievalAugmented Generation (RAG) technology, which\nsupplements models by fetching external data in\nresponse to queries, thus ensuring more accurate\nand current outputs. Figure 1 illustrates how RAG\ncan enable ChatGPT to provide precise answers\nbeyond its initial training data.\nSince its introduction by Lewis et al. (Lewis\net al., 2020b) in 2020, RAG technology has undergone significant advancements, particularly influenced by ChatGPT\u2019s success. However, there is a\nnoticeable gap in the literature regarding a thorough\nanalysis of RAG\u2019s mechanisms and the progress\nmade by subsequent studies. Furthermore, the field\nis characterized by diverse research focuses and the\nuse of ambiguous terminology for similar methods,\nleading to confusion. This paper aims to clarify these aspects by offering a structured overview of\nRAG, categorizing various methods, and delivering an in-depth understanding of this research area.\nThis survey will primarily focus on textual applications of RAG, reflecting the current emphasis of\nresearch efforts in this area.\nRAG combines retrieval methods and advanced\ndeep learning to address two main questions: effectively retrieving relevant information and generating accurate responses. The workflow of RAG\nis outlined in Section 2, categorizing the methodologies into pre-retrieval, retrieval, post-retrieval,\nand generation phases. These sections, from 3 to\n6, provide an in-depth analysis of the technologies\nwithin these phases. Section 7 offers summaries of\nthe reviewed studies, along with the retrievers and\ngenerators utilized. Section 8 details the evaluation\nmethodologies for RAG.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4609, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0126db65-46d9-407e-bab2-34645eb23bc4": {"__data__": {"id_": "0126db65-46d9-407e-bab2-34645eb23bc4", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "252110de-689e-4281-8bc0-dbfb5bd4e2a6", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "83a848b60155eeaded233a8bc198f90a82b61afad78bc90974caf86bdec1e8df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "95958144-ff5a-40c6-a20f-25a531213d2f", "node_type": "1", "metadata": {}, "hash": "ae84b06a5119733d6d7bae7fe6d2b44024b30d07705228b276b614b629b5a3e1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This paper aims to clarify these aspects by offering a structured overview of\nRAG, categorizing various methods, and delivering an in-depth understanding of this research area.\nThis survey will primarily focus on textual applications of RAG, reflecting the current emphasis of\nresearch efforts in this area.\nRAG combines retrieval methods and advanced\ndeep learning to address two main questions: effectively retrieving relevant information and generating accurate responses. The workflow of RAG\nis outlined in Section 2, categorizing the methodologies into pre-retrieval, retrieval, post-retrieval,\nand generation phases. These sections, from 3 to\n6, provide an in-depth analysis of the technologies\nwithin these phases. Section 7 offers summaries of\nthe reviewed studies, along with the retrievers and\ngenerators utilized. Section 8 details the evaluation\nmethodologies for RAG. Section 9 explores future\nresearch directions, concentrating on text-based\nstudies and extending to image and multimodal\ndata considerations. The conclusion is presented in\nSection 10.\nThe contributions of this paper are threefold:\nThis paper offers a comprehensive framework for\nunderstanding the RAG domain, identifying areas\nfor improvement and challenges for future research.\nIt provides a detailed analysis of RAG\u2019s core technologies, examining their strengths in addressing\nretrieval and generation. Additionally, it introduces\nthe evaluation methods used in RAG research, highlighting current challenges and suggesting promising directions for future studies.\n2 RAG Framework\nThe hallucinations are largely attributed to LLMs\u2019\ninability to access up-to-date information. This\nlimitation stems from the models\u2019 reliance on their\ntraining datasets. RAG proposes a solution to this\nissue by supplementing the LLM\u2019s training data\nwith current information from external sources\nthrough a retrieval model, thereby enabling the generation of accurate responses. RAG presents a more\ncost-effective alternative to the extensive training\nand fine-tuning processes typically required for\nLLMs. It allows for the dynamic incorporation\nof fresh information via traditional retrieval methods or pre-trained LMs, without the need to directly\nintegrate this new data into the LLM. This feature\nmakes RAG both flexible and scalable, facilitating its application across different LLMs for various purposes. The information retrieved through\nRAG is derived from real-world data, authored\nby humans, which not only simplifies the generation process but also increases the reliability of\nthe generated responses. Figure 2 represents the\nunified RAG framework with basic workflow and\nparadigm.\nResearch by Khandelwal et al. (Khandelwal\net al., 2020) demonstrates that accessing relevant\ninformation from the training dataset itself can significantly improve LLM performance, highlighting the effectiveness of RAG. Over time, RAG\nhas evolved from a means of providing supplementary information to enabling multiple interactions\nbetween the retrieval and generation components.\nThis involves conducting several rounds of retrieval\nto refine the accuracy of the information retrieved\nand iteratively improve the quality of the generated output. Platforms such as LangChain1\nand\nLlamaIndex2 have modularized the RAG approach,\nenhancing its adaptability and expanding its range\nof applications. Despite these platforms employing\ndiverse methodologies to tackle different aspects of\nRAG\u2014from multiple search iterations to iterative\ngeneration\u2014they maintain adherence to the fundamental RAG workflow. This consistency is crucial\nfor understanding their operation and pinpointing\nopportunities for further development.\n2.1 Basic RAG Workflow\nThe foundational workflow of RAG begins with the\ncreation of an index comprising external sources.\nThis index serves as the basis for retrieving relevant\ninformation through a retriever model based on a\nspecific query. The final step involves a generator\nmodel, which combines the retrieved information\nwith the query to produce the desired output.\n2.1.1 Indexing\nEfficient retrieval begins with comprehensive indexing, where data preparation is key. This stage\ninvolves text normalization processes such as tokenization, stemming, and the removal of stop words\nto enhance the text\u2019s suitability for indexing (Manning et al., 2008). Text segments are then organized\ninto sentences or paragraphs to facilitate more focused searches, allowing for the pinpointing of segments containing pertinent keywords. The integration of deep learning has revolutionized indexing\nthrough the use of pretrained LMs for generating\nsemantic vector representations of texts. These vectors are stored, enabling rapid and precise retrieval from extensive data collections, significantly\nenhancing retrieval efficiency.\n2.1.2 Retrieval\nWhile traditional retrieval methods, such as the\nBM25 algorithm (Hancock-Beaulieu et al., 1996),\nfocus on term frequency and presence for document\nranking, they often overlook the semantic information of queries.", "mimetype": "text/plain", "start_char_idx": 3729, "end_char_idx": 8755, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "95958144-ff5a-40c6-a20f-25a531213d2f": {"__data__": {"id_": "95958144-ff5a-40c6-a20f-25a531213d2f", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0126db65-46d9-407e-bab2-34645eb23bc4", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "0cfa0238f57b4cb477e40bf0dffcb500dc4ef7664c724feb209d25a4e8585457", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1d5a6903-e644-41f6-96da-19bb887ef111", "node_type": "1", "metadata": {}, "hash": "8f2b17df3f4849f75d2b10eb76fe176e271ad89099763a9112a885aedcf57ee7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2.1.1 Indexing\nEfficient retrieval begins with comprehensive indexing, where data preparation is key. This stage\ninvolves text normalization processes such as tokenization, stemming, and the removal of stop words\nto enhance the text\u2019s suitability for indexing (Manning et al., 2008). Text segments are then organized\ninto sentences or paragraphs to facilitate more focused searches, allowing for the pinpointing of segments containing pertinent keywords. The integration of deep learning has revolutionized indexing\nthrough the use of pretrained LMs for generating\nsemantic vector representations of texts. These vectors are stored, enabling rapid and precise retrieval from extensive data collections, significantly\nenhancing retrieval efficiency.\n2.1.2 Retrieval\nWhile traditional retrieval methods, such as the\nBM25 algorithm (Hancock-Beaulieu et al., 1996),\nfocus on term frequency and presence for document\nranking, they often overlook the semantic information of queries. Current strategies leverage pretrained LMs like BERT (Devlin et al., 2019), which\ncapture the semantic essence of queries more effectively. These models improve search accuracy by\nconsidering synonyms and the structure of phrases,\nthereby refining document ranking through the detection of semantic similarities. This is typically\nachieved by measuring vector distances between\ndocuments and queries, combining traditional retrieval metrics with semantic understanding to yield\nsearch results that are both relevant and aligned\nwith user intent.\n2.1.3 Generation\nThe generation phase is tasked with producing text\nthat is both relevant to the query and reflective of\nthe information found in the retrieved documents.\nThe usual method involves concatenating the query\nwith the retrieved information, which is then fed\ninto an LLM for text generation (Li et al., 2022).\nAlthough ensuring the generated text\u2019s alignment\nand accuracy with the retrieved content presents\nchallenges, it is also essential to strike a balance between adhering closely to the source material and\ninfusing the output with creativity. The generated\ntext should accurately convey the information from\nthe retrieved documents and align with the query\u2019s\nintent, while also offering the flexibility to introduce new insights or perspectives not explicitly\ncontained within the retrieved data.\n2.2 RAG Paradigm\nThe RAG paradigm organizes research within\nthe domain, offering a straightforward yet robust\nframework to enhance LLM performance. Central to RAG is its search mechanism, crucial for\ngenerating high-quality outcomes. Therefore, this\nparadigm is structured into four main phases from\na retrieval perspective: pre-retrieval, retrieval, postretrieval, and generation. Both single-hop and\nmulti-hop retrieval approaches, encompassing iterative retrieve-generate cycles, follow this four-phase\nstructure. Figure 3 is the taxonomy tree of RAG\u2019s\ncore techniques.\n2.2.1 Pre-Retrieval\nThe pre-retrieval phase of retrieval-augmented generation lays the foundation for successful data and\nquery preparation, ensuring efficient information\nretrieval. This phase includes essential tasks to\nprepare for effective data access.\nIndexing The process starts with indexing, which\nestablishes an organized system to enable fast and\naccurate retrieval of information. The specificity\nof indexing depends on the task and data type.\nFor example, sentence-level indexing is beneficial\nfor question-answering systems to precisely locate\nanswers, while document-level indexing is more\nappropriate for summarizing documents to understand their main concepts and ideas.\nQuery Manipulation After indexing, query manipulation is performed to adjust user queries for\na better match with the indexed data. This involves query reformulation (Jansen et al., 2009;\nYu et al., 2020), which rewrites the query to align\nmore closely with the user\u2019s intention; query expansion (Huang et al., 2013), which extends the query\nto capture more relevant results through synonyms\nor related terms; and query normalization, which\nresolves differences in spelling or terminology for\nconsistent query matching.\nData Modification Data modification is also critical in enhancing retrieval efficiency. This step\nincludes preprocessing techniques like removing\nirrelevant or redundant information to improve the\nquality of results and enriching the data with additional information such as metadata to boost the\nrelevance and diversity of the retrieved content\n(Bevilacqua et al., 2022a).\n2.2.2 Retrieval\nSearch & Ranking The retrieval stage is the\ncombination of search and ranking. It focuses on\nselecting and prioritizing documents from a dataset\nto enhance the quality of the generation model\u2019s\noutputs. This stage employs search algorithms to\nnavigate through the indexed data, finding documents that match a user\u2019s query.", "mimetype": "text/plain", "start_char_idx": 7778, "end_char_idx": 12610, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1d5a6903-e644-41f6-96da-19bb887ef111": {"__data__": {"id_": "1d5a6903-e644-41f6-96da-19bb887ef111", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "95958144-ff5a-40c6-a20f-25a531213d2f", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "572c47777c7ada93bb4174077120bb131b8a81dd3b96194bacb6068ad5f040a1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a04d64a-65c2-4d9e-8970-db30a9b4b21a", "node_type": "1", "metadata": {}, "hash": "0b097ee00479d91445742f10063950b9e5d34611ae72ccdfface2053f39a5386", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Data Modification Data modification is also critical in enhancing retrieval efficiency. This step\nincludes preprocessing techniques like removing\nirrelevant or redundant information to improve the\nquality of results and enriching the data with additional information such as metadata to boost the\nrelevance and diversity of the retrieved content\n(Bevilacqua et al., 2022a).\n2.2.2 Retrieval\nSearch & Ranking The retrieval stage is the\ncombination of search and ranking. It focuses on\nselecting and prioritizing documents from a dataset\nto enhance the quality of the generation model\u2019s\noutputs. This stage employs search algorithms to\nnavigate through the indexed data, finding documents that match a user\u2019s query. After identifying\nrelevant documents, the process of initially ranking\nthese documents starts to sort them according to\ntheir relevance to the query.\n2.2.3 Post-Retrieval\nThe post-retrieval phase serves to refine the initially\nretrieved documents to improve the quality of text\ngeneration. This phase consists of re-ranking and\nfiltering, each aimed at optimizing the document\nselection for the final generation task.\nRe-Ranking In the re-ranking step, the documents previously retrieved are reassessed, scored,\nand reorganized. The objective is to more accurately highlight the documents most relevant to\nthe query and diminish the importance of the less\nrelevant ones. This step involves incorporating additional metrics and external knowledge sources\nto enhance precision. In this context, pre-trained\nmodels with superior accuracy but lower efficiency\ncan be effectively employed due to the limited set\nof candidate documents available (Huang and Hu,\n2009).\nFiltering Filtering aims to remove documents\nthat fail to meet specified quality or relevance\nstandards. This can be done through several approaches, such as establishing a minimum relevance score threshold to exclude documents below\na certain relevance level. Furthermore, the use of\nfeedback from users or prior relevance evaluations\nassists in adjusting the filtering process, guaranteeing that only the most relevant documents are\nretained for text generation (Khattab and Zaharia,\n2020; Huang and Huang, 2023).\n2.2.4 Generation\nThe generation stage is a crucial component of the\nRAG process, responsible for leveraging retrieved\ninformation to enhance the quality of the generated\nresponse. This stage encompasses several sub-steps\naimed at producing content that is readable, engaging, and informative.\nEnhancing At the heart of the generation phase\nis the enhancement step, where the objective is\nto merge the retrieved information with the user\u2019s\nquery to create a coherent and relevant response.\nThis includes the process of elaboration, adding\nextra details to the retrieved content to enrich it. Efforts are focused on improving the output\u2019s quality\nby increasing its clarity, coherence, and stylistic\nappeal through methods such as rephrasing and\nrestructuring. Information from various sources\nis combined to offer a comprehensive perspective,\nand verification is conducted to ensure the accuracy\nand relevance of the content.\nCustomization Customization is an optional\nstep, involving the adjustment of content to align\nwith the user\u2019s specific preferences or the context\nof the request. This tailoring includes adapting the\ncontent to meet the needs of the target audience or\nthe format in which it will be presented and condensing the information to succinctly convey the\nessence of the content. The process also entails\ncreating summaries or abstracts that emphasize the\nkey points or arguments, ensuring the output is both\ninformative and concise.\n3 Pre-Retrieval\n3.1 Indexing\nThe integration of the k-nearest neighbor (kNN)\nalgorithm with pre-trained neural LMs, as demonstrated in kNN-LMs (Khandelwal et al., 2020), represents significant progress in language modeling. This method employs a datastore created from collections of texts, enabling the dynamic retrieval of\ncontextually relevant examples to improve perplexity without necessitating additional training.\nKnown for its efficiency, FAISS (Johnson et al.,\n2021) has been adopted in many studies for indexing purposes (Khandelwal et al., 2020; Lewis et al.,\n2020b; Khattab et al., 2022). Some research integrates enhancements like the Hierarchical Navigable Small World (HNSW) approximation (Malkov\nand Yashunin, 2020) to achieve faster retrieval\n(Lewis et al., 2020b). In addition, alternative tools\nlike utilizing the Bing API 3\nfor indexing based\non actual user search histories as outlined in Webgpt (Nakano et al., 2021), illustrate the variety of\nindexing techniques under investigation.", "mimetype": "text/plain", "start_char_idx": 11898, "end_char_idx": 16545, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5a04d64a-65c2-4d9e-8970-db30a9b4b21a": {"__data__": {"id_": "5a04d64a-65c2-4d9e-8970-db30a9b4b21a", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1d5a6903-e644-41f6-96da-19bb887ef111", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "36af097b892ee17daf78f00b451436c71c7266ec3d3ba13975bf279f7345cdc5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ee78a3c-2954-48c3-a27c-d87b4a5003f2", "node_type": "1", "metadata": {}, "hash": "f306c9c3601c0c556e248ef0d59ac87e4c0fd1bac0b4ac65e1562cd80b9e1419", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This method employs a datastore created from collections of texts, enabling the dynamic retrieval of\ncontextually relevant examples to improve perplexity without necessitating additional training.\nKnown for its efficiency, FAISS (Johnson et al.,\n2021) has been adopted in many studies for indexing purposes (Khandelwal et al., 2020; Lewis et al.,\n2020b; Khattab et al., 2022). Some research integrates enhancements like the Hierarchical Navigable Small World (HNSW) approximation (Malkov\nand Yashunin, 2020) to achieve faster retrieval\n(Lewis et al., 2020b). In addition, alternative tools\nlike utilizing the Bing API 3\nfor indexing based\non actual user search histories as outlined in Webgpt (Nakano et al., 2021), illustrate the variety of\nindexing techniques under investigation.\nFurthermore, MEMWALKER (Chen et al.,\n2023a) introduces an innovative method to overcome the limitations of context window size in\nLLMs by creating a memory tree from the input\ntext. This tree is formed by initially segmenting\nthe text into smaller pieces and then summarizing these segments into a hierarchical structure of\nsummary nodes, facilitating efficient indexing and\nmanagement of large volumes of information.\n3.2 Query Manipulation\nStudies such as FiD (Izacard and Grave, 2021),\nCOK(Li et al., 2023), and Query2doc (Wang et al.,\n2023a) emphasize the significance of creating new\nqueries or refining existing ones to achieve more\n3\nhttps://www.microsoft.com/en-us/bing/apis/bing-websearch-api\npertinent retrieval results. These research efforts\nhighlight the necessity of efficiently gathering evidence from multiple passages and tailoring queries\nto suit various knowledge sources, whether structured or unstructured. Techniques ranging from the\ncreation of pseudo-documents to enhance queries\nhave shown to bolster retrieval performance across\ndiverse information retrieval datasets.\nFurther exploration into query manipulation has\nbeen conducted by Step-Back (Zheng et al., 2023)\nand PROMPTAGATOR (Dai et al., 2023), which\nfocus on abstracting high-level concepts or utilizing LLMs for prompt-based query generation.\nThese strategies strive to better align queries with\nthe retrieval system\u2019s functionality by rephrasing\ntasks into more generalized versions or crafting\ntask-specific queries from limited examples. Such\nmethodologies enhance the consistency between\nqueries and indexed data, facilitating the retrieval\nof more pertinent and insightful information.\nMoreover, KnowledGPT (Wang et al., 2023b)\nand Rewrite-Retrieve-Read (Ma et al., 2023) introduce approaches for query manipulation through\n\u201cprogram of thought\u201d prompting and innovative\nquery rewriting techniques. KnowledGPT innovates by generating code to interface with knowledge bases, converting user queries into structured\nsearch commands. In contrast, Rewrite-RetrieveRead utilizes a trainable compact LM for query\nreformulation, adjusting them to more effectively\nreflect the user\u2019s intent and context.\nLastly, FLARE (Jiang et al., 2023) presents a\nstrategy based on confidence for query formulation, which focuses on crafting queries that precisely\nreflect the information needs. This method incorporates the use of generated sentences or fragments\nthereof as a foundation for search queries. By opting to directly use sentences, obscuring tokens of\nlow confidence, or formulating explicit questions,\nthis approach aims to boost the efficiency of the\nretrieval process, ensuring that the retrieved information faithfully satisfies the requirements of the\ngeneration process.\n3.3 Data Modification\nRA-DIT (Lin et al., 2023b) and RECITE (Sun et al.,\n2023) emphasize enhancements through internal\ndata modifications. RA-DIT distinguishes between\nfine-tuning datasets for LLMs and retrievers, aiming to bolster the LLM\u2019s contextual comprehension\nand the retriever\u2019s ability to align with queries. RECITE, on the other hand, utilizes passage hints and\nsynthetic question-passage pairs to increase the\nvariety and relevance of its generated recitations\nand responses. This approach seeks to broaden the\nmodel\u2019s knowledge base and improve its response\naccuracy.\nUPRISE (Cheng et al., 2023a) and GENREAD\n(Yu et al., 2023a) target the refinement of external\ndata. UPRISE converts raw task data into a structured format and refines the selection of prompts\nto enhance retrieval outcomes. In contrast, the\nClustering-Based Prompts method employed by\nGENREAD generates documents from questions\nand clusters them to eliminate irrelevant data, enriching the input with varied contextual insights.", "mimetype": "text/plain", "start_char_idx": 15763, "end_char_idx": 20312, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4ee78a3c-2954-48c3-a27c-d87b4a5003f2": {"__data__": {"id_": "4ee78a3c-2954-48c3-a27c-d87b4a5003f2", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5a04d64a-65c2-4d9e-8970-db30a9b4b21a", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "4544ec9b1bba8a44dd38c940567ed9c4487c5f0cfd63ed94b4e5b343f55dabfb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d6e6d34b-d99e-4058-bed6-a465f3d2cbbd", "node_type": "1", "metadata": {}, "hash": "460719457111e2e75700e1b9ab4d31a0b6b7892747687d450f35a7d9a4a37504", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "RA-DIT distinguishes between\nfine-tuning datasets for LLMs and retrievers, aiming to bolster the LLM\u2019s contextual comprehension\nand the retriever\u2019s ability to align with queries. RECITE, on the other hand, utilizes passage hints and\nsynthetic question-passage pairs to increase the\nvariety and relevance of its generated recitations\nand responses. This approach seeks to broaden the\nmodel\u2019s knowledge base and improve its response\naccuracy.\nUPRISE (Cheng et al., 2023a) and GENREAD\n(Yu et al., 2023a) target the refinement of external\ndata. UPRISE converts raw task data into a structured format and refines the selection of prompts\nto enhance retrieval outcomes. In contrast, the\nClustering-Based Prompts method employed by\nGENREAD generates documents from questions\nand clusters them to eliminate irrelevant data, enriching the input with varied contextual insights.\nThis technique aims to improve the performance of\nthe generative model by providing it with a richer\nset of information.\nFurthermore, KnowledGPT (Wang et al., 2023b)\nis dedicated to augmenting raw text data with structured, semantically rich information through entity\nlinking. This enrichment process not only structures the data more cohesively and makes it more\namenable to queries but also boosts the model\u2019s\nretrieval efficiency. It leverages precise, linked\nknowledge to enhance the model\u2019s understanding and its ability to generate relevant responses,\nthereby improving its overall performance.\n4 Retrieval\n4.1 Search & Ranking\nAtlas (Izacard et al., 2023) investigates few-shot\nlearning approaches, including Attention Distillation and Perplexity Distillation, to steer the retriever toward retrieving more relevant documents.\nIRCOT (Trivedi et al., 2023) integrates retrieval\nwith reasoning to improve the effectiveness of retrieval. SURGE (Kang et al., 2023) employs a\nsubgraph retriever to extract relevant subgraphs\nfrom a knowledge graph, while AAR (Yu et al.,\n2023b) modifies search preferences to help LLMs\nin fetching pertinent documents.\nPRCA (Yang et al., 2023a) focuses on employing domain-specific abstractive summarization to\nextract relevant and context-rich information from\ndocuments, using a supervised learning strategy\nto prioritize content crucial for accurate query responses. Meanwhile, MEMWALKER (Chen et al.,\n2023a) leverages an internal search and ranking\nmechanism in the constructed memory tree to identify pertinent information for long-context question\nanswering. Additionally, the Confidence-based Active Retrieval approach of FLARE (Jiang et al.,\n2023) dynamically triggers information retrieval\nbased on the confidence levels of generated sentences, utilizing the insight that low-confidence\ntokens signal a need for external knowledge.\n5 Post-Retrieval\n5.1 Re-Ranking\nRe2G (Glass et al., 2022) introduces a sequencepair classification approach for re-ranking, utilizing a BERT transformer to simultaneously analyze\nthe query and passage. This interaction model, employing cross-attention between sequences, offers a\ncontrast to the representation model typically used\nin initial retrieval phases. PROMPTAGATOR (Dai\net al., 2023) also employs a cross-attention model\nfor re-scoring. Its \u201cLift Yourself Up\u201d strategy iteratively selects the best candidate from a pool for\nfurther generation rounds, progressively improving\ncontent quality via self-generated content.\nRe-ranking is also a significant focus of InContext RALM (Ram et al., 2023). Two approaches to reranking are explored: zero-shot\nreranking using language models and predictive\nreranking through trained models. This step is\naimed at refining the selection of documents based\non their expected utility for improving language\nmodel performance. ITER-RETGEN (Shao et al.,\n2023), in particular, leverages knowledge distillation from the re-ranker to the dense retriever, finetuning retrieval efforts based on relevance signals\nfrom LLM outputs. This optimization of the retrieval model aims to more accurately capture query\nnuances, thereby improving document selection.\nDKS-RAC (Huang et al., 2023) presents the\nDense Knowledge Similarity (DKS) for aligning\nthe knowledge between answers and retrieved passages at the sequence level. This approach is categorized under re-ranking due to its direct impact on\npassage selection based on knowledge similarity,\nrefining the match between queries and documents.\nFiD-light (Hofst\u00e4tter et al., 2023) introduces a\nlistwise autoregressive re-ranking method that employs source pointers to optimize the ranking order.", "mimetype": "text/plain", "start_char_idx": 19444, "end_char_idx": 23971, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d6e6d34b-d99e-4058-bed6-a465f3d2cbbd": {"__data__": {"id_": "d6e6d34b-d99e-4058-bed6-a465f3d2cbbd", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ee78a3c-2954-48c3-a27c-d87b4a5003f2", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "5ed505e4cfdfe7c8f8eb119b7669d5ed29a74f0e82c54d085a14a2792cad0ed0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b7f6ff3-833c-408d-845c-3935decdbed1", "node_type": "1", "metadata": {}, "hash": "0b0d1eeef3b9f777d18db47d57904df1eb7d7128c2c176d2b887b163a662fb4e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ITER-RETGEN (Shao et al.,\n2023), in particular, leverages knowledge distillation from the re-ranker to the dense retriever, finetuning retrieval efforts based on relevance signals\nfrom LLM outputs. This optimization of the retrieval model aims to more accurately capture query\nnuances, thereby improving document selection.\nDKS-RAC (Huang et al., 2023) presents the\nDense Knowledge Similarity (DKS) for aligning\nthe knowledge between answers and retrieved passages at the sequence level. This approach is categorized under re-ranking due to its direct impact on\npassage selection based on knowledge similarity,\nrefining the match between queries and documents.\nFiD-light (Hofst\u00e4tter et al., 2023) introduces a\nlistwise autoregressive re-ranking method that employs source pointers to optimize the ranking order.\nThis method maintains a link between the generated text and source passages, enabling a more\nstructured generation process. By incorporating\ntextual citations within the model\u2019s output as pointers to relevant information sources, this approach\nfacilitates an organized retrieval and generation\nprocess, enhancing the overall coherence and relevance of the generated content.\n5.2 Filtering\nCOK (Li et al., 2023) presents the Progressive Rationale Correction technique, aimed at iteratively\nrefining rationales with retrieved knowledge. This\nmethod constitutes a continuous optimization process, significantly enhancing the relevance and\nquality of information used in content generation.\nSelf-RAG (Asai et al., 2023) introduces a selfreflection mechanism to efficiently filter out irrelevant content. By employing critique tokens, this\napproach evaluates the relevance, supportiveness,\nand utility of retrieved passages, ensuring the integration of only high-quality information into the\ncontent generation process.\nAdditionally, FiD-TF (Berchansky et al., 2023)\nand RECOMP (Xu et al., 2023) are dedicated to the\nremoval of irrelevant or redundant tokens and information from retrieved documents. FiD-TF employs\na dynamic mechanism to identify and eliminate unnecessary tokens, enhancing the efficiency of information processing. RECOMP, on the other hand,\ncompresses documents into concise summaries, focusing on selecting only the most pertinent content\nfor the generation process. These methods streamline the content generation workflow by ensuring\nthat only relevant and supportive information is\nutilized, thereby improving the overall quality and\nrelevance of the generated content.\n6 Generation\n6.1 Enhancing\nDSP (Khattab et al., 2022) introduces a framework\ndesigned to generate multiple retrieval queries to\nsummarize and answer questions, drawing upon information aggregated from various passages. This\nframework employs CombSUM (Fox and Shaw,\n1994) to calculate a cumulative probability score\nfor passages across different retrieval lists, facilitating the compilation of a comprehensive response\nfrom multiple sources.\nPRCA (Yang et al., 2023a) outlines a RewardDriven Stage, wherein the distilled context is refined based on feedback from the generator. Utilizing reinforcement learning, this stage adjusts\nthe parameters of PRCA according to the rewards\nreceived for providing relevant context. The objective is to fine-tune the extracted context to meet\nthe specific requirements of the generator, thereby\noptimizing the generation process.\nREPLUG (Shi et al., 2023) proposes a method\nfor prepending retrieved documents to the input\ncontext before the final prediction by the black-box\nLM. It introduces an ensemble strategy to encode\nretrieved documents in parallel, overcoming the\nlimitations of LM context length and enhancing\naccuracy through the allocation of increased computational resources. This approach improves the\ngeneration process by ensuring that the LM has\naccess to a broader range of relevant information.\nRECITE (Sun et al., 2023) implements a selfconsistency technique, which involves generating\nmultiple recitations independently and employing\na plurality/majority vote system to determine the\nmost appropriate answer. This method is designed\nto increase the reliability and accuracy of the answers, thereby improving the quality and credibility\nof the output.\n6.2 Customization\nThe PKG framework, introduced by (Luo et al.,\n2023), represents an approach to customizing the\noutput of LMs. By generating background knowledge internally using a pre-trained model, PKG\neliminates the need for traditional external retrieval\nprocesses. This method directly integrates domainor task-specific knowledge into the generation step,\nsignificantly enhancing the LM\u2019s capacity to produce responses that are specifically tailored to the\ngiven context or requirements.\nSelf-RAG (Asai et al., 2023) offers a strategy that incorporates reflection tokens within a customizable decoding algorithm.", "mimetype": "text/plain", "start_char_idx": 23160, "end_char_idx": 27988, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b7f6ff3-833c-408d-845c-3935decdbed1": {"__data__": {"id_": "8b7f6ff3-833c-408d-845c-3935decdbed1", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d6e6d34b-d99e-4058-bed6-a465f3d2cbbd", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "2c736fff94f17e22e4669a638a89b989e2df31075656e5d08c8c19b443ecfb0b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70cd81ad-f239-413a-bd73-ce4413d92e2a", "node_type": "1", "metadata": {}, "hash": "7cb136075dc62a9b3c5cf5cb9995ce580c6bcedc227e36d2313ef83b5396338f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "RECITE (Sun et al., 2023) implements a selfconsistency technique, which involves generating\nmultiple recitations independently and employing\na plurality/majority vote system to determine the\nmost appropriate answer. This method is designed\nto increase the reliability and accuracy of the answers, thereby improving the quality and credibility\nof the output.\n6.2 Customization\nThe PKG framework, introduced by (Luo et al.,\n2023), represents an approach to customizing the\noutput of LMs. By generating background knowledge internally using a pre-trained model, PKG\neliminates the need for traditional external retrieval\nprocesses. This method directly integrates domainor task-specific knowledge into the generation step,\nsignificantly enhancing the LM\u2019s capacity to produce responses that are specifically tailored to the\ngiven context or requirements.\nSelf-RAG (Asai et al., 2023) offers a strategy that incorporates reflection tokens within a customizable decoding algorithm. This technique permits dynamic adjustment of the model\u2019s retrieval\nand generation behaviors based on the specific task,\nfacilitating more versatile response generation. Depending on the requirements, this approach can be\ntuned for accuracy or creativity, providing flexibility in generating outputs that meet diverse needs.\nSURGE (Kang et al., 2023) achieves customization through the application of graph-text contrastive learning. This method ensures that the\ngenerated dialogue responses are in tight alignment\nwith the knowledge contained in the retrieved subgraph, yielding responses that are specific, relevant,\nand deeply rooted in the dialogue context. By maintaining consistency between the retrieved knowledge and the generated text, SURGE is capable\nof producing outputs that precisely reflect the detailed knowledge of the subgraph, enhancing the\nrelevance and specificity of the responses.\n7 Comparisons of RAG\n7.1 The Comprehensive Summary of RAG\nTable 1 presents a detailed analysis of the RAG\nstudies discussed in this paper. The analysis shows\nthat the majority of these studies have utilized external data sources to enrich the content of LLMs.\nA preference for multiple-hop over single-hop retrieval was noted, indicating that iterative search\nrounds generally yield superior results. In other\nwords, most methods employ dense retrieval to secure higher quality candidate documents. Compared to modifying datasets in the pre-retrieval\nstage, more studies focus on manipulating the query\nto improve retrieval performance. Additionally,\nthere is a significant emphasis on optimizing the\nretrieval phase, highlighting its crucial role in the\nresearch. However, there seems to be a scarcity\nof studies concentrating on customization in the\ngeneration stage, pointing to this as a potential area\nfor future exploration. Overall, while the goal of\nRAG is to enhance the response quality of LLMs,\ngreater efforts have been directed towards improving retrieval aspects.\n7.2 Retriever and Generator\nIn RAG, the retriever and the generator are the\nprimary components. Table 2 summarizes the retrievers and generators used in the studies discussed\nin this paper. It is clear from the table that while\nmost generators utilize advanced language models,\na significant number of retrievers still employ the\ntraditional BM25 due to its efficiency. The method\nof retrieval is a crucial aspect in RAG, highlighting the importance of exploring ways to enhance\nretrieval performance without compromising efficiency. Similarly, not many studies have adopted\npowerful LLMs such as LLaMA2, GPT-3.5, or\nGPT-4 as their generators. LLMs like T5 remain\npopular, yet fundamental models like BERT and\nTransformers are rarely used in 2023. Compared\nto generators, it is evident that not many IR-based\nLLMs are used in retrievers, indicating a promising\ndirection for developing such models in the future.\n8 Evaluation in RAG\nTo understand the effectiveness of LMs in generating more accurate, relevant, and robust responses\nby leveraging external knowledge, the evaluation\nof RAG systems has become a significant research\narea. With the popularity of dialogue-based interactions, recent works have been focused on assessing\nthe performance of RAG models on such downstream tasks using established metrics like Exact\nMatch (EM) and F1 scores. Furthermore, a wide\narray of datasets has been utilized for this purpose,\nincluding TriviaQA (Joshi et al., 2017), HotpotQA\n(Yang et al., 2018), FEVER (Thorne et al., 2018),\nNatural Questions (Kwiatkowski et al., 2019), Wizard of Wikipedia (Dinan et al., 2019), and T-REX\n(ElSahar et al., 2018).", "mimetype": "text/plain", "start_char_idx": 27012, "end_char_idx": 31615, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70cd81ad-f239-413a-bd73-ce4413d92e2a": {"__data__": {"id_": "70cd81ad-f239-413a-bd73-ce4413d92e2a", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b7f6ff3-833c-408d-845c-3935decdbed1", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "3bb9519d23ee180e2eb901a74f7adbbc44e8f0858a4320a07cfe8abf74c79837", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42908003-e72d-4bfb-be8d-23db30e7938c", "node_type": "1", "metadata": {}, "hash": "80fed9c8fbaaeb4dd039afc07bf8ed2f55b1b2261f968bf9c2e52a77ae3330f6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "8 Evaluation in RAG\nTo understand the effectiveness of LMs in generating more accurate, relevant, and robust responses\nby leveraging external knowledge, the evaluation\nof RAG systems has become a significant research\narea. With the popularity of dialogue-based interactions, recent works have been focused on assessing\nthe performance of RAG models on such downstream tasks using established metrics like Exact\nMatch (EM) and F1 scores. Furthermore, a wide\narray of datasets has been utilized for this purpose,\nincluding TriviaQA (Joshi et al., 2017), HotpotQA\n(Yang et al., 2018), FEVER (Thorne et al., 2018),\nNatural Questions (Kwiatkowski et al., 2019), Wizard of Wikipedia (Dinan et al., 2019), and T-REX\n(ElSahar et al., 2018).\nHowever, evaluation solely from the perspective of downstream tasks falls short in addressing\nthe evolving needs of RAG development. Recent\nresearch has introduced various frameworks and\nbenchmarks that aim to evaluate these systems\nacross multiple dimensions, including the quality\nof the generated text, the relevance of retrieved\ndocuments, and the model\u2019s resilience to misinformation, as shown in Table 3. These evaluations focus on assessing specific capabilities such as noise\nrobustness, negative prompting, information integration, and counterfactual robustness, highlighting the complex challenges faced by RAG systems\nin practical applications. The continuous development of evaluation frameworks and metrics is\ncrucial for advancing the field, broadening the applicability of RAG systems, and ensuring they meet\nthe demands of a complex and evolving information landscape.\n8.1 Retrieval-based Aspect\nIn information retrieval, the quality of search results is typically evaluated using standard metrics\nsuch as Mean Average Precision (MAP), Precision,\nReciprocal Rank, and Normalized Discounted Cumulative Gain (NDCG) (Radlinski and Craswell,\n2010; Reimers and Gurevych, 2019; Nogueira et al.,\n2019). These metrics primarily assess the relevance\nof retrieved documents to a given query.\nRetrieval-based Metrics in RAG focus on the effectiveness of retrieving relevant information to\nsupport generation tasks. These include Accuracy, which measures the precision of retrieved\ndocuments in providing correct information for answering queries, and Rejection Rate (Chen et al.,\n2023b), assessing a system\u2019s ability to decline answering when no relevant information is found.\nAdditionally, Error Detection Rate (Chen et al.,\n2023b) evaluates the model\u2019s capability to identify\nand disregard incorrect or misleading information\nfrom retrieved documents. Context Relevance is\nanother essential metric, assessing the pertinence\nof the retrieved documents to the query. It\u2019s vital to\nensure the information used to generate responses\nis directly related to the query\u2019s context. Faithfulness (Shahul et al., 2023) measures the accuracy\nwith which the generated content reflects the information in the retrieved documents, ensuring that\nthe generation process with no misinformation.\n8.2 Generation-based Aspect\nEvaluating the quality of text produced by LLMs\ninvolves analyzing their performance on various\ndownstream tasks using standard metrics. These\nmetrics assess linguistic quality, coherence, accuracy, and the extent to which the generated text\nreflects ground-truth data. Linguistic quality and\ncoherence are evaluated through metrics such as\nBLEU (Papineni et al., 2002), which measures fluency and similarity to human-produced text, and\nROUGE-L (Lin, 2004), which quantifies the overlap with reference summaries to gauge the text\u2019s\ncapacity to encapsulate main ideas and phrases.\nAccuracy and overlap with ground-truth data are\ngauged using metrics like EM and F1 Score, which\nrespectively determine the percentage of answers\nthat are entirely correct and offer a balanced assessment of precision and recall in retrieving relevant\nanswers while minimizing inaccuracies.\nBeyond these standard metrics, the evaluation\nmay also incorporate task-specific criteria and\nnovel metrics tailored to particular applications.\nFor instance, in dialogue generation, perplexity\nand entropy are used to evaluate response diversity and naturalness. Additionally, metrics such as\nMisleading Rate and Mistake Reappearance Rate\n(Liu et al., 2023) gauge a model\u2019s ability to avoid\nmisinformation and inaccuracies.", "mimetype": "text/plain", "start_char_idx": 30883, "end_char_idx": 35221, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42908003-e72d-4bfb-be8d-23db30e7938c": {"__data__": {"id_": "42908003-e72d-4bfb-be8d-23db30e7938c", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70cd81ad-f239-413a-bd73-ce4413d92e2a", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "c64a768515f2437edfab82191bef84f7a73d75aad218eab34608e6da90ca8d28", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "35a95c1d-1250-4e79-ba0c-059fb91d1ea2", "node_type": "1", "metadata": {}, "hash": "5bba71ac227d008914ca64068d6c3a7b87f20b5b6150e6b21e039b723e52658f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Accuracy and overlap with ground-truth data are\ngauged using metrics like EM and F1 Score, which\nrespectively determine the percentage of answers\nthat are entirely correct and offer a balanced assessment of precision and recall in retrieving relevant\nanswers while minimizing inaccuracies.\nBeyond these standard metrics, the evaluation\nmay also incorporate task-specific criteria and\nnovel metrics tailored to particular applications.\nFor instance, in dialogue generation, perplexity\nand entropy are used to evaluate response diversity and naturalness. Additionally, metrics such as\nMisleading Rate and Mistake Reappearance Rate\n(Liu et al., 2023) gauge a model\u2019s ability to avoid\nmisinformation and inaccuracies. Other specialized metrics include Answer Relevance (Shahul\net al., 2023), assessing the precision of responses\nto queries; Kendall\u2019s tau (Saad-Falcon et al., 2023),\nfor evaluating the accuracy of RAG system rankings; Micro-F1 (Saad-Falcon et al., 2023), which\nfine-tunes accuracy evaluation in tasks with multiple correct answers; and Prediction Accuracy, directly measuring the alignment of generated answers with expected responses, thereby offering a\ndirect insight into a system\u2019s effectiveness in generating accurate content.\n9 Future Directions\n9.1 Retrieval Quality\nThe integration of RAG into LLMs faces significant\nhurdles due to the vast amounts of unreliable information on the internet, including fake news. This\npresents a challenge for accurately retrieving useful\nknowledge, leading to the unreliable generation of\nresponses by LLMs. As a result, LLMs may generate content based on incorrect information, undermining their reliability. Recent research efforts\nare directed towards enhancing retrieval methods\nto improve the efficiency, scalability, and effectiveness of LLMs in generating accurate and reliable\nresponses.\nDifferentiable Search Indices (Tay et al., 2022)\nand (Bevilacqua et al., 2022b) developed differentiable search indices that integrate the retrieval\nprocess within a Transformer model, enabling direct mapping of text queries to document identifiers.\nThese approaches offer superior performance and\npotential for more efficient and scalable retrieval.\nGenerative Models for Search GERE (Chen\net al., 2022a) can directly generate document titles\nand evidence sentences for fact-verification tasks.\nPARADE (Li et al., 2024) is a method for document\nreranking that aggregates passage representations\ninto a unified document relevance score. Both of\nthem demonstrate significant improvements in retrieval quality over traditional methods.\nFine-tuning Pre-trained Language Models\nRankT5 (Zhuang et al., 2023) is a model that finetunes the T5 framework specifically for text ranking. It leverages ranking losses to optimize performance metrics and exhibits promising zero-shot\nperformance on out-of-domain data.\nNoise Power (Cuconasu et al., 2024) provide a\ncomprehensive analysis of the impact of IR components on RAG systems, revealing that the inclusion\nof irrelevant documents can significantly improve\naccuracy. It challenges conventional retrieval strategies and underscores the potential for developing\nspecialized approaches that integrate retrieval with\nlanguage generation models.\n9.2 Multimodal RAG\nThe multimodal RAG domain has experienced significant growth, highlighting a pivotal advancement\nat the confluence of text and visual comprehension.\nThe introduction of MuRAG (Chen et al., 2022b)\nmarked a breakthrough by amalgamating textual\nand visual information for language generation, establishing a new standard for multimodal datasets.\nThis model showcased the efficacy of utilizing a\nmultimodal memory system to boost the accuracy\nin question-answering and reasoning tasks.\nAfter MuRAG, studies such as REVEAL (Hu\net al., 2023) and Re-Imagen (Chen et al., 2023c)\nhave focused on enhancing visual question answering and text-to-image generation. They achieved\nthis through the incorporation of dynamic retrieval\nmechanisms and the improvement of image fidelity,\nrespectively. These advancements laid the groundwork for further models by researchers like Sarto\net al. (Sarto et al., 2022) for image captioning,\nand Yuan et al. (Yuan et al., 2023) for text-to-audio\ngeneration, broadening the scope of RAG\u2019s application across different modalities and improving the\nquality and realism of the generated outputs. Furthermore, Re-ViLM (Yang et al., 2023b) refined\nimage captioning capabilities through a retrievalaugmented visual language model. By fine-tuning\nmodel parameters and implementing innovative filtering strategies, it has made strides in producing\nmore precise and contextually appropriate captions.", "mimetype": "text/plain", "start_char_idx": 34508, "end_char_idx": 39177, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "35a95c1d-1250-4e79-ba0c-059fb91d1ea2": {"__data__": {"id_": "35a95c1d-1250-4e79-ba0c-059fb91d1ea2", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42908003-e72d-4bfb-be8d-23db30e7938c", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "fd18fcb5862650f4b2b7f38000dad060d6ae374b151cdf889577555a9bb7b41e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cbaf087c-3db6-4926-be11-4a69eea18f2d", "node_type": "1", "metadata": {}, "hash": "76374c1510934153aeaa1b02f1ad710324ded3d9d5d3144ef51898be253aab8c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They achieved\nthis through the incorporation of dynamic retrieval\nmechanisms and the improvement of image fidelity,\nrespectively. These advancements laid the groundwork for further models by researchers like Sarto\net al. (Sarto et al., 2022) for image captioning,\nand Yuan et al. (Yuan et al., 2023) for text-to-audio\ngeneration, broadening the scope of RAG\u2019s application across different modalities and improving the\nquality and realism of the generated outputs. Furthermore, Re-ViLM (Yang et al., 2023b) refined\nimage captioning capabilities through a retrievalaugmented visual language model. By fine-tuning\nmodel parameters and implementing innovative filtering strategies, it has made strides in producing\nmore precise and contextually appropriate captions.\nBy tapping into external resources, these models\nhave provided significant enhancements over traditional benchmarks, highlighting the advantage of\nintegrating diverse sources of knowledge.\n10 Conclusions\nIn this paper, we have presented a comprehensive framework for understanding the RAG domain, highlighting its significance in enhancing\nthe capabilities of LLMs. Through a structured\noverview of RAG, categorizing various methods,\nand an in-depth analysis of its core technologies\nand evaluation methods, this study illuminates the\npath for future research. It identifies crucial areas\nfor improvement and outlines potential directions\nfor advancing RAG applications, especially in textual contexts. This survey aims to elucidate the\ncore concepts of the RAG field from a retrieval\nperspective, and it is intended to facilitate further\nexploration and innovation in the accurate retrieval\nand generation of information.\n11 Limitations\nThis survey comprehensively examines existing\nRAG models, summarizing their core techniques\ninto four main steps from a retrieval perspective. It\nrecognizes that some methods may encompass multiple steps and that decoupling these steps could\npotentially obscure their intrinsic connections. Nevertheless, the primary objective is to simplify the\ncomplexity of the approach, clearly delineating the\nspecific problems it addresses. This allows for a\nclearer identification of areas ripe for further optimization and improvement. Despite the thorough investigation, the rapid evolution of the field and\npage limits mean that certain aspects might not\nhave been fully analyzed and explored, or recent\ndevelopments could have been missed. While the\npaper references evaluation methods that can aid\nin the development of RAG, it also acknowledges\nmature tools like LangChain and LlamaIndex as\nuseful resources. However, the focus of this survey\nis not on detailing the evaluation pipeline or how\nthese tools are specifically used, but rather on illustrating how evaluation aspects can support the\nadvancement of RAG. This choice highlights an\narea for future work, emphasizing the importance\nof methodological clarity and the application of\nevaluation tools in refining and enhancing RAG\nmodels.\nAcknowledgements\nThis work was supported by the Natural Sciences\nand Engineering Research Council (NSERC) of\nCanada and the York Research Chairs (YRC) program.\nAcknowledgements\nThis work was supported by the Natural Sciences\nand Engineering Research Council (NSERC) of\nCanada and the York Research Chairs (YRC) program.\nReferences\nAkari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and\nHannaneh Hajishirzi. 2023. Self-RAG: Learning\nto Retrieve, Generate, and Critique through SelfReflection. arXiv, abs/2310.11511.\nMoshe Berchansky, Peter Izsak, Avi Caciularu, Ido\nDagan, and Moshe Wasserblat. 2023. Optimizing\nRetrieval-augmented Reader Models via Token Elimination. In Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1506\u20131524. Association for Computational\nLinguistics.\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick S. H.\nLewis, Scott Yih, Sebastian Riedel, and Fabio Petroni.\n2022a. Autoregressive search engines: Generating\nsubstrings as document identifiers. In Advances in\nNeural Information Processing Systems 35: Annual\nConference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,\nNovember 28 - December 9, 2022.\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick S. H.\nLewis, Scott Yih, Sebastian Riedel, and Fabio Petroni.\n2022b. Autoregressive Search Engines: Generating Substrings as Document Identifiers. In Conference on Neural Information Processing Systems\n(NeurIPS).", "mimetype": "text/plain", "start_char_idx": 38415, "end_char_idx": 42865, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cbaf087c-3db6-4926-be11-4a69eea18f2d": {"__data__": {"id_": "cbaf087c-3db6-4926-be11-4a69eea18f2d", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35a95c1d-1250-4e79-ba0c-059fb91d1ea2", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "b56d8ce9833b66d73f9b6187b2aea0b279968d1151a8e40fa942f3923193f275", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "abddf7d5-2aa6-4361-ac77-38272c6c7ed7", "node_type": "1", "metadata": {}, "hash": "559eec59f19afb039a4c8a4f39488e1e5c84061d4bfd71d686a8f79dbb145a58", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Association for Computational\nLinguistics.\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick S. H.\nLewis, Scott Yih, Sebastian Riedel, and Fabio Petroni.\n2022a. Autoregressive search engines: Generating\nsubstrings as document identifiers. In Advances in\nNeural Information Processing Systems 35: Annual\nConference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,\nNovember 28 - December 9, 2022.\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick S. H.\nLewis, Scott Yih, Sebastian Riedel, and Fabio Petroni.\n2022b. Autoregressive Search Engines: Generating Substrings as Document Identifiers. In Conference on Neural Information Processing Systems\n(NeurIPS).\nSid Black, Gao Leo, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021. GPT-Neo: Large\nScale Autoregressive Language Modeling with MeshTensorflow.\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\nTrevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\nSaffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen\nSimonyan, Jack W. Rae, Erich Elsen, and Laurent\nSifre. 2022. Improving Language Models by Retrieving from Trillions of Tokens. In International Conference on Machine Learning (ICML), pages 2206\u2013\n2240.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners. In\nConference on Neural Information Processing Systems (NeurIPS), volume abs/2005.14165.\nHoward Chen, Ramakanth Pasunuru, Jason Weston, and\nAsli Celikyilmaz. 2023a. Walking Down the Memory\nMaze: Beyond Context Limit through Interactive\nReading. arXiv, abs/2310.05029.\nJiangui Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan,\nand Xueqi Cheng. 2022a. Gere: Generative Evidence\nRetrieval for Fact Verification. In Proceedings of\nthe 45th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval.\nACM.\nJiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.\n2023b. Benchmarking large language models in retrieval-augmented generation. arXiv,\nabs/2309.01431.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, and others. 2021. Evaluating\nlarge language models trained on code. arXiv,\nabs/2107.03374.\nWenhu Chen, Hexiang Hu, Xi Chen, Pat Verga,\nand William Cohen. 2022b. Murag: Multimodal\nRetrieval-Augmented Generator for Open Question\nAnswering over Images and Text. In Proceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).\nWenhu Chen, Hexiang Hu, Chitwan Saharia, and\nWilliam W. Cohen. 2023c. Re-Imagen: RetrievalAugmented Text-to-Image Generator. In International Conference on Learning Representations\n(ICLR).", "mimetype": "text/plain", "start_char_idx": 42179, "end_char_idx": 45511, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "abddf7d5-2aa6-4361-ac77-38272c6c7ed7": {"__data__": {"id_": "abddf7d5-2aa6-4361-ac77-38272c6c7ed7", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbaf087c-3db6-4926-be11-4a69eea18f2d", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "8df8b4d71f8895b784c40ceb2eebec4644fac7d49dc2605afd5bbff77f2ad91a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e975e2f-b34b-4362-b279-cba2c2540009", "node_type": "1", "metadata": {}, "hash": "193a6cb37ab3d63d35e2c67c1309f0d5393d5a00d4cd794d3cdcf62bd97a0997", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2021. Evaluating\nlarge language models trained on code. arXiv,\nabs/2107.03374.\nWenhu Chen, Hexiang Hu, Xi Chen, Pat Verga,\nand William Cohen. 2022b. Murag: Multimodal\nRetrieval-Augmented Generator for Open Question\nAnswering over Images and Text. In Proceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).\nWenhu Chen, Hexiang Hu, Chitwan Saharia, and\nWilliam W. Cohen. 2023c. Re-Imagen: RetrievalAugmented Text-to-Image Generator. In International Conference on Learning Representations\n(ICLR).\nZhihong Chen, Feng Jiang, Junying Chen, Tiannan\nWang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao\nLiang, Chen Zhang, Zhiyi Zhang, and others. 2023d.\nPhoenix: Democratizing chatgpt across languages.\narXiv, abs/2304.10453.\nDaixuan Cheng, Shaohan Huang, Junyu Bi, Yuefeng\nZhan, Jianfeng Liu, Yujing Wang, Hao Sun, Furu\nWei, Weiwei Deng, and Qi Zhang. 2023a. Uprise:\nUniversal Prompt Retrieval for Improving Zero-Shot\nEvaluation. In Proceedings of the 2023 Conference\non Empirical Methods in Natural Language Processing, pages 12318\u201312337. Association for Computational Linguistics.\nXin Cheng, Di Luo, Xiuying Chen, Lemao Liu,\nDongyan Zhao, and Rui Yan. 2023b. Lift Yourself Up: Retrieval-augmented Text Generation with\nSelf-Memory. In Thirty-seventh Conference on\nNeural Information Processing Systems, volume\nabs/2305.02437.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2023. Palm: Scaling Language\nModeling with Pathways. Journal of Machine Learning Research (JMLR), 24:240:1\u2013240:113.\nHyung Won Chung, Le Hou, S. Longpre, Barret\nZoph, Yi Tay, W. Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Webson, S. Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen,\nAakanksha Chowdhery, Dasha Valter, Sharan Narang,\nGaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav\nPetrov, E. Chi, J. Dean, Jacob Devlin, Adam Roberts,\nDenny Zhou, Quoc V. Le, and Jason Wei. 2022. Scaling Instruction-Finetuned Language Models. arXiv,\nabs/2210.11416.", "mimetype": "text/plain", "start_char_idx": 44977, "end_char_idx": 47963, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e975e2f-b34b-4362-b279-cba2c2540009": {"__data__": {"id_": "5e975e2f-b34b-4362-b279-cba2c2540009", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "abddf7d5-2aa6-4361-ac77-38272c6c7ed7", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "1fc9cf3c1c58819d56422c6e0c6df268ac7ec168b5403df1e406b2c443f2ae89", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "527bb4c7-2740-4f64-80ec-e4ba28137497", "node_type": "1", "metadata": {}, "hash": "79f5e2d754eb2a3f34a3de5325f09b2ebdc39bad08542880c943478e2e09f480", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Journal of Machine Learning Research (JMLR), 24:240:1\u2013240:113.\nHyung Won Chung, Le Hou, S. Longpre, Barret\nZoph, Yi Tay, W. Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Webson, S. Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen,\nAakanksha Chowdhery, Dasha Valter, Sharan Narang,\nGaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav\nPetrov, E. Chi, J. Dean, Jacob Devlin, Adam Roberts,\nDenny Zhou, Quoc V. Le, and Jason Wei. 2022. Scaling Instruction-Finetuned Language Models. arXiv,\nabs/2210.11416.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised\nCross-lingual Representation Learning at Scale. In\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440\u2013\n8451. Association for Computational Linguistics.\nFlorin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle\nMaarek, Nicola Tonellotto, and Fabrizio Silvestri.\n2024. The Power of Noise: Redefining Retrieval for\nRAG Systems. arXiv, abs/2401.14887.\nZhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo\nNi, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B.\nHall, and Ming-Wei Chang. 2023. Promptagator:\nFew-shot Dense Retrieval From 8 Examples. In International Conference on Learning Representations\n(ICLR).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of Deep\nBidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the\nNorth, pages 4171\u20134186. Association for Computational Linguistics.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\nFan, Michael Auli, and Jason Weston. 2019. Wizard\nof Wikipedia: Knowledge-Powered Conversational\nAgents. In International Conference on Learning\nRepresentations (ICLR).\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,\nJiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:\nGeneral Language Model Pretraining with Autoregressive Blank Infilling. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers). Association for\nComputational Linguistics.\nHady ElSahar, Pavlos Vougiouklis, Arslen Remaci,\nChristophe Gravier, Jonathon S. Hare, Fr\u00e9d\u00e9rique\nLaforest, and Elena Simperl. 2018. T-REx: A Large\nScale Alignment of Natural Language with Knowledge Base Triples. In International Conference on\nLanguage Resources and Evaluation (LREC).\nZhangyin Feng, Xiaocheng Feng, Dezhi Zhao, Maojin Yang, and Bing Qin. 2023. Retrieval-generation\nsynergy augmented large language models. arXiv,\nabs/2310.05149.\nEdward A. Fox and Joseph A. Shaw. 1994. Combination of multiple searches. In TREC-2: Text retrieval\nconference, 500215, pages 105\u2013108.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimcse: Simple Contrastive Learning of Sentence\nEmbeddings. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, pages 6894\u20136910. Association for Computational Linguistics.\nMichael Glass, Gaetano Rossiello, Md Faisal Mahbub\nChowdhury, Ankita Naik, Pengshan Cai, and Alfio\nGliozzo. 2022. Re2g: Retrieve, Rerank, Generate.", "mimetype": "text/plain", "start_char_idx": 47405, "end_char_idx": 50648, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "527bb4c7-2740-4f64-80ec-e4ba28137497": {"__data__": {"id_": "527bb4c7-2740-4f64-80ec-e4ba28137497", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e975e2f-b34b-4362-b279-cba2c2540009", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "45a68cc461398ac5d61dea00400e71738333e6741dd3dc26d28946b91aa138a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc9640d4-d7f0-4166-bdfe-792d84bc1dd4", "node_type": "1", "metadata": {}, "hash": "4a082f0e4794d2ddef8d46dcbd19a6b46121f758f96cb1c280e582a2b6b8e0cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Retrieval-generation\nsynergy augmented large language models. arXiv,\nabs/2310.05149.\nEdward A. Fox and Joseph A. Shaw. 1994. Combination of multiple searches. In TREC-2: Text retrieval\nconference, 500215, pages 105\u2013108.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimcse: Simple Contrastive Learning of Sentence\nEmbeddings. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, pages 6894\u20136910. Association for Computational Linguistics.\nMichael Glass, Gaetano Rossiello, Md Faisal Mahbub\nChowdhury, Ankita Naik, Pengshan Cai, and Alfio\nGliozzo. 2022. Re2g: Retrieve, Rerank, Generate.\nIn Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,\npages 2701\u20132715. Association for Computational\nLinguistics.\nSimon Gottschalk and Elena Demidova. 2018. EventKG: A Multilingual Event-Centric Temporal Knowledge Graph. Springer International Publishing.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\nand Ming-Wei Chang. 2020. Retrieval Augmented\nLanguage Model Pre-Training. In International Conference on Machine Learning (ICML), pages 3929\u2013\n3938.\nWilliam L. Hamilton. 2020. Graph representation learning. Springer International Publishing.\nMicheline Hancock-Beaulieu, Mike Gatford, Xiangji\nHuang, Stephen E. Robertson, Steve Walker, and\nP. W. Williams. 1996. Okapi at TREC-5. In Proceedings of The Fifth Text REtrieval Conference, TREC\n1996, Gaithersburg, Maryland, USA, November 20-\n22, 1996, volume 500-238 of NIST Special Publication. National Institute of Standards and Technology\n(NIST).\nSebastian Hofst\u00e4tter, Jiecao Chen, Karthik Raman, and\nHamed Zamani. 2023. Fid-light: Efficient and effective retrieval-augmented text generation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information\nRetrieval, pages 1437\u20131447.\nZiniu Hu, Ahmet Iscen, Chen Sun, Zirui Wang,\nKai-Wei Chang, Yizhou Sun, Cordelia Schmid,\nDavid A. Ross, and Alireza Fathi. 2023. Reveal:\nRetrieval-Augmented Visual-Language Pre-Training\nwith Multi-Source Multimodal Knowledge Memory. In 2023 IEEE/CVF Conference on Computer\nVision and Pattern Recognition (CVPR), pages 23369\u2013\n23379. IEEE.\nJie Huang, Hanyin Shao, Kevin Chen-Chuan Chang,\nJinjun Xiong, and Wen-mei Hwu. 2022. Understanding Jargon: Combining Extraction and Generation\nfor Definition Modeling. In Proceedings of the 2022\nConference on Empirical Methods in Natural Language Processing. Association for Computational\nLinguistics.\nJimmy Xiangji Huang, Jun Miao, and Ben He. 2013.\nHigh performance query expansion using adaptive\nco-training. Inf. Process. Manag., 49(2):441\u2013453.\nWenyu Huang, Mirella Lapata, Pavlos Vougiouklis,\nNikos Papasarantopoulos, and Jeff Z Pan. 2023. Retrieval Augmented Generation with Rich Answer Encoding. Proc. of IJCNLP-AACL, 2023.\nXiangji Huang and Qinmin Hu. 2009. A bayesian learning approach to promoting diversity in ranking for\nbiomedical information retrieval. In Proceedings of\nthe 32nd Annual International ACM SIGIR Conference on Research and Development in Information\nRetrieval, SIGIR 2009, Boston, MA, USA, July 19-23,\n2009, pages 307\u2013314. ACM.\nYizheng Huang and Jimmy Huang. 2024. Exploring\nchatgpt for next-generation information retrieval: Opportunities and challenges. CoRR, abs/2402.11203.\nYizheng Huang and Jimmy X. Huang. 2023. Diversified\nprior knowledge enhanced general language model\nfor biomedical information retrieval.", "mimetype": "text/plain", "start_char_idx": 50015, "end_char_idx": 53507, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc9640d4-d7f0-4166-bdfe-792d84bc1dd4": {"__data__": {"id_": "cc9640d4-d7f0-4166-bdfe-792d84bc1dd4", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "527bb4c7-2740-4f64-80ec-e4ba28137497", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "4b6abb279d06aa88c6d1f064d595b5c9d830382fda906dcc4843c51bd83142a2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86f3bc33-ae35-4343-8928-110f8495083d", "node_type": "1", "metadata": {}, "hash": "e395b5269dc85e8a846fdcda6016d816662135a2cc5c840a6bdb61c32ac1d2fe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Retrieval Augmented Generation with Rich Answer Encoding. Proc. of IJCNLP-AACL, 2023.\nXiangji Huang and Qinmin Hu. 2009. A bayesian learning approach to promoting diversity in ranking for\nbiomedical information retrieval. In Proceedings of\nthe 32nd Annual International ACM SIGIR Conference on Research and Development in Information\nRetrieval, SIGIR 2009, Boston, MA, USA, July 19-23,\n2009, pages 307\u2013314. ACM.\nYizheng Huang and Jimmy Huang. 2024. Exploring\nchatgpt for next-generation information retrieval: Opportunities and challenges. CoRR, abs/2402.11203.\nYizheng Huang and Jimmy X. Huang. 2023. Diversified\nprior knowledge enhanced general language model\nfor biomedical information retrieval. In ECAI 2023 -\n26th European Conference on Artificial Intelligence,\nSeptember 30 - October 4, 2023, Krak\u00f3w, Poland - Including 12th Conference on Prestigious Applications\nof Intelligent Systems (PAIS 2023), volume 372 of\nFrontiers in Artificial Intelligence and Applications,\npages 1109\u20131115. IOS Press.\nGautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and\nEdouard Grave. 2022. Unsupervised Dense Information Retrieval with Contrastive Learning. Transactions on Machine Learning Research (TMLR), 2022.\nGautier Izacard and Edouard Grave. 2021. Leveraging\nPassage Retrieval with Generative Models for Open\nDomain Question Answering. In Proceedings of the\n16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,\npages 874\u2013880. Association for Computational Linguistics.\nGautier Izacard, Patrick S. H. Lewis, Maria Lomeli,\nLucas Hosseini, Fabio Petroni, Timo Schick, Jane\nDwivedi-Yu, Armand Joulin, Sebastian Riedel, and\nEdouard Grave. 2023. Atlas: Few-shot Learning with\nRetrieval Augmented Language Models. Journal\nof Machine Learning Research (JMLR), 24:251:1\u2013\n251:43.\nIsrat Jahan, Md. Tahmid Rahman Laskar, Chun Peng,\nand Jimmy Xiangji Huang. 2023. Evaluation of\nchatgpt on biomedical tasks: A zero-shot comparison with fine-tuned generative transformers. CoRR,\nabs/2306.04504.\nBernard J. Jansen, Danielle L. Booth, and Amanda\nSpink. 2009. Patterns of query reformulation during web searching. J. Assoc. Inf. Sci. Technol.,\n60(7):1358\u20131371.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu,\nDan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of hallucination in natural language generation. ACM Comput.\nSurv., 55(12):248:1\u2013248:38.\nZhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun,\nQian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\nCallan, and Graham Neubig. 2023. Active Retrieval\nAugmented Generation. In Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 7969\u20137992.\nJeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2021.\nBillion-scale similarity search with gpus. IEEE\nTransactions on Big Data, 7(3):535\u2013547.\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\nZettlemoyer. 2017. Triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601\u20131611. Association\nfor Computational Linguistics.\nMinki Kang, Jin Myung Kwak, Jinheon Baek,\nand Sung Ju Hwang. 2023. Knowledge\nGraph-Augmented Language Models for\nKnowledge-Grounded Dialogue Generation.\narXiv, abs/2305.18846.", "mimetype": "text/plain", "start_char_idx": 52802, "end_char_idx": 56186, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "86f3bc33-ae35-4343-8928-110f8495083d": {"__data__": {"id_": "86f3bc33-ae35-4343-8928-110f8495083d", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc9640d4-d7f0-4166-bdfe-792d84bc1dd4", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "22da115b432161604155f12b33e6af4062634ea9049b38c7bf6ec17ad4f2bc50", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e7d2d185-6e43-41a9-8d61-ca6cf6acc305", "node_type": "1", "metadata": {}, "hash": "66a897e1815456cb02c6764f7abd1be0acb7d0928d81db500a4ae5fed0b81621", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2021.\nBillion-scale similarity search with gpus. IEEE\nTransactions on Big Data, 7(3):535\u2013547.\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\nZettlemoyer. 2017. Triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601\u20131611. Association\nfor Computational Linguistics.\nMinki Kang, Jin Myung Kwak, Jinheon Baek,\nand Sung Ju Hwang. 2023. Knowledge\nGraph-Augmented Language Models for\nKnowledge-Grounded Dialogue Generation.\narXiv, abs/2305.18846.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nS. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen,\nand Wen-tau Yih. 2020. Dense Passage Retrieval for\nOpen-Domain Question Answering. In Conference\non Empirical Methods in Natural Language Processing (EMNLP), pages 6769\u20136781.\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\nZettlemoyer, and Mike Lewis. 2020. Generalization\nthrough Memorization: Nearest Neighbor Language\nModels. In International Conference on Learning\nRepresentations (ICLR).\nO. Khattab, Keshav Santhanam, Xiang Lisa Li, David\nLeo Wright Hall, Percy Liang, Christopher Potts,\nand M. Zaharia. 2022. Demonstrate-Search-Predict:\nComposing retrieval and language models for\nknowledge-intensive NLP. arXiv, abs/2212.14024.\nOmar Khattab and Matei Zaharia. 2020. Colbert - Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In Proceedings of\nthe 43rd International ACM SIGIR Conference on\nResearch and Development in Information Retrieval,\npages 39\u201348. ACM.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natural\nQuestions: A Benchmark for Question Answering\nResearch. Transactions of the Association for Computational Linguistics, 7:453\u2013466.\nMd. Tahmid Rahman Laskar, M. Saiful Bari, Mizanur\nRahman, Md Amran Hossen Bhuiyan, Shafiq Joty,\nand Jimmy Xiangji Huang. 2023. A systematic study\nand comprehensive evaluation of chatgpt on benchmark datasets. CoRR, abs/2305.18486.\nMd. Tahmid Rahman Laskar, Enamul Hoque, and\nJimmy X. Huang. 2020. Query focused abstractive\nsummarization via incorporating query relevance and\ntransfer learning with transformer models. In Advances in Artificial Intelligence - 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020,\nOttawa, ON, Canada, May 13-15, 2020, Proceedings,\nvolume 12109 of Lecture Notes in Computer Science,\npages 342\u2013348. Springer.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020a.\nBart: Denoising Sequence-to-Sequence Pre-training\nfor Natural Language Generation, Translation, and\nComprehension. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics, pages 7871\u20137880. Association for Computational Linguistics.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih,\nTim Rockt\u00e4schel, Sebastian Riedel, and Douwe\nKiela. 2020b.", "mimetype": "text/plain", "start_char_idx": 55536, "end_char_idx": 58888, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7d2d185-6e43-41a9-8d61-ca6cf6acc305": {"__data__": {"id_": "e7d2d185-6e43-41a9-8d61-ca6cf6acc305", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "86f3bc33-ae35-4343-8928-110f8495083d", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "10ee45fb4997cfdae9a93599050fb9526974b16e038ee0b4f4374cb8ea08c519", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d20c864f-7aa7-4fc7-a4be-402e71af427e", "node_type": "1", "metadata": {}, "hash": "7af304b4c87a7717608c48d43b295e39e36605787c7c20a6d5d135aa40176f67", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Springer.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020a.\nBart: Denoising Sequence-to-Sequence Pre-training\nfor Natural Language Generation, Translation, and\nComprehension. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics, pages 7871\u20137880. Association for Computational Linguistics.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih,\nTim Rockt\u00e4schel, Sebastian Riedel, and Douwe\nKiela. 2020b. Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks. In Conference on\nNeural Information Processing Systems (NeurIPS).\nCanjia Li, Andrew Yates, Sean MacAvaney, Ben He,\nand Yingfei Sun. 2024. Parade: Passage Representation Aggregation forDocument Reranking. ACM\nTransactions on Information Systems, 42(2):1\u201326.\nHuayang Li, Yixuan Su, Deng Cai, Yan Wang, and\nLemao Liu. 2022. A Survey on Retrieval-Augmented\nText Generation. arXiv, abs/2202.01110.\nXingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng\nDing, Shafiq R. Joty, Soujanya Poria, and Lidong\nBing. 2023. Chain-of-Knowledge: Grounding Large\nLanguage Models via Dynamic Knowledge Adapting\nover Heterogeneous Sources. arXiv.\nChin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain.\nAssociation for Computational Linguistics.\nSheng-Chieh Lin, Akari Asai, Minghan Li, Barlas\nOguz, Jimmy Lin, Yashar Mehdad, Wen-tau Yih,\nand Xilun Chen. 2023a. How to Train Your Dragon:\nDiverse Augmentation Towards Generalizable Dense\nRetrieval. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 6385\u2013\n6400. Association for Computational Linguistics.\nXi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi,\nMaria Lomeli, Rich James, Pedro Rodriguez, Jacob\nKahn, Gergely Szilvasy, Mike Lewis, and others.\n2023b. Ra-dit: Retrieval-augmented dual instruction tuning. arXiv, abs/2310.01352.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth\nPasunuru, Sam Shleifer, Punit Singh Koura, Vishrav\nChaudhary, Brian O\u2019Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, and Xian Li. 2022. Few-shot Learning with\nMultilingual Generative Language Models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for\nComputational Linguistics.\nYi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen,\nHao Zhou, Fandong Meng, Jie Zhou, and Xu Sun.\n2023. Recall: A Benchmark for LLMs Robustness\nagainst External Counterfactual Knowledge. arXiv,\nabs/2311.08147.\nZiyang Luo, Can Xu, Pu Zhao, Xiubo Geng, Chongyang\nTao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023.\nAugmented Large Language Models with Parametric\nKnowledge Guiding. arXiv, abs/2305.04757.\nXinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,\nand Nan Duan. 2023. Query Rewriting in RetrievalAugmented Large Language Models.", "mimetype": "text/plain", "start_char_idx": 58271, "end_char_idx": 61378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d20c864f-7aa7-4fc7-a4be-402e71af427e": {"__data__": {"id_": "d20c864f-7aa7-4fc7-a4be-402e71af427e", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7d2d185-6e43-41a9-8d61-ca6cf6acc305", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "b283d3ee10ff9dacaeb3a0c99d1bfec00b74f7db5777b227afda44055a8c74e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0b403d1-f8c4-48c0-90bf-ab39a1239637", "node_type": "1", "metadata": {}, "hash": "deeeb368b44c3dcf3addd11fb31bbaa458d6f72e8100a45d170517309b94f253", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Association for\nComputational Linguistics.\nYi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen,\nHao Zhou, Fandong Meng, Jie Zhou, and Xu Sun.\n2023. Recall: A Benchmark for LLMs Robustness\nagainst External Counterfactual Knowledge. arXiv,\nabs/2311.08147.\nZiyang Luo, Can Xu, Pu Zhao, Xiubo Geng, Chongyang\nTao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023.\nAugmented Large Language Models with Parametric\nKnowledge Guiding. arXiv, abs/2305.04757.\nXinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,\nand Nan Duan. 2023. Query Rewriting in RetrievalAugmented Large Language Models. In Proceedings\nof the 2023 Conference on Empirical Methods in\nNatural Language Processing, pages 5303\u20135315. Association for Computational Linguistics.\nYu A. Malkov and D. A. Yashunin. 2020. Efficient\nand robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE\nTransactions on Pattern Analysis and Machine Intelligence, 42(4):824\u2013836.\nChristopher D. Manning, Prabhakar Raghavan, and Hinrich Sch\u00fctze. 2008. Introduction to Information Retrieval. Cambridge University Press.\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff\nWu, Long Ouyang, Christina Kim, Christopher\nHesse, Shantanu Jain, Vineet Kosaraju, William\nSaunders, and others. 2021. Webgpt: Browserassisted question-answering with human feedback.\narXiv, abs/2112.09332.\nJianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan,\nKeith Hall, Ming-Wei Chang, and Yinfei Yang. 2022.\nLarge Dual Encoders Are Generalizable Retrievers.\nIn Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages\n9844\u20139855. Association for Computational Linguistics.\nRodrigo Nogueira, Wei Yang, Kyunghyun Cho, and\nJimmy Lin. 2019. Multi-stage document ranking\nwith BERT. CoRR, abs/1910.14424.", "mimetype": "text/plain", "start_char_idx": 60810, "end_char_idx": 62624, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0b403d1-f8c4-48c0-90bf-ab39a1239637": {"__data__": {"id_": "c0b403d1-f8c4-48c0-90bf-ab39a1239637", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d20c864f-7aa7-4fc7-a4be-402e71af427e", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "1c3a551927bb0c709f1645d58b3296f6b25229c7af7febe0ced3d31c31a7e17c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5509687d-5633-419b-9c49-d3c8c2ece59c", "node_type": "1", "metadata": {}, "hash": "be1dfd8b9ab9c641e54dae3627c879703ad509f3029e495de47b73dcd5410735", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2021. Webgpt: Browserassisted question-answering with human feedback.\narXiv, abs/2112.09332.\nJianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan,\nKeith Hall, Ming-Wei Chang, and Yinfei Yang. 2022.\nLarge Dual Encoders Are Generalizable Retrievers.\nIn Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages\n9844\u20139855. Association for Computational Linguistics.\nRodrigo Nogueira, Wei Yang, Kyunghyun Cho, and\nJimmy Lin. 2019. Multi-stage document ranking\nwith BERT. CoRR, abs/1910.14424.\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,\nLama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin,\nSuchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello,\nJake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman,\nTim Brooks, Miles Brundage, Kevin Button, Trevor\nCai, Rosie Campbell, Andrew Cann, Brittany Carey,\nChelsea Carlson, Rory Carmichael, Brooke Chan,\nChe Chang, Fotis Chantzis, Derek Chen, Sully Chen,\nRuby Chen, Jason Chen, Mark Chen, Ben Chess,\nChester Cho, Casey Chu, Hyung Won Chung, Dave\nCummings, Jeremiah Currier, Yunxing Dai, Cory\nDecareaux, Thomas Degry, Noah Deutsch, Damien\nDeville, Arka Dhar, David Dohan, Steve Dowling,\nSheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna\nEloundou, David Farhi, Liam Fedus, Niko Felix,\nSim\u00f3n Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik\nGoel, Tarun Gogineni, Gabriel Goh, Rapha GontijoLopes, Jonathan Gordon, Morgan Grafstein, Scott\nGray, Ryan Greene, Joshua Gross, Shixiang Shane\nGu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris,\nYuchen He, Mike Heaton, Johannes Heidecke, Chris\nHesse, Alan Hickey, Wade Hickey, Peter Hoeschele,\nBrandon Houghton, Kenny Hsu, Shengli Hu, Xin\nHu, Joost Huizinga, Shantanu Jain, Shawn Jain,\nJoanne Jang, Angela Jiang, Roger Jiang, Haozhun\nJin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo\nJun, Tomer Kaftan, \u0141ukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak\nKhan, Logan Kilpatrick, Jong Wook Kim, Christina\nKim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros,\nMatt Knight, Daniel Kokotajlo, \u0141ukasz Kondraciuk,\nAndrew Kondrich, Aris Konstantinidis, Kyle Kosic,\nGretchen Krueger, Vishal Kuo, Michael Lampe, Ikai\nLan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy,\nChak Ming Li, Rachel Lim, Molly Lin, Stephanie\nLin, Mateusz Litwin, Theresa Lopez, Ryan Lowe,\nPatricia Lue, Anna Makanju, Kim Malfacini, Sam\nManning, Todor Markov, Yaniv Markovski, Bianca\nMartin, Katie Mayer, Andrew Mayne, Bob McGrew,\nScott Mayer McKinney, Christine McLeavey, Paul\nMcMillan, Jake McNeil, and others. 2023. Gpt-4\nTechnical Report. PREPRINT.", "mimetype": "text/plain", "start_char_idx": 62057, "end_char_idx": 64923, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5509687d-5633-419b-9c49-d3c8c2ece59c": {"__data__": {"id_": "5509687d-5633-419b-9c49-d3c8c2ece59c", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0b403d1-f8c4-48c0-90bf-ab39a1239637", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "44fe7e1c8ef828ff03c2583b09637113ef1dba6798470857ae76496d082b1d39", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "21aaaee8-939f-4a2d-b298-db323ec6ec00", "node_type": "1", "metadata": {}, "hash": "1452f37b431b0642e38660efa6ec2a0657328e578e8694dec5d29104296915ea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Gpt-4\nTechnical Report. PREPRINT.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instructions with human feedback. In Conference on Neural\nInformation Processing Systems (NeurIPS).\nKishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the\n40th Annual Meeting on Association for Computational Linguistics, ACL \u201902, page 311\u2013318, USA.\nAssociation for Computational Linguistics.\nBaolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with\ngpt-4. arXiv.\nFabio Petroni, Aleksandra Piktus, Angela Fan, Patrick\nLewis, Majid Yazdani, Nicola De Cao, James Thorne,\nYacine Jernite, Vladimir Karpukhin, Jean Maillard,\nVassilis Plachouras, Tim Rockt\u00e4schel, and Sebastian\nRiedel. 2021. Kilt: a Benchmark for Knowledge Intensive Language Tasks. In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2523\u20132544. Association for Computational Linguistics.\nFilip Radlinski and Nick Craswell. 2010. Comparing\nthe sensitivity of information retrieval metrics. In\nProceedings of the 33rd International ACM SIGIR\nConference on Research and Development in Information Retrieval, SIGIR \u201910, page 667\u2013674, New\nYork, NY, USA. Association for Computing Machinery.\nColin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring\nthe Limits of Transfer Learning with a Unified Textto-Text Transformer. Journal of Machine Learning\nResearch (JMLR), 21:140:1\u2013140:67.\nOri Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\nShoham. 2023. In-Context Retrieval-Augmented\nLanguage Models. Transactions of the Association\nfor Computational Linguistics, 11:1316\u20131331.\nOri Ram, Gal Shachaf, Omer Levy, Jonathan Berant,\nand Amir Globerson. 2022. Learning to Retrieve\nPassages without Supervision. In Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.\nNils Reimers and Iryna Gurevych. 2019. SentenceBERT: Sentence Embeddings using Siamese BERTNetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages\n3980\u20133990. Association for Computational Linguistics.\nStephen Robertson and Hugo Zaragoza. 2009. The\nProbabilistic Relevance Framework: Bm25 and Beyond. Foundations and Trends\u00ae in Information Retrieval, 3(4):333\u2013389.\nJon Saad-Falcon, O. Khattab, Christopher Potts, and\nMatei Zaharia. 2023. Ares: An Automated Evaluation Framework for Retrieval-Augmented Generation\nSystems. arXiv, abs/2311.09476.\nSara Sarto, Marcella Cornia, Lorenzo Baraldi, and Rita\nCucchiara. 2022. Retrieval-Augmented Transformer\nfor Image Captioning. In International Conference\non Content-based Multimedia Indexing. ACM.\nES Shahul, Jithin James, Luis Espinosa Anke, and\nS. Schockaert. 2023. Ragas: Automated Evaluation of Retrieval Augmented Generation.", "mimetype": "text/plain", "start_char_idx": 64884, "end_char_idx": 68395, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "21aaaee8-939f-4a2d-b298-db323ec6ec00": {"__data__": {"id_": "21aaaee8-939f-4a2d-b298-db323ec6ec00", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5509687d-5633-419b-9c49-d3c8c2ece59c", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "5dd51b48e6b9549c7233c80e480800aef72af4d5acc7c71a1199e0bf9b1a14aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fd1c253c-c9f8-41c0-a89b-bb33cc5826c4", "node_type": "1", "metadata": {}, "hash": "befe0076d880e1694deaa515c011a1fbcae96e17f1c32f84dbc9eed8357b29aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2009. The\nProbabilistic Relevance Framework: Bm25 and Beyond. Foundations and Trends\u00ae in Information Retrieval, 3(4):333\u2013389.\nJon Saad-Falcon, O. Khattab, Christopher Potts, and\nMatei Zaharia. 2023. Ares: An Automated Evaluation Framework for Retrieval-Augmented Generation\nSystems. arXiv, abs/2311.09476.\nSara Sarto, Marcella Cornia, Lorenzo Baraldi, and Rita\nCucchiara. 2022. Retrieval-Augmented Transformer\nfor Image Captioning. In International Conference\non Content-based Multimedia Indexing. ACM.\nES Shahul, Jithin James, Luis Espinosa Anke, and\nS. Schockaert. 2023. Ragas: Automated Evaluation of Retrieval Augmented Generation. arXiv,\nabs/2309.15217.\nZhihong Shao, Yeyun Gong, Yelong Shen, Minlie\nHuang, Nan Duan, and Weizhu Chen. 2023. Enhancing Retrieval-Augmented Large Language Models\nwith Iterative Retrieval-Generation Synergy. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9248\u20139274. Association\nfor Computational Linguistics.\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\nWen-tau Yih. 2023. Replug: Retrieval-augmented\nblack-box language models. arXiv, abs/2301.12652.\nZhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and\nDenny Zhou. 2023. Recitation-Augmented Language Models. In International Conference on Learning Representations (ICLR).\nYi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia,\nJason Wei, Xuezhi Wang, Hyung Won Chung, Dara\nBahri, Tal Schuster, Huaixiu Steven Zheng, Denny\nZhou, Neil Houlsby, and Donald Metzler. 2023. Ul2:\nUnifying Language Learning Paradigms. In International Conference on Learning Representations\n(ICLR).\nYi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara\nBahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao,\nJai Prakash Gupta, Tal Schuster, William W. Cohen,\nand Donald Metzler. 2022. Transformer Memory\nas a Differentiable Search Index. In Conference on\nNeural Information Processing Systems (NeurIPS).\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFever: a Large-scale Dataset for Fact Extraction\nand VERification. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers),\npages 809\u2013819. Association for Computational\nLinguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothee Lacroix,\nBaptiste Roziere, Naman Goyal, Eric Hambro, Faisal\nAzhar, and others. 2023a. Llama: Open and efficient\nfoundation language models. arXiv, abs/2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter\nAlbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\nShruti Bhosale, and others. 2023b. Llama 2: Open\nfoundation and fine-tuned chat models. arxiv,\nabs/2307.09288.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\nand Ashish Sabharwal. 2023. Interleaving Retrieval\nwith Chain-of-Thought Reasoning for KnowledgeIntensive Multi-Step Questions. In Proceedings of\nthe 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npages 10014\u201310037. Association for Computational\nLinguistics.", "mimetype": "text/plain", "start_char_idx": 67760, "end_char_idx": 70953, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fd1c253c-c9f8-41c0-a89b-bb33cc5826c4": {"__data__": {"id_": "fd1c253c-c9f8-41c0-a89b-bb33cc5826c4", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "21aaaee8-939f-4a2d-b298-db323ec6ec00", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "9c16e95c7c2ed5a4a0f3168fcbfbd995d8f171667e470ebc24d78fc9f5905d27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da8dff95-2d7e-4ffe-ad44-027dd67f9365", "node_type": "1", "metadata": {}, "hash": "a8fe3c3cee11c7ff4b450bb159e15d57f39f1f27027dcde93ab0ca39a559b3c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "arXiv, abs/2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter\nAlbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\nShruti Bhosale, and others. 2023b. Llama 2: Open\nfoundation and fine-tuned chat models. arxiv,\nabs/2307.09288.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\nand Ashish Sabharwal. 2023. Interleaving Retrieval\nwith Chain-of-Thought Reasoning for KnowledgeIntensive Multi-Step Questions. In Proceedings of\nthe 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npages 10014\u201310037. Association for Computational\nLinguistics.\nAshish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Neural Information Processing Systems, pages 5998\u20136008.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel R. Bowman. 2019. Superglue: A Stickier Benchmark for General-Purpose Language Understanding Systems. In Conference on Neural Information Processing Systems (NeurIPS), pages 3261\u2013\n3275.\nBen Wang and Aran Komatsuzaki. 2021. GPT-J6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/\nmesh-transformer-jax.\nLiang Wang, Nan Yang, and Furu Wei. 2023a.\nQuery2doc: Query Expansion with Large Language\nModels. In Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Processing,\npages 9414\u20139423. Association for Computational\nLinguistics.\nXintao Wang, Qian Yang, Yongting Qiu, Jiaqing Liang,\nQi He, Zhouhong Gu, Yanghua Xiao, and W. Wang.\n2023b. Knowledgpt: Enhancing Large Language\nModels with Retrieval and Storage Access on Knowledge Bases. arXiv, abs/2308.11761.\nBigScience Workshop, Teven Le Scao, Angela Fan,\nChristopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel\nHesslow, Roman Castagn\u00e9, Alexandra Sasha Luccioni, Fran\u00e7ois Yvon, and others. 2022. Bloom: A\n176b-parameter open-access multilingual language\nmodel. arXiv, abs/2211.05100.\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\nJialin Liu, Paul N. Bennett, Junaid Ahmed, and\nArnold Overwijk. 2021. Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text\nRetrieval. In International Conference on Learning\nRepresentations (ICLR).\nFangyuan Xu, Weijia Shi, and Eunsol Choi. 2023. Recomp: Improving Retrieval-Augmented LMs with\nCompression and Selective Augmentation. arXiv,\nabs/2310.04408.\nHaoyan Yang, Zhitao Li, Yong Zhang, Jianzong Wang,\nNing Cheng, Ming Li, and Jing Xiao. 2023a. Prca:\nFitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable RewardDriven Contextual Adapter. In Proceedings of the\n2023 Conference on Empirical Methods in Natural\nLanguage Processing, pages 5364\u20135375. Association\nfor Computational Linguistics.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: A Dataset for\nDiverse, Explainable Multi-hop Question Answering.\nIn Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages\n2369\u20132380. Association for Computational Linguistics.", "mimetype": "text/plain", "start_char_idx": 70320, "end_char_idx": 73522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "da8dff95-2d7e-4ffe-ad44-027dd67f9365": {"__data__": {"id_": "da8dff95-2d7e-4ffe-ad44-027dd67f9365", "embedding": null, "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19", "node_type": "4", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "e12ff982e364fc15547212b23ec7560be7041c083d4f56cdac605a6b49459550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fd1c253c-c9f8-41c0-a89b-bb33cc5826c4", "node_type": "1", "metadata": {"source_url": "https://arxiv.org/pdf/2404.10981", "document_index": 19}, "hash": "962253c349cf7009004ed8a6e3c194b51a83a5b4def4a778c134590479b195c7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Haoyan Yang, Zhitao Li, Yong Zhang, Jianzong Wang,\nNing Cheng, Ming Li, and Jing Xiao. 2023a. Prca:\nFitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable RewardDriven Contextual Adapter. In Proceedings of the\n2023 Conference on Empirical Methods in Natural\nLanguage Processing, pages 5364\u20135375. Association\nfor Computational Linguistics.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: A Dataset for\nDiverse, Explainable Multi-hop Question Answering.\nIn Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages\n2369\u20132380. Association for Computational Linguistics.\nZhuolin Yang, Wei Ping, Zihan Liu, Vijay Korthikanti,\nWeili Nie, De-An Huang, Linxi Fan, Zhiding Yu,\nShiyi Lan, Bo Li, Mohammad Shoeybi, Ming-Yu\nLiu, Yuke Zhu, Bryan Catanzaro, Chaowei Xiao, and\nAnima Anandkumar. 2023b. Re-ViLM: RetrievalAugmented Visual Language Model for Zero and\nFew-Shot Image Captioning. In Findings of the Association for Computational Linguistics: EMNLP 2023,\npages 11844\u201311857. Association for Computational\nLinguistics.\nShi Yu, Jiahua Liu, Jingqin Yang, Chenyan Xiong,\nPaul N. Bennett, Jianfeng Gao, and Zhiyuan Liu.\n2020. Few-shot generative conversational query\nrewriting. In Proceedings of the 43rd International\nACM SIGIR conference on research and development\nin Information Retrieval, SIGIR 2020, Virtual Event,\nChina, July 25-30, 2020, pages 1933\u20131936. ACM.\nWenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,\nMingxuan Ju, Soumya Sanyal, Chenguang Zhu,\nMichael Zeng, and Meng Jiang. 2023a. Generate\nrather than Retrieve: Large Language Models are\nStrong Context Generators. In International Conference on Learning Representations (ICLR).\nWenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu,\nQingyun Wang, Heng Ji, and Meng Jiang. 2022. A\nsurvey of knowledge-enhanced text generation. ACM\nComput. Surv., 54(11s):227:1\u2013227:38.\nZichun Yu, Chenyan Xiong, Shi Yu, and Zhiyuan Liu.\n2023b. Augmentation-Adapted Retriever Improves\nGeneralization of Language Models as Generic PlugIn. In Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 2421\u20132436. Association for\nComputational Linguistics.\nYi Yuan, Haohe Liu, Xubo Liu, Qiushi Huang, Mark D\nPlumbley, and Wenwu Wang. 2023. RetrievalAugmented Text-to-Audio Generation. arXiv,\nabs/2309.08051.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, and others.\n2022. Opt: Open pre-trained transformer language\nmodels. arXiv, abs/2205.01068.\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,\nHeng-Tze Cheng, E. Chi, Quoc V. Le, and Denny\nZhou. 2023. Take a Step Back: Evoking Reasoning\nvia Abstraction in Large Language Models. arXiv,\nabs/2310.06117.\nHonglei Zhuang, Zhen Qin, Rolf Jagerman, Kai Hui,\nJi Ma, Jing Lu, Jianmo Ni, Xuanhui Wang, and\nMichael Bendersky. 2023. Rankt5: Fine-Tuning T5\nfor Text Ranking with Ranking Losses. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information\nRetrieval. ACM.", "mimetype": "text/plain", "start_char_idx": 72802, "end_char_idx": 75993, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}