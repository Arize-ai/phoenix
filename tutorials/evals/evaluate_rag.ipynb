{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Evaluate RAG with LLM Evals</h1>\n",
    "\n",
    "In this tutorial we will look into building a RAG pipeline and evaluating it with Phoenix Evals.\n",
    "\n",
    "It has the the following sections:\n",
    "\n",
    "1. Understanding Retrieval Augmented Generation (RAG).\n",
    "2. Building RAG (with the help of a framework such as LlamaIndex).\n",
    "3. Evaluating RAG with Phoenix Evals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "LLMs are trained on vast datasets, but these will not include your specific data (things like company knowledge bases and documentation). Retrieval-Augmented Generation (RAG) addresses this by dynamically incorporating your data as context during the generation process. This is done not by altering the training data of the LLMs but by allowing the model to access and utilize your data in real-time to provide more tailored and contextually relevant responses.\n",
    "\n",
    "In RAG, your data is loaded and prepared for queries. This process is called indexing. User queries act on this index, which filters your data down to the most relevant context. This context and your query then are sent to the LLM along with a prompt, and the LLM provides a response.\n",
    "\n",
    "RAG is a critical component for building applications such a chatbots or agents and you will want to know RAG techniques on how to get data into your application.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/RAG_Pipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stages within RAG\n",
    "\n",
    "There are five key stages within RAG, which will in turn be a part of any larger RAG application.\n",
    "\n",
    "- **Loading**: This refers to getting your data from where it lives - whether it's text files, PDFs, another website, a database or an API - into your pipeline.\n",
    "- **Indexing**: This means creating a data structure that allows for querying the data. For LLMs this nearly always means creating vector embeddings, numerical representations of the meaning of your data, as well as numerous other metadata strategies to make it easy to accurately find contextually relevant data.\n",
    "- **Storing**: Once your data is indexed, you will want to store your index, along with any other metadata, to avoid the need to re-index it.\n",
    "\n",
    "- **Querying**: For any given indexing strategy there are many ways you can utilize LLMs and data structures to query, including sub-queries, multi-step queries, and hybrid strategies. \n",
    "- **Evaluation**: A critical step in any pipeline is checking how effective it is relative to other strategies, or when you make changes. Evaluation provides objective measures on how accurate, faithful, and fast your responses to queries are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a RAG system \n",
    "\n",
    "Now that we have understood the stages of RAG, let's build a pipeline. We will use [LlamaIndex](https://www.llamaindex.ai/) for RAG and [Phoenix Evals](https://docs.arize.com/phoenix/llm-evals/llm-evals) for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq \"arize-phoenix[experimental,llama-index]>=3.0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeldking/work/phoenix/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mikeldking/work/phoenix/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# The nest_asyncio module enables the nesting of asynchronous functions within an already running async loop.\n",
    "# This is necessary because Jupyter notebooks inherently operate in an asynchronous loop.\n",
    "# By applying nest_asyncio, we can run additional async functions within this existing loop without conflicts.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, set_global_handler\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this tutorial, we will capture all the data we need to evaluate our RAG pipeline using Phoenix Tracing. To enable this, simply start the phoenix application and instrument LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phoenix.session.session.ThreadSession at 0x1050fac10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we will be using OpenAI for creating synthetic data as well as for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Build an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use an [essay by Paul Graham](https://www.paulgraham.com/worked.html) to build our RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "with tempfile.NamedTemporaryFile() as tf:\n",
    "    urlretrieve(\n",
    "        \"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/main/data/paul_graham/paul_graham_essay.txt\",\n",
    "        tf.name,\n",
    "    )\n",
    "    documents = SimpleDirectoryReader(input_files=[tf.name]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an LLM\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Build index with a chunk_size of 512\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a QueryEngine and start querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_vector = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the response that you get from the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author mentioned that before college, they worked on writing and programming. They wrote short stories and also tried writing programs on the IBM 1401 computer. They used an early version of Fortran and had to type programs on punch cards. They also mentioned being puzzled by the 1401 and not being able to do much with it.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_vector.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default LlamaIndex retrieves two similar nodes/ chunks. You can modify that in `vector_index.as_query_engine(similarity_top_k=k)`.\n",
    "\n",
    "Let's check the text in each of these retrieved nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines ‚Äî CPU, disk drives, printer, card reader ‚Äî sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First retrieved node\n",
    "response_vector.source_nodes[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\\n\\nOne night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\\n\\nJessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders.\\n\\nWhen the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm. It took them weeks to make up their minds, and during this time I started telling her about all the things that needed to be fixed about venture capital. They should make a larger number of smaller investments instead of a handful of giant ones, they should be funding younger, more technical founders instead of MBAs, they should let the founders remain as CEO, and so on.\\n\\nOne of my tricks for writing essays had always been to give talks. The prospect of having to stand up in front of a group of people and tell them something that won't waste their time is a great spur to the imagination. When the Harvard Computer Society, the undergrad computer club, asked me to give a talk, I decided I would tell them how to start a startup. Maybe they'd be able to avoid the worst of the mistakes we'd made.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second retrieved node\n",
    "response_vector.source_nodes[1].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we are using Phoenix Tracing to capture all the data we need to evaluate our RAG pipeline. You can view the traces in the phoenix application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoenix URL http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "print(\"phoenix URL\", px.active_session().url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the traces by directly pulling the spans from the phoenix session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_df = px.Client().get_spans_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.retrieval.documents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c64442b0f8bdc07a</th>\n",
       "      <td>llm</td>\n",
       "      <td>LLM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5d0ee3b8a1a4e64a</th>\n",
       "      <td>chunking</td>\n",
       "      <td>CHAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b39c90e550fba8dd</th>\n",
       "      <td>chunking</td>\n",
       "      <td>CHAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7a9855d6b17432d2</th>\n",
       "      <td>synthesize</td>\n",
       "      <td>CHAIN</td>\n",
       "      <td>What did the author do growing up?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf4524a39c275275</th>\n",
       "      <td>embedding</td>\n",
       "      <td>EMBEDDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  span_kind              attributes.input.value  \\\n",
       "context.span_id                                                               \n",
       "c64442b0f8bdc07a         llm        LLM                                 NaN   \n",
       "5d0ee3b8a1a4e64a    chunking      CHAIN                                 NaN   \n",
       "b39c90e550fba8dd    chunking      CHAIN                                 NaN   \n",
       "7a9855d6b17432d2  synthesize      CHAIN  What did the author do growing up?   \n",
       "cf4524a39c275275   embedding  EMBEDDING                                 NaN   \n",
       "\n",
       "                 attributes.retrieval.documents  \n",
       "context.span_id                                  \n",
       "c64442b0f8bdc07a                            NaN  \n",
       "5d0ee3b8a1a4e64a                            NaN  \n",
       "b39c90e550fba8dd                            NaN  \n",
       "7a9855d6b17432d2                            NaN  \n",
       "cf4524a39c275275                            NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_df[[\"name\", \"span_kind\", \"attributes.input.value\", \"attributes.retrieval.documents\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the traces have captured the documents that were retrieved by the query engine. This is nice because it means we can introspect the documents without having to keep track of them ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_with_docs_df = spans_df[spans_df[\"attributes.retrieval.documents\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.retrieval.documents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e6fca54f6224426a</th>\n",
       "      <td>What did the author do growing up?</td>\n",
       "      <td>[{'document.id': '1e37c08f-aa74-4517-8e06-0e7b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              attributes.input.value  \\\n",
       "context.span_id                                        \n",
       "e6fca54f6224426a  What did the author do growing up?   \n",
       "\n",
       "                                     attributes.retrieval.documents  \n",
       "context.span_id                                                      \n",
       "e6fca54f6224426a  [{'document.id': '1e37c08f-aa74-4517-8e06-0e7b...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_with_docs_df[[\"attributes.input.value\", \"attributes.retrieval.documents\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a RAG pipeline and also have instrumented it using Phoenix Tracing. We now need to evaluate it's performance. We can assess our RAG system/query engine using Phoenix's LLM Evals. Let's examine how to leverage these tools to quantify the quality of our retrieval-augmented generation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation should serve as the primary metric for assessing your RAG application. It determines whether the pipeline will produce accurate responses based on the data sources and range of queries.\n",
    "\n",
    "While it's beneficial to examine individual queries and responses, this approach is impractical as the volume of edge-cases and failures increases. Instead, it's more effective to establish a suite of metrics and automated evaluations. These tools can provide insights into overall system performance and can identify specific areas that may require scrutiny.\n",
    "\n",
    "In a RAG system, evaluation focuses on two critical aspects:\n",
    "\n",
    "- **Retrieval Evaluation**: To assess the accuracy and relevance of the documents that were retrieved\n",
    "- **Response Evaluation**: Measure the appropriateness of the response generated by the system when the context was provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Question Context Pairs\n",
    "\n",
    "For the evaluation of a RAG system, it's essential to have queries that can fetch the correct context and subsequently generate an appropriate response.\n",
    "\n",
    "For this tutorial, let's use Phoenix's `llm_generate` to help us create the question-context pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a dataframe of all the document chunks that we have indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was puzzled by the 1401. I couldn't figure o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I remember vividly how impressed and envious I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I couldn't have put this into words when I was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The default language at Cornell was a Pascal-l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...\n",
       "1  I was puzzled by the 1401. I couldn't figure o...\n",
       "2  I remember vividly how impressed and envious I...\n",
       "3  I couldn't have put this into words when I was...\n",
       "4  The default language at Cornell was a Pascal-l..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's construct a dataframe of just the documents that are in our index\n",
    "document_chunks_df = pd.DataFrame({\"text\": [node.get_text() for node in nodes]})\n",
    "document_chunks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the document chunks, let's prompt an LLM to generate us 3 questions per chunk. Note that you could manually solicit questions from your team or customers, but this is a quick and easy way to generate a large number of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_questions_template = \"\"\"\\\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{text}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "\n",
    "You are a Teacher/ Professor. Your task is to setup \\\n",
    "3 questions for an upcoming \\\n",
    "quiz/examination. The questions should be diverse in nature \\\n",
    "across the document. Restrict the questions to the \\\n",
    "context information provided.\"\n",
    "\n",
    "Output the questions in JSON format with the keys question_1, question_2, question_3.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_generate |          | 0/61 (0.0%) | ‚è≥ 00:00<? | ?it/s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_generate |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61/61 (100.0%) | ‚è≥ 00:16<00:00 |  3.78it/s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from phoenix.experimental.evals import OpenAIModel, llm_generate\n",
    "\n",
    "\n",
    "def output_parser(response: str, index: int):\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"__error__\": str(e)}\n",
    "\n",
    "\n",
    "questions_df = llm_generate(\n",
    "    dataframe=document_chunks_df,\n",
    "    template=generate_questions_template,\n",
    "    model=OpenAIModel(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "    ),\n",
    "    output_parser=output_parser,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>question_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>What was the language used for programming on ...</td>\n",
       "      <td>What was the author's clearest memory regardin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>How did microcomputers change the author's exp...</td>\n",
       "      <td>Why did the author's father buy a TRS-80 compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the author's first experience with co...</td>\n",
       "      <td>Why did the author decide to switch from study...</td>\n",
       "      <td>What were the two things that influenced the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What were the two things that inspired the aut...</td>\n",
       "      <td>What programming language did the author learn...</td>\n",
       "      <td>What was the author's undergraduate thesis about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the default language at Cornell and o...</td>\n",
       "      <td>What did the author reverse-engineer for their...</td>\n",
       "      <td>What realization did the author have during th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question_1  \\\n",
       "0  What were the two main things the author worke...   \n",
       "1  What were the limitations of the 1401 computer...   \n",
       "2  What was the author's first experience with co...   \n",
       "3  What were the two things that inspired the aut...   \n",
       "4  What was the default language at Cornell and o...   \n",
       "\n",
       "                                          question_2  \\\n",
       "0  What was the language used for programming on ...   \n",
       "1  How did microcomputers change the author's exp...   \n",
       "2  Why did the author decide to switch from study...   \n",
       "3  What programming language did the author learn...   \n",
       "4  What did the author reverse-engineer for their...   \n",
       "\n",
       "                                          question_3  \n",
       "0  What was the author's clearest memory regardin...  \n",
       "1  Why did the author's father buy a TRS-80 compu...  \n",
       "2  What were the two things that influenced the a...  \n",
       "3  What was the author's undergraduate thesis about?  \n",
       "4  What realization did the author have during th...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dataframe of the questions and the document chunks\n",
    "questions_with_document_chunk_df = pd.concat([questions_df, document_chunks_df], axis=1)\n",
    "questions_with_document_chunk_df = questions_with_document_chunk_df.melt(\n",
    "    id_vars=[\"text\"], value_name=\"question\"\n",
    ").drop(\"variable\", axis=1)\n",
    "# If the above step was interrupted, there might be questions missing. Let's run this to clean up the dataframe.\n",
    "questions_with_document_chunk_df = questions_with_document_chunk_df[\n",
    "    questions_with_document_chunk_df[\"question\"].notnull()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM has generated three questions per chunk. Let's take a quick look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was puzzled by the 1401. I couldn't figure o...</td>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I remember vividly how impressed and envious I...</td>\n",
       "      <td>What was the author's first experience with co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I couldn't have put this into words when I was...</td>\n",
       "      <td>What were the two things that inspired the aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The default language at Cornell was a Pascal-l...</td>\n",
       "      <td>What was the default language at Cornell and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I applied to 3 grad schools: MIT and Yale, whi...</td>\n",
       "      <td>What were the three grad schools that the auth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So I looked around to see what I could salvage...</td>\n",
       "      <td>What was the main reason people cared about Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>And indeed, it would seem very feeble work. On...</td>\n",
       "      <td>What realization did the author have while loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>And as an artist you could be truly independen...</td>\n",
       "      <td>What was the author's initial perception of ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I remember when my friend Robert Morris got ki...</td>\n",
       "      <td>What was the reason for Robert Morris getting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "1  I was puzzled by the 1401. I couldn't figure o...   \n",
       "2  I remember vividly how impressed and envious I...   \n",
       "3  I couldn't have put this into words when I was...   \n",
       "4  The default language at Cornell was a Pascal-l...   \n",
       "5  I applied to 3 grad schools: MIT and Yale, whi...   \n",
       "6  So I looked around to see what I could salvage...   \n",
       "7  And indeed, it would seem very feeble work. On...   \n",
       "8  And as an artist you could be truly independen...   \n",
       "9  I remember when my friend Robert Morris got ki...   \n",
       "\n",
       "                                            question  \n",
       "0  What were the two main things the author worke...  \n",
       "1  What were the limitations of the 1401 computer...  \n",
       "2  What was the author's first experience with co...  \n",
       "3  What were the two things that inspired the aut...  \n",
       "4  What was the default language at Cornell and o...  \n",
       "5  What were the three grad schools that the auth...  \n",
       "6  What was the main reason people cared about Li...  \n",
       "7  What realization did the author have while loo...  \n",
       "8  What was the author's initial perception of ar...  \n",
       "9  What was the reason for Robert Morris getting ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_document_chunk_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Evaluation\n",
    "\n",
    "We are now prepared to perform our retrieval evaluations. We will execute the queries we generated in the previous step and verify whether or not that the correct context is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phoenix.session.session.ThreadSession at 0x29e03ebb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |‚ñà‚ñè        | 26/220 (11.8%) | ‚è≥ 00:21<02:38 |  1.23it/s\n",
      "run_evals |‚ñà‚ñà‚ñà       | 67/220 (30.5%) | ‚è≥ 00:43<01:39 |  1.54it/s\n"
     ]
    }
   ],
   "source": [
    "# First things first, let's reset phoenix\n",
    "px.close_app()\n",
    "px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What were the two main things the author worked on before college?\n",
      "Answer: Before college, the author worked on writing and programming.\n",
      "\n",
      "Question: What were the limitations of the 1401 computer and why couldn't the author do much with it?\n",
      "Answer: The 1401 computer had limitations in terms of input. The only form of input to programs was data stored on punched cards, and the author didn't have any data stored on punched cards. Additionally, the author didn't know enough math to do anything interesting that didn't rely on any input, like calculating approximations of pi. Therefore, the author couldn't do much with the 1401 computer.\n",
      "\n",
      "Question: What was the author's first experience with computers and programming?\n",
      "Answer: The author's first experience with computers and programming was in 9th grade when they had access to an IBM 1401 computer in the basement of their junior high school. They used an early version of Fortran and had to type programs on punch cards. However, they were puzzled by the 1401 and didn't know what to do with it, as they didn't have any data stored on punched cards. They couldn't remember any programs they wrote on the 1401, but they do remember the moment they learned that programs could fail to terminate.\n",
      "\n",
      "Question: What were the two things that inspired the author to work on AI?\n",
      "Answer: The two things that inspired the author to work on AI were a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU.\n",
      "\n",
      "Question: What was the default language at Cornell and other universities during the author's time?\n",
      "Answer: The default language at Cornell and other universities during the author's time was a Pascal-like language called PL/I.\n",
      "\n",
      "Question: What were the three grad schools that the author applied to?\n",
      "Answer: The author applied to MIT, Yale, and Harvard for grad school.\n",
      "\n",
      "Question: What was the main reason people cared about Lisp at the time?\n",
      "Answer: The main reason people cared about Lisp at the time was its association with AI.\n",
      "\n",
      "Question: What realization did the author have while looking at a painting at the Carnegie Institute?\n",
      "Answer: The author realized that paintings could be made to last and that making art could be a viable career option.\n",
      "\n",
      "Question: What was the author's initial perception of artists and art-making?\n",
      "Answer: The author initially perceived artists and art-making as something almost miraculous and beyond their own capabilities. They viewed the people who made art as either belonging to a different species or being mysterious geniuses. The idea of actually being able to make art seemed surprising and almost impossible to the author.\n",
      "\n",
      "Question: What was the reason for Robert Morris getting kicked out of Cornell?\n",
      "Answer: Robert Morris got kicked out of Cornell for writing the internet worm of 1988.\n",
      "\n",
      "Question: What was the purpose of the foundation classes at RISD?\n",
      "Answer: The purpose of the foundation classes at RISD was to provide fundamental instruction in subjects like drawing, color, and design to all students, regardless of their previous experience or background.\n",
      "\n",
      "Question: What was the author's strategy for answering the essay question in the written exam?\n",
      "Answer: The context information does not provide any information about the author's strategy for answering the essay question in a written exam.\n",
      "\n",
      "Question: What was the model's source of income?\n",
      "Answer: The context does not provide any information about the model's source of income.\n",
      "\n",
      "Question: What is the advantage of emphasizing visual cues in paintings?\n",
      "Answer: Emphasizing visual cues in paintings allows for a more realistic representation of the subject matter. By highlighting details such as the edges of objects or sudden changes in color, the paintings can convey a sense of depth and dimension that surpasses the accuracy of photographs. This emphasis on visual cues enhances the overall realism of the artwork in an information-theoretic sense.\n",
      "\n",
      "Question: What was the reason for the author's decision to leave the Accademia and return to the US?\n",
      "Answer: The reason for the author's decision to leave the Accademia and return to the US was because the students and faculty in the painting department at the Accademia had an arrangement where the faculty didn't teach anything and the students didn't have to learn anything.\n",
      "\n",
      "Question: What did the author learn about technology companies from their experience at Interleaf?\n",
      "Answer: The author learned that low-end software tends to overshadow high-end software, and that Interleaf, the company they worked for, had added a scripting language inspired by Emacs and made it a dialect of Lisp. The author also mentions that Interleaf's software was primarily written in C, which they did not know and did not want to learn. Additionally, the author mentions that they were a bad employee and spent much of their time working on their own project instead of focusing on their job at Interleaf.\n",
      "\n",
      "Question: According to the author, why is it advantageous to be the 'entry level' option?\n",
      "Answer: Being the 'entry level' option is advantageous because if you're not, someone else will be, and they will squash you against the ceiling. This means that being the 'entry level' option allows you to avoid being overshadowed by competitors and maintain a strong position in the market.\n",
      "\n",
      "Question: What is the purpose of a signature style in painting?\n",
      "Answer: The purpose of a signature style in painting is to create a visual identity that distinguishes the work of an artist from others. It serves as a unique and recognizable characteristic that immediately identifies the artwork as belonging to a specific artist. This can be beneficial for both the artist and potential buyers, as a signature style can increase the value and marketability of the artwork.\n",
      "\n",
      "Question: What was the author's experience with drawing in high school?\n",
      "Answer: The author was not one of the kids who could draw in high school.\n",
      "\n",
      "Question: Why was the author nervous about money?\n",
      "Answer: The author was nervous about money because they could sense that Interleaf, the company they were working for, was on the way down. They were concerned about the lack of freelance Lisp hacking work and did not want to have to program in another language, such as C++.\n",
      "\n",
      "Question: What was the author's initial motivation for wanting to become rich?\n",
      "Answer: The author's initial motivation for wanting to become rich was to have the financial freedom to work on whatever they wanted, specifically to spend more time painting.\n",
      "\n",
      "Question: What was the initial difficulty faced by the author in selling their software?\n",
      "Answer: The initial difficulty faced by the author in selling their software was that they were unable to find any galleries willing to pay for the sites they had created.\n",
      "\n",
      "Question: What is a web app and why was it not clear that it was possible at the time?\n",
      "Answer: A web app is an application that runs on a web browser instead of being installed on a local device. It allows users to access and use software or services through the internet. At the time mentioned in the context, it was not clear that building a web app for making web apps was possible because the concept of web apps was still relatively new and not widely understood. The idea of editing code on a server through a browser and hosting resulting applications was not a common practice, and the potential of web apps as the future of software development was not widely recognized.\n",
      "\n",
      "Question: What was the arrangement made with the person who provided legal work and business advice for the company?\n",
      "Answer: The person who provided legal work and business advice for the company was given 10% of the company in return for their services.\n",
      "\n",
      "Question: Who recommended Trevor Blackwell as a programmer to the author?\n",
      "Answer: Robert recommended Trevor Blackwell as a programmer to the author.\n",
      "\n",
      "Question: What were the three main parts of the software developed by the author and his team?\n",
      "Answer: The three main parts of the software developed by the author and his team were the editor, the shopping cart, and the manager.\n",
      "\n",
      "Question: What was the pricing strategy for Viaweb's software?\n",
      "Answer: Viaweb's pricing strategy for their software was to make it easy to use and inexpensive. They charged $100 a month for a small store and $300 a month for a big one. This low price was a big attraction and a constant challenge for their competitors. However, the decision to set the price low was not based on any clever insight, but rather because they had no idea what businesses paid for similar software and $300 a month seemed like a lot of money to them.\n",
      "\n",
      "Question: What did the author initially think about 'business' and why?\n",
      "Answer: The author initially had reservations about getting involved in angel investing and had been procrastinating about it. They were concerned about the prospect of having their inbox flooded with business plans.\n",
      "\n",
      "Question: What was the growth rate of the startup mentioned in the context?\n",
      "Answer: The growth rate of the startup mentioned in the context was 7x a year.\n",
      "\n",
      "Question: What was the author's initial reaction when Yahoo bought their company?\n",
      "Answer: The author's initial reaction when Yahoo bought their company was that it felt like going from rags to riches.\n",
      "\n",
      "Question: Why did the author quit their job at Yahoo?\n",
      "Answer: The author quit their job at Yahoo because they wanted to pursue their passion for painting. They had become rich after Yahoo bought their company, and they felt that it was the right time to focus on their artistic endeavors.\n",
      "\n",
      "Question: Why did the author go back to New York?\n",
      "Answer: The author went back to New York because they didn't know many people in California and felt isolated. Additionally, they still had their apartment in New York and there were other people trying to paint there, even though the author didn't know any of them.\n",
      "\n",
      "Question: What new approach did the author experiment with in their paintings?\n",
      "Answer: The author experimented with painting still lives in their bedroom at night.\n",
      "\n",
      "Question: Why did the author decide to start another company in Cambridge?\n",
      "Answer: The author decided to start another company in Cambridge because they got excited about the idea of building a web app for making web apps. They believed that web apps were the future and saw the potential in allowing people to edit code on their server through the browser and host resulting applications for them. Despite not particularly wanting to start another company, the author recognized that this idea would have to be embodied as one.\n",
      "\n",
      "Question: What was the original name of the company that the author started?\n",
      "Answer: The original name of the company that the author started was Aspra.\n",
      "\n",
      "Question: What was the new dialect of Lisp that the author and Dan worked on?\n",
      "Answer: The new dialect of Lisp that the author and Dan worked on was called Arc.\n",
      "\n",
      "Question: What was the channel for publishing essays like in the print era?\n",
      "Answer: In the print era, the channel for publishing essays was vanishingly small. Only a few officially anointed thinkers who went to the right parties in New York and specialists writing about their specialties were allowed to publish essays. This meant that many essays that could have been written were never published due to the lack of a means to do so.\n",
      "\n",
      "Question: What is the author's observation about working on things that aren't prestigious?\n",
      "Answer: Working on things that aren't prestigious can be beneficial because it indicates that there may be something valuable to discover in that area and suggests that the person has the right motives. The author believes that being drawn to unprestigious work is a sign of potential success and a way to avoid being led astray by the desire to impress others.\n",
      "\n",
      "Question: What was the purpose of the big party at the author's house in October 2003?\n",
      "Answer: The purpose of the big party at the author's house in October 2003 was for three separate hosts to invite their friends to one party, with the intention of introducing guests to people they didn't know but would probably like.\n",
      "\n",
      "Question: What were some of the changes the author suggested for venture capital?\n",
      "Answer: The author suggested several changes for venture capital. Some of these changes included making a larger number of smaller investments instead of a handful of giant ones, funding younger and more technical founders instead of MBAs, and allowing the founders to remain as CEO.\n",
      "\n",
      "Question: What was the author's realization after a conversation about angel investing?\n",
      "Answer: The author's realization after a conversation about angel investing was that they should stop procrastinating and actually start making angel investments. They had been meaning to do so since Yahoo bought them, but it had been 7 years and they still hadn't made any angel investments.\n",
      "\n",
      "Question: What were the two types of investment firms that existed before YC?\n",
      "Answer: Before YC, there were VC firms and angel investors. VC firms were organized companies that made big, million-dollar investments, while angel investors were individuals who made smaller investments on the side. However, neither of these types of firms provided enough help to founders in the beginning stages of their startups.\n",
      "\n",
      "Question: What is the batch model that sets YC apart from other VC firms?\n",
      "Answer: The batch model that sets YC apart from other VC firms is to fund a bunch of startups all at once, twice a year, and then spend three months focusing intensively on trying to help them.\n",
      "\n",
      "Question: How did the Summer Founders Program attract applicants?\n",
      "Answer: The Summer Founders Program attracted applicants by posting an announcement on the founder's website and inviting undergrads to apply. The program received 225 applications, and it was surprising to find that many of them were from people who had already graduated or were about to graduate that spring.\n",
      "\n",
      "Question: What was the deal offered to startups based on?\n",
      "Answer: The deal offered to startups was based on a combination of the deal made with Julian ($10k for 10%) and what Robert mentioned MIT grad students received for the summer ($6k). The investment per founder was $6k, which amounted to $12k in the case of a typical two-founder startup, in exchange for 6% equity.\n",
      "\n",
      "Question: What were the three things the author originally intended to do with YC?\n",
      "Answer: The author originally intended to do three things with YC: hack, write essays, and work on YC.\n",
      "\n",
      "Question: What was the biggest source of stress for the author in their work?\n",
      "Answer: The biggest source of stress for the author in their work was Hacker News (HN).\n",
      "\n",
      "Question: What were some of the challenges the author faced while working at Y Combinator?\n",
      "Answer: The author faced several challenges while working at Y Combinator. These challenges included disputes between cofounders, figuring out when people were lying to them, and fighting with people who maltreated the startups. Additionally, the author mentioned that dealing with urgent problems during YC often had a 60% chance of being related to Hacker News (HN), which was a significant source of stress. Despite these challenges, the author worked hard even at the parts they didn't like, driven by their desire for YC to be successful.\n",
      "\n",
      "Question: What did the person mean when they said 'you should make sure Y Combinator isn't the last cool thing you do'?\n",
      "Answer: The person meant that the individual should not let Y Combinator be the final significant achievement or project in their life. They were suggesting that the individual should not become too focused on Y Combinator and should consider exploring other opportunities or ventures beyond it.\n",
      "\n",
      "Question: Why did the founders of YC decide to recruit Sam Altman?\n",
      "Answer: The founders of YC decided to recruit Sam Altman because they wanted YC to last for a long time and believed that it couldn't be controlled by the founders. They wanted to make a complete changing of the guard and let Sam Altman reorganize YC. Additionally, Jessica, one of the founders, did not want to be the president, so they looked for someone else to take over the role.\n",
      "\n",
      "Question: What did the author decide to do after stopping work on YC?\n",
      "Answer: The author decided to hand YC over to someone else and recruit Sam Altman as the new president of YC.\n",
      "\n",
      "Question: What is the distinctive feature of Lisp that sets it apart from other programming languages?\n",
      "Answer: The distinctive feature of Lisp that sets it apart from other programming languages is that its core is a language defined by writing an interpreter in itself. This means that Lisp was originally intended as a formal model of computation, rather than a traditional programming language.\n",
      "\n",
      "Question: What were some of the things missing in the programming language that had to be added?\n",
      "Answer: The context information does not provide any specific details about missing features in a programming language that had to be added.\n",
      "\n",
      "Question: What challenges did the author face while developing Bel, the new Lisp language?\n",
      "Answer: The author faced several challenges while developing Bel, the new Lisp language. One challenge was the complexity of the problem itself. Working on an interpreter written in itself made it difficult to keep track of what was happening at different levels, and errors could be hard to identify. Additionally, the author had to ban themselves from writing essays during most of the development process to stay focused on Bel. This was because after spending three months writing essays, the author found it difficult to understand the code when they returned to working on Bel. Despite these challenges, the author worked intensively on Bel and had moments of satisfaction and clarity while developing the language.\n",
      "\n",
      "Question: What was the author's experience like working on Bel?\n",
      "Answer: The author's experience working on Bel was hard but satisfying. They worked on it intensively and had a decent chunk of the code in their head at any given time. They had moments where they felt like they were doing life right while working on Bel, such as figuring out how to deal with a problem involving continuations while watching their children play in the tide pools.\n",
      "\n",
      "Question: What was the author's motivation for writing a detailed version of their essay?\n",
      "Answer: The author's motivation for writing a detailed version of their essay was likely driven by the realization that with the advent of the internet and the ability to publish essays online, there was now a platform to reach a wider audience. They recognized that the traditional print era had limited the channel for publishing essays, and many essays had never been written due to the lack of a means to publish them. By publishing their essays online, the author saw an opportunity to share their ideas and insights with a broader audience.\n",
      "\n",
      "Question: What is the difference between rent-controlled and rent-stabilized apartments? Why is this difference significant?\n",
      "Answer: The difference between rent-controlled and rent-stabilized apartments is significant because it affects the amount of rent that can be charged to tenants. Rent-controlled apartments have strict regulations on rent increases and are typically occupied by long-term tenants. On the other hand, rent-stabilized apartments have more flexible rent increases and are subject to certain guidelines set by the government. This difference is significant because it determines the level of affordability and stability for tenants in terms of their housing costs.\n",
      "\n",
      "Question: What was the purpose of launching privately before launching publicly for the online store builder?\n",
      "Answer: To recruit an initial set of users and ensure that they had decent-looking stores.\n",
      "\n",
      "Question: What is the lesson that the experience with Y Combinator teaches about customs?\n",
      "Answer: The lesson that the experience with Y Combinator teaches about customs is that customs continue to constrain individuals even after the restrictions that caused them have disappeared. Customary practices in the venture capital industry, for example, were once based on real constraints that no longer exist. However, these customs still persist and reflect the old world, hindering progress and innovation. This implies that individuals who are independent-minded and less influenced by custom have an advantage in fields affected by rapid change, where customs are more likely to be obsolete.\n",
      "\n",
      "Question: Why did the author choose orange as the color for their company?\n",
      "Answer: The author chose orange as the color for their company partly because it is the warmest color and partly because no venture capitalist (VC) used it. In 2005, most VCs used more traditional colors like maroon, navy blue, and forest green to appeal to limited partners (LPs) rather than founders. The author also mentions that the YC logo, which is a white Y on an orange square, is an inside joke referencing the previous logo of Viaweb, which had a white V on a red circle.\n",
      "\n",
      "Question: What is the problem that occurs when you both write essays and run a forum?\n",
      "Answer: The combination of writing essays and running a forum can lead to a problem where highly imaginative misinterpretations of the essays are posted on the forum. This becomes problematic because if the person running the forum does not respond to these misinterpretations, it can be seen as a tacit admission that they are correct. This encourages more misinterpretations and can lead to conflicts and arguments.\n",
      "\n",
      "Question: What was the language used for programming on the IBM 1401?\n",
      "Answer: The language used for programming on the IBM 1401 was an early version of Fortran.\n",
      "\n",
      "Question: How did microcomputers change the author's experience with programming? Provide specific examples.\n",
      "Answer: Microcomputers changed the author's experience with programming by allowing them to have a computer right in front of them, on a desk, that could respond to their keystrokes as it was running. This was a significant departure from the previous method of programming, which involved using punched cards as input. With microcomputers, the author was able to directly type programs into the computer, which made the programming process more interactive and immediate. The author vividly remembers feeling impressed and envious while watching a friend type programs right into their microcomputer. Additionally, the author mentions writing simple games, a program to predict the height of model rockets, and a word processor for their father using the microcomputer. These examples highlight how microcomputers provided the author with the opportunity to engage in more hands-on and practical programming activities.\n",
      "\n",
      "Question: Why did the author decide to switch from studying philosophy to AI in college?\n",
      "Answer: The author decided to switch from studying philosophy to AI in college because they found philosophy courses to be boring.\n",
      "\n",
      "Question: What programming language did the author learn in order to teach themselves AI?\n",
      "Answer: The author learned Lisp in order to teach themselves AI.\n",
      "\n",
      "Question: What did the author reverse-engineer for their undergraduate thesis?\n",
      "Answer: The author did not reverse-engineer anything for their undergraduate thesis.\n",
      "\n",
      "Question: Why did the author decide to focus on Lisp?\n",
      "Answer: The author decided to focus on Lisp because they found it interesting for its own sake, not just for its association with AI. They also wanted to write a book about Lisp hacking and believed that writing a book about something would help them learn it.\n",
      "\n",
      "Question: What did the author decide to focus on and write a book about?\n",
      "Answer: The author decided to focus on and write a book about interviews with startup founders.\n",
      "\n",
      "Question: Why did the author consider making paintings instead of writing software?\n",
      "Answer: The author considered making paintings instead of writing software because they realized that paintings could last for hundreds of years and that being an artist offered independence without the need for a boss or research funding. Additionally, the author had always liked looking at paintings and was intrigued by the idea of being able to create art themselves.\n",
      "\n",
      "Question: Why did the author feel envious of their friend Robert Morris?\n",
      "Answer: The author felt envious of their friend Robert Morris because he was super rich, which made the author think about becoming rich themselves.\n",
      "\n",
      "Question: Why did the author decide to write their dissertation on applications of continuations?\n",
      "Answer: The author decided to write their dissertation on applications of continuations because they wanted to graduate from grad school and saw it as a way to quickly complete their dissertation within the remaining time before the deadline.\n",
      "\n",
      "Question: Why did the Accademia invite the author to take the entrance exam?\n",
      "Answer: The Accademia invited the author to take the entrance exam because they had initially sent the invitation to the wrong location, Cambridge England instead of Cambridge Massachusetts.\n",
      "\n",
      "Question: Describe the arrangement between the students and faculty in the painting department at the Accademia.\n",
      "Answer: The arrangement between the students and faculty in the painting department at the Accademia is such that the students do not require the faculty to teach anything, and in return, the faculty does not require the students to learn anything. This arrangement is maintained while adhering outwardly to the conventions of a 19th-century atelier. Additionally, the students spend their time chatting or occasionally trying to imitate things they have seen in American art magazines.\n",
      "\n",
      "Question: What is the difference between painting still lives and painting people?\n",
      "Answer: Painting still lives and painting people differ in terms of the subject and the process involved. While painting still lives, the subject is inanimate objects that do not move, hence the name \"still life.\" On the other hand, painting people involves capturing the likeness and characteristics of a living subject. Additionally, people cannot sit still for long periods of time, making it challenging to paint them accurately. In contrast, still life subjects can be observed and copied pixel by pixel for a more realistic representation.\n",
      "\n",
      "Question: Why did the author enjoy painting still lives?\n",
      "Answer: The author enjoyed painting still lives because it allowed them to closely observe and capture the details of what they were seeing. They found it interesting to emphasize visual cues and create paintings that were more realistic than photographs.\n",
      "\n",
      "Question: How did the author describe their experience working at Interleaf?\n",
      "Answer: The author described their experience working at Interleaf as a mixed one. They mentioned that they were a bad employee and didn't fully understand most of the software because they didn't know C and didn't want to learn it. They also mentioned that they found the concept of showing up every day during certain working hours unnatural and caused friction. However, they acknowledged that they got paid a lot of money, especially compared to their budget in Florence, and managed to save enough to go back to RISD and pay off their college loans. They also learned some useful things at Interleaf, although most of them were about what not to do in technology companies.\n",
      "\n",
      "Question: Why did the author believe it was better for technology companies to be run by product people rather than sales people?\n",
      "Answer: The author believed it was better for technology companies to be run by product people rather than sales people because they thought that product people would have a better understanding of the technical aspects of the business and would be more focused on creating a quality product. They believed that sales people, on the other hand, might prioritize making sales and generating revenue over the actual product itself.\n",
      "\n",
      "Question: What did the author learn about HTML and how did it impact their life?\n",
      "Answer: The author learned that HTML was a powerful tool for building websites and online stores. This realization had a significant impact on their life as it opened up new possibilities for publishing and reaching an audience. They discovered that by putting their writing on the web, anyone could read it, which was a surprising revelation at the time. This led to the author's decision to start publishing essays online and explore the potential of this new medium.\n",
      "\n",
      "Question: Why do buyers often pay a lot for artwork with a signature style?\n",
      "Answer: Buyers often pay a lot for artwork with a signature style because it immediately identifies the work as belonging to a specific artist and distinguishes it from the work of others. This uniqueness and recognition associated with a signature style can increase the value and desirability of the artwork, leading to higher prices in the market.\n",
      "\n",
      "Question: Why did the author decide to drop out of RISD in 1993?\n",
      "Answer: The context information does not provide any information about the author dropping out of RISD in 1993.\n",
      "\n",
      "Question: What motivated the author to write another book on Lisp?\n",
      "Answer: The author was motivated to write another book on Lisp because they were nervous about money and sensed that their current job was on the decline. They wanted to continue working with Lisp and avoid having to program in another language. They believed that writing a popular book on Lisp that could be used as a textbook would provide them with royalties to support themselves financially.\n",
      "\n",
      "Question: Why did the author believe that the World Wide Web would be a big deal?\n",
      "Answer: The author believed that the World Wide Web would be a big deal because they had seen how graphical user interfaces had increased the popularity of microcomputers. They believed that the web would have a similar effect on the internet.\n",
      "\n",
      "Question: Why did the author decide to write software for building online stores?\n",
      "Answer: The author decided to write software for building online stores because they realized that online stores were similar to the websites they were already generating for art galleries. They saw an opportunity to leverage their existing knowledge and skills to create a product that could be used by online stores.\n",
      "\n",
      "Question: Why did the author start a new company called Viaweb?\n",
      "Answer: The author started a new company called Viaweb because they needed the money.\n",
      "\n",
      "Question: Why did the author need seed funding to live on?\n",
      "Answer: The author needed seed funding to live on because they wanted to start their own investment firm and implement the ideas they had been discussing. They planned to fund the firm themselves and have their partner quit their job to work for it.\n",
      "\n",
      "Question: What were the three main parts of the software developed by the author, Robert, and Trevor?\n",
      "Answer: The three main parts of the software developed by the author, Robert, and Trevor were the editor, the shopping cart, and the manager.\n",
      "\n",
      "Question: Why did the author describe the next 3 years as the most stressful?\n",
      "Answer: The author described the next three years as the most stressful because they were dealing with urgent problems during YC, which had a 60% chance of being related to HN (presumably Hacker News) and a 40% chance of being related to everything else combined. Additionally, the author mentioned disputes between cofounders, figuring out when people were lying to them, and fighting with people who maltreated the startups as parts of the job they didn't like.\n",
      "\n",
      "Question: Why did Viaweb build stores for their users, despite the purpose of their software?\n",
      "Answer: Viaweb built stores for their users despite the purpose of their software because it allowed them to learn more about retail and understand how it felt to use their software. This hands-on approach helped them gain insights and improve their product based on user feedback and needs. Additionally, building stores for users was a desperate measure to attract more users and drive adoption of their software.\n",
      "\n",
      "Question: Why did the author hire more people for the company?\n",
      "Answer: The author hired more people for the company partly because the investors wanted them to and partly because it was a common practice during the Internet Bubble for startups to hire more employees. Additionally, having just a handful of employees would have seemed amateurish for a company during that time.\n",
      "\n",
      "Question: Why did the company hire more people despite the advice given?\n",
      "Answer: The company hired more people despite the advice given because their investors wanted them to and because it was a common practice during the Internet Bubble for startups to hire more employees. Additionally, having just a handful of employees would have seemed amateurish for a company during that time.\n",
      "\n",
      "Question: Why did the author feel worn out during the year after Yahoo bought their company?\n",
      "Answer: The author felt worn out during the year after Yahoo bought their company because of the effort and stress of running Viaweb. Additionally, the author mentioned that fatigue combined with Yahoo's culture and work environment gradually dragged them down.\n",
      "\n",
      "Question: What was the author's initial plan after becoming rich?\n",
      "Answer: The author's initial plan after becoming rich was to quit their job and start painting.\n",
      "\n",
      "Question: What did the author experiment with in their painting?\n",
      "Answer: The author experimented with painting still lives in their bedroom at night.\n",
      "\n",
      "Question: What idea did the author have in the spring of 2000?\n",
      "Answer: The author had the idea of building a web app for making web apps in the spring of 2000.\n",
      "\n",
      "Question: What was the name given to the kind of company Viaweb was?\n",
      "Answer: The name given to the kind of company Viaweb was is \"application service provider\" or ASP.\n",
      "\n",
      "Question: Why did the author decide to build a subset of the company's vision as an open source project?\n",
      "Answer: The author decided to build a subset of the company's vision as an open source project because they realized that they didn't want to run a company, especially a big one. They had initially started the company because they needed money, but now that they didn't need money anymore, they questioned why they were pursuing this vision. Therefore, they decided to build a subset of the vision that could be done as an open source project instead.\n",
      "\n",
      "Question: What was the author's initial reaction when he realized that anyone could publish anything on the web?\n",
      "Answer: The author's initial reaction when he realized that anyone could publish anything on the web was surprise.\n",
      "\n",
      "Question: Why did the author find it encouraging that online essays would initially seem like rants posted by nutjobs?\n",
      "Answer: The author found it encouraging that online essays would initially seem like rants posted by nutjobs because it meant that online essays were not constrained by the traditional standards and gatekeepers of the print era. The author saw this as an opportunity for a new generation of essays to be written and published, free from the limitations imposed by the narrow channel of publishing in the print era. The lack of prestige associated with online essays allowed for more diverse and unconventional voices to be heard, which the author found encouraging.\n",
      "\n",
      "Question: What are the potential dangers of having impure motives for the ambitious?\n",
      "Answer: Having impure motives can be a big danger for the ambitious. It can lead them astray and potentially hinder their progress. Impure motives, such as the desire to impress others, can distract individuals from pursuing meaningful work and instead focus on superficial achievements. This can prevent them from discovering something real and valuable in their chosen field. It is important for ambitious individuals to have the right kind of motives, driven by a genuine passion and curiosity, in order to stay on the right track and make meaningful contributions.\n",
      "\n",
      "Question: Why did Jessica Livingston decide to compile a book of interviews with startup founders?\n",
      "Answer: Jessica Livingston decided to compile a book of interviews with startup founders because she realized that the reality of startups was different from what her Boston investment bank understood. She was surprised by the colorful stories of startup founders and wanted to document their experiences in a book.\n",
      "\n",
      "Question: Why did the author decide to start their own investment firm?\n",
      "Answer: The author decided to start their own investment firm because they were frustrated with the slow decision-making process of venture capital firms and wanted to implement their own ideas about how investments should be made. They also wanted to collaborate with their colleagues and saw an opportunity to provide the kind of support and guidance to founders that they themselves had needed when starting their own company.\n",
      "\n",
      "Question: Who did the author plan to collaborate with on projects?\n",
      "Answer: The author planned to collaborate with Robert and Trevor on projects.\n",
      "\n",
      "Question: What was the main goal of YC in relation to startups?\n",
      "Answer: The main goal of YC in relation to startups was to provide seed investments and comprehensive support to help founders overcome the challenges they faced in the early stages of their startups. YC aimed to replicate the assistance that Julian had provided to the founders of YC, such as helping them set up their company, and extend it to other startups. Additionally, YC aimed to create a community of founders who could support and learn from each other, and to facilitate networking and customer acquisition opportunities among the startups in each batch.\n",
      "\n",
      "Question: Why did the founders of YC decide to start a summer program for undergrads?\n",
      "Answer: The founders of YC decided to start a summer program for undergrads because they wanted to gain experience as investors and thought it would be a good way to practice being investors. They also believed that organizing a summer program where undergrads would start startups instead of working at tech companies would be more interesting for the students. Additionally, the founders saw it as an opportunity to fund a whole bunch of startups at once and solve the problem of isolation that many founders face.\n",
      "\n",
      "Question: Who were some of the notable individuals selected for funding in the first batch of the Summer Founders Program?\n",
      "Answer: Some of the notable individuals selected for funding in the first batch of the Summer Founders Program were Justin Kan and Emmett Shear, who went on to found Twitch, Aaron Swartz, who had already helped write the RSS spec and would later become a martyr for open access, and Sam Altman, who would later become the second president of YC.\n",
      "\n",
      "Question: What advantages did YC notice as it grew?\n",
      "Answer: As YC grew, one advantage that was noticed was that lots of startups were able to get their initial set of customers from among their batchmates. This suggests that being part of the YC network provided startups with a valuable customer base and potential partnerships.\n",
      "\n",
      "Question: Why did the author change the name and topic of Hacker News?\n",
      "Answer: The author changed the name and topic of Hacker News because they got tired of reading about nothing but startups and realized that they wanted to reach future startup founders instead of just current ones.\n",
      "\n",
      "Question: Why did the author gradually stop working on Arc?\n",
      "Answer: The author gradually stopped working on Arc partly because they didn't have time to and partly because it was less attractive to work on the language now that there was infrastructure depending on it.\n",
      "\n",
      "Question: What advice did Robert Morris give to the author and how did the author interpret it?\n",
      "Answer: The context does not provide any information about the advice that Robert Morris gave to the author or how the author interpreted it.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m questions_with_document_chunk_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      3\u001b[0m     question \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m     response_vector \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_vector\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/base/base_query_engine.py:40\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     39\u001b[0m     str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/query_engine/retriever_query_engine.py:187\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    184\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    185\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    186\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 187\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/base.py:180\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    178\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    179\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 180\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    189\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py:38\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py:160\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refine_response_single(\n\u001b[1;32m    166\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[1;32m    167\u001b[0m         )\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py:214\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    213\u001b[0m             StructuredRefineResponse,\n\u001b[0;32m--> 214\u001b[0m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    218\u001b[0m         )\n\u001b[1;32m    219\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py:68\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     66\u001b[0m     answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[38;5;241m=\u001b[39manswer, query_satisfied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/llms/llm.py:239\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[1;32m    238\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[0;32m--> 239\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/core/llms/callbacks.py:93\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self) \u001b[38;5;28;01mas\u001b[39;00m callback_manager:\n\u001b[1;32m     85\u001b[0m     event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m     86\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m     87\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m         },\n\u001b[1;32m     92\u001b[0m     )\n\u001b[0;32m---> 93\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f_return_val, Generator):\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_gen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponseGen:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:237\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:296\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_client()\n\u001b[1;32m    295\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[0;32m--> 296\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m openai_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    302\u001b[0m message \u001b[38;5;241m=\u001b[39m from_openai_message(openai_message)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/openai/_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    915\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    924\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpx/_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    907\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    911\u001b[0m )\n\u001b[1;32m    913\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 915\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpx/_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpx/_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    978\u001b[0m     hook(request)\n\u001b[0;32m--> 980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpx/_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1016\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1020\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpx/_transports/default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    219\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    220\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 231\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    236\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    237\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    238\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    239\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:132\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:110\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    104\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    105\u001b[0m     (\n\u001b[1;32m    106\u001b[0m         http_version,\n\u001b[1;32m    107\u001b[0m         status,\n\u001b[1;32m    108\u001b[0m         reason_phrase,\n\u001b[1;32m    109\u001b[0m         headers,\n\u001b[0;32m--> 110\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    112\u001b[0m         http_version,\n\u001b[1;32m    113\u001b[0m         status,\n\u001b[1;32m    114\u001b[0m         reason_phrase,\n\u001b[1;32m    115\u001b[0m         headers,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    119\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    120\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     },\n\u001b[1;32m    127\u001b[0m )\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:175\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    172\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:211\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    208\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 211\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/work/phoenix/.venv/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop over the questions and generate the answers\n",
    "for _, row in questions_with_document_chunk_df.iterrows():\n",
    "    question = row[\"question\"]\n",
    "    response_vector = query_engine.query(question)\n",
    "    print(f\"Question: {question}\\nAnswer: {response_vector.response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have executed the queries, we can start validating whether or not the RAG system was able to retrieve the correct context. Let's extract all the retrieved documents from the traces logged to phoenix. (For an in-depth explanation of how to export trace data from the phoenix runtime, consult the [docs](https://docs.arize.com/phoenix/how-to/extract-data-from-spans))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>document_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7b9433a78ff833cf</th>\n",
       "      <th>0</th>\n",
       "      <td>4612b67092d84365290c4c0b2851eb96</td>\n",
       "      <td>Why did the author think it was strange advice...</td>\n",
       "      <td>\"You know,\" he said, \"you should make sure Y C...</td>\n",
       "      <td>0.867832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4612b67092d84365290c4c0b2851eb96</td>\n",
       "      <td>Why did the author think it was strange advice...</td>\n",
       "      <td>If you were trying to learn the most you could...</td>\n",
       "      <td>0.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8e6cd5ba6ab58a85</th>\n",
       "      <th>0</th>\n",
       "      <td>1ce64bbadbdc80bbe1cf91134c5c7491</td>\n",
       "      <td>What advice did Robert Morris give to the auth...</td>\n",
       "      <td>He wasn't that much older than me, and was sup...</td>\n",
       "      <td>0.805880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ce64bbadbdc80bbe1cf91134c5c7491</td>\n",
       "      <td>What advice did Robert Morris give to the auth...</td>\n",
       "      <td>I was nervous about money, because I could sen...</td>\n",
       "      <td>0.803608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1f1f622a3d0a53b6</th>\n",
       "      <th>0</th>\n",
       "      <td>acc7a78bc11749a3e65593ab46d44d84</td>\n",
       "      <td>Why did the author gradually stop working on Arc?</td>\n",
       "      <td>Now lots of startups get their initial set of ...</td>\n",
       "      <td>0.838596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad8f43ecee5b9ff</th>\n",
       "      <th>1</th>\n",
       "      <td>8606c5abf52e622a290161d66d3df6c0</td>\n",
       "      <td>What was the author's first experience with co...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>0.878844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">370c1b15cf293d31</th>\n",
       "      <th>0</th>\n",
       "      <td>d2493437d64fff6200e05b8793edc63b</td>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>I was puzzled by the 1401. I couldn't figure o...</td>\n",
       "      <td>0.855102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2493437d64fff6200e05b8793edc63b</td>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>0.838523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">328a8cff9344df81</th>\n",
       "      <th>0</th>\n",
       "      <td>8cbdca83323878f45d2af33ede5db939</td>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>0.843388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8cbdca83323878f45d2af33ede5db939</td>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>I had been intimately involved with building t...</td>\n",
       "      <td>0.818337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    context.trace_id  \\\n",
       "context.span_id  document_position                                     \n",
       "7b9433a78ff833cf 0                  4612b67092d84365290c4c0b2851eb96   \n",
       "                 1                  4612b67092d84365290c4c0b2851eb96   \n",
       "8e6cd5ba6ab58a85 0                  1ce64bbadbdc80bbe1cf91134c5c7491   \n",
       "                 1                  1ce64bbadbdc80bbe1cf91134c5c7491   \n",
       "1f1f622a3d0a53b6 0                  acc7a78bc11749a3e65593ab46d44d84   \n",
       "...                                                              ...   \n",
       "dad8f43ecee5b9ff 1                  8606c5abf52e622a290161d66d3df6c0   \n",
       "370c1b15cf293d31 0                  d2493437d64fff6200e05b8793edc63b   \n",
       "                 1                  d2493437d64fff6200e05b8793edc63b   \n",
       "328a8cff9344df81 0                  8cbdca83323878f45d2af33ede5db939   \n",
       "                 1                  8cbdca83323878f45d2af33ede5db939   \n",
       "\n",
       "                                                                                input  \\\n",
       "context.span_id  document_position                                                      \n",
       "7b9433a78ff833cf 0                  Why did the author think it was strange advice...   \n",
       "                 1                  Why did the author think it was strange advice...   \n",
       "8e6cd5ba6ab58a85 0                  What advice did Robert Morris give to the auth...   \n",
       "                 1                  What advice did Robert Morris give to the auth...   \n",
       "1f1f622a3d0a53b6 0                  Why did the author gradually stop working on Arc?   \n",
       "...                                                                               ...   \n",
       "dad8f43ecee5b9ff 1                  What was the author's first experience with co...   \n",
       "370c1b15cf293d31 0                  What were the limitations of the 1401 computer...   \n",
       "                 1                  What were the limitations of the 1401 computer...   \n",
       "328a8cff9344df81 0                  What were the two main things the author worke...   \n",
       "                 1                  What were the two main things the author worke...   \n",
       "\n",
       "                                                                            reference  \\\n",
       "context.span_id  document_position                                                      \n",
       "7b9433a78ff833cf 0                  \"You know,\" he said, \"you should make sure Y C...   \n",
       "                 1                  If you were trying to learn the most you could...   \n",
       "8e6cd5ba6ab58a85 0                  He wasn't that much older than me, and was sup...   \n",
       "                 1                  I was nervous about money, because I could sen...   \n",
       "1f1f622a3d0a53b6 0                  Now lots of startups get their initial set of ...   \n",
       "...                                                                               ...   \n",
       "dad8f43ecee5b9ff 1                  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "370c1b15cf293d31 0                  I was puzzled by the 1401. I couldn't figure o...   \n",
       "                 1                  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "328a8cff9344df81 0                  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "                 1                  I had been intimately involved with building t...   \n",
       "\n",
       "                                    document_score  \n",
       "context.span_id  document_position                  \n",
       "7b9433a78ff833cf 0                        0.867832  \n",
       "                 1                        0.863600  \n",
       "8e6cd5ba6ab58a85 0                        0.805880  \n",
       "                 1                        0.803608  \n",
       "1f1f622a3d0a53b6 0                        0.838596  \n",
       "...                                            ...  \n",
       "dad8f43ecee5b9ff 1                        0.878844  \n",
       "370c1b15cf293d31 0                        0.855102  \n",
       "                 1                        0.838523  \n",
       "328a8cff9344df81 0                        0.843388  \n",
       "                 1                        0.818337  \n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_retrieved_documents\n",
    "\n",
    "retrieved_documents_df = get_retrieved_documents(px.Client())\n",
    "retrieved_documents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use Phoenix's LLM Evals to evaluate the relevance of the retrieved documents with regards to the query. Note, we've turned on `explanations` which prompts the LLM to explain it's reasoning. This can be useful for debugging and for figuring out potential corrective actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |          | 0/220 (0.0%) | ‚è≥ 00:00<? | ?it/s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |‚ñà‚ñè        | 26/220 (11.8%) | ‚è≥ 00:19<01:18 |  2.47it/s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process was interrupted. The return value will be incomplete...\n"
     ]
    }
   ],
   "source": [
    "from phoenix.experimental.evals import (\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(OpenAIModel(model_name=\"gpt-4-turbo-preview\"))\n",
    "\n",
    "retrieved_documents_relevance_df = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=retrieved_documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7b9433a78ff833cf</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text directly addresses the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text directly addresses the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8e6cd5ba6ab58a85</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks for the advice Robert Morris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks for the advice Robert Morris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1f1f622a3d0a53b6</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text directly addresses the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       label  score  \\\n",
       "context.span_id  document_position                    \n",
       "7b9433a78ff833cf 0                  relevant    1.0   \n",
       "                 1                  relevant    1.0   \n",
       "8e6cd5ba6ab58a85 0                  relevant    1.0   \n",
       "                 1                  relevant    1.0   \n",
       "1f1f622a3d0a53b6 0                  relevant    1.0   \n",
       "\n",
       "                                                                          explanation  \n",
       "context.span_id  document_position                                                     \n",
       "7b9433a78ff833cf 0                  The reference text directly addresses the ques...  \n",
       "                 1                  The reference text directly addresses the ques...  \n",
       "8e6cd5ba6ab58a85 0                  The question asks for the advice Robert Morris...  \n",
       "                 1                  The question asks for the advice Robert Morris...  \n",
       "1f1f622a3d0a53b6 0                  The reference text directly addresses the ques...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents_relevance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the documents with the relevance evaluations to compute retrieval metrics. These metrics will help us understand how well the RAG system is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>document_score</th>\n",
       "      <th>eval_label</th>\n",
       "      <th>eval_score</th>\n",
       "      <th>eval_explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7b9433a78ff833cf</th>\n",
       "      <th>0</th>\n",
       "      <td>4612b67092d84365290c4c0b2851eb96</td>\n",
       "      <td>Why did the author think it was strange advice...</td>\n",
       "      <td>\"You know,\" he said, \"you should make sure Y C...</td>\n",
       "      <td>0.867832</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text directly addresses the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4612b67092d84365290c4c0b2851eb96</td>\n",
       "      <td>Why did the author think it was strange advice...</td>\n",
       "      <td>If you were trying to learn the most you could...</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text directly addresses the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8e6cd5ba6ab58a85</th>\n",
       "      <th>0</th>\n",
       "      <td>1ce64bbadbdc80bbe1cf91134c5c7491</td>\n",
       "      <td>What advice did Robert Morris give to the auth...</td>\n",
       "      <td>He wasn't that much older than me, and was sup...</td>\n",
       "      <td>0.805880</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks for the advice Robert Morris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ce64bbadbdc80bbe1cf91134c5c7491</td>\n",
       "      <td>What advice did Robert Morris give to the auth...</td>\n",
       "      <td>I was nervous about money, because I could sen...</td>\n",
       "      <td>0.803608</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks for the advice Robert Morris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1f1f622a3d0a53b6</th>\n",
       "      <th>0</th>\n",
       "      <td>acc7a78bc11749a3e65593ab46d44d84</td>\n",
       "      <td>Why did the author gradually stop working on Arc?</td>\n",
       "      <td>Now lots of startups get their initial set of ...</td>\n",
       "      <td>0.838596</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text directly addresses the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad8f43ecee5b9ff</th>\n",
       "      <th>1</th>\n",
       "      <td>8606c5abf52e622a290161d66d3df6c0</td>\n",
       "      <td>What was the author's first experience with co...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>0.878844</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">370c1b15cf293d31</th>\n",
       "      <th>0</th>\n",
       "      <td>d2493437d64fff6200e05b8793edc63b</td>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>I was puzzled by the 1401. I couldn't figure o...</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2493437d64fff6200e05b8793edc63b</td>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>0.838523</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">328a8cff9344df81</th>\n",
       "      <th>0</th>\n",
       "      <td>8cbdca83323878f45d2af33ede5db939</td>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "      <td>0.843388</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8cbdca83323878f45d2af33ede5db939</td>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>I had been intimately involved with building t...</td>\n",
       "      <td>0.818337</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    context.trace_id  \\\n",
       "context.span_id  document_position                                     \n",
       "7b9433a78ff833cf 0                  4612b67092d84365290c4c0b2851eb96   \n",
       "                 1                  4612b67092d84365290c4c0b2851eb96   \n",
       "8e6cd5ba6ab58a85 0                  1ce64bbadbdc80bbe1cf91134c5c7491   \n",
       "                 1                  1ce64bbadbdc80bbe1cf91134c5c7491   \n",
       "1f1f622a3d0a53b6 0                  acc7a78bc11749a3e65593ab46d44d84   \n",
       "...                                                              ...   \n",
       "dad8f43ecee5b9ff 1                  8606c5abf52e622a290161d66d3df6c0   \n",
       "370c1b15cf293d31 0                  d2493437d64fff6200e05b8793edc63b   \n",
       "                 1                  d2493437d64fff6200e05b8793edc63b   \n",
       "328a8cff9344df81 0                  8cbdca83323878f45d2af33ede5db939   \n",
       "                 1                  8cbdca83323878f45d2af33ede5db939   \n",
       "\n",
       "                                                                                input  \\\n",
       "context.span_id  document_position                                                      \n",
       "7b9433a78ff833cf 0                  Why did the author think it was strange advice...   \n",
       "                 1                  Why did the author think it was strange advice...   \n",
       "8e6cd5ba6ab58a85 0                  What advice did Robert Morris give to the auth...   \n",
       "                 1                  What advice did Robert Morris give to the auth...   \n",
       "1f1f622a3d0a53b6 0                  Why did the author gradually stop working on Arc?   \n",
       "...                                                                               ...   \n",
       "dad8f43ecee5b9ff 1                  What was the author's first experience with co...   \n",
       "370c1b15cf293d31 0                  What were the limitations of the 1401 computer...   \n",
       "                 1                  What were the limitations of the 1401 computer...   \n",
       "328a8cff9344df81 0                  What were the two main things the author worke...   \n",
       "                 1                  What were the two main things the author worke...   \n",
       "\n",
       "                                                                            reference  \\\n",
       "context.span_id  document_position                                                      \n",
       "7b9433a78ff833cf 0                  \"You know,\" he said, \"you should make sure Y C...   \n",
       "                 1                  If you were trying to learn the most you could...   \n",
       "8e6cd5ba6ab58a85 0                  He wasn't that much older than me, and was sup...   \n",
       "                 1                  I was nervous about money, because I could sen...   \n",
       "1f1f622a3d0a53b6 0                  Now lots of startups get their initial set of ...   \n",
       "...                                                                               ...   \n",
       "dad8f43ecee5b9ff 1                  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "370c1b15cf293d31 0                  I was puzzled by the 1401. I couldn't figure o...   \n",
       "                 1                  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "328a8cff9344df81 0                  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...   \n",
       "                 1                  I had been intimately involved with building t...   \n",
       "\n",
       "                                    document_score eval_label  eval_score  \\\n",
       "context.span_id  document_position                                          \n",
       "7b9433a78ff833cf 0                        0.867832   relevant         1.0   \n",
       "                 1                        0.863600   relevant         1.0   \n",
       "8e6cd5ba6ab58a85 0                        0.805880   relevant         1.0   \n",
       "                 1                        0.803608   relevant         1.0   \n",
       "1f1f622a3d0a53b6 0                        0.838596   relevant         1.0   \n",
       "...                                            ...        ...         ...   \n",
       "dad8f43ecee5b9ff 1                        0.878844       None         NaN   \n",
       "370c1b15cf293d31 0                        0.855102       None         NaN   \n",
       "                 1                        0.838523       None         NaN   \n",
       "328a8cff9344df81 0                        0.843388       None         NaN   \n",
       "                 1                        0.818337       None         NaN   \n",
       "\n",
       "                                                                     eval_explanation  \n",
       "context.span_id  document_position                                                     \n",
       "7b9433a78ff833cf 0                  The reference text directly addresses the ques...  \n",
       "                 1                  The reference text directly addresses the ques...  \n",
       "8e6cd5ba6ab58a85 0                  The question asks for the advice Robert Morris...  \n",
       "                 1                  The question asks for the advice Robert Morris...  \n",
       "1f1f622a3d0a53b6 0                  The reference text directly addresses the ques...  \n",
       "...                                                                               ...  \n",
       "dad8f43ecee5b9ff 1                                                               None  \n",
       "370c1b15cf293d31 0                                                               None  \n",
       "                 1                                                               None  \n",
       "328a8cff9344df81 0                                                               None  \n",
       "                 1                                                               None  \n",
       "\n",
       "[220 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_with_relevance_df = pd.concat(\n",
    "    [retrieved_documents_df, retrieved_documents_relevance_df.add_prefix(\"eval_\")], axis=1\n",
    ")\n",
    "documents_with_relevance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute Normalized Discounted Cumulative Gain [NCDG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) at 2 for all our retrieval steps.  In information retrieval, this metric is often used to measure effectiveness of search engine algorithms and related applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def _compute_ndcg(df: pd.DataFrame, k: int):\n",
    "    \"\"\"Compute NDCG@k in the presence of missing values\"\"\"\n",
    "    n = max(2, len(df))\n",
    "    eval_scores = np.zeros(n)\n",
    "    doc_scores = np.zeros(n)\n",
    "    eval_scores[: len(df)] = df.eval_score\n",
    "    doc_scores[: len(df)] = df.document_score\n",
    "    try:\n",
    "        return ndcg_score([eval_scores], [doc_scores], k=k)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "ndcg_at_2 = pd.DataFrame(\n",
    "    {\"score\": documents_with_relevance_df.groupby(\"context.span_id\").apply(_compute_ndcg, k=2)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>016e0e812b485e15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c14f5a490018dd</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>037d5dc13c8802ac</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0608fd82cc153ff7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>078d4d9a618440b5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3db83f2dbcf04a9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f686b0d79cc3cf81</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f902a04eb8c566fb</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9cc9782a26892a1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8573dc175c0be2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score\n",
       "context.span_id        \n",
       "016e0e812b485e15    NaN\n",
       "01c14f5a490018dd    NaN\n",
       "037d5dc13c8802ac    NaN\n",
       "0608fd82cc153ff7    NaN\n",
       "078d4d9a618440b5    NaN\n",
       "...                 ...\n",
       "f3db83f2dbcf04a9    NaN\n",
       "f686b0d79cc3cf81    NaN\n",
       "f902a04eb8c566fb    NaN\n",
       "f9cc9782a26892a1    NaN\n",
       "fb8573dc175c0be2    NaN\n",
       "\n",
       "[110 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute precision at 2 for all our retrieval steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_2 = pd.DataFrame(\n",
    "    {\n",
    "        \"score\": documents_with_relevance_df.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:2].sum(skipna=False) / 2\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>016e0e812b485e15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c14f5a490018dd</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>037d5dc13c8802ac</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0608fd82cc153ff7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>078d4d9a618440b5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3db83f2dbcf04a9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f686b0d79cc3cf81</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f902a04eb8c566fb</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9cc9782a26892a1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8573dc175c0be2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score\n",
       "context.span_id        \n",
       "016e0e812b485e15    NaN\n",
       "01c14f5a490018dd    NaN\n",
       "037d5dc13c8802ac    NaN\n",
       "0608fd82cc153ff7    NaN\n",
       "078d4d9a618440b5    NaN\n",
       "...                 ...\n",
       "f3db83f2dbcf04a9    NaN\n",
       "f686b0d79cc3cf81    NaN\n",
       "f902a04eb8c566fb    NaN\n",
       "f9cc9782a26892a1    NaN\n",
       "fb8573dc175c0be2    NaN\n",
       "\n",
       "[110 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's compute whether or not a correct document was retrieved at all for each query (e.g. a hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit = pd.DataFrame(\n",
    "    {\n",
    "        \"hit\": documents_with_relevance_df.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:2].sum(skipna=False) > 0\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now view the results in a combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>ncdg@2_score</th>\n",
       "      <th>precision@2_score</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7b9433a78ff833cf</th>\n",
       "      <td>Why did the author think it was strange advice...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e6cd5ba6ab58a85</th>\n",
       "      <td>What advice did Robert Morris give to the auth...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1f1f622a3d0a53b6</th>\n",
       "      <td>Why did the author gradually stop working on Arc?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e56a80385bc860c</th>\n",
       "      <td>Why did the author change the name and topic o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f5af22507ec226b</th>\n",
       "      <td>What advantages did YC notice as it grew?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0608fd82cc153ff7</th>\n",
       "      <td>What was the default language at Cornell and o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f274d9ab9bf8cfd</th>\n",
       "      <td>What were the two things that inspired the aut...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad8f43ecee5b9ff</th>\n",
       "      <td>What was the author's first experience with co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370c1b15cf293d31</th>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328a8cff9344df81</th>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             attributes.input.value  \\\n",
       "context.span_id                                                       \n",
       "7b9433a78ff833cf  Why did the author think it was strange advice...   \n",
       "8e6cd5ba6ab58a85  What advice did Robert Morris give to the auth...   \n",
       "1f1f622a3d0a53b6  Why did the author gradually stop working on Arc?   \n",
       "4e56a80385bc860c  Why did the author change the name and topic o...   \n",
       "9f5af22507ec226b          What advantages did YC notice as it grew?   \n",
       "...                                                             ...   \n",
       "0608fd82cc153ff7  What was the default language at Cornell and o...   \n",
       "5f274d9ab9bf8cfd  What were the two things that inspired the aut...   \n",
       "dad8f43ecee5b9ff  What was the author's first experience with co...   \n",
       "370c1b15cf293d31  What were the limitations of the 1401 computer...   \n",
       "328a8cff9344df81  What were the two main things the author worke...   \n",
       "\n",
       "                  ncdg@2_score  precision@2_score    hit  \n",
       "context.span_id                                           \n",
       "7b9433a78ff833cf           1.0                1.0   True  \n",
       "8e6cd5ba6ab58a85           1.0                1.0   True  \n",
       "1f1f622a3d0a53b6           1.0                1.0   True  \n",
       "4e56a80385bc860c           1.0                0.5   True  \n",
       "9f5af22507ec226b           1.0                1.0   True  \n",
       "...                        ...                ...    ...  \n",
       "0608fd82cc153ff7           NaN                NaN  False  \n",
       "5f274d9ab9bf8cfd           NaN                NaN  False  \n",
       "dad8f43ecee5b9ff           NaN                NaN  False  \n",
       "370c1b15cf293d31           NaN                NaN  False  \n",
       "328a8cff9344df81           NaN                NaN  False  \n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievals_df = px.Client().get_spans_dataframe(\"span_kind == 'RETRIEVER'\")\n",
    "rag_evaluation_dataframe = pd.concat(\n",
    "    [\n",
    "        retrievals_df[\"attributes.input.value\"],\n",
    "        ndcg_at_2.add_prefix(\"ncdg@2_\"),\n",
    "        precision_at_2.add_prefix(\"precision@2_\"),\n",
    "        hit,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "rag_evaluation_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Let's now take our results and aggregate them to get a sense of how well our RAG system is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ncdg@2_score         0.969244\n",
       "precision@2_score    0.875000\n",
       "hit                  0.109091\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the scores across the retrievals\n",
    "results = rag_evaluation_dataframe.mean(numeric_only=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above numbers, our RAG system is not perfect, there are times when it fails to retrieve the correct context within the first two documents. At other times the correct context is included in the top 2 results but non-relevant information is also included in the context. This is an indication that we need to improve our retrieval strategy. One possible solution could be to increase the number of documents retrieved and then use a more sophisticated ranking strategy (such as a reranker) to select the correct context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now evaluated our RAG system's retrieval performance. Let's send these evaluations to Phoenix for visualization. By sending the evaluations to Phoenix, you will be able to view the evaluations alongside the traces that were captured earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(dataframe=ndcg_at_2, eval_name=\"ndcg@2\"),\n",
    "    SpanEvaluations(dataframe=precision_at_2, eval_name=\"precision@2\"),\n",
    "    DocumentEvaluations(dataframe=retrieved_documents_relevance_df, eval_name=\"relevance\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Evaluation\n",
    "\n",
    "The retrieval evaluations demonstrates that our RAG system is not perfect. However, it's possible that the LLM is able to generate the correct response even when the context is incorrect. Let's evaluate the responses generated by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fcc8776cdbfe32f3</th>\n",
       "      <td>Why did the author think it was strange advice...</td>\n",
       "      <td>None</td>\n",
       "      <td>\"You know,\" he said, \"you should make sure Y C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe3158a0812c3dd</th>\n",
       "      <td>What advice did Robert Morris give to the auth...</td>\n",
       "      <td>The context does not provide any information a...</td>\n",
       "      <td>He wasn't that much older than me, and was sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58d285496b285699</th>\n",
       "      <td>Why did the author gradually stop working on Arc?</td>\n",
       "      <td>The author gradually stopped working on Arc pa...</td>\n",
       "      <td>Now lots of startups get their initial set of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c0f07ae84c796cc</th>\n",
       "      <td>Why did the author change the name and topic o...</td>\n",
       "      <td>The author changed the name and topic of Hacke...</td>\n",
       "      <td>Now lots of startups get their initial set of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e81e48efab0c66c9</th>\n",
       "      <td>What advantages did YC notice as it grew?</td>\n",
       "      <td>As YC grew, one advantage that was noticed was...</td>\n",
       "      <td>Surely the biggest source of stress in one's w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13933260b8c422ea</th>\n",
       "      <td>What was the default language at Cornell and o...</td>\n",
       "      <td>The default language at Cornell and other univ...</td>\n",
       "      <td>The default language at Cornell was a Pascal-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222463a33ebb114f</th>\n",
       "      <td>What were the two things that inspired the aut...</td>\n",
       "      <td>The two things that inspired the author to wor...</td>\n",
       "      <td>I applied to 3 grad schools: MIT and Yale, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c388fb98dca7fb4</th>\n",
       "      <td>What was the author's first experience with co...</td>\n",
       "      <td>The author's first experience with computers a...</td>\n",
       "      <td>I remember vividly how impressed and envious I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7c838b5657296e9</th>\n",
       "      <td>What were the limitations of the 1401 computer...</td>\n",
       "      <td>The 1401 computer had limitations in terms of ...</td>\n",
       "      <td>I was puzzled by the 1401. I couldn't figure o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089d993b50748f3d</th>\n",
       "      <td>What were the two main things the author worke...</td>\n",
       "      <td>Before college, the author worked on writing a...</td>\n",
       "      <td>What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              input  \\\n",
       "context.span_id                                                       \n",
       "fcc8776cdbfe32f3  Why did the author think it was strange advice...   \n",
       "abe3158a0812c3dd  What advice did Robert Morris give to the auth...   \n",
       "58d285496b285699  Why did the author gradually stop working on Arc?   \n",
       "3c0f07ae84c796cc  Why did the author change the name and topic o...   \n",
       "e81e48efab0c66c9          What advantages did YC notice as it grew?   \n",
       "...                                                             ...   \n",
       "13933260b8c422ea  What was the default language at Cornell and o...   \n",
       "222463a33ebb114f  What were the two things that inspired the aut...   \n",
       "4c388fb98dca7fb4  What was the author's first experience with co...   \n",
       "f7c838b5657296e9  What were the limitations of the 1401 computer...   \n",
       "089d993b50748f3d  What were the two main things the author worke...   \n",
       "\n",
       "                                                             output  \\\n",
       "context.span_id                                                       \n",
       "fcc8776cdbfe32f3                                               None   \n",
       "abe3158a0812c3dd  The context does not provide any information a...   \n",
       "58d285496b285699  The author gradually stopped working on Arc pa...   \n",
       "3c0f07ae84c796cc  The author changed the name and topic of Hacke...   \n",
       "e81e48efab0c66c9  As YC grew, one advantage that was noticed was...   \n",
       "...                                                             ...   \n",
       "13933260b8c422ea  The default language at Cornell and other univ...   \n",
       "222463a33ebb114f  The two things that inspired the author to wor...   \n",
       "4c388fb98dca7fb4  The author's first experience with computers a...   \n",
       "f7c838b5657296e9  The 1401 computer had limitations in terms of ...   \n",
       "089d993b50748f3d  Before college, the author worked on writing a...   \n",
       "\n",
       "                                                          reference  \n",
       "context.span_id                                                      \n",
       "fcc8776cdbfe32f3  \"You know,\" he said, \"you should make sure Y C...  \n",
       "abe3158a0812c3dd  He wasn't that much older than me, and was sup...  \n",
       "58d285496b285699  Now lots of startups get their initial set of ...  \n",
       "3c0f07ae84c796cc  Now lots of startups get their initial set of ...  \n",
       "e81e48efab0c66c9  Surely the biggest source of stress in one's w...  \n",
       "...                                                             ...  \n",
       "13933260b8c422ea  The default language at Cornell was a Pascal-l...  \n",
       "222463a33ebb114f  I applied to 3 grad schools: MIT and Yale, whi...  \n",
       "4c388fb98dca7fb4  I remember vividly how impressed and envious I...  \n",
       "f7c838b5657296e9  I was puzzled by the 1401. I couldn't figure o...  \n",
       "089d993b50748f3d  What I Worked On\\n\\nFebruary 2021\\n\\nBefore co...  \n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_qa_with_reference\n",
    "\n",
    "qa_with_reference_df = get_qa_with_reference(px.Client())\n",
    "qa_with_reference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataset of the question, context, and response (input, reference, and output), we now can measure how well the LLM is responding to the queries. For details on the QA correctness evaluation, see the [LLM Evals documentation](https://docs.arize.com/phoenix/llm-evals/running-pre-tested-evals/q-and-a-on-retrieved-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n",
      "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |‚ñà‚ñà‚ñà       | 67/220 (30.5%) | ‚è≥ 00:41<00:46 |  3.27it/s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process was interrupted. The return value will be incomplete...\n"
     ]
    }
   ],
   "source": [
    "from phoenix.experimental.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "\n",
    "qa_evaluator = QAEvaluator(OpenAIModel(model=\"gpt-4-turbo-preview\"))\n",
    "hallucination_evaluator = HallucinationEvaluator(OpenAIModel(model=\"gpt-4-turbo-preview\"))\n",
    "\n",
    "qa_correctness_eval_df, hallucination_eval_df = run_evals(\n",
    "    evaluators=[qa_evaluator, hallucination_evaluator],\n",
    "    dataframe=qa_with_reference_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fcc8776cdbfe32f3</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The question asks why the author thought it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe3158a0812c3dd</th>\n",
       "      <td>correct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text does not explicitly mention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58d285496b285699</th>\n",
       "      <td>correct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text provides a clear explanatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c0f07ae84c796cc</th>\n",
       "      <td>correct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The reference text provides a clear explanatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e81e48efab0c66c9</th>\n",
       "      <td>correct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks about the advantages YC noti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  score  \\\n",
       "context.span_id                      \n",
       "fcc8776cdbfe32f3  incorrect    0.0   \n",
       "abe3158a0812c3dd    correct    1.0   \n",
       "58d285496b285699    correct    1.0   \n",
       "3c0f07ae84c796cc    correct    1.0   \n",
       "e81e48efab0c66c9    correct    1.0   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "fcc8776cdbfe32f3  The question asks why the author thought it wa...  \n",
       "abe3158a0812c3dd  The reference text does not explicitly mention...  \n",
       "58d285496b285699  The reference text provides a clear explanatio...  \n",
       "3c0f07ae84c796cc  The reference text provides a clear explanatio...  \n",
       "e81e48efab0c66c9  The question asks about the advantages YC noti...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_correctness_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fcc8776cdbfe32f3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe3158a0812c3dd</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58d285496b285699</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c0f07ae84c796cc</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e81e48efab0c66c9</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label score explanation\n",
       "context.span_id                         \n",
       "fcc8776cdbfe32f3  None  None        None\n",
       "abe3158a0812c3dd  None  None        None\n",
       "58d285496b285699  None  None        None\n",
       "3c0f07ae84c796cc  None  None        None\n",
       "e81e48efab0c66c9  None  None        None"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "Let's now take our results and aggregate them to get a sense of how well the LLM is answering the questions given the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    0.865672\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_correctness_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our QA Correctness score of `0.91` and a Hallucinations score `0.05` signifies that the generated answers are correct ~91% of the time and that the responses contain hallucinations 5% of the time - there is room for improvement. This could be due to the retrieval strategy or the LLM itself. We will need to investigate further to determine the root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have evaluated our RAG system's QA performance and Hallucinations performance, let's send these evaluations to Phoenix for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(dataframe=qa_correctness_eval_df, eval_name=\"Q&A Correctness\"),\n",
    "    SpanEvaluations(dataframe=hallucination_eval_df, eval_name=\"Hallucination\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have sent all our evaluations to Phoenix. Let's go to the Phoenix application and view the results! Since we've sent all the evals to Phoenix, we can analyze the results together to make a determination on whether or not poor retrieval or irrelevant context has an effect on the LLM's ability to generate the correct response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoenix URL http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "print(\"phoenix URL\", px.active_session().url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have explored how to build and evaluate a RAG pipeline using LlamaIndex and Phoenix, with a specific focus on evaluating the retrieval system and generated responses within the pipelines. \n",
    "\n",
    "Phoenix offers a variety of other evaluations that can be used to assess the performance of your LLM Application. For more details, see the [LLM Evals](https://docs.arize.com/phoenix/llm-evals/llm-evals) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
