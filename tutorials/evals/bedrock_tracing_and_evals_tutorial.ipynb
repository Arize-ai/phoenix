{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumenting AWS Bedrock client with OpenInference and Phoenix\n",
    "\n",
    "In this tutorial we will trace model calls to AWS Bedrock using OpenInference. The OpenInference Bedrock tracer instruments the Python `boto3` library, so all `invoke_model` calls will automatically generate traces that can be sent to Phoenix.\n",
    "\n",
    "‚ÑπÔ∏è This notebook requires a valid AWS configuration and access to AWS Bedrock and the `claude-v2` model from Anthropic & an OpenAI API key for LLM as a Judge Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies and set up OpenTelemetry tracer\n",
    "\n",
    "First install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arize-phoenix in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (12.12.0)\n",
      "Requirement already satisfied: boto3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.41.2)\n",
      "Requirement already satisfied: openinference-instrumentation-bedrock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.1.31)\n",
      "Requirement already satisfied: aioitertools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.12.0)\n",
      "Requirement already satisfied: aiosqlite in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.20.0)\n",
      "Requirement already satisfied: alembic<2,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.14.0)\n",
      "Requirement already satisfied: arize-phoenix-client>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.22.0)\n",
      "Requirement already satisfied: arize-phoenix-evals>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (2.2.0)\n",
      "Requirement already satisfied: arize-phoenix-otel>=0.10.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.12.1)\n",
      "Requirement already satisfied: authlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.4.0)\n",
      "Requirement already satisfied: cachetools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (5.5.2)\n",
      "Requirement already satisfied: email-validator in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (2.2.0)\n",
      "Requirement already satisfied: fastapi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.115.12)\n",
      "Requirement already satisfied: grpc-interceptor in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.15.4)\n",
      "Requirement already satisfied: grpcio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.71.0)\n",
      "Requirement already satisfied: httpx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.27.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (3.1.5)\n",
      "Requirement already satisfied: jmespath in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.0.1)\n",
      "Requirement already satisfied: numpy!=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (2.3.3)\n",
      "Requirement already satisfied: openinference-instrumentation>=0.1.32 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.1.35)\n",
      "Requirement already satisfied: openinference-semantic-conventions>=0.1.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.1.21)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.59b0)\n",
      "Requirement already satisfied: orjson in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (3.10.14)\n",
      "Requirement already satisfied: pandas>=1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (2.2.3)\n",
      "Requirement already satisfied: prometheus-client in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.22.1)\n",
      "Requirement already satisfied: protobuf>=4.25.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (5.29.3)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (6.1.1)\n",
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (21.0.0)\n",
      "Requirement already satisfied: pydantic>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (2.11.7)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (2.9.0.post0)\n",
      "Requirement already satisfied: python-multipart in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.0.20)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.15.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=2.0.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (2.0.37)\n",
      "Requirement already satisfied: sqlean-py>=3.45.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (3.47.0)\n",
      "Requirement already satisfied: starlette in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.46.2)\n",
      "Requirement already satisfied: strawberry-graphql==0.270.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.270.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (4.12.2)\n",
      "Requirement already satisfied: uvicorn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (0.34.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.17.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix) (1.17.2)\n",
      "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from strawberry-graphql==0.270.1->arize-phoenix) (3.2.5)\n",
      "Requirement already satisfied: packaging>=23 in /Users/sriichavali/Library/Python/3.13/lib/python/site-packages (from strawberry-graphql==0.270.1->arize-phoenix) (24.2)\n",
      "Requirement already satisfied: Mako in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.3.8)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil->arize-phoenix) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (3.1.1)\n",
      "Requirement already satisfied: botocore<1.42.0,>=1.41.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from boto3) (1.41.2)\n",
      "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from boto3) (0.15.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from botocore<1.42.0,>=1.41.2->boto3) (2.3.0)\n",
      "Requirement already satisfied: dacite>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openinference-instrumentation-bedrock) (1.9.2)\n",
      "Requirement already satisfied: opentelemetry-api in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openinference-instrumentation-bedrock) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openinference-instrumentation-bedrock) (0.59b0)\n",
      "Requirement already satisfied: jsonpath-ng in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix-evals>=2.0.0->arize-phoenix) (1.7.0)\n",
      "Requirement already satisfied: pystache in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from arize-phoenix-evals>=2.0.0->arize-phoenix) (0.6.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.0->arize-phoenix) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.0->arize-phoenix) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.1.0->arize-phoenix) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.1.0->arize-phoenix) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.1.0->arize-phoenix) (0.4.1)\n",
      "Requirement already satisfied: cryptography in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from authlib->arize-phoenix) (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from cryptography->authlib->arize-phoenix) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.22)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from email-validator->arize-phoenix) (2.7.0)\n",
      "Requirement already satisfied: idna>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from email-validator->arize-phoenix) (3.10)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from starlette->arize-phoenix) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette->arize-phoenix) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx->arize-phoenix) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx->arize-phoenix) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx->arize-phoenix) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->arize-phoenix) (2.1.5)\n",
      "Requirement already satisfied: ply in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonpath-ng->arize-phoenix-evals>=2.0.0->arize-phoenix) (3.11)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-api->openinference-instrumentation-bedrock) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation-bedrock) (3.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.38.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.38.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.38.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp->arize-phoenix) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp->arize-phoenix) (1.38.0)\n",
      "Requirement already satisfied: requests~=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-http==1.38.0->opentelemetry-exporter-otlp->arize-phoenix) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.38.0->opentelemetry-exporter-otlp->arize-phoenix) (3.4.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->arize-phoenix) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->arize-phoenix) (3.5.0)\n",
      "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn->arize-phoenix) (8.1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arize-phoenix boto3 openinference-instrumentation-bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following env variables will allow you to connect to a cloud instance of Arize Phoenix. You can get your API key and endpoint on setting page of your [Phoenix Cloud](https://app.phoenix.arize.com) account.\n",
    "\n",
    "If you'd prefer to self-host Phoenix, please see [instructions for self-hosting](https://arize.com/docs/phoenix/deployment). The Cloud and Self-hosted versions are functionally identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import boto3\n",
    "from openinference.instrumentation.bedrock import BedrockInstrumentor\n",
    "\n",
    "import phoenix as px\n",
    "from phoenix.otel import SimpleSpanProcessor, register\n",
    "\n",
    "if not (phoenix_endpoint := os.getenv(\"PHOENIX_COLLECTOR_ENDPOINT\")):\n",
    "    phoenix_endpoint = getpass(\"üîë Enter your Phoenix Collector Endpoint: \")\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = phoenix_endpoint\n",
    "\n",
    "if not (phoenix_api_key := os.getenv(\"PHOENIX_API_KEY\")):\n",
    "    phoenix_api_key = getpass(\"üîë Enter your Phoenix API key: \")\n",
    "os.environ[\"PHOENIX_API_KEY\"] = phoenix_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're configuring the OpenTelemetry tracer by adding two SpanProcessors. The first SpanProcessor will simply print all traces received from OpenInference instrumentation to the console. The second will export traces to Phoenix so they can be collected and viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: bedrock-tracing-and-evals-tutorial\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracer_provider = register(project_name=\"bedrock-tracing-and-evals-tutorial\", auto_instrument=True)\n",
    "tracer_provider.add_span_processor(\n",
    "    SimpleSpanProcessor(endpoint=os.getenv(\"PHOENIX_COLLECTOR_ENDPOINT\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Prompt for AWS credentials if not already set\n",
    "# Uncomment the code below to be prompted for credentials interactively\n",
    "\n",
    "if not os.getenv(\"AWS_ACCESS_KEY_ID\"):\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass(\"üîë Enter your AWS Access Key ID: \")\n",
    "if not os.getenv(\"AWS_SECRET_ACCESS_KEY\"):\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass(\"üîë Enter your AWS Secret Access Key: \")\n",
    "# if not os.getenv(\"AWS_DEFAULT_REGION\"):\n",
    "#     os.environ[\"AWS_DEFAULT_REGION\"] = input(\"üåç Enter your AWS Region (default: us-west-2): \") or \"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instrumenting Bedrock clients\n",
    "\n",
    "Now, let's create a `boto3` session. This initiates a configured environment for interacting with AWS services. If you haven't yet configured `boto3` to use your credentials, please refer to the [official documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html). Or, if you have the AWS CLI, run `aws configure` from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clients created using this session configuration are currently uninstrumented. We'll make one for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uninstrumented_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instrument Bedrock with our OpenInference instrumentor. All Bedrock clients created after this call will automatically produce traces when calling `invoke_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "BedrockInstrumentor().instrument(skip_dep_check=True)\n",
    "instrumented_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calling the LLM and viewing OpenInference traces\n",
    "\n",
    "Calling `invoke_model` using the `uninstrumented_client` will produce no traces, but will show the output from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting attribute on ended span.\n",
      "Calling end() on an ended span.\n"
     ]
    },
    {
     "ename": "ResourceNotFoundException",
     "evalue": "An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: This model version has reached the end of its life. Please refer to the AWS documentation for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman: What is the 3rd month of the year in alphabetical order? Assistant:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens_to_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 1024}\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43muninstrumented_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manthropic.claude-v2:1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m response_body \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_body[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openinference/instrumentation/bedrock/__init__.py:208\u001b[0m, in \u001b[0;36m_model_invocation_wrapper.<locals>._invocation_wrapper.<locals>.instrumented_response\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     span\u001b[38;5;241m.\u001b[39mset_status(Status(StatusCode\u001b[38;5;241m.\u001b[39mERROR))\n\u001b[1;32m    207\u001b[0m     span\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Process the streaming response body\u001b[39;00m\n\u001b[1;32m    211\u001b[0m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m BufferedStreamingBody(\n\u001b[1;32m    212\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m_raw_stream, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m_content_length\n\u001b[1;32m    213\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openinference/instrumentation/bedrock/__init__.py:204\u001b[0m, in \u001b[0;36m_model_invocation_wrapper.<locals>._invocation_wrapper.<locals>.instrumented_response\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Execute the model invocation with proper error handling\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unwrapped_invoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     span\u001b[38;5;241m.\u001b[39mset_status(Status(StatusCode\u001b[38;5;241m.\u001b[39mERROR))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/botocore/client.py:602\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/botocore/client.py:1078\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m request_context\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1075\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code_override\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1076\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1077\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mResourceNotFoundException\u001b[0m: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: This model version has reached the end of its life. Please refer to the AWS documentation for more details."
     ]
    }
   ],
   "source": [
    "prompt = b\"\"\"{\"prompt\": \"Human: What is the 3rd month of the year in alphabetical order? Assistant:\", \"max_tokens_to_sample\": 1024}\"\"\"\n",
    "response = uninstrumented_client.invoke_model(modelId=\"anthropic.claude-v2:1\", body=prompt)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body[\"completion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM calls using the `instrumented_client` will print traces to the console! By configuring the `SpanProcessor` to export to a different OpenTelemetry collector, your OpenInference spans can be collected and analyzed to better understand the behavior of your LLM application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = instrumented_client.invoke_model(modelId=\"anthropic.claude-v2:1\", body=prompt)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body[\"completion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect all your Traces & Data\n",
    "\n",
    "Use the `instrumented_client` to collect all your traces; This example uses a set of trivia questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_questions = [\n",
    "    \"What is the only U.S. state that starts with two vowels?\",\n",
    "    \"What is the 3rd month of the year in alphabetical order?\",\n",
    "    \"What is the capital of Mongolia?\",\n",
    "    \"How many minutes are there in a leap year?\",\n",
    "    \"If a train leaves New York at 3 PM traveling west at 60 mph, and another leaves Chicago at 4 PM traveling east at 80 mph, at what time will they meet?\",\n",
    "    \"Which element has the chemical symbol 'Fe'?\",\n",
    "    \"What five-letter word becomes shorter when you add two letters to it?\",\n",
    "    \"What country has won the most FIFA World Cups?\",\n",
    "    \"If today is Wednesday, what day of the week will it be 100 days from now?\",\n",
    "    \"A farmer has 17 sheep and all but 9 run away. How many does he have left?\",\n",
    "]\n",
    "\n",
    "for i, question in enumerate(trivia_questions, start=1):\n",
    "    prompt_str = f\"\"\"\n",
    "{{\n",
    "    \"prompt\": \"Human: {question} Assistant:\",\n",
    "    \"max_tokens_to_sample\": 300\n",
    "}}\n",
    "\"\"\"\n",
    "    response = instrumented_client.invoke_model(\n",
    "        modelId=\"anthropic.claude-v2:1\",\n",
    "        body=prompt_str.encode(\"utf-8\"),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    print(f\"Q{i}: {question}\")\n",
    "    print(f\"A{i}: {response_body['completion'].strip()}\\n{'-' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup & Run your Eval\n",
    "\n",
    "After importing your traces as a dataframe, modify your columns to fit into your eval template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_template = \"\"\"You are given a question and an answer. You must determine whether the\n",
    "given answer correctly answers the question. Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {Question}\n",
    "    ************\n",
    "    [Answer]: {Answer}\n",
    "    [END DATA]\n",
    "Your response must be a single word, either \"correct\" or \"incorrect\",\n",
    "and should not contain any text or characters aside from that word.\n",
    "\"correct\" means that the question is correctly and fully answered by the answer.\n",
    "\"incorrect\" means that the question is not correctly or only partially answered by the\n",
    "answer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_df = px.Client().get_spans_dataframe(project_name=\"bedrock-tracing-and-evals-tutorial\")\n",
    "spans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = spans_df[[\"context.span_id\", \"attributes.input.value\", \"attributes.output.value\"]].copy()\n",
    "eval_df.set_index(\"context.span_id\", inplace=True)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_copy = eval_df.copy()\n",
    "evals_copy[\"attributes.input.value\"] = (\n",
    "    evals_copy[\"attributes.input.value\"]\n",
    "    .str.replace(r\"^Human: \", \"\", regex=True)\n",
    "    .str.replace(r\"Assistant:$\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "evals_copy = evals_copy.rename(\n",
    "    columns={\"attributes.input.value\": \"Question\", \"attributes.output.value\": \"Answer\"}\n",
    ")\n",
    "evals_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation import suppress_tracing\n",
    "\n",
    "from phoenix.evals import (\n",
    "    async_evaluate_dataframe,\n",
    "    create_classifier,\n",
    ")\n",
    "from phoenix.evals.llm import LLM\n",
    "\n",
    "llm = LLM(provider=\"openai\", model=\"gpt-4\")\n",
    "\n",
    "qa_correctness_eval = create_classifier(\n",
    "    name=\"qa_correctness\",\n",
    "    prompt_template=qa_template,\n",
    "    llm=llm,\n",
    "    choices={\"correct\": 1.0, \"incorrect\": 0.0},\n",
    ")\n",
    "with suppress_tracing():\n",
    "    Q_and_A_classifications = await async_evaluate_dataframe(\n",
    "        dataframe=evals_copy, evaluators=[qa_correctness_eval]\n",
    "    )\n",
    "Q_and_A_classifications.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Log your traces into Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals.utils import to_annotation_dataframe\n",
    "\n",
    "relevancy_eval_df = to_annotation_dataframe(dataframe=Q_and_A_classifications)\n",
    "\n",
    "await px.Client().annotations.log_span_annotations_dataframe(\n",
    "    dataframe=relevancy_eval_df,\n",
    "    annotator_kind=\"LLM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GIF showcasing what the phoenix UI will look like with all the traces & eval](https://storage.googleapis.com/arize-phoenix-assets/assets/gifs/bedrock_tracing_eval_medium.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about our instrumentation integrations, OpenInference can be found in our [documentation](https://arize.com/docs/phoenix/references/openinference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
