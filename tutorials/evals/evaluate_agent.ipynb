{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Evaluating an Agent</h1>\n",
    "\n",
    "\n",
    "\n",
    "## Install Dependencies, Import Libraries, Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai arize-phoenix openinference-instrumentation-openai python-dotenv duckdb \"openinference-instrumentation>=0.1.21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from phoenix.otel import register\n",
    "from opentelemetry.trace import StatusCode\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "import duckdb\n",
    "import json\n",
    "import os\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "from typing import Any, Dict\n",
    "\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from opentelemetry.trace import Status, StatusCode, set_tracer_provider\n",
    "\n",
    "from openinference.instrumentation import (\n",
    "    TracerProvider,\n",
    "    suppress_tracing,\n",
    ")\n",
    "from openinference.semconv.resource import ResourceAttributes\n",
    "import phoenix as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Phoenix Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = OpenAI()\n",
    "model = \"gpt-4o-mini\"\n",
    "project_name = \"github-1-15-2025-live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This will be replaced with the Phoenix register() call\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={ResourceAttributes.PROJECT_NAME: project_name})\n",
    "tracer_provider = TracerProvider(resource=resource)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "tracer = tracer_provider.get_tracer(__name__)\n",
    "\n",
    "session = px.launch_app()\n",
    "\n",
    "# Initialize OpenAI instrumentation\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_Number</th>\n",
       "      <th>SKU_Coded</th>\n",
       "      <th>Product_Class_Code</th>\n",
       "      <th>Sold_Date</th>\n",
       "      <th>Qty_Sold</th>\n",
       "      <th>Total_Sale_Value</th>\n",
       "      <th>On_Promo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1320</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>3</td>\n",
       "      <td>56.849998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2310</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3080</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2310</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4840</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store_Number  SKU_Coded  Product_Class_Code   Sold_Date  Qty_Sold  \\\n",
       "0          1320    6172800               22875  2021-11-02         3   \n",
       "1          2310    6172800               22875  2021-11-03         1   \n",
       "2          3080    6172800               22875  2021-11-03         1   \n",
       "3          2310    6172800               22875  2021-11-06         1   \n",
       "4          4840    6172800               22875  2021-11-07         1   \n",
       "\n",
       "   Total_Sale_Value  On_Promo  \n",
       "0         56.849998         0  \n",
       "1         18.950001         0  \n",
       "2         18.950001         0  \n",
       "3         18.950001         0  \n",
       "4         18.950001         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_sales_df = pd.read_parquet(\"https://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/llama-index/Store_Sales_Price_Elasticity_Promotions_Data.parquet\")\n",
    "store_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\"\n",
    "\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, columns=columns, table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "        table_name = \"sales\"\n",
    "        # Read the parquet file into a DuckDB table\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM store_sales_df\")\n",
    "        \n",
    "        print(store_sales_df.columns)\n",
    "        print(table_name)\n",
    "        sql_query = generate_sql_query(prompt, store_sales_df.columns, table_name)\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "        with tracer.start_as_current_span(\"execute_sql_query\", openinference_span_kind=\"chain\") as span:\n",
    "            span.set_input(value=sql_query)\n",
    "            \n",
    "            # Execute the SQL query\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_output(value=str(result))\n",
    "            span.set_status(StatusCode.OK)\n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    Store_Number  SKU_Coded  Product_Class_Code  Sold_Date  Qty_Sold  Total_Sale_Value  On_Promo\\n0           1320    6173050               22875 2021-11-01         1          4.990000         0\\n1           1320    6174250               22875 2021-11-01         1          0.890000         0\\n2           1320    6176200               22975 2021-11-01         2         99.980003         0\\n3           1320    6176800               22800 2021-11-01         1         14.970000         0\\n4           1320    6177250               22975 2021-11-01         1          6.890000         0\\n5           1320    6177300               22800 2021-11-01         1          9.990000         0\\n6           1320    6177350               22800 2021-11-01         2         16.980000         0\\n7           1320    6177700               22875 2021-11-01         1          3.190000         0\\n8           1320    6178000               22875 2021-11-01         2          6.380000         0\\n9           1320    6178250               22800 2021-11-01         1         16.590000         0\\n10          1320    6179250               24400 2021-11-01         1         14.990000         0\\n11          1320    6179300               22800 2021-11-01         2          9.980000         0\\n12          1320    6179400               24400 2021-11-01         2         29.980000         0\\n13          1320    6179450               24400 2021-11-01         1         14.990000         0\\n14          1320    6179500               24400 2021-11-01         1         14.990000         0\\n15          1320    6179750               22800 2021-11-01         2         39.980000         0\\n16          1320    6180550               22975 2021-11-01         1         15.990000         0\\n17          1320    6182050               22975 2021-11-01         1          7.990000         0\\n18          1320    6183750               22850 2021-11-01         3         38.970001         0\\n19          1320    6184100               22975 2021-11-01         3         59.970001         0\\n20          1320    6188550               22950 2021-11-01         2         15.980000         0\\n21          1320    6190050               24425 2021-11-01         5         19.950001         0\\n22          1320    6190150               24425 2021-11-01         1          8.990000         0\\n23          1320    6190200               24425 2021-11-01         1          8.990000         0\\n24          1320    6190250               24425 2021-11-01         1          7.990000         0\\n25          1320    6190350               22950 2021-11-01         1          6.990000         0\\n26          1320    6190400               22950 2021-11-01         1          6.990000         0\\n27          1320    6193750               22875 2021-11-01         1          6.990000         0\\n28          1320    6195350               24375 2021-11-01         1         16.990000         0\\n29          1320    6195800               22850 2021-11-01         3         25.719999         1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data = lookup_sales_data(\"Show me all the sales for store 1320 on November 1st, 2021\")\n",
    "example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")\n",
    "\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Generate a chart configuration based on this data: {data}\n",
    "    The goal is to show: {visualization_goal}\"\"\"\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "@tracer.chain()\n",
    "def create_chart(config: VisualizationConfig) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    prompt = f\"\"\"Write python code to create a chart based on the following configuration.\n",
    "    Only return the code, no other text.\n",
    "    config: {config}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code\n",
    "\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code = generate_visualization(example_data, \"A line chart of sales over each day in november.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool()\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Execute Python code in a restricted environment\"\"\"\n",
    "    # Create restricted globals/locals dictionaries with plotting libraries\n",
    "    restricted_globals = {\n",
    "        '__builtins__': {\n",
    "            'print': print,\n",
    "            'len': len,\n",
    "            'range': range,\n",
    "            'sum': sum,\n",
    "            'min': min,\n",
    "            'max': max,\n",
    "            'int': int, \n",
    "            'float': float,\n",
    "            'str': str,\n",
    "            'list': list,\n",
    "            'dict': dict,\n",
    "            'tuple': tuple,\n",
    "            'set': set,\n",
    "            'round': round,\n",
    "            '__import__': __import__,\n",
    "            'json': __import__('json')\n",
    "        },\n",
    "        'plt': __import__('matplotlib.pyplot'),\n",
    "        'pd': __import__('pandas'),\n",
    "        'np': __import__('numpy'),\n",
    "        'sns': __import__('seaborn')\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Execute code in restricted environment\n",
    "        exec_locals = {}\n",
    "        exec(code, restricted_globals, exec_locals)\n",
    "        \n",
    "        # Capture any printed output or return the plot\n",
    "        output = exec_locals.get('__builtins__', {}).get('_', '')\n",
    "        if 'plt' in exec_locals:\n",
    "            return exec_locals['plt']\n",
    "        \n",
    "        # Try to parse output as JSON before returning\n",
    "        return \"Code executed successfully\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 3: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    # Construct prompt based on analysis type and data subset\n",
    "    prompt = f\"\"\"Analyze the following data: {data}\n",
    "    Your job is to answer the following question: {prompt}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis = analyze_sales_data(\"What is the most popular product SKU?\", example_data)\n",
    "# analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\", \n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\n",
    "    #         \"name\": \"run_python_code\",\n",
    "    #         \"description\": \"Run Python code in a restricted environment\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"code\": {\"type\": \"string\", \"description\": \"The Python code to run.\"}\n",
    "    #             },\n",
    "    #             \"required\": [\"code\"]\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data, \n",
    "    \"generate_visualization\": generate_visualization,\n",
    "    # \"run_python_code\": run_python_code\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    for tool_call in tool_calls:\n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "                    \n",
    "        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    \n",
    "    \n",
    "    with tracer.start_as_current_span(\"AgentRun\", openinference_span_kind=\"agent\") as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret\n",
    "\n",
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "        print(\"Converted string message to list format\")\n",
    "    \n",
    "    # Check and add system prompt if needed\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\"}\n",
    "            messages.append(system_prompt)\n",
    "            print(\"Added system prompt to messages\")\n",
    "\n",
    "    while True:\n",
    "        # Router call span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\",\n",
    "            openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "            \n",
    "            if tool_calls:\n",
    "                # Tool calls span\n",
    "                print(\"Processing tool calls\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "\n",
    "                return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'Create a line chart showing sales in 2021'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Create a line chart showing sales in 2021'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: I have created the line chart showing the total sales value in 2021 based on the available data for November and December. The chart visualizes the sales performance during these two months. If you need any modifications or additional insights, let me know!\n",
      "<IPython.core.display.Markdown object>\n"
     ]
    }
   ],
   "source": [
    "ret = start_main_span([{\"role\": \"user\", \"content\": \"Create a line chart showing sales in 2021\"}])\n",
    "print(Markdown(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737590793.902275 17274972 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Processing questions:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'What was the most popular product SKU?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the most popular product SKU?'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  10%|‚ñà         | 1/10 [00:02<00:25,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The most popular product SKU was 6200700, with a total quantity sold of 52,262 units.\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'What was the total revenue across all stores?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the total revenue across all stores?'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  20%|‚ñà‚ñà        | 2/10 [00:05<00:19,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The total revenue across all stores was approximately $13,272,640.\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'Which store had the highest sales volume?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Which store had the highest sales volume?'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:14<00:39,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The store with the highest sales volume is Store Number 2970, with a total sales volume of 59,322.0.\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'Create a bar chart showing total sales by store'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Create a bar chart showing total sales by store'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:43<01:28, 14.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Error processing question: Create a bar chart showing total sales by store\n",
      "'run_python_code'\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'What percentage of items were sold on promotion?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What percentage of items were sold on promotion?'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:45<00:51, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: Approximately 62.56% of items were sold on promotion.\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'Plot daily sales volume over time'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Plot daily sales volume over time'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [09:15<12:00, 180.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Error processing question: Plot daily sales volume over time\n",
      "'run_python_code'\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'What was the average transaction value?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the average transaction value?'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [09:17<06:06, 122.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The average transaction value was approximately **$19.02**.\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'Create a box plot of transaction values'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Create a box plot of transaction values'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [09:28<02:53, 86.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: Create a box plot of transaction values\n",
      "Error code: 400 - {'error': {'message': \"Invalid 'messages[3].content': string too long. Expected a string with maximum length 1048576, but got a string with length 17447374 instead.\", 'type': 'invalid_request_error', 'param': 'messages[3].content', 'code': 'string_above_max_length'}}\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'Which products were frequently purchased together?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Which products were frequently purchased together?'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [09:36<01:01, 61.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: Which products were frequently purchased together?\n",
      "Error code: 400 - {'error': {'message': \"Invalid 'messages[3].content': string too long. Expected a string with maximum length 1048576, but got a string with length 11902599 instead.\", 'type': 'invalid_request_error', 'param': 'messages[3].content', 'code': 'string_above_max_length'}}\n",
      "Starting main span with messages: [{'role': 'user', 'content': 'Plot a line graph showing the sales trend over time with a 7-day moving average'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Plot a line graph showing the sales trend over time with a 7-day moving average'}]\n",
      "Added system prompt to messages\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [10:08<00:00, 60.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: Plot a line graph showing the sales trend over time with a 7-day moving average\n",
      "Error code: 400 - {'error': {'message': \"Invalid 'messages[3].content': string too long. Expected a string with maximum length 1048576, but got a string with length 70487394 instead.\", 'type': 'invalid_request_error', 'param': 'messages[3].content', 'code': 'string_above_max_length'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent_questions = [\n",
    "    \"What was the most popular product SKU?\",\n",
    "    \"What was the total revenue across all stores?\",\n",
    "    \"Which store had the highest sales volume?\",\n",
    "    \"Create a bar chart showing total sales by store\",\n",
    "    \"What percentage of items were sold on promotion?\",\n",
    "    \"Plot daily sales volume over time\", \n",
    "    \"What was the average transaction value?\",\n",
    "    \"Create a box plot of transaction values\",\n",
    "    \"Which products were frequently purchased together?\",\n",
    "    \"Plot a line graph showing the sales trend over time with a 7-day moving average\"\n",
    "]\n",
    "\n",
    "for question in tqdm(agent_questions, desc=\"Processing questions\"):\n",
    "    try:\n",
    "        ret = start_main_span([{\"role\": \"user\", \"content\": question}])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAIInstrumentor().uninstrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "from phoenix.evals import (\n",
    "    TOOL_CALLING_PROMPT_TEMPLATE, \n",
    "    llm_classify,\n",
    "    OpenAIModel\n",
    ")\n",
    "from phoenix.trace import SpanEvaluations\n",
    "from phoenix.experiments import run_experiment, evaluate_experiment\n",
    "from phoenix.trace.dsl import SpanQuery\n",
    "from phoenix.experiments.types import Example\n",
    "from phoenix.experiments.evaluators import create_evaluator\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_client = px.Client()\n",
    "eval_model = OpenAIModel(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Evals using LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>output_messages</th>\n",
       "      <th>tool_call</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d8d048cfadc1b8fb</th>\n",
       "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"Whi...</td>\n",
       "      <td>[{'tool': {'json_schema': '{\"type\": \"function\"...</td>\n",
       "      <td>[{'tool': {'json_schema': '{\"type\": \"function\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5eeb77eb2c180656</th>\n",
       "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"Whi...</td>\n",
       "      <td>[{'tool': {'json_schema': '{\"type\": \"function\"...</td>\n",
       "      <td>[{'tool': {'json_schema': '{\"type\": \"function\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243ffb56898e032c</th>\n",
       "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"Wha...</td>\n",
       "      <td>[{'tool': {'json_schema': '{\"type\": \"function\"...</td>\n",
       "      <td>[{'tool': {'json_schema': '{\"type\": \"function\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           question  \\\n",
       "context.span_id                                                       \n",
       "d8d048cfadc1b8fb  {\"messages\": [{\"role\": \"user\", \"content\": \"Whi...   \n",
       "5eeb77eb2c180656  {\"messages\": [{\"role\": \"user\", \"content\": \"Whi...   \n",
       "243ffb56898e032c  {\"messages\": [{\"role\": \"user\", \"content\": \"Wha...   \n",
       "\n",
       "                                                    output_messages  \\\n",
       "context.span_id                                                       \n",
       "d8d048cfadc1b8fb  [{'tool': {'json_schema': '{\"type\": \"function\"...   \n",
       "5eeb77eb2c180656  [{'tool': {'json_schema': '{\"type\": \"function\"...   \n",
       "243ffb56898e032c  [{'tool': {'json_schema': '{\"type\": \"function\"...   \n",
       "\n",
       "                                                          tool_call  \n",
       "context.span_id                                                      \n",
       "d8d048cfadc1b8fb  [{'tool': {'json_schema': '{\"type\": \"function\"...  \n",
       "5eeb77eb2c180656  [{'tool': {'json_schema': '{\"type\": \"function\"...  \n",
       "243ffb56898e032c  [{'tool': {'json_schema': '{\"type\": \"function\"...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = SpanQuery().where(\n",
    "    # Filter for the `RETRIEVER` span kind.\n",
    "    # The filter condition is a string of valid Python boolean expression.\n",
    "    \"span_kind == 'LLM'\",\n",
    ").select(\n",
    "    # Extract the span attribute `input.value` which contains the query for the\n",
    "    # retriever. Rename it as the `input` column in the output dataframe.\n",
    "    question=\"input.value\",\n",
    "    output_messages=\"llm.tools\"\n",
    "    \n",
    ")\n",
    "\n",
    "# The Phoenix Client can take this query and return the dataframe.\n",
    "tool_calls_df = px.Client().query_spans(query, project_name=project_name, timeout=None)\n",
    "tool_calls_df = tool_calls_df.dropna(subset=[\"output_messages\"])\n",
    "tool_calls_df[\"tool_call\"] = tool_calls_df[\"output_messages\"]\n",
    "\n",
    "tool_calls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc587dade9c4ae2bba1b5eea154ce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/3 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>execution_status</th>\n",
       "      <th>execution_seconds</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d8d048cfadc1b8fb</th>\n",
       "      <td>correct</td>\n",
       "      <td>The tools called include 'lookup_sales_data' t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>1.931483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5eeb77eb2c180656</th>\n",
       "      <td>correct</td>\n",
       "      <td>The tool call to 'lookup_sales_data' is approp...</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>2.468532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243ffb56898e032c</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>The chosen tools include 'lookup_sales_data' t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>2.350198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  \\\n",
       "context.span_id               \n",
       "d8d048cfadc1b8fb    correct   \n",
       "5eeb77eb2c180656    correct   \n",
       "243ffb56898e032c  incorrect   \n",
       "\n",
       "                                                        explanation  \\\n",
       "context.span_id                                                       \n",
       "d8d048cfadc1b8fb  The tools called include 'lookup_sales_data' t...   \n",
       "5eeb77eb2c180656  The tool call to 'lookup_sales_data' is approp...   \n",
       "243ffb56898e032c  The chosen tools include 'lookup_sales_data' t...   \n",
       "\n",
       "                 exceptions execution_status  execution_seconds  score  \n",
       "context.span_id                                                         \n",
       "d8d048cfadc1b8fb         []        COMPLETED           1.931483      1  \n",
       "5eeb77eb2c180656         []        COMPLETED           2.468532      1  \n",
       "243ffb56898e032c         []        COMPLETED           2.350198      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_eval = llm_classify(\n",
    "    dataframe = tool_calls_df,\n",
    "    template = TOOL_CALLING_PROMPT_TEMPLATE.template.replace(\"{tool_definitions}\", \"generate_visualization, lookup_sales_data, analyze_sales_data, run_python_code\"),\n",
    "    rails = ['correct', 'incorrect'],\n",
    "    model=eval_model,\n",
    "    provide_explanation=True\n",
    ")\n",
    "\n",
    "tool_call_eval['score'] = tool_call_eval.apply(lambda x: 1 if x['label']=='correct' else 0, axis=1)\n",
    "\n",
    "tool_call_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Tool Calling Eval\", dataframe=tool_call_eval),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling Evals using Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n",
      "üíæ Examples uploaded: http://localhost:6006/datasets/RGF0YXNldDox/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246MQ==\n"
     ]
    }
   ],
   "source": [
    "agent_tool_responses = {\n",
    "    \"What was the most popular product SKU?\": \"lookup_sales_data, analyze_sales_data\",\n",
    "    \"What was the total revenue across all stores?\": \"lookup_sales_data, analyze_sales_data\",\n",
    "    \"Which store had the highest sales volume?\": \"lookup_sales_data, analyze_sales_data\",\n",
    "    \"Create a bar chart showing total sales by store\": \"generate_visualization, lookup_sales_data, run_python_code\",\n",
    "    \"What percentage of items were sold on promotion?\": \"lookup_sales_data, analyze_sales_data\",\n",
    "    \"Plot daily sales volume over time\": \"generate_visualization, lookup_sales_data, run_python_code\", \n",
    "    \"What was the average transaction value?\": \"lookup_sales_data, analyze_sales_data\",\n",
    "    \"Create a box plot of transaction values\": \"generate_visualization, lookup_sales_data, run_python_code\",\n",
    "    \"Which products were frequently purchased together?\": \"lookup_sales_data, analyze_sales_data\",\n",
    "    \"Plot a line graph showing the sales trend over time with a 7-day moving average\": \"generate_visualization, lookup_sales_data, run_python_code\"\n",
    "}\n",
    "\n",
    "\n",
    "tool_calling_df = pd.DataFrame(agent_tool_responses.items(), columns=[\"question\", \"tool_calls\"])\n",
    "dataset = px_client.upload_dataset(dataframe=tool_calling_df, dataset_name=\"tool_calling_ground_truth\", input_keys=[\"question\"], output_keys=[\"tool_calls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_router_step(example: Example) -> str:\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": example.input.get(\"question\")})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    tool_calls = []\n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        tool_calls.append(tool_call.function.name)\n",
    "    return tool_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_match(expected: str, output: str) -> bool:\n",
    "    expected_tools = expected.get(\"tool_calls\").split(\", \")\n",
    "    return expected_tools == output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: http://localhost:6006/datasets/RGF0YXNldDox/experiments\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDox/compare?experimentId=RXhwZXJpbWVudDox\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c13e562b714960a2b5b716286eb657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running tasks |          | 0/10 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task runs completed.\n",
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97994c82b2f84450886fb009e6ce5dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/10 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDox/compare?experimentId=RXhwZXJpbWVudDox\n",
      "\n",
      "Experiment Summary (01/16/25 06:00 PM -0800)\n",
      "--------------------------------------------\n",
      "| evaluator   |   n |   n_scores |   avg_score |   n_labels | top_2_labels   |\n",
      "|:------------|----:|-----------:|------------:|-----------:|:---------------|\n",
      "| tools_match |  10 |         10 |           0 |         10 | {'False': 10}  |\n",
      "\n",
      "Tasks Summary (01/16/25 06:00 PM -0800)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|           10 |       10 |          0 |\n"
     ]
    }
   ],
   "source": [
    "experiment = run_experiment(dataset,\n",
    "                            run_router_step,\n",
    "                            evaluators=[tools_match],\n",
    "                            experiment_name=\"Tool Calling Eval\",\n",
    "                            experiment_description=\"Evaluating the tool calling step of the agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our SQL generation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing SQL lookup questions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:12<00:00,  1.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>expected_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the most popular product SKU?</td>\n",
       "      <td>SKU_Coded  Total_Quantity_Sold\\n0    620070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which store had the highest total sales value?</td>\n",
       "      <td>Store_Number  Total_Sales_Value\\n0         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many items were sold on promotion?</td>\n",
       "      <td>Total_Items_Sold_On_Promotion\\n0           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the average quantity sold per transac...</td>\n",
       "      <td>Average_Quantity_Sold_Per_Transaction\\n0   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which product class code generated the most re...</td>\n",
       "      <td>Product_Class_Code  Total_Revenue\\n0       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What day of the week had the highest sales vol...</td>\n",
       "      <td>Day_Of_Week  Total_Sales_Volume\\n0         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many unique stores made sales?</td>\n",
       "      <td>unique_stores\\n0             35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What was the highest single transaction value?</td>\n",
       "      <td>Highest_Single_Transaction_Value\\n0        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Which products were frequently sold together?</td>\n",
       "      <td>Product_A  Product_B  Frequency\\n0    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What's the trend in sales over time?</td>\n",
       "      <td>Sales_Month  Total_Quantity_Sold  Total_Sal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             What was the most popular product SKU?   \n",
       "1     Which store had the highest total sales value?   \n",
       "2             How many items were sold on promotion?   \n",
       "3  What was the average quantity sold per transac...   \n",
       "4  Which product class code generated the most re...   \n",
       "5  What day of the week had the highest sales vol...   \n",
       "6                 How many unique stores made sales?   \n",
       "7     What was the highest single transaction value?   \n",
       "8      Which products were frequently sold together?   \n",
       "9               What's the trend in sales over time?   \n",
       "\n",
       "                                     expected_result  \n",
       "0     SKU_Coded  Total_Quantity_Sold\\n0    620070...  \n",
       "1     Store_Number  Total_Sales_Value\\n0         ...  \n",
       "2     Total_Items_Sold_On_Promotion\\n0           ...  \n",
       "3     Average_Quantity_Sold_Per_Transaction\\n0   ...  \n",
       "4     Product_Class_Code  Total_Revenue\\n0       ...  \n",
       "5     Day_Of_Week  Total_Sales_Volume\\n0         ...  \n",
       "6                    unique_stores\\n0             35  \n",
       "7     Highest_Single_Transaction_Value\\n0        ...  \n",
       "8          Product_A  Product_B  Frequency\\n0    ...  \n",
       "9     Sales_Month  Total_Quantity_Sold  Total_Sal...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This step will be replaced by a human annotated set of ground truth data, instead of generated examples\n",
    "\n",
    "db_lookup_questions = [\n",
    "    \"What was the most popular product SKU?\",\n",
    "    \"Which store had the highest total sales value?\", \n",
    "    \"How many items were sold on promotion?\",\n",
    "    \"What was the average quantity sold per transaction?\",\n",
    "    \"Which product class code generated the most revenue?\",\n",
    "    \"What day of the week had the highest sales volume?\",\n",
    "    \"How many unique stores made sales?\",\n",
    "    \"What was the highest single transaction value?\",\n",
    "    \"Which products were frequently sold together?\",\n",
    "    \"What's the trend in sales over time?\"\n",
    "]\n",
    "\n",
    "expected_results = []\n",
    "\n",
    "for question in tqdm(db_lookup_questions, desc=\"Processing SQL lookup questions\"):\n",
    "    try:\n",
    "        with suppress_tracing():\n",
    "            expected_results.append(lookup_sales_data(question))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\")\n",
    "        print(e)\n",
    "        db_lookup_questions.remove(question)\n",
    "\n",
    "# Create a DataFrame with the questions\n",
    "questions_df = pd.DataFrame({\n",
    "    'question': db_lookup_questions,\n",
    "    'expected_result': expected_results\n",
    "})\n",
    "\n",
    "display(questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n",
      "üíæ Examples uploaded: http://localhost:6006/datasets/RGF0YXNldDoy/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246Mg==\n"
     ]
    }
   ],
   "source": [
    "dataset = px_client.upload_dataset(dataframe=questions_df, dataset_name=\"sales_db_lookup_questions\", input_keys=[\"question\"], output_keys=[\"expected_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_query(example: Example) -> str:\n",
    "    with suppress_tracing():\n",
    "        return lookup_sales_data(example.input.get(\"question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sql_result(output: str, expected: str) -> bool:    \n",
    "    # Extract just the numbers from both strings\n",
    "    result_nums = ''.join(filter(str.isdigit, output))\n",
    "    expected_nums = ''.join(filter(str.isdigit, expected.get(\"expected_result\")))\n",
    "    return result_nums == expected_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: http://localhost:6006/datasets/RGF0YXNldDoy/experiments\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDoy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955fd21e7af046fdac6b8442fbc1abc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running tasks |          | 0/10 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task runs completed.\n",
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c00473a77984c7e88a204a6825bfcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/10 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDoy\n",
      "\n",
      "Experiment Summary (01/16/25 06:02 PM -0800)\n",
      "--------------------------------------------\n",
      "| evaluator           |   n |   n_scores |   avg_score |   n_labels | top_2_labels            |\n",
      "|:--------------------|----:|-----------:|------------:|-----------:|:------------------------|\n",
      "| evaluate_sql_result |  10 |         10 |         0.8 |         10 | {'True': 8, 'False': 2} |\n",
      "\n",
      "Tasks Summary (01/16/25 06:02 PM -0800)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|           10 |       10 |          0 |\n"
     ]
    }
   ],
   "source": [
    "experiment = run_experiment(dataset,\n",
    "                            run_sql_query,\n",
    "                            evaluators=[evaluate_sql_result],\n",
    "                            experiment_name=\"SQL Query Eval\",\n",
    "                            experiment_description=\"Evaluating the SQL query generation step of the agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Python code generation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Processing code generation questions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:20<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n",
      "üíæ Examples uploaded: http://localhost:6006/datasets/RGF0YXNldDoz/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246Mw==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace this with a human annotated set of ground truth data, instead of generated examples\n",
    "\n",
    "code_generation_questions = [\n",
    "    \"Create a bar chart showing total sales by store\",\n",
    "    \"Plot daily sales volume over time\", \n",
    "    \"Plot a line graph showing the sales trend over time with a 7-day moving average\",\n",
    "    \"Create a histogram of quantities sold per transaction\",\n",
    "    \"Generate a pie chart showing sales distribution across product classes\",\n",
    "    \"Create a stacked bar chart showing promotional vs non-promotional sales by store\",\n",
    "    \"Generate a heatmap of sales by day of week and store number\",\n",
    "    \"Plot a line chart comparing sales trends between top 5 stores\"\n",
    "]\n",
    "\n",
    "example_data = []\n",
    "chart_configs = []\n",
    "for question in tqdm(code_generation_questions[:], desc=\"Processing code generation questions\"):\n",
    "    try:\n",
    "        with suppress_tracing():\n",
    "            example_data.append(lookup_sales_data(question))\n",
    "            chart_configs.append(json.dumps(extract_chart_config(example_data[-1], question)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\")\n",
    "        print(e)\n",
    "        code_generation_questions.remove(question)\n",
    "\n",
    "code_generation_df = pd.DataFrame({\n",
    "    'question': code_generation_questions,\n",
    "    'example_data': example_data,\n",
    "    'chart_configs': chart_configs\n",
    "})\n",
    "\n",
    "dataset = px_client.upload_dataset(dataframe=code_generation_df, dataset_name=\"code_generation_questions\", input_keys=[\"question\", \"example_data\", \"chart_configs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_generation(example: Example) -> str:\n",
    "    with suppress_tracing():\n",
    "        chart_config = extract_chart_config(data=example.input.get(\"example_data\"), visualization_goal=example.input.get(\"question\"))\n",
    "        code = generate_visualization(visualization_goal=example.input.get(\"question\"), \n",
    "                                    data=example.input.get(\"example_data\"))\n",
    "    \n",
    "    return {\"code\": code, \"chart_config\": chart_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_is_runnable(output: str) -> bool:\n",
    "    \"\"\"Check if the code is runnable\"\"\"\n",
    "    output = output.get(\"code\")\n",
    "    output = output.strip()\n",
    "    output = output.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    try:\n",
    "        exec(output)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chart_config(output: str, expected: str) -> bool:\n",
    "    return output.get(\"chart_config\") == expected.get(\"chart_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = run_experiment(dataset,\n",
    "                            run_code_generation,\n",
    "                            evaluators=[code_is_runnable, evaluate_chart_config],\n",
    "                            experiment_name=\"Code Generation Eval\",\n",
    "                            experiment_description=\"Evaluating the code generation step of the agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the agent path and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n",
      "üíæ Examples uploaded: http://localhost:6006/datasets/RGF0YXNldDoy/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246Mg==\n"
     ]
    }
   ],
   "source": [
    "# Replace this with a human annotated set of ground truth data, instead of generated examples\n",
    "\n",
    "convergence_questions = [\n",
    "    \"What was the average quantity sold per transaction?\",\n",
    "    \"What is the mean number of items per sale?\", \n",
    "    \"Calculate the typical quantity per transaction\",\n",
    "    \"Show me the average number of units sold in each transaction\",\n",
    "    \"What's the mean transaction size in terms of quantity?\",\n",
    "    \"On average, how many items were purchased per transaction?\",\n",
    "    \"What is the average basket size per sale?\",\n",
    "    \"Calculate the mean number of products per purchase\",\n",
    "    \"What's the typical number of units per order?\",\n",
    "    \"Find the average quantity of items in each transaction\",\n",
    "    \"What is the average number of products bought per purchase?\",\n",
    "    \"Tell me the mean quantity of items in a typical transaction\",\n",
    "    \"How many items does a customer buy on average per transaction?\",\n",
    "    \"What's the usual number of units in each sale?\",\n",
    "    \"Calculate the average basket quantity per order\",\n",
    "    \"What is the typical amount of products per transaction?\",\n",
    "    \"Show the mean number of items customers purchase per visit\",\n",
    "    \"What's the average quantity of units per shopping trip?\",\n",
    "    \"How many products do customers typically buy in one transaction?\",\n",
    "    \"What is the standard basket size in terms of quantity?\"\n",
    "]\n",
    "\n",
    "convergence_df = pd.DataFrame({\n",
    "    'question': convergence_questions\n",
    "})\n",
    "\n",
    "dataset = px_client.upload_dataset(dataframe=convergence_df, dataset_name=\"convergence_questions\", input_keys=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_message_steps(messages):\n",
    "    \"\"\"\n",
    "    Convert a list of message objects into a readable format that shows the steps taken.\n",
    "\n",
    "    Args:\n",
    "        messages (list): A list of message objects containing role, content, tool calls, etc.\n",
    "\n",
    "    Returns:\n",
    "        str: A readable string showing the steps taken.\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    for message in messages:\n",
    "        role = message.get(\"role\")\n",
    "        if role == \"user\":\n",
    "            steps.append(f\"User: {message.get('content')}\")\n",
    "        elif role == \"system\":\n",
    "            steps.append(\"System: Provided context\")\n",
    "        elif role == \"assistant\":\n",
    "            if message.get(\"tool_calls\"):\n",
    "                for tool_call in message[\"tool_calls\"]:\n",
    "                    tool_name = tool_call[\"function\"][\"name\"]\n",
    "                    steps.append(f\"Assistant: Called tool '{tool_name}'\")\n",
    "            else:\n",
    "                steps.append(f\"Assistant: {message.get('content')}\")\n",
    "        elif role == \"tool\":\n",
    "            steps.append(f\"Tool response: {message.get('content')}\")\n",
    "    \n",
    "    return \"\\n\".join(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_and_track_path(example: Example) -> str:\n",
    "    print(\"Starting main span with messages:\", example.input.get(\"question\"))\n",
    "    messages = [{\"role\": \"user\", \"content\": example.input.get(\"question\")}]\n",
    "    ret = run_agent_messages(messages)\n",
    "    return {\"path_length\": len(ret), \"messages\": format_message_steps(ret)}\n",
    "\n",
    "def run_agent_messages(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "        print(\"Converted string message to list format\")\n",
    "    \n",
    "    # Check and add system prompt if needed\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\"}\n",
    "            messages.append(system_prompt)\n",
    "            print(\"Added system prompt to messages\")\n",
    "\n",
    "    while True:\n",
    "        # Router call span\n",
    "        print(\"Starting router\")\n",
    "            \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "\n",
    "        messages.append(response.choices[0].message.model_dump())\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "        \n",
    "        if tool_calls:\n",
    "            # Tool calls span\n",
    "            print(\"Processing tool calls\")\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            messages = handle_tool_calls(tool_calls, messages)\n",
    "        else:\n",
    "            print(\"No tool calls, returning final response\")\n",
    "            return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: http://localhost:6006/datasets/RGF0YXNldDoy/experiments\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737727433.065744  608053 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2a9b18753f480898cb56d54e0c9933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running tasks |          | 0/20 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: What was the average quantity sold per transaction?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the average quantity sold per transaction?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What is the mean number of items per sale?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What is the mean number of items per sale?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Calculate the typical quantity per transaction\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Calculate the typical quantity per transaction'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Show me the average number of units sold in each transaction\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Show me the average number of units sold in each transaction'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What's the mean transaction size in terms of quantity?\n",
      "Running agent with messages: [{'role': 'user', 'content': \"What's the mean transaction size in terms of quantity?\"}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: On average, how many items were purchased per transaction?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'On average, how many items were purchased per transaction?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What is the average basket size per sale?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What is the average basket size per sale?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Calculate the mean number of products per purchase\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Calculate the mean number of products per purchase'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What's the typical number of units per order?\n",
      "Running agent with messages: [{'role': 'user', 'content': \"What's the typical number of units per order?\"}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Find the average quantity of items in each transaction\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Find the average quantity of items in each transaction'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_18242/2871659481.py\", line 4, in run_agent_and_track_path\n",
      "    ret = run_agent_messages(messages)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_18242/2871659481.py\", line 25, in run_agent_messages\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 859, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openinference/instrumentation/openai/_request.py\", line 272, in __call__\n",
      "    response = wrapped(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_base_client.py\", line 1064, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 128000 tokens. However, your messages resulted in 263486 tokens (263315 in the messages, 171 in the functions). Please reduce the length of the messages or functions.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTE=', repetition 1\n",
      "\u001b[0m\n",
      "Starting main span with messages: What is the average number of products bought per purchase?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What is the average number of products bought per purchase?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Tell me the mean quantity of items in a typical transaction\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Tell me the mean quantity of items in a typical transaction'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: How many items does a customer buy on average per transaction?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'How many items does a customer buy on average per transaction?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What's the usual number of units in each sale?\n",
      "Running agent with messages: [{'role': 'user', 'content': \"What's the usual number of units in each sale?\"}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Calculate the average basket quantity per order\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Calculate the average basket quantity per order'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_18242/2871659481.py\", line 4, in run_agent_and_track_path\n",
      "    ret = run_agent_messages(messages)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_18242/2871659481.py\", line 25, in run_agent_messages\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 859, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openinference/instrumentation/openai/_request.py\", line 272, in __call__\n",
      "    response = wrapped(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/openai/_base_client.py\", line 1064, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'messages[3].content': string too long. Expected a string with maximum length 1048576, but got a string with length 1203800 instead.\", 'type': 'invalid_request_error', 'param': 'messages[3].content', 'code': 'string_above_max_length'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTY=', repetition 1\n",
      "\u001b[0m\n",
      "Starting main span with messages: What is the typical amount of products per transaction?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What is the typical amount of products per transaction?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Show the mean number of items customers purchase per visit\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Show the mean number of items customers purchase per visit'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What's the average quantity of units per shopping trip?\n",
      "Running agent with messages: [{'role': 'user', 'content': \"What's the average quantity of units per shopping trip?\"}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: How many products do customers typically buy in one transaction?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'How many products do customers typically buy in one transaction?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What is the standard basket size in terms of quantity?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What is the standard basket size in terms of quantity?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "‚úÖ Task runs completed.\n",
      "\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDox\n",
      "\n",
      "Tasks Summary (01/24/25 09:05 AM -0500)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors | top_error                                                                                            |\n",
      "|-------------:|---------:|-----------:|:-----------------------------------------------------------------------------------------------------|\n",
      "|           20 |       20 |          2 | BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"This model\\'s maximum context length i |\n"
     ]
    }
   ],
   "source": [
    "experiment = run_experiment(dataset,\n",
    "                            run_agent_and_track_path,\n",
    "                            experiment_name=\"Convergence Eval\",\n",
    "                            experiment_description=\"Evaluating the convergence of the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "      <th>example_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjox</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: What was...</td>\n",
       "      <td>{'question': 'What was the average quantity so...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6MQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjoy</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: What is ...</td>\n",
       "      <td>{'question': 'What is the mean number of items...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6Mg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjoz</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: Calculat...</td>\n",
       "      <td>{'question': 'Calculate the typical quantity p...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6Mw==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjo0</th>\n",
       "      <td>BadRequestError('Error code: 400 - {\\'error\\':...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'question': 'Show me the average number of un...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6NA==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjo1</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: What's t...</td>\n",
       "      <td>{'question': 'What's the mean transaction size...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6NQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjo2</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: On avera...</td>\n",
       "      <td>{'question': 'On average, how many items were ...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6Ng==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjo3</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: What is ...</td>\n",
       "      <td>{'question': 'What is the average basket size ...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6Nw==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjo4</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: Calculat...</td>\n",
       "      <td>{'question': 'Calculate the mean number of pro...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6OA==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjo5</th>\n",
       "      <td>None</td>\n",
       "      <td>{'path_length': 5, 'messages': 'User: What's t...</td>\n",
       "      <td>{'question': 'What's the typical number of uni...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6OQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RXhwZXJpbWVudFJ1bjoxMA==</th>\n",
       "      <td>BadRequestError('Error code: 400 - {\\'error\\':...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'question': 'Find the average quantity of ite...</td>\n",
       "      <td>RGF0YXNldEV4YW1wbGU6MTA=</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      error  \\\n",
       "run_id                                                                        \n",
       "RXhwZXJpbWVudFJ1bjox                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjoy                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjoz                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjo0      BadRequestError('Error code: 400 - {\\'error\\':...   \n",
       "RXhwZXJpbWVudFJ1bjo1                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjo2                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjo3                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjo4                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjo5                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjoxMA==  BadRequestError('Error code: 400 - {\\'error\\':...   \n",
       "\n",
       "                                                                     output  \\\n",
       "run_id                                                                        \n",
       "RXhwZXJpbWVudFJ1bjox      {'path_length': 5, 'messages': 'User: What was...   \n",
       "RXhwZXJpbWVudFJ1bjoy      {'path_length': 5, 'messages': 'User: What is ...   \n",
       "RXhwZXJpbWVudFJ1bjoz      {'path_length': 5, 'messages': 'User: Calculat...   \n",
       "RXhwZXJpbWVudFJ1bjo0                                                   None   \n",
       "RXhwZXJpbWVudFJ1bjo1      {'path_length': 5, 'messages': 'User: What's t...   \n",
       "RXhwZXJpbWVudFJ1bjo2      {'path_length': 5, 'messages': 'User: On avera...   \n",
       "RXhwZXJpbWVudFJ1bjo3      {'path_length': 5, 'messages': 'User: What is ...   \n",
       "RXhwZXJpbWVudFJ1bjo4      {'path_length': 5, 'messages': 'User: Calculat...   \n",
       "RXhwZXJpbWVudFJ1bjo5      {'path_length': 5, 'messages': 'User: What's t...   \n",
       "RXhwZXJpbWVudFJ1bjoxMA==                                               None   \n",
       "\n",
       "                                                                      input  \\\n",
       "run_id                                                                        \n",
       "RXhwZXJpbWVudFJ1bjox      {'question': 'What was the average quantity so...   \n",
       "RXhwZXJpbWVudFJ1bjoy      {'question': 'What is the mean number of items...   \n",
       "RXhwZXJpbWVudFJ1bjoz      {'question': 'Calculate the typical quantity p...   \n",
       "RXhwZXJpbWVudFJ1bjo0      {'question': 'Show me the average number of un...   \n",
       "RXhwZXJpbWVudFJ1bjo1      {'question': 'What's the mean transaction size...   \n",
       "RXhwZXJpbWVudFJ1bjo2      {'question': 'On average, how many items were ...   \n",
       "RXhwZXJpbWVudFJ1bjo3      {'question': 'What is the average basket size ...   \n",
       "RXhwZXJpbWVudFJ1bjo4      {'question': 'Calculate the mean number of pro...   \n",
       "RXhwZXJpbWVudFJ1bjo5      {'question': 'What's the typical number of uni...   \n",
       "RXhwZXJpbWVudFJ1bjoxMA==  {'question': 'Find the average quantity of ite...   \n",
       "\n",
       "                                        example_id  \n",
       "run_id                                              \n",
       "RXhwZXJpbWVudFJ1bjox      RGF0YXNldEV4YW1wbGU6MQ==  \n",
       "RXhwZXJpbWVudFJ1bjoy      RGF0YXNldEV4YW1wbGU6Mg==  \n",
       "RXhwZXJpbWVudFJ1bjoz      RGF0YXNldEV4YW1wbGU6Mw==  \n",
       "RXhwZXJpbWVudFJ1bjo0      RGF0YXNldEV4YW1wbGU6NA==  \n",
       "RXhwZXJpbWVudFJ1bjo1      RGF0YXNldEV4YW1wbGU6NQ==  \n",
       "RXhwZXJpbWVudFJ1bjo2      RGF0YXNldEV4YW1wbGU6Ng==  \n",
       "RXhwZXJpbWVudFJ1bjo3      RGF0YXNldEV4YW1wbGU6Nw==  \n",
       "RXhwZXJpbWVudFJ1bjo4      RGF0YXNldEV4YW1wbGU6OA==  \n",
       "RXhwZXJpbWVudFJ1bjo5      RGF0YXNldEV4YW1wbGU6OQ==  \n",
       "RXhwZXJpbWVudFJ1bjoxMA==  RGF0YXNldEV4YW1wbGU6MTA=  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal path length is 5\n"
     ]
    }
   ],
   "source": [
    "outputs = experiment.as_dataframe()[\"output\"].to_dict().values()\n",
    "optimal_path_length = min(output.get('path_length') for output in outputs if output and output.get('path_length') is not None)\n",
    "print(f\"The optimal path length is {optimal_path_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_evaluator(name=\"Convergence Eval\", kind=\"CODE\")\n",
    "def evaluate_path_length(output: str) -> float:\n",
    "    if output and output.get(\"path_length\"):\n",
    "        return optimal_path_length/float(output.get(\"path_length\"))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1ef3879e2349d89d862e7481fb01a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/20 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDox\n",
      "\n",
      "Experiment Summary (01/24/25 09:09 AM -0500)\n",
      "--------------------------------------------\n",
      "| evaluator        |   n |   n_scores |   avg_score |\n",
      "|:-----------------|----:|-----------:|------------:|\n",
      "| Convergence Eval |  20 |         20 |         0.9 |\n",
      "\n",
      "Tasks Summary (01/24/25 09:05 AM -0500)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors | top_error                                                                                            |\n",
      "|-------------:|---------:|-----------:|:-----------------------------------------------------------------------------------------------------|\n",
      "|           20 |       20 |          2 | BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"This model\\'s maximum context length i |\n"
     ]
    }
   ],
   "source": [
    "experiment = evaluate_experiment(experiment,\n",
    "                            evaluators=[evaluate_path_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the evals into our experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a version of our agent that tracks all the necessary information for evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_messages(messages):\n",
    "    tool_calls = []\n",
    "    tool_responses = []\n",
    "    final_output = None\n",
    "\n",
    "    for i, message in enumerate(messages):\n",
    "        # Extract tool calls\n",
    "        if 'tool_calls' in message and message['tool_calls']:\n",
    "            for tool_call in message['tool_calls']:\n",
    "                tool_name = tool_call['function']['name']\n",
    "                tool_input = tool_call['function']['arguments']\n",
    "                tool_calls.append(tool_name)\n",
    "\n",
    "                # Prepare tool response structure with tool name and input\n",
    "                tool_responses.append({\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"tool_input\": tool_input,\n",
    "                    \"tool_response\": None\n",
    "                })\n",
    "\n",
    "        # Extract tool responses\n",
    "        if message['role'] == 'tool' and 'tool_call_id' in message:\n",
    "            for tool_response in tool_responses:\n",
    "                if message['tool_call_id'] in message.values():\n",
    "                    tool_response[\"tool_response\"] = message['content']\n",
    "\n",
    "        # Extract final output\n",
    "        if message['role'] == 'assistant' and not message.get('tool_calls') and not message.get('function_call'):\n",
    "            final_output = message['content']\n",
    "\n",
    "    result = {\n",
    "        \"tool_calls\": tool_calls,\n",
    "        \"tool_responses\": tool_responses,\n",
    "        \"final_output\": final_output,\n",
    "        \"unchanged_messages\": messages,\n",
    "        \"path_length\": len(messages)\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_and_track_path(example: Example) -> str:\n",
    "    print(\"Starting main span with messages:\", example.input.get(\"question\"))\n",
    "    messages = [{\"role\": \"user\", \"content\": example.input.get(\"question\")}]\n",
    "    ret = run_agent_messages(messages)\n",
    "    return process_messages(ret)\n",
    "\n",
    "def run_agent_messages(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "        print(\"Converted string message to list format\")\n",
    "    \n",
    "    # Check and add system prompt if needed\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\"}\n",
    "            messages.append(system_prompt)\n",
    "            print(\"Added system prompt to messages\")\n",
    "\n",
    "    while True:\n",
    "        # Router call span\n",
    "        print(\"Starting router\")\n",
    "            \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "\n",
    "        messages.append(response.choices[0].message.model_dump())\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "        \n",
    "        if tool_calls:\n",
    "            # Tool calls span\n",
    "            print(\"Processing tool calls\")\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            messages = handle_tool_calls(tool_calls, messages)\n",
    "        else:\n",
    "            print(\"No tool calls, returning final response\")\n",
    "            return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```sql\\nSELECT SKU_Coded, SUM(Qty_Sold) AS Total_Qty_Sold\\nFROM sales\\nGROUP BY SKU_Coded\\nORDER BY Total_Qty_Sold DESC\\nLIMIT 1;\\n```'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sql_query(\"What was the most popular product SKU?\", store_sales_df.columns, \"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What was the most popular product SKU?', 'sql_result': '   SKU_Coded  Total_Qty_Sold 0    6200700         52262.0', 'sql_generated': '```sql\\nSELECT SKU_Coded, SUM(Qty_Sold) AS Total_Qty_Sold\\nFROM sales\\nGROUP BY SKU_Coded\\nORDER BY Total_Qty_Sold DESC\\nLIMIT 1;\\n```'}, {'question': 'What was the total revenue across all stores?', 'sql_result': '   Total_Revenue 0   1.327264e+07', 'sql_generated': '```sql\\nSELECT SUM(Total_Sale_Value) AS Total_Revenue\\nFROM sales;\\n```'}, {'question': 'Which store had the highest sales volume?', 'sql_result': '   Store_Number  Total_Sales_Volume 0          2970             59322.0', 'sql_generated': '```sql\\nSELECT Store_Number, SUM(Total_Sale_Value) AS Total_Sales\\nFROM sales\\nGROUP BY Store_Number\\nORDER BY Total_Sales DESC\\nLIMIT 1;\\n```'}, {'question': 'Create a bar chart showing total sales by store', 'sql_result': '    Store_Number    Total_Sales 0            880  420302.088397 1           1650  580443.007953 2           4180  272208.118542 3            550  229727.498752 4           1100  497509.528013 5           3300  619660.167018 6           3190  335035.018792 7           2970  836341.327191 8           3740  359729.808228 9           2530  324046.518720 10          4400   95745.620250 11          1210  508393.767785 12           330  370503.687331 13          2750  453664.808068 14          1980  242290.828499 15          1760  350747.617798 16          3410  410567.848126 17           990  378433.018639 18          4730  239711.708869 19          4070  322307.968330 20          3080  495458.238811 21          2090  309996.247965 22          1320  592832.067579 23          2640  308990.318559 24          1540  427777.427815 25          4840  389056.668316 26          2860  132320.519487 27          2420  406715.767402 28           770  292968.918642 29          3520  145701.079372 30           660  343594.978075 31          3630  405034.547846 32          2310  412579.388504 33          2200  361173.288199 34          1870  401070.997685', 'sql_generated': '```sql\\nSELECT Store_Number, SUM(Total_Sale_Value) AS Total_Sales\\nFROM sales\\nGROUP BY Store_Number;\\n```'}, {'question': 'What percentage of items were sold on promotion?', 'sql_result': '   Promotion_Percentage 0              0.625596', 'sql_generated': \"```sql\\nSELECT \\n    (SUM(CASE WHEN On_Promo = 'Yes' THEN 1 ELSE 0 END) * 100.0 / COUNT(*)) AS Percentage_On_Promo\\nFROM \\n    sales;\\n```\"}, {'question': 'What was the average transaction value?', 'sql_result': '   Average_Transaction_Value 0                  19.018132', 'sql_generated': '```sql\\nSELECT AVG(Total_Sale_Value) AS Average_Transaction_Value\\nFROM sales;\\n```'}, {'question': 'Create a line chart showing sales in 2021', 'sql_result': '  sale_month  total_quantity_sold  total_sales_value 0 2021-11-01              43056.0      499984.428193 1 2021-12-01              75724.0      910982.118423', 'sql_generated': '```sql\\nSELECT MONTH(Sold_Date) AS Month, SUM(Total_Sale_Value) AS Total_Sales\\nFROM sales\\nWHERE YEAR(Sold_Date) = 2021\\nGROUP BY MONTH(Sold_Date)\\nORDER BY MONTH(Sold_Date);\\n```'}]\n"
     ]
    }
   ],
   "source": [
    "overall_experiment_questions = [\n",
    "    {\"question\": \"What was the most popular product SKU?\",  \"sql_result\": \"   SKU_Coded  Total_Qty_Sold 0    6200700         52262.0\"}, \n",
    "    {\"question\": \"What was the total revenue across all stores?\", \"sql_result\": \"   Total_Revenue 0   1.327264e+07\"},\n",
    "    {\"question\": \"Which store had the highest sales volume?\", \"sql_result\": \"   Store_Number  Total_Sales_Volume 0          2970             59322.0\"},\n",
    "    {\"question\": \"Create a bar chart showing total sales by store\", \"sql_result\": \"    Store_Number    Total_Sales 0            880  420302.088397 1           1650  580443.007953 2           4180  272208.118542 3            550  229727.498752 4           1100  497509.528013 5           3300  619660.167018 6           3190  335035.018792 7           2970  836341.327191 8           3740  359729.808228 9           2530  324046.518720 10          4400   95745.620250 11          1210  508393.767785 12           330  370503.687331 13          2750  453664.808068 14          1980  242290.828499 15          1760  350747.617798 16          3410  410567.848126 17           990  378433.018639 18          4730  239711.708869 19          4070  322307.968330 20          3080  495458.238811 21          2090  309996.247965 22          1320  592832.067579 23          2640  308990.318559 24          1540  427777.427815 25          4840  389056.668316 26          2860  132320.519487 27          2420  406715.767402 28           770  292968.918642 29          3520  145701.079372 30           660  343594.978075 31          3630  405034.547846 32          2310  412579.388504 33          2200  361173.288199 34          1870  401070.997685\"},\n",
    "    {\"question\": \"What percentage of items were sold on promotion?\", \"sql_result\": \"   Promotion_Percentage 0              0.625596\"},\n",
    "    {\"question\": \"What was the average transaction value?\", \"sql_result\": \"   Average_Transaction_Value 0                  19.018132\"},\n",
    "    {\"question\": \"Create a line chart showing sales in 2021\", \"sql_result\": \"  sale_month  total_quantity_sold  total_sales_value 0 2021-11-01              43056.0      499984.428193 1 2021-12-01              75724.0      910982.118423\"}\n",
    "]\n",
    "\n",
    "overall_experiment_questions[0][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[0][\"question\"], store_sales_df.columns, \"sales\")\n",
    "overall_experiment_questions[1][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[1][\"question\"], store_sales_df.columns, \"sales\")\n",
    "overall_experiment_questions[2][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[2][\"question\"], store_sales_df.columns, \"sales\")\n",
    "overall_experiment_questions[3][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[3][\"question\"], store_sales_df.columns, \"sales\")\n",
    "overall_experiment_questions[4][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[4][\"question\"], store_sales_df.columns, \"sales\")\n",
    "overall_experiment_questions[5][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[5][\"question\"], store_sales_df.columns, \"sales\")\n",
    "overall_experiment_questions[6][\"sql_generated\"] = generate_sql_query(overall_experiment_questions[6][\"question\"], store_sales_df.columns, \"sales\")\n",
    "\n",
    "print(overall_experiment_questions[6])\n",
    "\n",
    "# overall_experiment_df = pd.DataFrame(overall_experiment_questions)\n",
    "\n",
    "# dataset = px_client.upload_dataset(dataframe=overall_experiment_df, dataset_name=\"overall_experiment_questions_all\", input_keys=[\"question\"], output_keys=[\"sql_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Create a line chart showing sales in 2021', 'sql_result': '  sale_month  total_quantity_sold  total_sales_value 0 2021-11-01              43056.0      499984.428193 1 2021-12-01              75724.0      910982.118423', 'sql_generated': '```sql\\nSELECT MONTH(Sold_Date) AS Month, SUM(Total_Sale_Value) AS Total_Sales\\nFROM sales\\nWHERE YEAR(Sold_Date) = 2021\\nGROUP BY MONTH(Sold_Date)\\nORDER BY MONTH(Sold_Date);\\n```'}\n"
     ]
    }
   ],
   "source": [
    "print(overall_experiment_questions[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {'question': 'What was the most popular product SKU?', 'sql_result': '   SKU_Coded  Total_Qty_Sold 0    6200700         52262.0', 'sql_generated': '```sql\\nSELECT SKU_Coded, SUM(Qty_Sold) AS Total_Qty_Sold\\nFROM sales\\nGROUP BY SKU_Coded\\nORDER BY Total_Qty_Sold DESC\\nLIMIT 1;\\n```'},\n",
    "    {'question': 'What was the total revenue across all stores?', 'sql_result': '   Total_Revenue 0   1.327264e+07', 'sql_generated': '```sql\\nSELECT SUM(Total_Sale_Value) AS Total_Revenue\\nFROM sales;\\n```'},\n",
    "    {'question': 'Which store had the highest sales volume?', 'sql_result': '   Store_Number  Total_Sales_Volume 0          2970             59322.0', 'sql_generated': '```sql\\nSELECT Store_Number, SUM(Total_Sale_Value) AS Total_Sales_Volume\\nFROM sales\\nGROUP BY Store_Number\\nORDER BY Total_Sales_Volume DESC\\nLIMIT 1;\\n```'},\n",
    "    {'question': 'Create a bar chart showing total sales by store', 'sql_result': '    Store_Number    Total_Sales 0            880  420302.088397 1           1650  580443.007953 2           4180  272208.118542 3            550  229727.498752 4           1100  497509.528013 5           3300  619660.167018 6           3190  335035.018792 7           2970  836341.327191 8           3740  359729.808228 9           2530  324046.518720 10          4400   95745.620250 11          1210  508393.767785 12           330  370503.687331 13          2750  453664.808068 14          1980  242290.828499 15          1760  350747.617798 16          3410  410567.848126 17           990  378433.018639 18          4730  239711.708869 19          4070  322307.968330 20          3080  495458.238811 21          2090  309996.247965 22          1320  592832.067579 23          2640  308990.318559 24          1540  427777.427815 25          4840  389056.668316 26          2860  132320.519487 27          2420  406715.767402 28           770  292968.918642 29          3520  145701.079372 30           660  343594.978075 31          3630  405034.547846 32          2310  412579.388504 33          2200  361173.288199 34          1870  401070.997685', 'sql_generated': '```sql\\nSELECT Store_Number, SUM(Total_Sale_Value) AS Total_Sales\\nFROM sales\\nGROUP BY Store_Number;\\n```'},\n",
    "    {'question': 'What percentage of items were sold on promotion?', 'sql_result': '   Promotion_Percentage 0              0.625596', 'sql_generated': \"```sql\\nSELECT \\n    (SUM(CASE WHEN On_Promo = 'Yes' THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS Promotion_Percentage\\nFROM \\n    sales;\\n```\"},\n",
    "    {'question': 'What was the average transaction value?', 'sql_result': '   Average_Transaction_Value 0                  19.018132', 'sql_generated': '```sql\\nSELECT AVG(Total_Sale_Value) AS Average_Transaction_Value\\nFROM sales;\\n```'},\n",
    "    {'question': 'Create a line chart showing sales in 2021', 'sql_result': '  sale_month  total_quantity_sold  total_sales_value 0 2021-11-01              43056.0      499984.428193 1 2021-12-01              75724.0      910982.118423', 'sql_generated': '```sql\\nSELECT MONTH(Sold_Date) AS Month, SUM(Total_Sale_Value) AS Total_Sales\\nFROM sales\\nWHERE YEAR(Sold_Date) = 2021\\nGROUP BY MONTH(Sold_Date)\\nORDER BY MONTH(Sold_Date);\\n```'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLARITY_LLM_JUDGE_PROMPT = \"\"\"\n",
    "In this task, you will be presented with a query and an answer. Your objective is to evaluate the clarity \n",
    "of the answer in addressing the query. A clear response is one that is precise, coherent, and directly \n",
    "addresses the query without introducing unnecessary complexity or ambiguity. An unclear response is one \n",
    "that is vague, disorganized, or difficult to understand, even if it may be factually correct.\n",
    "\n",
    "Your response should be a single word: either \"clear\" or \"unclear,\" and it should not include any other \n",
    "text or characters. \"clear\" indicates that the answer is well-structured, easy to understand, and \n",
    "appropriately addresses the query. \"unclear\" indicates that the answer is ambiguous, poorly organized, or \n",
    "not effectively communicated. Please carefully consider the query and answer before determining your \n",
    "response.\n",
    "\n",
    "After analyzing the query and the answer, you must write a detailed explanation of your reasoning to \n",
    "justify why you chose either \"clear\" or \"unclear.\" Avoid stating the final label at the beginning of your \n",
    "explanation. Your reasoning should include specific points about how the answer does or does not meet the \n",
    "criteria for clarity.\n",
    "\n",
    "[BEGIN DATA]\n",
    "Query: {query}\n",
    "Answer: {response}\n",
    "[END DATA]\n",
    "Please analyze the data carefully and provide an explanation followed by your response.\n",
    "\n",
    "EXPLANATION: Provide your reasoning step by step, evaluating the clarity of the answer based on the query.\n",
    "LABEL: \"clear\" or \"unclear\"\n",
    "\"\"\"\n",
    "\n",
    "ENTITY_CORRECTNESS_LLM_JUDGE_PROMPT = \"\"\"\n",
    "In this task, you will be presented with a query and an answer. Your objective is to determine whether all \n",
    "the entities mentioned in the answer are correctly identified and accurately match those in the query. An \n",
    "entity refers to any specific person, place, organization, date, or other proper noun. Your evaluation \n",
    "should focus on whether the entities in the answer are correctly named and appropriately associated with \n",
    "the context in the query.\n",
    "\n",
    "Your response should be a single word: either \"correct\" or \"incorrect,\" and it should not include any \n",
    "other text or characters. \"correct\" indicates that all entities mentioned in the answer match those in the \n",
    "query and are properly identified. \"incorrect\" indicates that the answer contains errors or mismatches in \n",
    "the entities referenced compared to the query.\n",
    "\n",
    "After analyzing the query and the answer, you must write a detailed explanation of your reasoning to \n",
    "justify why you chose either \"correct\" or \"incorrect.\" Avoid stating the final label at the beginning of \n",
    "your explanation. Your reasoning should include specific points about how the entities in the answer do or \n",
    "do not match the entities in the query.\n",
    "\n",
    "[BEGIN DATA]\n",
    "Query: {query}\n",
    "Answer: {response}\n",
    "[END DATA]\n",
    "Please analyze the data carefully and provide an explanation followed by your response.\n",
    "\n",
    "EXPLANATION: Provide your reasoning step by step, evaluating whether the entities in the answer are \n",
    "correct and consistent with the query.\n",
    "LABEL: \"correct\" or \"incorrect\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an evaluation assistant evaluating questions and tool calls to\\ndetermine whether the tool called would answer the question. The tool\\ncalls have been generated by a separate agent, and chosen from the list of\\ntools provided below. It is your job to decide whether that agent chose\\nthe right tool to call.\\n\\n    [BEGIN DATA]\\n    ************\\n    [Question]: {question}\\n    ************\\n    [Tool Called]: {tool_call}\\n    [END DATA]\\n\\nYour response must be single word, either \"correct\" or \"incorrect\",\\nand should not contain any text or characters aside from that word.\\n\"incorrect\" means that the chosen tool would not answer the question,\\nthe tool includes information that is not presented in the question,\\nor that the tool signature includes parameter values that don\\'t match\\nthe formats specified in the tool signatures below.\\n\\n\"correct\" means the correct tool call was chosen, the correct parameters\\nwere extracted from the question, the tool call generated is runnable and correct,\\nand that no outside information not present in the question was used\\nin the generated question.\\n\\n    [Tool Definitions]: [{\"type\": \"function\", \"function\": {\"name\": \"lookup_sales_data\", \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\", \"parameters\": {\"type\": \"object\", \"properties\": {\"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}}, \"required\": [\"prompt\"]}}}, {\"type\": \"function\", \"function\": {\"name\": \"analyze_sales_data\", \"description\": \"Analyze sales data to extract insights\", \"parameters\": {\"type\": \"object\", \"properties\": {\"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool\\'s output.\"}, \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}}, \"required\": [\"data\", \"prompt\"]}}}, {\"type\": \"function\", \"function\": {\"name\": \"generate_visualization\", \"description\": \"Generate Python code to create data visualizations\", \"parameters\": {\"type\": \"object\", \"properties\": {\"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool\\'s output.\"}, \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}}, \"required\": [\"data\", \"visualization_goal\"]}}}]\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOL_CALLING_PROMPT_TEMPLATE.template.replace(\"{tool_definitions}\", json.dumps(tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_calling_eval(input: str, output: str) -> float:\n",
    "    function_calls = output.get(\"tool_calls\")\n",
    "    if function_calls:\n",
    "        eval_df = pd.DataFrame({\n",
    "            \"question\": [input.get(\"question\")] * len(function_calls),\n",
    "            \"tool_call\": function_calls\n",
    "        })\n",
    "            \n",
    "        tool_call_eval = llm_classify(\n",
    "            dataframe = eval_df,\n",
    "            template = TOOL_CALLING_PROMPT_TEMPLATE.template.replace(\"{tool_definitions}\", json.dumps(tools).replace(\"{\", '\"').replace(\"}\", '\"')),\n",
    "            rails = ['correct', 'incorrect'],\n",
    "            model=eval_model,\n",
    "            provide_explanation=True\n",
    "        )\n",
    "\n",
    "        tool_call_eval['score'] = tool_call_eval.apply(lambda x: 1 if x['label']=='correct' else 0, axis=1)\n",
    "        return tool_call_eval['score'].mean()\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def code_is_runnable(output: str) -> bool:\n",
    "    \"\"\"Check if the code is runnable\"\"\"\n",
    "    generated_code = output.get(\"tool_responses\")\n",
    "    if not generated_code:\n",
    "        return True\n",
    "    \n",
    "    # Find first lookup_sales_data response\n",
    "    generated_code = next((r for r in generated_code if r.get(\"tool_name\") == \"generate_visualization\"), None)\n",
    "    if not generated_code:\n",
    "        return True\n",
    "        \n",
    "    # Get the first response\n",
    "    generated_code = generated_code.get(\"tool_response\", \"\")\n",
    "    generated_code = generated_code.strip()\n",
    "    generated_code = generated_code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    try:\n",
    "        exec(generated_code)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    \n",
    "def evaluate_sql_result(output, expected) -> bool:    \n",
    "    sql_result = output.get(\"tool_responses\")\n",
    "    if not sql_result:\n",
    "        return True\n",
    "    \n",
    "    # Find first lookup_sales_data response\n",
    "    sql_result = next((r for r in sql_result if r.get(\"tool_name\") == \"lookup_sales_data\"), None)\n",
    "    if not sql_result:\n",
    "        return True\n",
    "        \n",
    "    # Get the first response\n",
    "    sql_result = sql_result.get(\"tool_response\", \"\")\n",
    "\n",
    "    # Extract just the numbers from both strings\n",
    "    result_nums = ''.join(filter(str.isdigit, sql_result))\n",
    "    expected_nums = ''.join(filter(str.isdigit, expected.get(\"sql_result\")))\n",
    "    return result_nums == expected_nums\n",
    "\n",
    "def evaluate_clarity(output: str, input: str) -> bool:\n",
    "    df = pd.DataFrame({\"query\": [input.get(\"question\")], \"response\": [output.get(\"final_output\")]})\n",
    "    response = llm_classify(\n",
    "        dataframe=df,\n",
    "        template=CLARITY_LLM_JUDGE_PROMPT,\n",
    "        rails=[\"clear\", \"unclear\"],\n",
    "        model=eval_model,\n",
    "        provide_explanation=True\n",
    "    )\n",
    "    return response['label'] == 'clear'\n",
    "    \n",
    "def evaluate_entity_correctness(output: str, input: str) -> bool:\n",
    "    df = pd.DataFrame({\"query\": [input.get(\"question\")], \"response\": [output.get(\"final_output\")]})\n",
    "    response = llm_classify(\n",
    "        dataframe=df,\n",
    "        template=ENTITY_CORRECTNESS_LLM_JUDGE_PROMPT,\n",
    "        rails=[\"correct\", \"incorrect\"],\n",
    "        model=eval_model,\n",
    "        provide_explanation=True\n",
    "    )\n",
    "    return response['label'] == 'correct'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: http://localhost:6006/datasets/RGF0YXNldDo4/experiments\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNQ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f549cf71b1e9434b988915949913d318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running tasks |          | 0/6 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: What was the most popular product SKU?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the most popular product SKU?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What was the total revenue across all stores?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the total revenue across all stores?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Which store had the highest sales volume?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Which store had the highest sales volume?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: Create a bar chart showing total sales by store\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Create a bar chart showing total sales by store'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What percentage of items were sold on promotion?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What percentage of items were sold on promotion?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Starting main span with messages: What was the average transaction value?\n",
      "Running agent with messages: [{'role': 'user', 'content': 'What was the average transaction value?'}]\n",
      "Added system prompt to messages\n",
      "Starting router\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "‚úÖ Task runs completed.\n",
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd35d9bc2874530ae4edc4ac2d588db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/30 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb9e6bc2b3a492ab525cd405ebc1cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3fb7a4c6e74d469fe269ea5f5bd3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce824a6c7d4f4f5fa101220e1c1cabbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152f2ca637294ac2a54d6a118b8819d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b973ab8f93204466889a017dd42582ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a54a04cc2ae433aab08ce3a1dcf3dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e47e45f0b45405396fd7ae07d5b0eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7feea2d6d0de41c2919de9145f8f12c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n",
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc99cc85e1ea43418cc30a5232430599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c2495b6f144e16b0299105c6404ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/2 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add2a29ed6fb4451abadbf32a6b72368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1d2fe18f374322bb8bb2b83c71263a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e28d00e5944e5f98ccfd180a57d689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2178e0f7a64fcca0057a1faf80243e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22114dafa374cdf928f8a4ffe39d116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b918ac693a174ecb9ca93c9f654b9878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6df13de3914183ae71c43a828b0ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718080da4f374311b52ad96bd25ecb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/1 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/phoenix/experiments/evaluators/utils.py:229: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return EvaluationResult(score=float(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://localhost:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNQ==\n",
      "\n",
      "Experiment Summary (01/24/25 10:29 AM -0500)\n",
      "--------------------------------------------\n",
      "| evaluator                   |   n |   n_scores |   avg_score |   n_labels | top_2_labels            |\n",
      "|:----------------------------|----:|-----------:|------------:|-----------:|:------------------------|\n",
      "| code_is_runnable            |   6 |          6 |    0.833333 |          6 | {'True': 5, 'False': 1} |\n",
      "| evaluate_clarity            |   6 |          6 |    1        |          0 |                         |\n",
      "| evaluate_entity_correctness |   6 |          6 |    1        |          0 |                         |\n",
      "| evaluate_sql_result         |   6 |          6 |    0.666667 |          6 | {'True': 4, 'False': 2} |\n",
      "| function_calling_eval       |   6 |          6 |    0.916667 |          0 |                         |\n",
      "\n",
      "Tasks Summary (01/24/25 10:28 AM -0500)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|            6 |        6 |          0 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_overall_experiment(example: Example) -> str:\n",
    "    with suppress_tracing():\n",
    "        return run_agent_and_track_path(example)\n",
    "\n",
    "experiment = run_experiment(dataset,\n",
    "                            run_overall_experiment,\n",
    "                            evaluators=[function_calling_eval, evaluate_sql_result, evaluate_clarity, evaluate_entity_correctness, code_is_runnable],\n",
    "                            experiment_name=\"Overall Experiment\",\n",
    "                            experiment_description=\"Evaluating the overall experiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
