{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <p style=\"text-align:center\">\n",
                "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
                "        <br>\n",
                "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
                "        |\n",
                "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
                "        |\n",
                "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
                "    </p>\n",
                "</center>\n",
                "<h1 align=\"center\">Code Readability Evals</h1>\n",
                "\n",
                "Arize provides tooling to evaluate LLM applications, including tools to determine the readability or unreadability of code generated by LLM applications.\n",
                "\n",
                "The purpose of this notebook is:\n",
                "\n",
                "- to evaluate the performance of an LLM-assisted approach to classifying\n",
                "  generated code as readable or unreadable using datasets with ground-truth\n",
                "  labels\n",
                "- to provide an experimental framework for users to iterate and improve on the default classification template.\n",
                "\n",
                "## Install Dependencies and Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": [
                "#####################\n",
                "## N_EVAL_SAMPLE_SIZE\n",
                "#####################\n",
                "# Eval sample size determines the run time\n",
                "# 100 samples: GPT-4 ~ 80 sec / GPT-3.5 ~ 40 sec\n",
                "# 1,000 samples: GPT-4 ~15-17 min / GPT-3.5 ~ 6-7min (depending on retries)\n",
                "# 10,000 samples GPT-4 ~170 min / GPT-3.5 ~ 70min\n",
                "N_EVAL_SAMPLE_SIZE = 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -qq \"arize-phoenix-evals>=0.0.2\" ipython matplotlib pycm scikit-learn tiktoken nest_asyncio"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "‚ÑπÔ∏è To enable async request submission in notebook environments like Jupyter or Google Colab, optionally use `nest_asyncio`. `nest_asyncio` globally patches `asyncio` to enable event loops to be re-entrant. This is not required for non-notebook environments.\n",
                "\n",
                "Without `nest_asyncio`, eval submission can be much slower, depending on your organization's rate limits. Speed increases of about 5x are typical."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nest_asyncio\n",
                "\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import openai\n",
                "import pandas as pd\n",
                "from phoenix.evals import (\n",
                "    CODE_READABILITY_PROMPT_RAILS_MAP,\n",
                "    CODE_READABILITY_PROMPT_TEMPLATE,\n",
                "    OpenAIModel,\n",
                "    download_benchmark_dataset,\n",
                "    llm_classify,\n",
                ")\n",
                "from pycm import ConfusionMatrix\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "pd.set_option(\"display.max_colwidth\", None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download Benchmark Dataset\n",
                "\n",
                "We'll evaluate the evaluation system consisting of an LLM model and settings in\n",
                "addition to an evaluation prompt template against a benchmark datasets of\n",
                "readable and unreadable code with ground-truth labels. Currently supported\n",
                "datasets for this task include:\n",
                "\n",
                "- openai_humaneval_with_readability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Unnamed: 0</th>\n",
                            "      <th>task_id</th>\n",
                            "      <th>prompt</th>\n",
                            "      <th>canonical_solution</th>\n",
                            "      <th>test</th>\n",
                            "      <th>entry_point</th>\n",
                            "      <th>readable</th>\n",
                            "      <th>solution</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>HumanEval/0</td>\n",
                            "      <td>from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -&gt; bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n</td>\n",
                            "      <td>for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance &lt; threshold:\\n                    return True\\n\\n    return False\\n</td>\n",
                            "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n</td>\n",
                            "      <td>has_close_elements</td>\n",
                            "      <td>True</td>\n",
                            "      <td>for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance &lt; threshold:\\n                    return True\\n\\n    return False\\n</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>HumanEval/1</td>\n",
                            "      <td>from typing import List\\n\\n\\ndef separate_paren_groups(paren_string: str) -&gt; List[str]:\\n    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\\n    separate those group into separate strings and return the list of those.\\n    Separate groups are balanced (each open brace is properly closed) and not nested within each other\\n    Ignore any spaces in the input string.\\n    &gt;&gt;&gt; separate_paren_groups('( ) (( )) (( )( ))')\\n    ['()', '(())', '(()())']\\n    \"\"\"\\n</td>\n",
                            "      <td>result = []\\n    current_string = []\\n    current_depth = 0\\n\\n    for c in paren_string:\\n        if c == '(':\\n            current_depth += 1\\n            current_string.append(c)\\n        elif c == ')':\\n            current_depth -= 1\\n            current_string.append(c)\\n\\n            if current_depth == 0:\\n                result.append(''.join(current_string))\\n                current_string.clear()\\n\\n    return result\\n</td>\n",
                            "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate('(()()) ((())) () ((())()())') == [\\n        '(()())', '((()))', '()', '((())()())'\\n    ]\\n    assert candidate('() (()) ((())) (((())))') == [\\n        '()', '(())', '((()))', '(((())))'\\n    ]\\n    assert candidate('(()(())((())))') == [\\n        '(()(())((())))'\\n    ]\\n    assert candidate('( ) (( )) (( )( ))') == ['()', '(())', '(()())']\\n</td>\n",
                            "      <td>separate_paren_groups</td>\n",
                            "      <td>True</td>\n",
                            "      <td>result = []\\n    current_string = []\\n    current_depth = 0\\n\\n    for c in paren_string:\\n        if c == '(':\\n            current_depth += 1\\n            current_string.append(c)\\n        elif c == ')':\\n            current_depth -= 1\\n            current_string.append(c)\\n\\n            if current_depth == 0:\\n                result.append(''.join(current_string))\\n                current_string.clear()\\n\\n    return result\\n</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2</td>\n",
                            "      <td>HumanEval/2</td>\n",
                            "      <td>\\n\\ndef truncate_number(number: float) -&gt; float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number.\\n    &gt;&gt;&gt; truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n</td>\n",
                            "      <td>return number % 1.0\\n</td>\n",
                            "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate(3.5) == 0.5\\n    assert abs(candidate(1.33) - 0.33) &lt; 1e-6\\n    assert abs(candidate(123.456) - 0.456) &lt; 1e-6\\n</td>\n",
                            "      <td>truncate_number</td>\n",
                            "      <td>False</td>\n",
                            "      <td>return((lambda x: (lambda y: y(x))(lambda f: (lambda x: f(lambda v: x(x)(v)))(lambda y: f(lambda u: y(y)(u)))))(lambda f: (lambda x: f(lambda v: x(x)(v)))(lambda y: f(lambda u: y(y)(u))))(lambda f: lambda x: x if x == 0 else f(x - 1) + 1)(number % 1.0))</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>3</td>\n",
                            "      <td>HumanEval/3</td>\n",
                            "      <td>from typing import List\\n\\n\\ndef below_zero(operations: List[int]) -&gt; bool:\\n    \"\"\" You're given a list of deposit and withdrawal operations on a bank account that starts with\\n    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\\n    at that point function should return True. Otherwise it should return False.\\n    &gt;&gt;&gt; below_zero([1, 2, 3])\\n    False\\n    &gt;&gt;&gt; below_zero([1, 2, -4, 5])\\n    True\\n    \"\"\"\\n</td>\n",
                            "      <td>balance = 0\\n\\n    for op in operations:\\n        balance += op\\n        if balance &lt; 0:\\n            return True\\n\\n    return False\\n</td>\n",
                            "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([]) == False\\n    assert candidate([1, 2, -3, 1, 2, -3]) == False\\n    assert candidate([1, 2, -4, 5, 6]) == True\\n    assert candidate([1, -1, 2, -2, 5, -5, 4, -4]) == False\\n    assert candidate([1, -1, 2, -2, 5, -5, 4, -5]) == True\\n    assert candidate([1, -2, 2, -2, 5, -5, 4, -4]) == True\\n</td>\n",
                            "      <td>below_zero</td>\n",
                            "      <td>True</td>\n",
                            "      <td>balance = 0\\n\\n    for op in operations:\\n        balance += op\\n        if balance &lt; 0:\\n            return True\\n\\n    return False\\n</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>4</td>\n",
                            "      <td>HumanEval/4</td>\n",
                            "      <td>from typing import List\\n\\n\\ndef mean_absolute_deviation(numbers: List[float]) -&gt; float:\\n    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\\n    around the mean of this dataset.\\n    Mean Absolute Deviation is the average absolute difference between each\\n    element and a centerpoint (mean in this case):\\n    MAD = average | x - x_mean |\\n    &gt;&gt;&gt; mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\\n    1.0\\n    \"\"\"\\n</td>\n",
                            "      <td>mean = sum(numbers) / len(numbers)\\n    return sum(abs(x - mean) for x in numbers) / len(numbers)\\n</td>\n",
                            "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert abs(candidate([1.0, 2.0, 3.0]) - 2.0/3.0) &lt; 1e-6\\n    assert abs(candidate([1.0, 2.0, 3.0, 4.0]) - 1.0) &lt; 1e-6\\n    assert abs(candidate([1.0, 2.0, 3.0, 4.0, 5.0]) - 6.0/5.0) &lt; 1e-6\\n\\n</td>\n",
                            "      <td>mean_absolute_deviation</td>\n",
                            "      <td>True</td>\n",
                            "      <td>mean = sum(numbers) / len(numbers)\\n    return sum(abs(x - mean) for x in numbers) / len(numbers)\\n</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   Unnamed: 0      task_id  \\\n",
                            "0           0  HumanEval/0   \n",
                            "1           1  HumanEval/1   \n",
                            "2           2  HumanEval/2   \n",
                            "3           3  HumanEval/3   \n",
                            "4           4  HumanEval/4   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  prompt  \\\n",
                            "0                                                                                                                                                                from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n   \n",
                            "1  from typing import List\\n\\n\\ndef separate_paren_groups(paren_string: str) -> List[str]:\\n    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\\n    separate those group into separate strings and return the list of those.\\n    Separate groups are balanced (each open brace is properly closed) and not nested within each other\\n    Ignore any spaces in the input string.\\n    >>> separate_paren_groups('( ) (( )) (( )( ))')\\n    ['()', '(())', '(()())']\\n    \"\"\"\\n   \n",
                            "2                                                                                                                                                                                 \\n\\ndef truncate_number(number: float) -> float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number.\\n    >>> truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n   \n",
                            "3                                                           from typing import List\\n\\n\\ndef below_zero(operations: List[int]) -> bool:\\n    \"\"\" You're given a list of deposit and withdrawal operations on a bank account that starts with\\n    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\\n    at that point function should return True. Otherwise it should return False.\\n    >>> below_zero([1, 2, 3])\\n    False\\n    >>> below_zero([1, 2, -4, 5])\\n    True\\n    \"\"\"\\n   \n",
                            "4                                                                             from typing import List\\n\\n\\ndef mean_absolute_deviation(numbers: List[float]) -> float:\\n    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\\n    around the mean of this dataset.\\n    Mean Absolute Deviation is the average absolute difference between each\\n    element and a centerpoint (mean in this case):\\n    MAD = average | x - x_mean |\\n    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\\n    1.0\\n    \"\"\"\\n   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                     canonical_solution  \\\n",
                            "0                                                                                                                                                                                      for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n   \n",
                            "1      result = []\\n    current_string = []\\n    current_depth = 0\\n\\n    for c in paren_string:\\n        if c == '(':\\n            current_depth += 1\\n            current_string.append(c)\\n        elif c == ')':\\n            current_depth -= 1\\n            current_string.append(c)\\n\\n            if current_depth == 0:\\n                result.append(''.join(current_string))\\n                current_string.clear()\\n\\n    return result\\n   \n",
                            "2                                                                                                                                                                                                                                                                                                                                                                                                                                 return number % 1.0\\n   \n",
                            "3                                                                                                                                                                                                                                                                                                               balance = 0\\n\\n    for op in operations:\\n        balance += op\\n        if balance < 0:\\n            return True\\n\\n    return False\\n   \n",
                            "4                                                                                                                                                                                                                                                                                                                                                   mean = sum(numbers) / len(numbers)\\n    return sum(abs(x - mean) for x in numbers) / len(numbers)\\n   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   test  \\\n",
                            "0  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n   \n",
                            "1                                                                                          \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate('(()()) ((())) () ((())()())') == [\\n        '(()())', '((()))', '()', '((())()())'\\n    ]\\n    assert candidate('() (()) ((())) (((())))') == [\\n        '()', '(())', '((()))', '(((())))'\\n    ]\\n    assert candidate('(()(())((())))') == [\\n        '(()(())((())))'\\n    ]\\n    assert candidate('( ) (( )) (( )( ))') == ['()', '(())', '(()())']\\n   \n",
                            "2                                                                                                                                                                                                                                                                                                                                      \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate(3.5) == 0.5\\n    assert abs(candidate(1.33) - 0.33) < 1e-6\\n    assert abs(candidate(123.456) - 0.456) < 1e-6\\n   \n",
                            "3                                                                                                                                             \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([]) == False\\n    assert candidate([1, 2, -3, 1, 2, -3]) == False\\n    assert candidate([1, 2, -4, 5, 6]) == True\\n    assert candidate([1, -1, 2, -2, 5, -5, 4, -4]) == False\\n    assert candidate([1, -1, 2, -2, 5, -5, 4, -5]) == True\\n    assert candidate([1, -2, 2, -2, 5, -5, 4, -4]) == True\\n   \n",
                            "4                                                                                                                                                                                                                                                                      \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert abs(candidate([1.0, 2.0, 3.0]) - 2.0/3.0) < 1e-6\\n    assert abs(candidate([1.0, 2.0, 3.0, 4.0]) - 1.0) < 1e-6\\n    assert abs(candidate([1.0, 2.0, 3.0, 4.0, 5.0]) - 6.0/5.0) < 1e-6\\n\\n   \n",
                            "\n",
                            "               entry_point  readable  \\\n",
                            "0       has_close_elements      True   \n",
                            "1    separate_paren_groups      True   \n",
                            "2          truncate_number     False   \n",
                            "3               below_zero      True   \n",
                            "4  mean_absolute_deviation      True   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                               solution  \n",
                            "0                                                                                                                                                                                      for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n  \n",
                            "1      result = []\\n    current_string = []\\n    current_depth = 0\\n\\n    for c in paren_string:\\n        if c == '(':\\n            current_depth += 1\\n            current_string.append(c)\\n        elif c == ')':\\n            current_depth -= 1\\n            current_string.append(c)\\n\\n            if current_depth == 0:\\n                result.append(''.join(current_string))\\n                current_string.clear()\\n\\n    return result\\n  \n",
                            "2                                                                                                                                                                                         return((lambda x: (lambda y: y(x))(lambda f: (lambda x: f(lambda v: x(x)(v)))(lambda y: f(lambda u: y(y)(u)))))(lambda f: (lambda x: f(lambda v: x(x)(v)))(lambda y: f(lambda u: y(y)(u))))(lambda f: lambda x: x if x == 0 else f(x - 1) + 1)(number % 1.0))  \n",
                            "3                                                                                                                                                                                                                                                                                                               balance = 0\\n\\n    for op in operations:\\n        balance += op\\n        if balance < 0:\\n            return True\\n\\n    return False\\n  \n",
                            "4                                                                                                                                                                                                                                                                                                                                                   mean = sum(numbers) / len(numbers)\\n    return sum(abs(x - mean) for x in numbers) / len(numbers)\\n  "
                        ]
                    },
                    "execution_count": 63,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_name = \"openai_humaneval_with_readability\"\n",
                "df = download_benchmark_dataset(task=\"code-readability-classification\", dataset_name=dataset_name)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Display Binary Readability Classification Template\n",
                "\n",
                "View the default template used to classify readability. You can tweak this template and evaluate its performance relative to the default."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "You are a stern but practical senior software engineer who cares a lot about simplicity and\n",
                        "readability of code. Can you review the following code that was written by another engineer?\n",
                        "Focus on readability of the code. Respond with \"readable\" if you think the code is readable,\n",
                        "or \"unreadable\" if the code is unreadable or needlessly complex for what it's trying\n",
                        "to accomplish.\n",
                        "\n",
                        "ONLY respond with \"readable\" or \"unreadable\"\n",
                        "\n",
                        "Task Assignment:\n",
                        "```\n",
                        "{input}\n",
                        "```\n",
                        "\n",
                        "Implementation to Evaluate:\n",
                        "```\n",
                        "{output}\n",
                        "```\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(CODE_READABILITY_PROMPT_TEMPLATE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The template variables are:\n",
                "\n",
                "- **input:** the query from the user describing the coding task\n",
                "- **output:** an implementation of the coding task"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configure the LLM\n",
                "\n",
                "Configure your OpenAI API key."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
                "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
                "openai.api_key = openai_api_key\n",
                "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Instantiate the LLM and set parameters."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Benchmark Dataset Sample\n",
                "Sample size determines run time\n",
                "Recommend iterating small: 100 samples\n",
                "Then increasing to large test set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.sample(n=N_EVAL_SAMPLE_SIZE).reset_index(drop=True)\n",
                "df = df.rename(\n",
                "    columns={\"prompt\": \"input\", \"solution\": \"output\"},\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LLM Evals: Code Readability Classifications GPT-4\n",
                "\n",
                "Run readability classifications against a subset of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = OpenAIModel(\n",
                "    model=\"gpt-4\",\n",
                "    temperature=0.0,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\"Hello! I'm working perfectly. How can I assist you today?\""
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model(\"Hello world, this is a test if you are working?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "216e1cab493f458b985a3b99a8d61ccc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "llm_classify |          | 0/10 (0.0%) | ‚è≥ 00:00<? | ?it/s"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# The rails is used to hold the output to specific values based on the template\n",
                "# It will remove text such as \",,,\" or \"...\"\n",
                "# Will ensure the binary value expected from the template is returned\n",
                "rails = list(CODE_READABILITY_PROMPT_RAILS_MAP.values())\n",
                "readability_classifications = llm_classify(\n",
                "    dataframe=df,\n",
                "    template=CODE_READABILITY_PROMPT_TEMPLATE,\n",
                "    model=model,\n",
                "    rails=rails,\n",
                "    concurrency=20,\n",
                ")[\"label\"].tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Evaluate the predictions against human-labeled ground-truth readability labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    readable       1.00      0.75      0.86         4\n",
                        "  unreadable       0.86      1.00      0.92         6\n",
                        "\n",
                        "    accuracy                           0.90        10\n",
                        "   macro avg       0.93      0.88      0.89        10\n",
                        "weighted avg       0.91      0.90      0.90        10\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Axes: title={'center': 'Confusion Matrix (Normalized)'}, xlabel='Predicted Classes', ylabel='Actual Classes'>"
                        ]
                    },
                    "execution_count": 71,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "true_labels = df[\"readable\"].map(CODE_READABILITY_PROMPT_RAILS_MAP).tolist()\n",
                "\n",
                "print(classification_report(true_labels, readability_classifications, labels=rails))\n",
                "confusion_matrix = ConfusionMatrix(\n",
                "    actual_vector=true_labels, predict_vector=readability_classifications, classes=rails\n",
                ")\n",
                "confusion_matrix.plot(\n",
                "    cmap=plt.colormaps[\"Blues\"],\n",
                "    number_label=True,\n",
                "    normalized=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Inspecting evaluations\n",
                "\n",
                "Because the evals are binary classifications, we can easily sample a few rows\n",
                "where the evals deviated from ground truth and see what the actual code was in\n",
                "that case."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Unnamed: 0</th>\n",
                            "      <th>task_id</th>\n",
                            "      <th>input</th>\n",
                            "      <th>canonical_solution</th>\n",
                            "      <th>test</th>\n",
                            "      <th>entry_point</th>\n",
                            "      <th>readable</th>\n",
                            "      <th>output</th>\n",
                            "      <th>readability</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "Empty DataFrame\n",
                            "Columns: [Unnamed: 0, task_id, input, canonical_solution, test, entry_point, readable, output, readability]\n",
                            "Index: []"
                        ]
                    },
                    "execution_count": 81,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df[\"readability\"] = readability_classifications\n",
                "# inspect instances where ground truth was readable but evaluated to unreadable by the LLM\n",
                "filtered_df = df.query('readable == False and readability == \"readable\"')\n",
                "\n",
                "# inspect first 5 rows that meet this condition\n",
                "result = filtered_df.head(5)\n",
                "result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Classifications with explanations\n",
                "\n",
                "When evaluating a dataset for readability, it can be useful to know why the LLM classified text as readable or not. The following code block runs `llm_classify` with explanations turned on so that we can inspect why the LLM made the classification it did. There is speed tradeoff since more tokens is being generated but it can be highly informative when troubleshooting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using prompt:\n",
                        "\n",
                        "\n",
                        "You are a stern but practical senior software engineer who cares a lot about simplicity and\n",
                        "readability of code. Can you review the following code that was written by another engineer?\n",
                        "Focus on readability of the code. The implementation is \"readable\" if you think the code is\n",
                        "readable, or \"unreadable\" if the code is unreadable or needlessly complex for what it's trying\n",
                        "to accomplish.\n",
                        "\n",
                        "Task Assignment:\n",
                        "```\n",
                        "{input}\n",
                        "```\n",
                        "\n",
                        "Implementation to Evaluate:\n",
                        "```\n",
                        "{output}\n",
                        "```\n",
                        "\n",
                        "Please read the code carefully, then write out in a step by step manner an EXPLANATION to show how\n",
                        "to evaluate the readability of the code. Avoid simply stating the correct answer at the outset.\n",
                        "Your response LABEL must be a single word, either \"readable\" or \"unreadable\", and should not\n",
                        "contain any text or characters aside from that. \"readable\" means that the code is readable.\n",
                        "\"unreadable\" means the code is unreadable or needlessly complex for what it's trying to accomplish.\n",
                        "\n",
                        "Example response:\n",
                        "************\n",
                        "EXPLANATION: An explanation of your reasoning for why the label is \"readable\" or \"unreadable\"\n",
                        "LABEL: \"readable\" or \"unreadable\"\n",
                        "************\n",
                        "\n",
                        "EXPLANATION:\n",
                        "OpenAI invocation parameters: {'model': 'gpt-4', 'temperature': 0.0, 'max_tokens': 256, 'frequency_penalty': 0, 'presence_penalty': 0, 'top_p': 1, 'n': 1, 'timeout': None}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a4af7a97817544488a837a790ef3d60e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "llm_classify |          | 0/5 (0.0%) | ‚è≥ 00:00<? | ?it/s"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "- Snapped 'unreadable' to rail: unreadable\n",
                        "- Snapped 'unreadable' to rail: unreadable\n",
                        "- Snapped 'readable' to rail: readable\n",
                        "- Snapped 'readable' to rail: readable\n",
                        "- Snapped 'unreadable' to rail: unreadable\n"
                    ]
                }
            ],
            "source": [
                "small_df_sample = df.copy().sample(n=5).reset_index(drop=True)\n",
                "readability_classifications_df = llm_classify(\n",
                "    dataframe=small_df_sample,\n",
                "    template=CODE_READABILITY_PROMPT_TEMPLATE,\n",
                "    model=model,\n",
                "    rails=rails,\n",
                "    provide_explanation=True,\n",
                "    verbose=True,\n",
                "    concurrency=20,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's view the data\n",
                "merged_df = pd.merge(\n",
                "    small_df_sample, readability_classifications_df, left_index=True, right_index=True\n",
                ")\n",
                "merged_df[[\"input\", \"output\", \"label\", \"explanation\"]].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LLM Evals: Code Readability Classifications GPT-3.5\n",
                "\n",
                "Run readability classifications against a subset of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The rails is used to hold the output to specific values based on the template\n",
                "# It will remove text such as \",,,\" or \"...\"\n",
                "# Will ensure the binary value expected from the template is returned\n",
                "rails = list(CODE_READABILITY_PROMPT_RAILS_MAP.values())\n",
                "readability_classifications = llm_classify(\n",
                "    dataframe=df,\n",
                "    template=CODE_READABILITY_PROMPT_TEMPLATE,\n",
                "    model=OpenAIModel(\n",
                "        model_name=\"gpt-3.5-turbo\", temperature=0.0, request_timeout=20, max_retries=0\n",
                "    ),\n",
                "    rails=rails,\n",
                "    concurrency=20,\n",
                ")[\"label\"].tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "true_labels = df[\"readable\"].map(CODE_READABILITY_PROMPT_RAILS_MAP).tolist()\n",
                "\n",
                "print(classification_report(true_labels, readability_classifications, labels=rails))\n",
                "confusion_matrix = ConfusionMatrix(\n",
                "    actual_vector=true_labels, predict_vector=readability_classifications, classes=rails\n",
                ")\n",
                "confusion_matrix.plot(\n",
                "    cmap=plt.colormaps[\"Blues\"],\n",
                "    number_label=True,\n",
                "    normalized=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preview: GPT-4 Turbo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rails = list(CODE_READABILITY_PROMPT_RAILS_MAP.values())\n",
                "readability_classifications = llm_classify(\n",
                "    dataframe=df,\n",
                "    template=CODE_READABILITY_PROMPT_TEMPLATE,\n",
                "    model=OpenAIModel(model_name=\"gpt-4-turbo-preview\", temperature=0.0),\n",
                "    rails=rails,\n",
                "    concurrency=20,\n",
                ")[\"label\"].tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "true_labels = df[\"readable\"].map(CODE_READABILITY_PROMPT_RAILS_MAP).tolist()\n",
                "\n",
                "print(classification_report(true_labels, readability_classifications, labels=rails))\n",
                "confusion_matrix = ConfusionMatrix(\n",
                "    actual_vector=true_labels, predict_vector=readability_classifications, classes=rails\n",
                ")\n",
                "confusion_matrix.plot(\n",
                "    cmap=plt.colormaps[\"Blues\"],\n",
                "    number_label=True,\n",
                "    normalized=True,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
