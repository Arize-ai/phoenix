{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9GuXoSXleA"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Phoenix Quickstart</h1>\n",
    "\n",
    "This quickstart dives straight into the code with minimal explanation. Click below to explore the capabilities of Phoenix for various tasks.\n",
    "\n",
    "- [Computer Vision](#Computer-Vision)\n",
    "- [Natural Language Processing](#Natural-Language-Processing)\n",
    "- [Tabular Data](#Tabular-Data)\n",
    "\n",
    "## Computer Vision\n",
    "\n",
    "Install Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from dataclasses import replace\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFeF5_Bysd2f"
   },
   "source": [
    "Download production and training image data containing photographs of people performing various actions (sleeping, eating, running, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"http://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_training.parquet\"\n",
    ")\n",
    "prod_df = pd.read_parquet(\n",
    "    \"http://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_production.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a few training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the DataFrame are:\n",
    "- **prediction_id:** a unique identifier for each data point\n",
    "- **prediction_ts:** the Unix timestamps of your predictions\n",
    "- **url:** a link to the image data\n",
    "- **image_vector:** the embedding vectors representing each image\n",
    "- **actual_action:** the ground truth for each image\n",
    "- **predicted_action:** the predicted class for the image\n",
    "\n",
    "View a few production data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the production data is missing ground truth, i.e., has no \"actual_action\" column.\n",
    "\n",
    "Display a few images alongside their predicted and actual labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_examples(df):\n",
    "    \"\"\"\n",
    "    Displays each image alongside the actual and predicted classes.\n",
    "    \"\"\"\n",
    "    sample_df = df[[\"actual_action\", \"predicted_action\", \"url\"]].rename(columns={\"url\": \"image\"})\n",
    "    html = sample_df.to_html(\n",
    "        escape=False, index=False, formatters={\"image\": lambda url: f'<img src=\"{url}\">'}\n",
    "    )\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "display_examples(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a schema for your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_schema = px.Schema(\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"predicted_action\",\n",
    "    actual_label_column_name=\"actual_action\",\n",
    "    embedding_feature_column_names={\n",
    "        \"image_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"image_vector\",\n",
    "            link_to_data_column_name=\"url\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema for your production data is the same, except it does not have an actual label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_schema = replace(train_schema, actual_label_column_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your primary and reference datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ds = px.Dataset(prod_df, prod_schema)\n",
    "train_ds = px.Dataset(train_df, train_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(prod_ds, train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Phoenix UI by copying and pasting the session URL into a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, open the Phoenix UI in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the embeddings view. Find a cluster of production data that is unlike any of your training data. Export the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the exported cluster as a DataFrame in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = session.exports[-1]\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few examples from your exported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(export_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download training and production data from a model that classifies the sentiment of product reviews as positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/nlp/sentiment-classification-language-drift/sentiment_classification_language_drift_training.parquet\",\n",
    ")\n",
    "prod_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/nlp/sentiment-classification-language-drift/sentiment_classification_language_drift_production.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a few training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the DataFrame are:\n",
    "- **prediction_ts:** the Unix timestamps of your predictions\n",
    "- **review_age**, **reviewer_gender**, **product_category**, **language:** the features of your model\n",
    "- **text:** the text of each product review\n",
    "- **text_vector:** the embedding vectors representing each review\n",
    "- **pred_label:** the label your model predicted\n",
    "- **label:** the ground-truth label for each review\n",
    "\n",
    "Define your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = px.Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"pred_label\",\n",
    "    actual_label_column_name=\"label\",\n",
    "    embedding_feature_column_names={\n",
    "        \"text_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"text_vector\", raw_data_column_name=\"text\"\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your primary and reference datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_ds = px.Dataset(dataframe=prod_df, schema=schema, name=\"production\")\n",
    "ref_ds = px.Dataset(dataframe=train_df, schema=schema, name=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(primary=prim_ds, reference=ref_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Phoenix by copying and pasting the output of `session.url` into a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, open the Phoenix UI in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the embeddings page. Select a period of high drift. Click on the clusters on the left and inspect the data in each cluster. One cluster contains positive reviews, one contains negative reviews, and another contains production data that has drifted from the training distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WSnqj3dtf4F"
   },
   "source": [
    "Install Phoenix and Arize auto-embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix \"arize[AutoEmbeddings]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.embeddings.tabular_generators import EmbeddingGeneratorForTabularFeatures\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ux2rILWtf4I"
   },
   "source": [
    "Download your training and production data from a fraud detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/structured/credit-card-fraud/credit_card_fraud_train.parquet\",\n",
    ")\n",
    "prod_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/structured/credit-card-fraud/credit_card_fraud_production.parquet\",\n",
    ")\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZebmnDlutf4J"
   },
   "source": [
    "The columns of the DataFrame are:\n",
    "- **prediction_id:** the unique ID for each prediction\n",
    "- **prediction_timestamp:** the timestamps of your predictions\n",
    "- **predicted_label:** the label your model predicted\n",
    "- **predicted_score:** the score of each prediction\n",
    "- **actual_label:** the true, ground-truth label for each prediction (fraud vs. not_fraud)\n",
    "- **tabular_vector:** pre-computed tabular embeddings for each row of data\n",
    "- **age:** a tag used to filter your data in the Phoenix UI\n",
    "- the rest of the columns are features\n",
    "\n",
    "Run the cell below if you have a CUDA-enabled GPU and want to compute embeddings for your tabular data from scratch; otherwise, skip this step to use the pre-computed embeddings downloaded with the rest of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = [\n",
    "    \"fico_score\",\n",
    "    \"loan_amount\",\n",
    "    \"term\",\n",
    "    \"interest_rate\",\n",
    "    \"installment\",\n",
    "    \"grade\",\n",
    "    \"home_ownership\",\n",
    "    \"annual_income\",\n",
    "    \"verification_status\",\n",
    "    \"pymnt_plan\",\n",
    "    \"addr_state\",\n",
    "    \"dti\",\n",
    "    \"delinq_2yrs\",\n",
    "    \"inq_last_6mths\",\n",
    "    \"mths_since_last_delinq\",\n",
    "    \"mths_since_last_record\",\n",
    "    \"open_acc\",\n",
    "    \"pub_rec\",\n",
    "    \"revol_bal\",\n",
    "    \"revol_util\",\n",
    "    \"state\",\n",
    "    \"merchant_ID\",\n",
    "    \"merchant_risk_score\",\n",
    "]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = EmbeddingGeneratorForTabularFeatures(\n",
    "        model_name=\"distilbert-base-uncased\",\n",
    "    )\n",
    "    train_df[\"tabular_vector\"] = generator.generate_embeddings(\n",
    "        train_df,\n",
    "        selected_columns=feature_column_names,\n",
    "    )\n",
    "    prod_df[\"tabular_vector\"] = generator.generate_embeddings(\n",
    "        prod_df,\n",
    "        selected_columns=feature_column_names,\n",
    "    )\n",
    "else:\n",
    "    print(\"CUDA is not available. Using pre-computed embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW-npos-tf4J"
   },
   "source": [
    "Define your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = px.Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    prediction_label_column_name=\"predicted_label\",\n",
    "    prediction_score_column_name=\"predicted_score\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    timestamp_column_name=\"prediction_timestamp\",\n",
    "    feature_column_names=feature_column_names,\n",
    "    tag_column_names=[\"age\"],\n",
    "    embedding_feature_column_names={\n",
    "        \"tabular_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"tabular_vector\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmM01H1Ytf4K"
   },
   "source": [
    "Define your primary and reference datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ds = px.Dataset(dataframe=prod_df, schema=schema, name=\"production\")\n",
    "train_ds = px.Dataset(dataframe=train_df, schema=schema, name=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0LzPbuytf4K"
   },
   "source": [
    "Launch Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(primary=prod_ds, reference=train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzTRaybgtf4K"
   },
   "source": [
    "Open Phoenix by copying and pasting the output of `session.url` into a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkTRHpI1tf4L"
   },
   "source": [
    "Alternatively, open the Phoenix UI in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFYdi3vktf4L"
   },
   "source": [
    "Navigate to the embeddings page. Select a period of high drift. Select a drifted cluster. Color your data by the `merchant_ID` feature. Select a cluster of drifted production data. Notice that much of this data consists of fraudulent transactions from the Scammeds merchant. Export the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFYdi3vktf4L"
   },
   "source": [
    "View your most recently exported data as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = session.exports[-1]\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siUbGmK2tf4L"
   },
   "source": [
    "Close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
