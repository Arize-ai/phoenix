{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Embedding Drift for a Sentiment Classification Model\n",
    "\n",
    "Imagine you're in charge of maintaining a model that takes as input online reviews of your U.S.-based product and classifies the sentiment of each review as positive, negative, or neutral. Your model initially performs well in production, but its performance gradually degrades over time.\n",
    "\n",
    "Phoenix helps you surface the reason for this regression by analyzing the [embeddings](https://docs.arize.com/phoenix/concepts/embeddings) representing the text of each review. Your model was trained on English reviews, but as you'll discover, it's encountering Spanish reviews in production that it can't correctly classify.\n",
    "\n",
    "In this tutorial, you will:\n",
    "* Download curated datasets of embeddings and predictions\n",
    "* Define a schema to describe the format of your data\n",
    "* Launch Phoenix to visually explore your embeddings\n",
    "* Investigate problematic clusters\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Dependencies and Import Libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download the Data üìä\n",
    "\n",
    "Load your training and production data into two Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/nlp/sentiment-classification-language-drift/sentiment_classification_language_drift_training.parquet\",\n",
    ")\n",
    "prod_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/nlp/sentiment-classification-language-drift/sentiment_classification_language_drift_production.parquet\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect a few rows of the training DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the DataFrame are:\n",
    "- **prediction_ts:** the Unix timestamps of your predictions\n",
    "- **review_age**, **reviewer_gender**, **product_category**, **language:** the features of your model\n",
    "- **text:** the text of each review\n",
    "- **text_vector:** the embedding vectors representing each review\n",
    "- **pred_label:** the label your model predicted\n",
    "- **label:** the ground-truth label for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Launch Phoenix üî•üê¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Define Your Schema\n",
    "\n",
    "To launch Phoenix with your data, you first need to define a schema that tells Phoenix which columns of your DataFrames correspond to features, predictions, actuals (i.e., ground truth), embeddings, etc.\n",
    "\n",
    "The trickiest part is defining embedding features. In this case, each embedding feature has two pieces of information: the embedding vector itself contained in the \"text_vector\" column and the review text contained in the \"text\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features = {\n",
    "    \"text_embedding\": px.EmbeddingColumnNames(\n",
    "        vector_column_name=\"text_vector\", raw_data_column_name=\"text\"\n",
    "    ),\n",
    "}\n",
    "schema = px.Schema(\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"pred_label\",\n",
    "    actual_label_column_name=\"label\",\n",
    "    embedding_feature_column_names=embedding_features,\n",
    ")\n",
    "schema\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the schema above doesn't explicitly specify features. That's because feature columns are [implicitly inferred](https://docs.arize.com/phoenix/how-to/define-your-schema#implicit-features) if you don't pass `feature_column_names` to your `Schema` object."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Define Your Datasets \n",
    "Next, define your [primary and reference datasets](https://docs.arize.com/phoenix/concepts/phoenix-basics#which-dataset-is-which). In this case, your reference dataset contains training data and your primary dataset contains production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_ds = px.Dataset(dataframe=prod_df, schema=schema, name=\"primary\")\n",
    "ref_ds = px.Dataset(dataframe=train_df, schema=schema, name=\"reference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your primary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Create a Phoenix Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(primary=prim_ds, reference=ref_ds)\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Launch the Phoenix UI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open Phoenix by copying and pasting the output of `session.url` into a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can open the Phoenix UI in your notebook with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore Your Data üìà\n",
    "\n",
    "Investigate troublesome clusters of your data:\n",
    "\n",
    "1. Navigate to the \"Embeddings\" tab and click on \"text_embedding\".\n",
    "2. In the Euclidean distance graph at the top of the page, click a point on the graph where the Euclidean distance is high.\n",
    "3. Click on the top cluster in the panel on the left.\n",
    "4. Use the panel at the bottom to examine the data points in this cluster.\n",
    "\n",
    "Answer the questions below and click to see answers:\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        What does the Euclidean distance graph measure?\n",
    "    </summary>\n",
    "    <p>\n",
    "        This graph measures the drift of your production data relative to your training data over time. See <a href=\"https://docs.arize.com/phoenix/reference/metrics/euclidean-distance\">here</a> for details.\n",
    "    </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        What do the points in the point cloud represent?\n",
    "    </summary>\n",
    "    <p>\n",
    "        Each point in the point cloud corresponds to a single product review. Phoenix has taken the high-dimensional embeddings in your original DataFrame and has reduced the dimensionality so that you can view them in lower dimensions.\n",
    "    </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        What do you notice about the cluster you selected?\n",
    "    </summary>\n",
    "    <p>\n",
    "        It consists almost entirely of production data, meaning that your model is seeing data in production the likes of which it never saw during training.\n",
    "    </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        What's gone wrong with your model in production?\n",
    "    </summary>\n",
    "    <p>\n",
    "        Your model was fine-tuned on examples of labeled product reviews in English. In production, your model is encountering product reviews in Spanish whose sentiment it cannot correctly predict.\n",
    "    </p>\n",
    "</details>\n",
    "\n",
    "Congrats! You've identified the root cause of your model's performance issue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Close the App üßπ\n",
    "\n",
    "When you're done, don't forget to close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "376112051f594f6e24fa74b51812fe15f3714622b4054162117957862f7bf942"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
