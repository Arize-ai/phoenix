{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Phoenix in Flight</center>\n",
    "## <center>Investigating Embedding Drift for a Sentiment Classification Model</center>\n",
    "\n",
    "Imagine you're in charge of maintaining a model that takes as input online reviews of your U.S.-based product and classifies the sentiment of each review as positive, negative, or neutral. Your model initially performs well in production, but its performance gradually degrades over time.\n",
    "\n",
    "Phoenix helps you surface the reason for this regression by analyzing the *embeddings* representing the text of each review. Your model was trained on English reviews, but as you'll discover, it's encountering Spanish reviews in production that it can't correctly classify.\n",
    "\n",
    "According to our research, embedding drift often precedes performance degradation. So Phoenix can help you proactively detect and fix this issue before it becomes noticable to your users.\n",
    "\n",
    "In this tutorial, you will:\n",
    "* Download curated datasets of embeddings and predictions\n",
    "* Visually explore embeddings in Phoenix\n",
    "* Investigate problematic clusters\n",
    "* Export data for labeling and re-training\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Dependencies and Import Libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download the Data üìä\n",
    "\n",
    "Load your training and production data into two pandas dataframes and inspect a few rows of the training dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/nlp/sentiment-classification-language-drift/sentiment_classification_language_drift_training.parquet\",\n",
    ")\n",
    "production_dataframe = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/nlp/sentiment-classification-language-drift/sentiment_classification_language_drift_production.parquet\",\n",
    ")\n",
    "training_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the dataframe are:\n",
    "- **prediction_ts:** the Unix timestamps of your predictions\n",
    "- **review_age**, **reviewer_gender**, **product_category**, **language:** the features of your model\n",
    "- **text:** the text of each review\n",
    "- **text_vector:** the embedding vectors representing each review\n",
    "- **pred_label:** the label your model predicted\n",
    "- **label:** the ground-truth label for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Launch Phoenix üî•üê¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Define Your Schema\n",
    "\n",
    "To launch Phoenix with your data, you first need to define a schema that tells Phoenix which columns of your dataframes correspond to features, predictions, actuals (i.e., ground truth), embeddings, etc.\n",
    "\n",
    "The trickiest part is defining embedding features. In this case, each embedding feature has two pieces of information: the embedding vector itself contained in the \"text_vector\" column and the review text contained in the \"text\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features = {\n",
    "    \"text_embedding\": px.EmbeddingColumnNames(\n",
    "        vector_column_name=\"text_vector\", raw_data_column_name=\"text\"\n",
    "    ),\n",
    "}\n",
    "schema = px.Schema(\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"pred_label\",\n",
    "    actual_label_column_name=\"label\",\n",
    "    embedding_feature_column_names=embedding_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the schema above doesn't explicitly specify features. That's because feature columns are automatically inferred if you don't pass `feature_column_names` to your `Schema` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Define Your Datasets \n",
    "Next, define your primary and reference datasets. In this case, your reference dataset contains training data and your primary dataset contains production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_dataset = px.Dataset(dataframe=production_dataframe, schema=schema, name=\"primary\")\n",
    "reference_dataset = px.Dataset(dataframe=training_dataframe, schema=schema, name=\"reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Create a Phoenix Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(primary=primary_dataset, reference=reference_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Launch the Phoenix UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore Your Data üìà\n",
    "\n",
    "Phoenix is under active development. At the moment, we display your model schema and a few data quality statistics. Check back soon for more updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Close the App üßπ\n",
    "\n",
    "When you're done, don't forget to close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "376112051f594f6e24fa74b51812fe15f3714622b4054162117957862f7bf942"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
