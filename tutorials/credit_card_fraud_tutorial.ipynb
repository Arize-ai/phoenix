{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WSnqj3dtf4F"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Detecting Fraud with Tabular Embeddings</h1>\n",
    "\n",
    "Imagine you maintain a fraud-detection service for your e-commerce company. In the past few weeks, there's been an alarming spike in undetected cases of fraudulent credit card transactions. These false negatives are hurting your bottom line, and you've been tasked with solving the issue.\n",
    "\n",
    "Phoenix provides opinionated workflows to surface feature drift and data quality issues quickly so you can get straight to the root-cause of the problem. As you'll see, your fraud-detection service is receiving more and more traffic from an untrustworthy merchant, causing your model's false negative rate to skyrocket.\n",
    "\n",
    "In this tutorial, you will:\n",
    "* Download curated datasets of credit card transaction and fraud-detection data\n",
    "* Compute tabular embeddings to represent each transaction\n",
    "* Pinpoint fraudulent transactions from a suspicious merchant\n",
    "* Export data from this merchant to retrain your model\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## 1. Install Dependencies and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix \"arize[AutoEmbeddings]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.embeddings.tabular_generators import EmbeddingGeneratorForTabularFeatures\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ux2rILWtf4I"
   },
   "source": [
    "## 2. Download the Data\n",
    "\n",
    "Load your training and production data into two pandas DataFrames and inspect a few rows of the training DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"http://storage.googleapis.com/arize-assets/phoenix/datasets/structured/credit-card-fraud/credit_card_fraud_train.parquet\",\n",
    ")\n",
    "prod_df = pd.read_parquet(\n",
    "    \"http://storage.googleapis.com/arize-assets/phoenix/datasets/structured/credit-card-fraud/credit_card_fraud_production.parquet\",\n",
    ")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZebmnDlutf4J"
   },
   "source": [
    "The columns of the dataframe are:\n",
    "- **prediction_id:** the unique ID for each prediction\n",
    "- **prediction_timestamp:** the timestamps of your predictions\n",
    "- **predicted_label:** the label your model predicted\n",
    "- **predicted_score:** the score of each prediction\n",
    "- **actual_label:** the true, ground-truth label for each prediction (fraud vs. not_fraud)\n",
    "- **tabular_vector:** pre-computed tabular embeddings for each row of data\n",
    "- **age:** a tag used to filter your data in the Phoenix UI\n",
    "- the rest of the columns are features\n",
    "\n",
    "## 3. Compute Embeddings\n",
    "\n",
    "Run the cell below if you have a CUDA-enabled GPU and want to compute embeddings for your tabular data from scratch; otherwise, skip this step to use the pre-computed embeddings downloaded with the rest of your data in step 2.\n",
    "\n",
    "`EmbeddingGeneratorForTabularFeatures` represents each row of your DataFrame as a piece of text and computes an embedding for that text using a pre-trained large language model (in this case, \"distilbert-base-uncased\"). For example, if a row of your DataFrame represents a transaction in the state of California from a merchant named \"Leannon Ward\" with a FICO score of 616 and a merchant risk score of 23, `EmbeddingGeneratorForTabularFeatures` computes an embedding for the text: \"The state is CA. The merchant ID is Leannon Ward. The fico score is 616. The merchant risk score is 23...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = [\n",
    "    \"fico_score\",\n",
    "    \"loan_amount\",\n",
    "    \"term\",\n",
    "    \"interest_rate\",\n",
    "    \"installment\",\n",
    "    \"grade\",\n",
    "    \"home_ownership\",\n",
    "    \"annual_income\",\n",
    "    \"verification_status\",\n",
    "    \"pymnt_plan\",\n",
    "    \"addr_state\",\n",
    "    \"dti\",\n",
    "    \"delinq_2yrs\",\n",
    "    \"inq_last_6mths\",\n",
    "    \"mths_since_last_delinq\",\n",
    "    \"mths_since_last_record\",\n",
    "    \"open_acc\",\n",
    "    \"pub_rec\",\n",
    "    \"revol_bal\",\n",
    "    \"revol_util\",\n",
    "    \"state\",\n",
    "    \"merchant_ID\",\n",
    "    \"merchant_risk_score\",\n",
    "]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = EmbeddingGeneratorForTabularFeatures(\n",
    "        model_name=\"distilbert-base-uncased\",\n",
    "    )\n",
    "    train_df[\"tabular_vector\"] = generator.generate_embeddings(\n",
    "        train_df,\n",
    "        selected_columns=feature_column_names,\n",
    "    )\n",
    "    prod_df[\"tabular_vector\"] = generator.generate_embeddings(\n",
    "        prod_df,\n",
    "        selected_columns=feature_column_names,\n",
    "    )\n",
    "else:\n",
    "    print(\"CUDA is not available. Using pre-computed embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW-npos-tf4J"
   },
   "source": [
    "## 4. Launch Phoenix\n",
    "\n",
    "### a) Define Your Schema\n",
    "\n",
    "To launch Phoenix with your data, you first need to define a schema that tells Phoenix which columns of your DataFrames correspond to features, predictions, actuals (i.e., ground truth), tags, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = px.Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    prediction_label_column_name=\"predicted_label\",\n",
    "    prediction_score_column_name=\"predicted_score\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    timestamp_column_name=\"prediction_timestamp\",\n",
    "    feature_column_names=feature_column_names,\n",
    "    tag_column_names=[\"age\"],\n",
    "    embedding_feature_column_names={\n",
    "        \"tabular_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"tabular_vector\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmM01H1Ytf4K"
   },
   "source": [
    "You'll notice that the schema above doesn't explicitly specify features. That's because feature columns are automatically inferred if you don't pass `feature_column_names` to your `Schema` object.\n",
    "\n",
    "### b) Define Your Datasets \n",
    "Next, define your primary and reference datasets. In this case, your reference dataset contains training data and your primary dataset contains production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ds = px.Dataset(dataframe=prod_df, schema=schema, name=\"production\")\n",
    "train_ds = px.Dataset(dataframe=train_df, schema=schema, name=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0LzPbuytf4K"
   },
   "source": [
    "### c) Create a Phoenix Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(primary=prod_ds, reference=train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzTRaybgtf4K"
   },
   "source": [
    "### d) Launch the Phoenix UI\n",
    "\n",
    "You can open Phoenix by copying and pasting the output of `session.url` into a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkTRHpI1tf4L"
   },
   "source": [
    "Alternatively, you can open the Phoenix UI in your notebook with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFYdi3vktf4L"
   },
   "source": [
    "## 5. Find and Export Fraudulent Transactions\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Click on \"tabular_embedding\" in the \"Embeddings\" section.\n",
    "1. In the Euclidean distance graph at the top of the page, select a point on the graph where the Euclidean distance is high.\n",
    "1. In the display settings in the bottom left, select \"dimension\" in the \"Color By\" dropdown. Then select the \"merchant_ID\" feature in the \"Dimension\" dropdown.\n",
    "1. Click on the top cluster in the panel on the left.\n",
    "1. Click on the \"Export\" button to save your cluster.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "1. What does the Euclidean distance graph measure?\n",
    "1. What do the points in the point cloud represent?\n",
    "1. What do you notice about the cluster you selected?\n",
    "1. What is the cause of your model's high false negative rate in production?\n",
    "\n",
    "### Answers\n",
    "\n",
    "1. This graph measures the drift of your production data relative to your training data over time.\n",
    "1. Each point in the point cloud represents an individual credit card transaction.\n",
    "1. It consists mostly of production data from the Scammeds merchant.\n",
    "1. Your model was trained on relatively little data from the Scammeds merchant, but is seeing a high volume of transactions from this merchant in production.\n",
    "\n",
    "## 6. Load and View Exported Data\n",
    "\n",
    "View your most recently exported data as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = session.exports[-1]\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhL6OoH5zs7G"
   },
   "source": [
    "Congrats! You've successfully pinpointed a cluster of fraudulent transactions. You can now fine-tune your model on the exported data in order to detect similar cases of fraud in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siUbGmK2tf4L"
   },
   "source": [
    "## 7. Close the App\n",
    "\n",
    "When you're done, don't forget to close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
