{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9GuXoSXleA"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Active Learning for a Drifting Image Classification Model</h1>\n",
    "\n",
    "Imagine you're in charge of maintaining a model that classifies the action of people in photographs. Your model initially performs well in production, but its performance gradually degrades over time.\n",
    "\n",
    "Phoenix helps you surface the reason for this regression by analyzing the embeddings representing each image. Your model was trained on crisp and high-resolution images, but as you'll discover, it's encountering blurred and noisy images in production that it can't correctly classify.\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "- Download curated datasets of embeddings and predictions\n",
    "- Define a schema to describe the format of your data\n",
    "- Launch Phoenix to visually explore your embeddings\n",
    "- Investigate problematic clusters\n",
    "- Export problematic production data for labeling and fine-tuning\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## 1. Install Dependencies and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from dataclasses import replace\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFeF5_Bysd2f"
   },
   "source": [
    "## 2. Download and Inspect the Data\n",
    "\n",
    "Download the curated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_training.parquet\"\n",
    ")\n",
    "prod_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_production.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first few rows of the training DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the DataFrame are:\n",
    "- **prediction_id:** a unique identifier for each data point\n",
    "- **prediction_ts:** the Unix timestamps of your predictions\n",
    "- **url:** a link to the image data\n",
    "- **image_vector:** the embedding vectors representing each review\n",
    "- **actual_action:** the ground truth for each image (sleeping, eating, running, etc.)\n",
    "- **predicted_action:** the predicted class for the image\n",
    "\n",
    "View the first few rows of the production DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the production data is missing ground truth, i.e., has no \"actual_action\" column.\n",
    "\n",
    "Display a few images alongside their predicted and actual labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_examples(df):\n",
    "    \"\"\"\n",
    "    Displays each image alongside the actual and predicted classes.\n",
    "    \"\"\"\n",
    "    sample_df = df[[\"actual_action\", \"predicted_action\", \"url\"]].rename(columns={\"url\": \"image\"})\n",
    "    html = sample_df.to_html(\n",
    "        escape=False, index=False, formatters={\"image\": lambda url: f'<img src=\"{url}\">'}\n",
    "    )\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "display_examples(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Launch Phoenix\n",
    "\n",
    "### a) Define Your Schema\n",
    "To launch Phoenix with your data, you first need to define a schema that tells Phoenix which columns of your DataFrames correspond to features, predictions, actuals (i.e., ground truth), embeddings, etc.\n",
    "\n",
    "The trickiest part is defining embedding features. In this case, each embedding feature has two pieces of information: the embedding vector itself contained in the \"image_vector\" column and the link to the image contained in the \"url\" column.\n",
    "\n",
    "Define a schema for your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_schema = px.Schema(\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"predicted_action\",\n",
    "    actual_label_column_name=\"actual_action\",\n",
    "    embedding_feature_column_names={\n",
    "        \"image_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"image_vector\",\n",
    "            link_to_data_column_name=\"url\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema for your production data is the same, except it does not have an actual label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_schema = replace(train_schema, actual_label_column_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Define Your Datasets\n",
    "Next, define your primary and reference datasets. In this case, your reference dataset contains training data and your primary dataset contains production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ds = px.Dataset(prod_df, prod_schema)\n",
    "train_ds = px.Dataset(train_df, train_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Create a Phoenix Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app(prod_ds, train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Launch the Phoenix UI\n",
    "\n",
    "You can open Phoenix by copying and pasting the output of `session.url` into a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can open the Phoenix UI in your notebook with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find and Export Problematic Clusters\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Click on \"image_embedding\" in the \"Embeddings\" section.\n",
    "1. In the Euclidean distance graph at the top of the page, select a point on the graph where the Euclidean distance is high.\n",
    "1. Click on the top cluster in the panel on the left.\n",
    "1. Use the panel at the bottom to examine the data points in this cluster.\n",
    "1. Click on the \"Export\" button to save your cluster.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "1. What does the Euclidean distance graph measure?\n",
    "1. What do the points in the point cloud represent?\n",
    "1. What do you notice about the cluster you selected?\n",
    "1. What's gone wrong with your model in production?\n",
    "\n",
    "### Answers\n",
    "\n",
    "1. This graph measures the drift of your production data relative to your training data over time.\n",
    "1. Each point in the point cloud corresponds to an image. Phoenix has taken the high-dimensional embeddings in your original DataFrame and has reduced the dimensionality so that you can view them in lower dimensions.\n",
    "1. It consists almost entirely of production data, meaning that your model is seeing data in production the likes of which it never saw during training.\n",
    "1. Your model was trained crisp and high-resolution images. In production, your model is encountering blurry and noisy images that it cannot correctly classify.\n",
    "\n",
    "## 5. Load and View Exported Data\n",
    "\n",
    "View your exported files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your most recent exported data back into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = session.exports[0].dataframe\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few examples from your export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(export_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've pinpointed the blurry or noisy images that are hurting your model's performance in production. As an actionable next step, you can label your exported production data and fine-tune your model to improve performance.\n",
    "\n",
    "## 6. Close the App\n",
    "\n",
    "When you're done, don't forget to close the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
