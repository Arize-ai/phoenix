{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_TEMPLATE = \"\"\"\n",
    "You are an assistant that generates complex customer service questions. You will try to answer the question with the tool if possible,\n",
    "do your best to answer, ask for more information only if needed.\n",
    "The questions should often involve:\n",
    "\n",
    "Please reference the product names, the product details, product IDS and product information.\n",
    "\n",
    "Multiple Categories: Questions that could logically fall into more than one category (e.g., combining product details with a discount code).\n",
    "Vague Details: Questions with limited or vague information that require clarification to categorize correctly.\n",
    "Mixed Intentions: Queries where the customer’s goal or need is unclear or seems to conflict within the question itself.\n",
    "Indirect Language: Use of indirect or polite phrasing that obscures the direct need or request (e.g., using \"I was wondering if...\" or \"Perhaps you could help me with...\").\n",
    "For specific categories:\n",
    "\n",
    "track_package: Include vague timing references (e.g., \"recently\" or \"a while ago\") instead of specific dates.\n",
    "product_comparison: Include generic descriptors without specific product names or IDs (e.g., \"high-end smartphones\" or \"energy-efficient appliances\").\n",
    "product_search: Include generic descriptors without specific product names or IDs (e.g., \"high-end smartphones\" or \"energy-efficient appliances\").\n",
    "apply_discount_code: Include questions about discounts that might apply to hypothetical or past situations, or without mentioning if they have made a purchase.\n",
    "product_details: Ask for comparisons or details that involve multiple products or categories ambiguously (e.g., \"Tell me about your range of electronics that are good for home office setups\").\n",
    "customer_support: Get contact information for customer support regarding an issue.\n",
    "\n",
    "Examples of More Challenging Questions\n",
    "Multiple Categories\n",
    "\n",
    "\"I recently bought a samsung 106i smart phone, and I was wondering if there's a way to check what deals I might have missed or if my order is on its way?\"\n",
    "\"Could you tell me if the samsung 15H adapater in my last order are covered under warranty and if they have shipped yet?\"\n",
    "Vague Details\n",
    "\n",
    "\"There's an issue with one of the Vizio 14Y TV I think I bought last month—what should I do?\"\n",
    "\"I need help with a iPhone 16H I ordered, or maybe I'm just looking for something new. Can you help?\"\n",
    "Mixed Intentions\n",
    "\n",
    "\"I'm not sure if I should ask for a refund or just find out when it will arrive. What do you suggest?\"\n",
    "\"Could you help me decide whether to upgrade my product or just track the current one?\"\n",
    "Indirect Language\n",
    "\n",
    "\"I was wondering if you might assist me in figuring out a problem I have with an order, or maybe it's more of a query?\"\n",
    "\"Perhaps you could help me understand the benefits of your premium products compared to the regular ones?\"\n",
    "\n",
    "Some questions should be straightforward uses of the provided functions\n",
    "\n",
    "Respond with a list, one question per line. Do not include any numbering at the beginning of each line. Do not include any category headings.\n",
    "Generate 20 questions. After each question, you must include a double colon (::) followed by a comma-separated list of the tools that you would expect to be called immediately after the question is asked.\n",
    "This list should be empty if the question should not be answered immediately with a tool call.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionUserMessageParam\n",
    "\n",
    "llm_client = OpenAI()\n",
    "\n",
    "response = llm_client.chat.completions.create(\n",
    "    messages=[ChatCompletionUserMessageParam(content=GEN_TEMPLATE, role=\"user\")],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "response_content = response.choices[0].message.content\n",
    "assert response_content\n",
    "response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "questions = []\n",
    "expected_tool_calls = []\n",
    "for line in response_content.strip().split(\"\\n\"):\n",
    "    assert len(parts := line.split(\"::\")) == 2\n",
    "    questions.append(parts[0].strip())\n",
    "    expected_tool_calls.append(list(map(lambda x: x.strip(), parts[1].split(\",\"))))\n",
    "df = pd.DataFrame({\"question\": questions, \"expected_tool_calls\": expected_tool_calls})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(endpoint=\"http://127.0.0.1:6006/v1/traces\")\n",
    "OpenAIInstrumentor(tracer_provider=tracer_provider).instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "llm_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat import ChatCompletionToolParam\n",
    "\n",
    "product_comparison_tool: ChatCompletionToolParam = {\n",
    "    \"function\": {\n",
    "        \"name\": \"product_comparison\",\n",
    "        \"description\": \"Compare features of two products.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"product_a_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier of Product A.\",\n",
    "                },\n",
    "                \"product_b_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier of Product B.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"product_a_id\", \"product_b_id\"],\n",
    "        },\n",
    "    },\n",
    "    \"type\": \"function\",\n",
    "}\n",
    "product_search_tool: ChatCompletionToolParam = {\n",
    "    \"function\": {\n",
    "        \"name\": \"product_search\",\n",
    "        \"description\": \"Search for products based on criteria.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query string.\"},\n",
    "                \"category\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The category to filter the search.\",\n",
    "                    \"default\": None,\n",
    "                },\n",
    "                \"min_price\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The minimum price of the products to search.\",\n",
    "                    \"default\": 0,\n",
    "                },\n",
    "                \"max_price\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The maximum price of the products to search.\",\n",
    "                    \"default\": None,\n",
    "                },\n",
    "                \"page\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The page number for pagination.\",\n",
    "                    \"default\": 1,\n",
    "                },\n",
    "                \"page_size\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of results per page.\",\n",
    "                    \"default\": 20,\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "    \"type\": \"function\",\n",
    "}\n",
    "customer_support_tool: ChatCompletionToolParam = {\n",
    "    \"function\": {\n",
    "        \"name\": \"customer_support\",\n",
    "        \"description\": \"Get contact information for customer support regarding an issue.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"issue_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The type of issue (e.g., billing, technical support).\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"issue_type\"],\n",
    "        },\n",
    "    },\n",
    "    \"type\": \"function\",\n",
    "}\n",
    "track_package_tool: ChatCompletionToolParam = {\n",
    "    \"function\": {\n",
    "        \"name\": \"track_package\",\n",
    "        \"description\": \"Track the status of a package based on the tracking number.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"tracking_number\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The tracking number of the package.\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"tracking_number\"],\n",
    "        },\n",
    "    },\n",
    "    \"type\": \"function\",\n",
    "}\n",
    "product_details_tool: ChatCompletionToolParam = {\n",
    "    \"function\": {\n",
    "        \"name\": \"product_details\",\n",
    "        \"description\": \"Returns details for a given product id\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"product_id\": {\"type\": \"string\", \"description\": \"The id of a product to look up.\"}\n",
    "            },\n",
    "            \"required\": [\"product_id\"],\n",
    "        },\n",
    "    },\n",
    "    \"type\": \"function\",\n",
    "}\n",
    "apply_discount_code_tool: ChatCompletionToolParam = {\n",
    "    \"function\": {\n",
    "        \"name\": \"apply_discount_code\",\n",
    "        \"description\": \"Applies the discount code to a given order.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"order_id\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The id of the order to apply the discount code to.\",\n",
    "                },\n",
    "                \"discount_code\": {\"type\": \"string\", \"description\": \"The discount code to apply\"},\n",
    "            },\n",
    "            \"required\": [\"order_id, discount_code\"],\n",
    "        },\n",
    "    },\n",
    "    \"type\": \"function\",\n",
    "}\n",
    "tools = [\n",
    "    product_comparison_tool,\n",
    "    product_search_tool,\n",
    "    customer_support_tool,\n",
    "    # track_package_tool,\n",
    "    # product_details_tool,\n",
    "    # apply_discount_code_tool,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation import using_metadata\n",
    "\n",
    "from phoenix.trace import using_project\n",
    "\n",
    "with using_project(\"customer-support-tools\"):\n",
    "    responses = []\n",
    "    for _, row in df.iterrows():\n",
    "        with using_metadata(metadata={\"expected_tool_calls\": row[\"expected_tool_calls\"]}):\n",
    "            response = llm_client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"content\": row[\"question\"], \"role\": \"user\"}],\n",
    "                tools=tools,\n",
    "                temperature=0.1,\n",
    "                max_tokens=2048,\n",
    "                frequency_penalty=0.1,\n",
    "                presence_penalty=0.2,\n",
    "                stop=[\"supercalafragilisticexpialidocious\"],\n",
    "                top_p=0.9,\n",
    "                seed=12,\n",
    "            )\n",
    "            responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "phoenix_client = px.Client()\n",
    "dataset = phoenix_client.upload_dataset(\n",
    "    dataset_name=\"customer-support-dataset\",\n",
    "    inputs=[{\"question\": question} for question in questions],\n",
    "    outputs=[{\"expected_tool_calls\": tool_calls} for tool_calls in expected_tool_calls],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from phoenix.evals.default_templates import TOOL_CALLING_BASE_TEMPLATE\n",
    "\n",
    "async_llm_client = AsyncOpenAI()\n",
    "\n",
    "\"\"\"\n",
    "You are an evaluation assistant evaluating questions and tool calls to\n",
    "determine whether the tool called would answer the question. The tool\n",
    "calls have been generated by a separate agent, and chosen from the list of\n",
    "tools provided below. It is your job to decide whether that agent chose\n",
    "the right tool to call.\n",
    "\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {question}\n",
    "    ************\n",
    "    [Tool Called]: {tool_call}\n",
    "    [END DATA]\n",
    "\n",
    "Your response must be single word, either \"correct\" or \"incorrect\",\n",
    "and should not contain any text or characters aside from that word.\n",
    "\"incorrect\" means that the chosen tool would not answer the question,\n",
    "the tool includes information that is not presented in the question,\n",
    "or that the tool signature includes parameter values that don't match\n",
    "the formats specified in the tool signatures below.\n",
    "\n",
    "\"correct\" means the correct tool call was chosen, the correct parameters\n",
    "were extracted from the question, the tool call generated is runnable and correct,\n",
    "and that no outside information not present in the question was used\n",
    "in the generated question.\n",
    "\n",
    "    [Tool Definitions]: {tool_definitions}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def evaluate_tool_call_correctness(input: dict[str, Any], output: dict[str, Any]) -> str:\n",
    "    if (\n",
    "        len(messages := output.get(\"messages\", {})) != 1\n",
    "        or len(tool_calls := messages[0].get(\"tool_calls\", [])) != 1\n",
    "    ):\n",
    "        return \"tool_not_called\"\n",
    "    evaluation_prompt = TOOL_CALLING_BASE_TEMPLATE.format(\n",
    "        question=input[\"question\"],\n",
    "        tool_call=json.dumps(tool_calls[0]),\n",
    "        tool_definitions=json.dumps(tools),\n",
    "    )\n",
    "    response = await async_llm_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"content\": evaluation_prompt, \"role\": \"user\"}],\n",
    "        tools=tools,\n",
    "    )\n",
    "    assert isinstance(response_content := response.choices[0].message.content, str)\n",
    "    if response_content not in TOOL_CALLING_PROMPT_RAILS_MAP.values():\n",
    "        return \"tool_not_called\"\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "from phoenix.experiments import evaluate_experiment\n",
    "\n",
    "phoenix_client = px.Client()\n",
    "\n",
    "experiment_ids = [\"RXhwZXJpbWVudDoyMDU=\", \"RXhwZXJpbWVudDoyMDY=\", \"RXhwZXJpbWVudDoyMDc=\"]\n",
    "for experiment_id in experiment_ids:\n",
    "    experiment = phoenix_client.get_experiment(experiment_id=experiment_id)\n",
    "    evaluate_experiment(experiment, evaluators=[evaluate_tool_call_correctness])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
