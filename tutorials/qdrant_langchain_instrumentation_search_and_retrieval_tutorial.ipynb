{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "<h1 align=\"center\">Evaluating and Improving Search and Retrieval Applications</h1>\n",
        "\n",
        "Imagine you're an engineer at Arize AI and you've built and deployed a documentation question-answering service using LangChain and Qdrant. Users send questions about Arize's core product via a chat interface, and your service retrieves chunks of your indexed documentation in order to generate a response to the user. As the engineer in charge of maintaining this system, you want to evaluate the quality of the responses from your service.\n",
        "\n",
        "Phoenix helps you:\n",
        "- identify gaps in your documentation\n",
        "- detect queries for which the LLM gave bad responses\n",
        "- detect failures to retrieve relevant documents\n",
        "\n",
        "In this tutorial, you will:\n",
        "\n",
        "- Ask questions of a LangChain application backed by Qdrant over a knowledge base of the Arize documentation\n",
        "- Use Phoenix to visualize user queries and knowledge base documents to identify areas of user interest not answered by your documentation\n",
        "- Find clusters of responses with negative user feedback\n",
        "- Identify failed retrievals using query density, cosine similarity, query distance, and LLM-assisted ranking metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "eAiaIXil21t4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot Architecture\n",
        "\n",
        "The architecture of your chatbot is shown below and can be explained in five steps.\n",
        "\n",
        "![chatbot architecture diagram](http://storage.googleapis.com/arize-phoenix-assets/assets/docs/notebooks/langchain-pinecone-search-and-retrieval/langchain_pinecone_openai_chatbot_architecture.png)\n",
        "\n",
        "1. The user sends a query about Arize to your service.\n",
        "1. `langchain.embeddings.OpenAIEmbeddings` makes a request to OpenAI to embed the user query using the text-embedding-ada-002 model.\n",
        "1. We retrieve by searching against the entries of your Qdrant database for the most similar pieces of context by MMR.\n",
        "1. `langchain.llms.ChatOpenAI` generates a response by formatting the query and retrieved context into a single prompt and sending a request to OpenAI with the gpt-4-turbo-preview model.\n",
        "1. The response is returned to the user.\n",
        "\n",
        "Phoenix makes your search and retrieval system observable by capturing the inputs and outputs of these steps for analysis, including:\n",
        "\n",
        "- your query embeddings\n",
        "- the retrieved documents and similarity scores (relevance) to each query\n",
        "- the generated response that is return to the user\n",
        "\n",
        "With that overview in mind, let's dive into the notebook."
      ],
      "metadata": {
        "id": "EDlylkFY7Wc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install needed dependencies and import relevant packages\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WdPhqT1BS9FL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caReRfQvyFG0",
        "outputId": "522f40a3-c660-4315-875a-2f06c505838a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.10)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.7.3)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.52)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: arize-phoenix[experimental,llama-index] in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: openai>=1 in /usr/local/lib/python3.10/dist-packages (1.13.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.28 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.14)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.62.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.48.2)\n",
            "Requirement already satisfied: httpx[http2]>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (0.27.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.4)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n",
            "Requirement already satisfied: ddsketch in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (2.0.4)\n",
            "Requirement already satisfied: hdbscan<1.0.0,>=0.8.33 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.8.33)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (3.1.3)\n",
            "Requirement already satisfied: openinference-instrumentation-langchain in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.1.11)\n",
            "Requirement already satisfied: openinference-instrumentation-llama-index in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.1.0)\n",
            "Requirement already satisfied: openinference-instrumentation-openai in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.1.3)\n",
            "Requirement already satisfied: openinference-semantic-conventions in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.1.4)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (14.0.2)\n",
            "Requirement already satisfied: scikit-learn<1.3.0 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.11.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (2.4.0)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.37.1)\n",
            "Requirement already satisfied: strawberry-graphql==0.208.2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.208.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (4.10.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.5.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.27.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (1.14.1)\n",
            "Requirement already satisfied: llama-index-callbacks-arize-phoenix>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.1.4)\n",
            "Requirement already satisfied: llama-index==0.10.3 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[experimental,llama-index]) (0.10.3)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.5)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.10.15)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.6)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.4)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.4)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.6)\n",
            "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.208.2->arize-phoenix[experimental,llama-index]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.208.2->arize-phoenix[experimental,llama-index]) (2.8.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.7.2)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan<1.0.0,>=0.8.33->arize-phoenix[experimental,llama-index]) (0.29.37)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan<1.0.0,>=0.8.33->arize-phoenix[experimental,llama-index]) (1.3.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx[http2]>=0.14.0->qdrant-client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index->arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index->arize-phoenix[experimental,llama-index]) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index->arize-phoenix[experimental,llama-index]) (0.44b0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.0->arize-phoenix[experimental,llama-index]) (3.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ddsketch->arize-phoenix[experimental,llama-index]) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->arize-phoenix[experimental,llama-index]) (2.1.5)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix[experimental,llama-index]) (1.2.14)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix[experimental,llama-index]) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix[experimental,llama-index]) (1.23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->arize-phoenix[experimental,llama-index]) (2023.4)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn->arize-phoenix[experimental,llama-index]) (0.58.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn->arize-phoenix[experimental,llama-index]) (0.5.11)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->arize-phoenix[experimental,llama-index]) (8.1.7)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (2023.6.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (3.8.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (9.4.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (4.12.3)\n",
            "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (0.0.2)\n",
            "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (1.23.26)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (4.1.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn->arize-phoenix[experimental,llama-index]) (0.41.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (2.5)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.10/dist-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.0->llama-index==0.10.3->arize-phoenix[experimental,llama-index]) (1.23.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain qdrant-client langchain_community tiktoken cohere langchain-openai protobuf==3.20.3 \"arize-phoenix[experimental,llama-index]\" \"openai>=1\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries."
      ],
      "metadata": {
        "id": "a8P6f4Zn7hk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o51nSmCQyIyw"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import urllib\n",
        "from getpass import getpass\n",
        "from urllib.request import urlopen\n",
        "import logging\n",
        "\n",
        "# Third-party library imports\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Phoenix imports\n",
        "import phoenix as px\n",
        "from phoenix.experimental.evals import (\n",
        "    HallucinationEvaluator,\n",
        "    OpenAIModel,\n",
        "    QAEvaluator,\n",
        "    RelevanceEvaluator,\n",
        "    run_evals,\n",
        ")\n",
        "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
        "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
        "from phoenix.trace.langchain import LangChainInstrumentor\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import GitbookLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.chat_models import ChatOpenAI as ChatOpenAI_LangChain\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "# Miscellaneous imports\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration and Initialization\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "nest_asyncio.apply()\n",
        "pd.set_option(\"display.max_colwidth\", None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configure Your OpenAI API Key\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PeVDyiFk8Adf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlesVzEr2Wtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9bd41a-f643-451a-d0a6-ce2da1d5ab01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Enter your OpenAI API key: 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
        "    openai_api_key = getpass(\" Enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Configure your Qdrant client in memory\n",
        "\n",
        "We need to configure the embeddings to be used as well as the documents to be used. In this example, the documents come from arize's documentation\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "i4Mztjvk8NM2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PFQlB6K5H0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c907ea8a-db8b-4503-9815-9885e8ea915d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "model_name = 'text-embedding-ada-002'\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=model_name,\n",
        "    openai_api_key=openai_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_gitbook_docs(docs_url):\n",
        "    \"\"\"\n",
        "    Loads documentation from a Gitbook URL.\n",
        "    \"\"\"\n",
        "\n",
        "    loader = GitbookLoader(\n",
        "        docs_url,\n",
        "        load_all_paths=True,\n",
        "    )\n",
        "    return loader.load()\n",
        "\n",
        "docs_url = \"https://docs.arize.com/arize/\"\n",
        "docs = load_gitbook_docs(docs_url)"
      ],
      "metadata": {
        "id": "mMFH626x3-xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f106f749-f759-43a1-c418-f77c8207bcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  k = self.parse_starttag(i)\n",
            "Fetching pages: 100%|##########| 187/187 [00:18<00:00,  9.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build our qdrant vectorstore in memory for this example, however additional alternatives can be found in both Langchain's and Qdrant's documentation."
      ],
      "metadata": {
        "id": "mCjtfIijTjAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant = Qdrant.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"my_documents\",\n",
        ")"
      ],
      "metadata": {
        "id": "7o1MP1DkPjMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build Your LangChain Application\n",
        "\n",
        "---\n",
        "\n",
        "This example uses a `RetrievalQA` chain over a pre-built index of the Arize documentation, but you can use whatever LangChain application you like."
      ],
      "metadata": {
        "id": "KHBNi91bCWqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "\n",
        "num_retrieved_documents = 2\n",
        "retriever = qdrant.as_retriever(search_type=\"mmr\",\n",
        "                                search_kwargs={\"k\": num_retrieved_documents},\n",
        "                                enable_limit=True)\n",
        "chain_type = \"stuff\"  # stuff, refine, map_reduce, and map_rerank\n",
        "chat_model_name = \"gpt-4-turbo-preview\"\n",
        "llm = ChatOpenAI(model_name=chat_model_name, temperature=0.0)\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=chain_type,\n",
        "    retriever=retriever,\n",
        "    metadata={\"application_type\": \"question_answering\"},\n",
        "    callbacks=[handler]\n",
        ")"
      ],
      "metadata": {
        "id": "XDLLdbd3XZqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use Phoenix, you must load your data into Pandas dataframes. First, load your knowledge base into a dataframe.\n"
      ],
      "metadata": {
        "id": "AeYHxBD_lG9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "database_df = pd.read_parquet(\n",
        "    \"http://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/context-retrieval/langchain-pinecone/database.parquet\"\n",
        ")\n",
        "#database_df.head()"
      ],
      "metadata": {
        "id": "UcofKBKrQwlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns of your dataframe are:\n",
        "\n",
        "text: the chunked text in your knowledge base\n",
        "text_vector: the embedding vector for the text, computed during the LangChain build using the \"text-embedding-ada-002\" embedding model from OpenAI"
      ],
      "metadata": {
        "id": "oApdfewWlIgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, download a dataframe containing query data."
      ],
      "metadata": {
        "id": "24lwJkColToL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_df = pd.read_parquet(\n",
        "    \"http://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/context-retrieval/langchain-pinecone/langchain_pinecone_query_dataframe_with_user_feedbackv2.parquet\"\n",
        ")\n",
        "#query_df.head()"
      ],
      "metadata": {
        "id": "30-qZMCDQwnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns of the dataframe are:\n",
        "\n",
        "text: the query text\n",
        "text_vector: the embedding representation of the query, captured from LangChain at query time\n",
        "response: the final response from the LangChain application\n",
        "context_text_0: the first retrieved context from the knowledge base\n",
        "context_similarity_0: the cosine similarity between the query and the first retrieved context\n",
        "context_text_1: the second retrieved context from the knowledge base\n",
        "context_similarity_1: the cosine similarity between the query and the first retrieved context\n",
        "user_feedback: approval or rejection from the user (-1 means thumbs down, +1 means thumbs up)"
      ],
      "metadata": {
        "id": "7o2FEaP8lqUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try out running out the first 10 queries on the query_df by using Qdrant as retriever!"
      ],
      "metadata": {
        "id": "uOUpRLLkkIRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    row = query_df.iloc[i]\n",
        "    response = chain.invoke(row['text'])\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw1_iLrQj410",
        "outputId": "11ded61f-ab54-487e-fca7-61327e1c3aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'How do I use the SDK to upload a ranking model?', 'result': \"The provided context does not include specific instructions or code examples on how to use an SDK to upload a ranking model. It focuses on using the Arize platform to troubleshoot and improve the performance of a search ranking model, particularly through evaluating NDCG at different @k values, comparing datasets, and identifying feature performance issues. \\n\\nFor uploading a ranking model or any model using an SDK, typically, you would follow these general steps, which might vary depending on the specific platform or SDK you are using:\\n\\n1. **Installation**: Ensure the SDK is installed in your environment. This usually involves running a pip install command or adding the SDK to your project dependencies.\\n\\n2. **Authentication**: Set up authentication by providing necessary credentials, which could be an API key, a service account, or other forms of authentication supported by the SDK.\\n\\n3. **Initialization**: Initialize the SDK or client in your code by importing it and setting up any required configuration, such as endpoint URLs or project IDs.\\n\\n4. **Model Preparation**: Prepare your model for upload. This might involve serializing the model into a specific format supported by the platform (e.g., a binary file, a ZIP archive, etc.).\\n\\n5. **Upload**: Use the SDK's method to upload the model. This typically involves specifying the path to the model file, and possibly additional metadata about the model (e.g., name, version, description).\\n\\n6. **Verification**: After uploading, verify that the model is correctly uploaded and is accessible for further operations like serving predictions.\\n\\nSince the context does not provide details about the SDK or the specific commands for uploading a model, I recommend consulting the official documentation of the SDK you are using for detailed instructions and examples.\"}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'What drift metrics are supported in Arize?', 'result': 'Arize calculates drift metrics including Population Stability Index, KL Divergence, KS Statistic, and JS Distance. These metrics help in measuring distribution changes between the models production values and a baseline, which can be a pre-production dataset (training, test, validation) or a fixed or moving time period from production.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'Does Arize support batch models?', 'result': 'Yes, Arize supports batch models. The documentation mentions \"Batch Logging - Designed for sending batches of data to Arize,\" indicating that you can use the Arize platform to monitor machine learning predictions for batch processed data. This is facilitated through the use of the `arize` Python library, which allows for logging model data from batches of data, such as those processed in a Jupyter Notebook or a Python server that batch processes backend data.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'Does Arize support training data?', 'result': \"Yes, Arize supports training data. It allows users to log training and validation records to the platform. This is part of its functionality to help users understand and visualize their model's performance, including during the pre-launch validation phase. By logging training data, users can compare the performance of models during the training phase with their performance in production, aiding in the identification of drift, data quality issues, and the overall effectiveness of the model.\"}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'How do I configure a threshold if my data has seasonality trends?', 'result': 'The provided context does not explicitly detail how to configure a threshold for models dealing with data that exhibits seasonality trends. However, understanding the nature of seasonality in your data is crucial for setting appropriate thresholds for drift detection. Seasonality can cause your model\\'s performance to fluctuate at regular intervals, which could be mistaken for drift if not accounted for properly.\\n\\nGiven the absence of direct instructions on configuring thresholds for seasonal data, a general approach would involve:\\n\\n1. **Analyzing Historical Data**: Understand the seasonality patterns in your data by analyzing historical performance. Look for regular intervals at which your data\\'s characteristics change.\\n\\n2. **Adjusting Baselines**: As suggested in the \"Change Your Baseline\" section, you might need to adjust your baseline to account for seasonality. For instance, comparing current production data against a baseline from a similar seasonal period in the past rather than using a fixed historical baseline.\\n\\n3. **Custom Alerts**: Configure custom alerts that account for expected seasonal variations. This might involve setting different thresholds for different times of the year or adjusting the sensitivity of your drift detection mechanisms during known periods of seasonal change.\\n\\n4. **Periodic Review**: Regularly review and adjust your thresholds and baselines to ensure they remain relevant as your model continues to operate over time. This is particularly important for models exposed to seasonal trends, as the impact of these trends on your data and model performance might evolve.\\n\\n5. **Proxy Metrics**: In cases where you have delayed actuals, as mentioned in the \"Delayed Actuals\" section, use proxy metrics that might be less sensitive to seasonal effects to evaluate model performance in the interim.\\n\\nIf your specific platform or tool supports more advanced configurations for handling seasonality, it would be advisable to consult the relevant documentation or reach out to support for guidance tailored to your situation.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'How are clusters in the UMAP calculated? When are the clusters refreshed?', 'result': 'Clusters in the UMAP are calculated using an unsupervised learning technique, which means the algorithm works on unlabelled data to find patterns and group similar data points together without prior knowledge of the categories. This process helps in identifying the structure within the dataset by grouping data points into clusters based on their similarity. The specific details of the clustering algorithm used (e.g., K-means, DBSCAN, etc.) are not mentioned, but the focus is on grouping similar embedding vectors that represent the data points.\\n\\nClusters are refreshed or recalculated in the context of using UMAP for visualization and analysis when new data is selected or parameters are changed. For instance, when a user selects a point on the drift visualization and generates UMAP to visualize the point in time selected, this action could trigger a refresh of the clusters based on the new data subset or time point selected. Additionally, changing configuration parameters for UMAP generation, such as dimensions, nNeighbors, minDist, or sample size, could also necessitate a recalculation of the clusters to reflect the new settings and provide the most relevant insights based on the updated conditions.\\n\\nHowever, the specific timing or conditions under which clusters are refreshed can depend on the implementation details of the system (e.g., Arize) and how it is set up to respond to user interactions or data updates.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'How does Arize calculate AUC?', 'result': 'The provided context does not include specific details on how Arize calculates the Area Under the Curve (AUC) for Receiver Operating Characteristic (ROC) curves or any other type of AUC. Arize is a platform for model monitoring and observability, and while it likely supports various metrics for evaluating model performance, including potentially AUC, the provided text does not elaborate on the methodologies or algorithms used for calculating AUC or any other specific metrics.\\n\\nFor calculating AUC in general, it involves plotting the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings. The AUC represents the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. However, without specific details from Arize documentation or context, I cannot provide a precise answer on how Arize calculates AUC.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'Can I send truth labels to Arize separtely? ', 'result': 'Yes, you can send truth labels to Arize separately. The Arize platform is designed to accommodate various data ingestion methods, including the ability to ingest truth labels independently from predictions. This flexibility allows you to update your models with actual outcomes as they become available, which is crucial for monitoring model performance and accuracy over time. If you need specific guidance on how to send truth labels separately or integrate them with your existing data in Arize, you might want to reach out to their support team at [email\\xa0protected] or use the #arize-support channel on Slack for more detailed assistance.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'How do I send embeddings to Arize?', 'result': 'To send embeddings to Arize, you can either generate your own embeddings or let Arize generate them for you. Once you have your embeddings ready, you can send them to Arize by following examples provided for specific use cases such as Image Classification and Natural Language Processing (NLP). These examples can guide you on how to properly format and send your embeddings data to Arize for analysis.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'Can I copy a dashboard', 'result': 'Yes, you can share dashboards across teams by simply copying the dashboard URL to share with your team. However, the provided information does not explicitly mention a feature for duplicating or copying a dashboard to create a new one with the same configuration. Sharing is facilitated through the dashboard URL for easy communication of ML model analytics among team members.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The query and database datasets are drawn from different distributions; the queries are short questions while the database entries are several sentences to a paragraph. The embeddings from OpenAI's \"text-embedding-ada-002\" capture these differences and naturally separate the query and context embeddings into distinct regions of the embedding space. When using Phoenix, you want to \"overlay\" the query and context embedding distributions so that queries appear close to their retrieved context in the Phoenix point cloud. To achieve this, we compute a centroid for each dataset that represents an average point in the embedding distribution and center the two distributions so they overlap."
      ],
      "metadata": {
        "id": "g3pm8gUwl0On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "database_centroid = database_df[\"text_vector\"].mean()\n",
        "database_df[\"centered_text_vector\"] = database_df[\"text_vector\"].apply(\n",
        "    lambda x: x - database_centroid\n",
        ")\n",
        "query_centroid = query_df[\"text_vector\"].mean()\n",
        "query_df[\"centered_text_vector\"] = query_df[\"text_vector\"].apply(lambda x: x - query_centroid)"
      ],
      "metadata": {
        "id": "CYLuL5Zz1ki3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Launch your phoenix session and Instrument LangChain"
      ],
      "metadata": {
        "id": "kRVe4p3O03Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a schema to tell Phoenix what the columns of your query and database dataframes represent (features, predictions, actuals, tags, embeddings, etc.). See the docs for guides on how to define your own schema and API reference on phoenix.Schema and phoenix.EmbeddingColumnNames."
      ],
      "metadata": {
        "id": "KUt8Ln5xmA1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_schema = px.Schema(\n",
        "    prompt_column_names=px.EmbeddingColumnNames(\n",
        "        raw_data_column_name=\"text\",\n",
        "        vector_column_name=\"centered_text_vector\",\n",
        "    ),\n",
        "    response_column_names=\"response\",\n",
        "    tag_column_names=[\n",
        "        \"context_text_0\",\n",
        "        \"context_similarity_0\",\n",
        "        \"context_text_1\",\n",
        "        \"context_similarity_1\",\n",
        "        \"euclidean_distance_0\",\n",
        "        \"euclidean_distance_1\",\n",
        "        \"openai_relevance_0\",\n",
        "        \"openai_relevance_1\",\n",
        "        \"openai_precision@1\",\n",
        "        \"openai_precision@2\",\n",
        "        \"user_feedback\",\n",
        "    ],\n",
        ")\n",
        "database_schema = px.Schema(\n",
        "    document_column_names=px.EmbeddingColumnNames(\n",
        "        raw_data_column_name=\"text\",\n",
        "        vector_column_name=\"centered_text_vector\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "uTHSVIIMxszM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Phoenix datasets that wrap your dataframes with the schemas that describe them."
      ],
      "metadata": {
        "id": "2EtLq92OmHNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "database_ds = px.Dataset(\n",
        "    dataframe=database_df,\n",
        "    schema=database_schema,\n",
        "    name=\"qdrant\",\n",
        ")\n",
        "query_ds = px.Dataset(\n",
        "    dataframe=query_df,\n",
        "    schema=query_schema,\n",
        "    name=\"query\",\n",
        ")"
      ],
      "metadata": {
        "id": "YsQDVgscxjEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch Phoenix. Note that the database dataset is passed in as the corpus - a reserved keyword argument for passing in the knowledge base for search and retrieval analysis. Follow the instructions in the cell output to open the Phoenix UI."
      ],
      "metadata": {
        "id": "v8_lGz3CmMiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session = px.launch_app(query_ds, corpus=database_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "nsmOpPUQxmh6",
        "outputId": "fd8f02ae-577b-4aab-e0b8-65b437aca63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " To view the Phoenix app in your browser, visit https://dbgz5stb1261-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
            " To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
            " For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make your LLM application observable, it must be instrumented. That is, the code must emit traces. The instrumented data must then be sent to an Observability backend, in our case the Phoenix server."
      ],
      "metadata": {
        "id": "SO5n6tCRmt0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LangChainInstrumentor().instrument()"
      ],
      "metadata": {
        "id": "6gq8jDLQxztq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Run LLM assisted Evals\n",
        "\n",
        "Cosine similarity and Euclidean distance are reasonable proxies for retrieval quality, but they don't always work perfectly. A novel idea is to use LLMs to measure retrieval quality by simply asking the LLM whether each piece of retrieved context is relevant or irrelevant to the corresponding query.\n",
        "\n",
        "锔 It's strongly recommended to use GPT-4 for this step if you have access, since we've found it to be more trustworthy for this particular task.\n",
        "\n",
        " Use OpenAI to predict whether each retrieved document is relevant or irrelevant to the query."
      ],
      "metadata": {
        "id": "GMo2bgkmoPPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EVALUATION_SYSTEM_MESSAGE = (\n",
        "    \"You will be given a query and a reference text. \"\n",
        "    \"You must determine whether the reference text contains an answer to the input query. \"\n",
        "    \"Your response must be binary (0 or 1) and \"\n",
        "    \"should not contain any text or characters aside from 0 or 1. \"\n",
        "    \"0 means that the reference text does not contain an answer to the query. \"\n",
        "    \"1 means the reference text contains an answer to the query.\"\n",
        ")\n",
        "QUERY_CONTEXT_PROMPT_TEMPLATE = \"\"\"# Query: {query}\n",
        "\n",
        "# Reference: {reference}\n",
        "\n",
        "f# Binary: \"\"\""
      ],
      "metadata": {
        "id": "1-hGjMLkXadf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def evaluate_query_and_retrieved_context(query: str, context: str, model_name: str) -> str:\n",
        "    prompt = QUERY_CONTEXT_PROMPT_TEMPLATE.format(\n",
        "        query=query,\n",
        "        reference=context,\n",
        "    )\n",
        "    response = openai.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": EVALUATION_SYSTEM_MESSAGE},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        model=model_name,\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def evaluate_retrievals(\n",
        "    retrievals_data: Dict[str, str],\n",
        "    model_name: str,\n",
        ") -> List[str]:\n",
        "    responses = []\n",
        "    for query, retrieved_context in tqdm(retrievals_data.items()):\n",
        "        response = evaluate_query_and_retrieved_context(query, retrieved_context, model_name)\n",
        "        responses.append(response)\n",
        "    return responses\n",
        "\n",
        "def process_binary_responses(\n",
        "    binary_responses: List[str], binary_to_string_map: Dict[int, str]\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Parse binary responses and convert to the desired format\n",
        "    converts them to the desired format. The binary_to_string_map parameter\n",
        "    should be a dictionary mapping binary values (0 or 1) to the desired\n",
        "    string values (e.g. \"irrelevant\" or \"relevant\").\n",
        "    \"\"\"\n",
        "    processed_responses = []\n",
        "    for binary_response in binary_responses:\n",
        "        try:\n",
        "            binary_value = int(binary_response.strip())\n",
        "            processed_response = binary_to_string_map[binary_value]\n",
        "        except (ValueError, KeyError):\n",
        "            processed_response = None\n",
        "        processed_responses.append(processed_response)\n",
        "    return processed_responses\n",
        "\n",
        "sample_query_df = query_df.copy() #.head(10).copy() to make a subset to work on\n",
        "evaluation_model_name = \"gpt-4-1106-preview\"  # use any GPT variable you have access to\n",
        "for context_index in range(num_retrieved_documents):\n",
        "    retrievals_data = {\n",
        "        row[\"text\"]: row[f\"context_text_{context_index}\"] for _, row in sample_query_df.iterrows()\n",
        "    }\n",
        "    raw_responses = evaluate_retrievals(retrievals_data, evaluation_model_name)\n",
        "    processed_responses = process_binary_responses(raw_responses, {0: \"irrelevant\", 1: \"relevant\"})\n",
        "    sample_query_df[f\"openai_relevance_{context_index}\"] = processed_responses\n",
        "sample_query_df[\n",
        "    [\"text\", \"context_text_0\", \"openai_relevance_0\", \"context_text_1\", \"openai_relevance_1\"]\n",
        "]#.head(10)"
      ],
      "metadata": {
        "id": "V86L1fEGXaso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62ebf241-9887-40da-9c68-5f7b9a82b6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/153 [00:00<01:28,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|         | 2/153 [00:01<02:14,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 3/153 [00:02<01:48,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 4/153 [00:03<02:18,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 5/153 [00:04<02:25,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|         | 6/153 [00:05<02:01,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|         | 7/153 [00:06<02:06,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|         | 8/153 [00:06<01:50,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|         | 9/153 [00:07<01:40,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 10/153 [00:07<01:34,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 11/153 [00:08<01:41,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 12/153 [00:09<01:40,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 13/153 [00:10<01:49,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|         | 14/153 [00:11<01:58,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 15/153 [00:11<01:43,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 16/153 [00:12<01:52,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|         | 17/153 [00:13<01:40,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 18/153 [00:13<01:31,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 19/153 [00:14<01:37,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|        | 20/153 [00:14<01:22,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|        | 21/153 [00:15<01:18,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|        | 22/153 [00:16<01:23,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|        | 23/153 [00:16<01:20,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|        | 24/153 [00:17<01:22,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|        | 25/153 [00:18<01:16,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 26/153 [00:19<01:31,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 27/153 [00:19<01:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 28/153 [00:20<01:22,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|        | 29/153 [00:20<01:15,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 30/153 [00:21<01:10,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 31/153 [00:22<01:22,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|        | 32/153 [00:23<02:01,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 33/153 [00:24<01:49,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 34/153 [00:24<01:28,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|       | 35/153 [00:26<01:46,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|       | 36/153 [00:27<01:47,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|       | 37/153 [00:27<01:33,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 38/153 [00:28<01:33,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 39/153 [00:30<01:55,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|       | 40/153 [00:30<01:38,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 41/153 [00:31<01:32,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 42/153 [00:31<01:26,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 43/153 [00:32<01:25,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|       | 44/153 [00:33<01:11,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|       | 45/153 [00:34<01:28,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 46/153 [00:34<01:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|       | 47/153 [00:35<01:08,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|      | 48/153 [00:37<01:45,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|      | 49/153 [00:37<01:29,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 50/153 [00:38<01:18,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 51/153 [00:38<01:09,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|      | 52/153 [00:39<01:07,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 53/153 [00:39<01:01,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 54/153 [00:40<01:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|      | 55/153 [00:41<01:02,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 56/153 [00:41<01:05,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 57/153 [00:42<01:10,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|      | 58/153 [00:43<01:04,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|      | 59/153 [00:44<01:30,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|      | 60/153 [00:45<01:22,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 61/153 [00:46<01:08,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|      | 62/153 [00:46<00:57,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|      | 63/153 [00:47<00:59,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 64/153 [00:47<00:52,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 65/153 [00:48<00:54,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 66/153 [00:49<00:57,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 67/153 [00:49<00:57,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 68/153 [00:50<00:54,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|     | 69/153 [00:50<00:46,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 70/153 [00:51<00:48,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 71/153 [00:52<00:52,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 72/153 [00:52<00:56,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|     | 73/153 [00:53<00:56,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|     | 74/153 [00:55<01:26,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|     | 75/153 [00:56<01:21,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 76/153 [00:57<01:10,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 77/153 [00:57<01:04,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|     | 78/153 [00:58<01:01,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 79/153 [00:59<00:57,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 80/153 [01:00<00:58,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|    | 81/153 [01:00<00:52,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|    | 82/153 [01:01<00:53,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|    | 83/153 [01:01<00:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|    | 84/153 [01:02<00:46,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|    | 85/153 [01:03<00:45,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|    | 86/153 [01:04<01:02,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 87/153 [01:06<01:11,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 88/153 [01:07<01:03,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 89/153 [01:07<00:58,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 90/153 [01:08<00:52,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 91/153 [01:09<00:46,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 92/153 [01:09<00:44,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|    | 93/153 [01:10<00:43,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|   | 94/153 [01:11<00:46,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|   | 95/153 [01:11<00:41,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 96/153 [01:12<00:35,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 97/153 [01:13<00:42,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|   | 98/153 [01:14<00:39,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|   | 99/153 [01:14<00:34,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|   | 100/153 [01:14<00:30,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 101/153 [01:15<00:31,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 102/153 [01:16<00:27,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 103/153 [01:16<00:24,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|   | 104/153 [01:17<00:27,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 105/153 [01:18<00:32,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 106/153 [01:18<00:30,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 107/153 [01:19<00:26,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 108/153 [01:19<00:30,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 109/153 [01:20<00:28,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|  | 110/153 [01:21<00:26,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 111/153 [01:21<00:22,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 112/153 [01:22<00:23,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 113/153 [01:24<00:45,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 114/153 [01:24<00:35,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 115/153 [01:25<00:32,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 116/153 [01:26<00:32,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 117/153 [01:27<00:26,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|  | 118/153 [01:27<00:24,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 119/153 [01:28<00:22,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 120/153 [01:28<00:20,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|  | 121/153 [01:29<00:21,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 122/153 [01:29<00:18,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 123/153 [01:30<00:17,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|  | 124/153 [01:31<00:17,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 125/153 [01:31<00:17,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 126/153 [01:32<00:15,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 127/153 [01:33<00:16,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%| | 128/153 [01:34<00:18,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%| | 129/153 [01:34<00:17,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%| | 130/153 [01:35<00:18,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 131/153 [01:36<00:18,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 132/153 [01:37<00:17,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 133/153 [01:37<00:14,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 134/153 [01:38<00:12,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 135/153 [01:38<00:10,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%| | 136/153 [01:39<00:10,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 137/153 [01:40<00:10,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 138/153 [01:40<00:08,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%| | 139/153 [01:41<00:07,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|| 140/153 [01:41<00:08,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|| 141/153 [01:42<00:08,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 142/153 [01:43<00:07,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 143/153 [01:45<00:12,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|| 144/153 [01:46<00:09,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|| 145/153 [01:47<00:08,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|| 146/153 [01:48<00:06,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 147/153 [01:48<00:04,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 148/153 [01:49<00:03,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 149/153 [01:50<00:02,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|| 150/153 [01:51<00:02,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|| 151/153 [01:51<00:01,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|| 152/153 [01:52<00:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 153/153 [01:52<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/153 [00:01<02:53,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|         | 2/153 [00:01<01:57,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 3/153 [00:02<01:41,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 4/153 [00:02<01:27,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 5/153 [00:03<01:18,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|         | 6/153 [00:03<01:35,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|         | 7/153 [00:04<01:20,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|         | 8/153 [00:05<01:40,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|         | 9/153 [00:05<01:30,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 10/153 [00:06<01:27,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 11/153 [00:06<01:22,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 12/153 [00:07<01:18,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 13/153 [00:07<01:11,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|         | 14/153 [00:08<01:16,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 15/153 [00:09<01:21,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 16/153 [00:09<01:14,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|         | 17/153 [00:10<01:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 18/153 [00:10<01:18,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 19/153 [00:11<01:19,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|        | 20/153 [00:12<01:25,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|        | 21/153 [00:12<01:14,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|        | 22/153 [00:13<01:32,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|        | 23/153 [00:14<01:32,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|        | 24/153 [00:14<01:22,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|        | 25/153 [00:15<01:27,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 26/153 [00:16<01:32,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 27/153 [00:16<01:18,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 28/153 [00:17<01:07,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|        | 29/153 [00:18<01:23,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 30/153 [00:18<01:25,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 31/153 [00:19<01:26,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|        | 32/153 [00:20<01:33,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 33/153 [00:21<01:17,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 34/153 [00:21<01:13,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|       | 35/153 [00:22<01:24,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|       | 36/153 [00:23<01:23,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|       | 37/153 [00:23<01:21,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 38/153 [00:24<01:17,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 39/153 [00:25<01:12,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|       | 40/153 [00:25<01:16,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 41/153 [00:26<01:23,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 42/153 [00:27<01:28,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 43/153 [00:28<01:15,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|       | 44/153 [00:28<01:09,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|       | 45/153 [00:29<01:10,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 46/153 [00:30<01:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|       | 47/153 [00:30<01:08,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|      | 48/153 [00:31<01:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|      | 49/153 [00:31<00:57,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 50/153 [00:32<00:59,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 51/153 [00:32<01:04,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|      | 52/153 [00:33<00:57,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 53/153 [00:33<00:53,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 54/153 [00:34<00:48,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|      | 55/153 [00:34<00:47,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 56/153 [00:35<00:59,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 57/153 [00:36<01:00,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|      | 58/153 [00:36<00:57,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|      | 59/153 [00:37<00:50,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|      | 60/153 [00:37<00:55,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 61/153 [00:38<00:52,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|      | 62/153 [00:39<00:58,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|      | 63/153 [00:40<01:06,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 64/153 [00:40<01:03,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 65/153 [00:41<00:57,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 66/153 [00:41<00:56,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 67/153 [00:42<00:49,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 68/153 [00:43<00:54,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|     | 69/153 [00:43<00:47,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 70/153 [00:44<00:45,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 71/153 [00:45<01:07,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 72/153 [00:45<00:55,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|     | 73/153 [00:46<00:56,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|     | 74/153 [00:47<00:50,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|     | 75/153 [00:47<00:47,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 76/153 [00:48<00:44,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 77/153 [00:48<00:40,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|     | 78/153 [00:49<00:52,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 79/153 [00:50<00:50,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 80/153 [00:51<00:52,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|    | 81/153 [00:52<00:57,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|    | 82/153 [00:52<00:53,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|    | 83/153 [00:53<00:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|    | 84/153 [00:53<00:42,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|    | 85/153 [00:54<00:44,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|    | 86/153 [00:54<00:37,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 87/153 [00:55<00:42,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 88/153 [00:56<00:42,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 89/153 [00:56<00:38,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 90/153 [00:57<00:37,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 91/153 [00:57<00:35,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 92/153 [00:58<00:30,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|    | 93/153 [00:58<00:32,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|   | 94/153 [00:59<00:30,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|   | 95/153 [01:00<00:35,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 96/153 [01:00<00:32,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 97/153 [01:01<00:36,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|   | 98/153 [01:02<00:35,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|   | 99/153 [01:02<00:36,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|   | 100/153 [01:03<00:30,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 101/153 [01:03<00:30,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 102/153 [01:04<00:37,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 103/153 [01:05<00:32,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|   | 104/153 [01:06<00:35,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 105/153 [01:06<00:31,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 106/153 [01:07<00:31,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 107/153 [01:08<00:33,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 108/153 [01:08<00:28,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 109/153 [01:09<00:27,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|  | 110/153 [01:10<00:31,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 111/153 [01:10<00:28,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 112/153 [01:11<00:24,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 113/153 [01:11<00:24,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 114/153 [01:12<00:23,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 115/153 [01:12<00:19,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 116/153 [01:13<00:20,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 117/153 [01:14<00:22,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|  | 118/153 [01:14<00:20,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 119/153 [01:15<00:18,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 120/153 [01:15<00:17,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|  | 121/153 [01:16<00:19,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 122/153 [01:18<00:30,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 123/153 [01:18<00:24,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|  | 124/153 [01:19<00:21,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 125/153 [01:20<00:21,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 126/153 [01:20<00:17,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 127/153 [01:21<00:20,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%| | 128/153 [01:21<00:16,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%| | 129/153 [01:22<00:16,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%| | 130/153 [01:23<00:16,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 131/153 [01:24<00:14,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 132/153 [01:24<00:13,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 133/153 [01:25<00:11,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 134/153 [01:27<00:22,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 135/153 [01:28<00:20,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%| | 136/153 [01:29<00:16,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 137/153 [01:29<00:13,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 138/153 [01:31<00:14,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%| | 139/153 [01:31<00:11,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|| 140/153 [01:31<00:08,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|| 141/153 [01:32<00:07,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 142/153 [01:32<00:06,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 143/153 [01:33<00:07,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|| 144/153 [01:34<00:06,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|| 145/153 [01:35<00:05,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|| 146/153 [01:35<00:04,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 147/153 [01:36<00:03,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 148/153 [01:36<00:02,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 149/153 [01:36<00:01,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|| 150/153 [01:37<00:01,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|| 151/153 [01:38<00:01,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|| 152/153 [01:38<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 153/153 [01:39<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                           text  \\\n",
              "0                                                                                                                                                                                                                                               How do I use the SDK to upload a ranking model?   \n",
              "1                                                                                                                                                                                                                                                    What drift metrics are supported in Arize?   \n",
              "2                                                                                                                                                                                                                                                              Does Arize support batch models?   \n",
              "3                                                                                                                                                                                                                                                             Does Arize support training data?   \n",
              "4                                                                                                                                                                                                                             How do I configure a threshold if my data has seasonality trends?   \n",
              "..                                                                                                                                                                                                                                                                                          ...   \n",
              "148                                                                                                                                                                                                                                                  Do you support IoU for image segmentation?   \n",
              "149                                                                                                                                                                                                                                                                    This is a test question?   \n",
              "150                                                                                                                                                                                                                                                                                           ?   \n",
              "151                                                                                                                                                                                                                                                                         This is a question?   \n",
              "152  My service is a hosting service designed for hosting your website. You can put your website on our service and host it with accelerated CDN delivery, tracking of usage data for running your website. Our service is one of the best on the internet in terms of delivery and experience.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            context_text_0  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \\n**Check out our** **How to Monitor Ranking Model's** **blog and follow along with our various** **Colab** **examples here.**&#x20;\\n\\n   \n",
              "1    \\nArize calculates drift metrics such as Population Stability Index, KL Divergence, and Wasserstein Distance. Arize computes drift by measuring distribution changes between the models production values and a baseline (reference dataset). Users can configure a baseline to be any time window of a:\\n\\n1. Pre-production dataset (training, test, validation) or\\n2. Fixed or moving time period from production (e.g. last 30 days, last 60 days).&#x20;\\n\\nBaselines are saved in Arize so that users can compare several versions and/or environments against each other across moving or fixed time windows. For more details on baselines, visit here.\\n\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \\nArize supports many model types - check out our various Model Types to learn more.&#x20;\\n\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                         \\nArize natively supports binary classification, multi-class classification, regression, ranking, NLP, and CV model types. Your model type informs the **data ingestion format** and **the performance metrics** that can be utilized in the platform.&#x20;\\n\\n   \n",
              "4                                                                                                                                                                        \\nAutomatic thresholds set a dynamic threshold value for each data point. Arize generates an auto threshold when there are at least 14 days of production data to determine a trend. You can edit your auto threshold sensitivity by changing the standard deviation number in the 'Monitor Settings' card.&#x20;\\n\\nLearn more here about how an auto threshold value is calculated.&#x20;\\n\\nAuto Threshold\\n\\nToggle automatic thresholds on or off from the Edit monitor configuration.\\n\\n   \n",
              "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
              "148                                                                                                                                                                                                                                                                                                                                                                                                                                                    \\nArize supports 2 methods for ingesting and visualizing feature importance\\n\\nMethodUser Calculated SHAPshap.mdimage (33).pngGroup 1 (2).pngSurrogate Modelsurrogate-model.mdimage (23).pngGroup 2 (2).png\\n\\n\\n\\n   \n",
              "149                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \\nIn the example above, there wasn't enough context on video quality to be able to correctly answer the user questions. Adding more context can help.&#x20;\\n\\n   \n",
              "150                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \\n\\n\\n\\n   \n",
              "151                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\n   \n",
              "152                                                                                                                                                                                                                                                                                                                                                                                                                                       \\nMonitors surface potential issues with performance and data, sending real-time alerts so you can take immediate action. Learn how to programmatically update email alerts and integrate with other altering systems.&#x20;\\n\\n   \n",
              "\n",
              "    openai_relevance_0  \\\n",
              "0           irrelevant   \n",
              "1             relevant   \n",
              "2           irrelevant   \n",
              "3           irrelevant   \n",
              "4           irrelevant   \n",
              "..                 ...   \n",
              "148         irrelevant   \n",
              "149         irrelevant   \n",
              "150         irrelevant   \n",
              "151         irrelevant   \n",
              "152         irrelevant   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                               context_text_1  \\\n",
              "0                                                                                                                                                                                                                                                  \\n**Use the 'arize-demo-hotel-ranking' model, available in all free accounts, to follow along.**&#x20;\\n\\n   \n",
              "1    \\nDrift monitors measure distribution drift, which is the difference between two statistical distributions.&#x20;\\n\\nArize offers various distributional drift metrics to choose from when setting up a monitor. Each metric is tailored to a specific use case; refer to this guide to help choose the appropriate metric for various ML use cases.\\n\\n   \n",
              "2                                                                                            \\nArize natively supports binary classification, multi-class classification, regression, ranking, NLP, and CV model types. Your model type informs the **data ingestion format** and **the performance metrics** that can be utilized in the platform.&#x20;\\n\\n   \n",
              "3                                                                                                                                                                               \\nArize natively supports tabular/structured data types (strings, floats, booleans, etc), as well as embedding support for NLP, Image, and other unstructured data types.\\n\\n   \n",
              "4                                 \\nAutothresholds are calculated based on a statistical analysis of data over 14 days. Each day, a data point is collected, and after 14 days, the average (mean) and standard deviation of these data points are computed. The thresholds is then set by adding or subtracting the standard deviation from the average.\\n\\n   \n",
              "..                                                                                                                                                                                                                                                                                                                                                        ...   \n",
              "148                                                                                      \\nObject detection models identify and locate objects within images or videos by assigning them specific bounding boxes.\\n\\nApplicable Metrics: Accuracy, Euclidian Distance (embeddings)\\n\\nClick here for all valid model types and metric combinations.&#x20;\\n\\n   \n",
              "149                                                                                                                                                                                                                                                                                                                                                        \\n   \n",
              "150                                                                                                                                                                                                                                                                                                                                                        \\n   \n",
              "151                                                                                                                                                                                                                                                                                                                                                  \\n\\n\\n\\n   \n",
              "152                                                                                                                                               \\n* Keep your data safe on your own company's network\\n* Integrate with your company's authentication system\\n* Premier support by the Arize engineering team\\n* Self-managed or Fully managed by Arize\\n\\n   \n",
              "\n",
              "    openai_relevance_1  \n",
              "0           irrelevant  \n",
              "1             relevant  \n",
              "2           irrelevant  \n",
              "3           irrelevant  \n",
              "4           irrelevant  \n",
              "..                 ...  \n",
              "148         irrelevant  \n",
              "149         irrelevant  \n",
              "150         irrelevant  \n",
              "151         irrelevant  \n",
              "152         irrelevant  \n",
              "\n",
              "[153 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc632293-a223-41cc-9b93-d478664ea037\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>context_text_0</th>\n",
              "      <th>openai_relevance_0</th>\n",
              "      <th>context_text_1</th>\n",
              "      <th>openai_relevance_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do I use the SDK to upload a ranking model?</td>\n",
              "      <td>\\n**Check out our** **How to Monitor Ranking Model's** **blog and follow along with our various** **Colab** **examples here.**&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\n**Use the 'arize-demo-hotel-ranking' model, available in all free accounts, to follow along.**&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What drift metrics are supported in Arize?</td>\n",
              "      <td>\\nArize calculates drift metrics such as Population Stability Index, KL Divergence, and Wasserstein Distance. Arize computes drift by measuring distribution changes between the models production values and a baseline (reference dataset). Users can configure a baseline to be any time window of a:\\n\\n1. Pre-production dataset (training, test, validation) or\\n2. Fixed or moving time period from production (e.g. last 30 days, last 60 days).&amp;#x20;\\n\\nBaselines are saved in Arize so that users can compare several versions and/or environments against each other across moving or fixed time windows. For more details on baselines, visit here.\\n\\n</td>\n",
              "      <td>relevant</td>\n",
              "      <td>\\nDrift monitors measure distribution drift, which is the difference between two statistical distributions.&amp;#x20;\\n\\nArize offers various distributional drift metrics to choose from when setting up a monitor. Each metric is tailored to a specific use case; refer to this guide to help choose the appropriate metric for various ML use cases.\\n\\n</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does Arize support batch models?</td>\n",
              "      <td>\\nArize supports many model types - check out our various Model Types to learn more.&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\nArize natively supports binary classification, multi-class classification, regression, ranking, NLP, and CV model types. Your model type informs the **data ingestion format** and **the performance metrics** that can be utilized in the platform.&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Does Arize support training data?</td>\n",
              "      <td>\\nArize natively supports binary classification, multi-class classification, regression, ranking, NLP, and CV model types. Your model type informs the **data ingestion format** and **the performance metrics** that can be utilized in the platform.&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\nArize natively supports tabular/structured data types (strings, floats, booleans, etc), as well as embedding support for NLP, Image, and other unstructured data types.\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do I configure a threshold if my data has seasonality trends?</td>\n",
              "      <td>\\nAutomatic thresholds set a dynamic threshold value for each data point. Arize generates an auto threshold when there are at least 14 days of production data to determine a trend. You can edit your auto threshold sensitivity by changing the standard deviation number in the 'Monitor Settings' card.&amp;#x20;\\n\\nLearn more here about how an auto threshold value is calculated.&amp;#x20;\\n\\nAuto Threshold\\n\\nToggle automatic thresholds on or off from the Edit monitor configuration.\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\nAutothresholds are calculated based on a statistical analysis of data over 14 days. Each day, a data point is collected, and after 14 days, the average (mean) and standard deviation of these data points are computed. The thresholds is then set by adding or subtracting the standard deviation from the average.\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Do you support IoU for image segmentation?</td>\n",
              "      <td>\\nArize supports 2 methods for ingesting and visualizing feature importance\\n\\nMethodUser Calculated SHAPshap.mdimage (33).pngGroup 1 (2).pngSurrogate Modelsurrogate-model.mdimage (23).pngGroup 2 (2).png\\n\\n\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\nObject detection models identify and locate objects within images or videos by assigning them specific bounding boxes.\\n\\nApplicable Metrics: Accuracy, Euclidian Distance (embeddings)\\n\\nClick here for all valid model types and metric combinations.&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>This is a test question?</td>\n",
              "      <td>\\nIn the example above, there wasn't enough context on video quality to be able to correctly answer the user questions. Adding more context can help.&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>?</td>\n",
              "      <td>\\n\\n\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>This is a question?</td>\n",
              "      <td>\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\n\\n\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>My service is a hosting service designed for hosting your website. You can put your website on our service and host it with accelerated CDN delivery, tracking of usage data for running your website. Our service is one of the best on the internet in terms of delivery and experience.</td>\n",
              "      <td>\\nMonitors surface potential issues with performance and data, sending real-time alerts so you can take immediate action. Learn how to programmatically update email alerts and integrate with other altering systems.&amp;#x20;\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>\\n* Keep your data safe on your own company's network\\n* Integrate with your company's authentication system\\n* Premier support by the Arize engineering team\\n* Self-managed or Fully managed by Arize\\n\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153 rows  5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc632293-a223-41cc-9b93-d478664ea037')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc632293-a223-41cc-9b93-d478664ea037 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc632293-a223-41cc-9b93-d478664ea037');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dcf39529-94f0-4b57-9b9d-9dccfcc5d85c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcf39529-94f0-4b57-9b9d-9dccfcc5d85c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dcf39529-94f0-4b57-9b9d-9dccfcc5d85c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"]#\",\n  \"rows\": 153,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 153,\n        \"samples\": [\n          \"How do I rotate my credentials?\",\n          \"What is arize's retention policy?\",\n          \"What counts against my plan usage?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_text_0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 105,\n        \"samples\": [\n          \"\\nThis section allows to set a specific threshold or allow Arize to automatically adjust the threshold to your data. More details here.\\n\\n\",\n          \"\\nUse the email address created for the rule to send for key retrain alerts.\\n\\n!\\n\\n\",\n          \"\\nNavigate here for step-by-step instructions to enable access to view private AWS S3 image links.&#x20;\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"openai_relevance_0\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"relevant\",\n          \"irrelevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_text_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 110,\n        \"samples\": [\n          \"\\nCustom metrics have the same functionality as any other metric within the Arize platform. Use custom metrics in monitors, dashboards, and performance tracing to ensure your model works as expected.&#x20;\\n\\n\",\n          \"\\nTable permissions enable Arize to access, read, and sync your data.\\n\\n**In Arize**: Copy the code snippet in the \\u201cPermissions Configuration\\u201d card\\n\\nCopy Permissions Configuration in Arize\\n\\n**In Snowflake**: Paste the 'Permissions Configuration' code snippet in a Snowflake SQL Worksheet and click 'Run All'. See docs on granting permissions to Arize's role for Snowflake.\\n\\nSnowflake SQL Worksheet\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"openai_relevance_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"relevant\",\n          \"irrelevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Compute Ranking Metrics\n",
        "\n",
        "Now that you know whether each piece of retrieved context is relevant or irrelevant to the corresponding query, you can compute precision@k for k = 1, 2 for each query. This metric tells you what percentage of the retrieved context is relevant to the corresponding query.\n",
        "\n",
        "precision@k = (# of top-k retrieved documents that are relevant) / (k retrieved documents)\n",
        "\n",
        "If your precision@2 is greater than zero for a particular query, your LangChain application successfully retrieved at least one relevant piece of context with which to answer the query. If the precision@k is zero for a particular query, that means that no relevant piece of context was retrieved.\n",
        "\n",
        "Compute precision@k for k = 1, 2 and view the results."
      ],
      "metadata": {
        "id": "wO_tx_UiocLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_relevant_documents_array = np.zeros(len(sample_query_df))\n",
        "num_retrieved_documents = 2\n",
        "for retrieved_document_index in range(0, num_retrieved_documents):\n",
        "    num_retrieved_documents = retrieved_document_index + 1\n",
        "    num_relevant_documents_array += (\n",
        "        sample_query_df[f\"openai_relevance_{retrieved_document_index}\"]\n",
        "        .map(lambda x: int(x == \"relevant\"))\n",
        "        .to_numpy()\n",
        "    )\n",
        "    sample_query_df[f\"openai_precision@{num_retrieved_documents}\"] = pd.Series(\n",
        "        num_relevant_documents_array / num_retrieved_documents\n",
        "    )\n",
        "\n",
        "sample_query_df[\n",
        "    [\n",
        "        \"openai_relevance_0\",\n",
        "        \"openai_relevance_1\",\n",
        "        \"openai_precision@1\",\n",
        "        \"openai_precision@2\",\n",
        "    ]\n",
        "]"
      ],
      "metadata": {
        "id": "7KSWOGfOX0SM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "58ecaaf4-29dd-432c-e58d-00c34b127bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    openai_relevance_0 openai_relevance_1  openai_precision@1  \\\n",
              "0           irrelevant         irrelevant                 0.0   \n",
              "1             relevant           relevant                 1.0   \n",
              "2           irrelevant         irrelevant                 0.0   \n",
              "3           irrelevant         irrelevant                 0.0   \n",
              "4           irrelevant         irrelevant                 0.0   \n",
              "..                 ...                ...                 ...   \n",
              "148         irrelevant         irrelevant                 0.0   \n",
              "149         irrelevant         irrelevant                 0.0   \n",
              "150         irrelevant         irrelevant                 0.0   \n",
              "151         irrelevant         irrelevant                 0.0   \n",
              "152         irrelevant         irrelevant                 0.0   \n",
              "\n",
              "     openai_precision@2  \n",
              "0                   0.0  \n",
              "1                   1.0  \n",
              "2                   0.0  \n",
              "3                   0.0  \n",
              "4                   0.0  \n",
              "..                  ...  \n",
              "148                 0.0  \n",
              "149                 0.0  \n",
              "150                 0.0  \n",
              "151                 0.0  \n",
              "152                 0.0  \n",
              "\n",
              "[153 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44606ad6-5c27-4d9f-b3f5-654b7482ff12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>openai_relevance_0</th>\n",
              "      <th>openai_relevance_1</th>\n",
              "      <th>openai_precision@1</th>\n",
              "      <th>openai_precision@2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relevant</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>irrelevant</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153 rows  4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44606ad6-5c27-4d9f-b3f5-654b7482ff12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44606ad6-5c27-4d9f-b3f5-654b7482ff12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44606ad6-5c27-4d9f-b3f5-654b7482ff12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0e39d89-c09d-423a-b29d-c9390408e3d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0e39d89-c09d-423a-b29d-c9390408e3d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0e39d89-c09d-423a-b29d-c9390408e3d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"]\",\n  \"rows\": 153,\n  \"fields\": [\n    {\n      \"column\": \"openai_relevance_0\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"relevant\",\n          \"irrelevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"openai_relevance_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"relevant\",\n          \"irrelevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"openai_precision@1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4655300916738573,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"openai_precision@2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3791125824728038,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Open the Phoenix UI if you haven't already: {session.url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sV743tR7FsTP",
        "outputId": "c4bb0753-9d0a-4206-9cf5-a9941fee9850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Open the Phoenix UI if you haven't already: https://dbgz5stb1262-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hmJVPNwL0cEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EE-Dx1TIONX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}