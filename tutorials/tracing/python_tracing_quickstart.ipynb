{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJk5gFYJtIUD"
   },
   "source": [
    "# Phoenix Tracing Tutorial - Support Agent (Python)\n",
    "\n",
    "This notebook follows along with the Phoenix Tracing Tutorial documentation:\n",
    "- [Chapter 1: Your First Traces](/docs/phoenix/tracing/tutorial/your-first-traces)\n",
    "- [Chapter 2: Annotations and Evaluation](/docs/phoenix/tracing/tutorial/annotations-and-evaluations)\n",
    "- [Chapter 3: Sessions](/docs/phoenix/tracing/tutorial/sessions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b6NIZYztIUF"
   },
   "source": [
    "# Chapter 1: Your First Traces\n",
    "\n",
    "## Setting Up Tracing\n",
    "\n",
    "### Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix-otel arize-phoenix-client openai openinference-instrumentation-openai openinference-instrumentation numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "os.environ[\"PHOENIX_API_KEY\"] = \"your-phoenix-api-key\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"your-phoenix-collector-endpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-jH-pp1tIUG"
   },
   "source": [
    "### Configure Tracing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(project_name=\"support-bot\", auto_instrument=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcZhlxUTtIUG"
   },
   "source": [
    "## Tracing LLM Calls\n",
    "\n",
    "Import libraries and set up the OpenAI client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import uuid\n",
    "from typing import Any, Dict, List, Literal, Optional, TypedDict\n",
    "\n",
    "from openai import OpenAI\n",
    "from opentelemetry import trace\n",
    "\n",
    "from phoenix.client import Client\n",
    "\n",
    "client = OpenAI()\n",
    "phoenix_client = Client()\n",
    "\n",
    "# Get a tracer for creating custom spans\n",
    "tracer = trace.get_tracer(\"support-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p63m_rk6YNH"
   },
   "source": [
    "This is a simple LLM call with tracing. All OpenAI calls are automatically traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Where is my order?\"\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Classify the query as 'order_status' or 'faq'\"},\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "    ],\n",
    ")\n",
    "print(\"\\n‚úÖ This LLM call is automatically traced! Check Phoenix UI to see the span.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anXZdap4tIUH"
   },
   "source": [
    "## Tracing Tool Calls\n",
    "\n",
    "Set up mock data for the support agent to access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(TypedDict):\n",
    "    role: Literal[\"user\", \"assistant\"]\n",
    "    content: str\n",
    "\n",
    "\n",
    "# Order Database (for tool calls)\n",
    "ORDER_DATABASE: Dict[str, Dict[str, str]] = {\n",
    "    \"ORD-12345\": {\n",
    "        \"status\": \"shipped\",\n",
    "        \"carrier\": \"FedEx\",\n",
    "        \"trackingNumber\": \"1234567890\",\n",
    "        \"eta\": \"December 11, 2025\",\n",
    "    },\n",
    "    \"ORD-67890\": {\n",
    "        \"status\": \"processing\",\n",
    "        \"carrier\": \"pending\",\n",
    "        \"trackingNumber\": \"pending\",\n",
    "        \"eta\": \"December 15, 2025\",\n",
    "    },\n",
    "    \"ORD-11111\": {\n",
    "        \"status\": \"delivered\",\n",
    "        \"carrier\": \"UPS\",\n",
    "        \"trackingNumber\": \"9876543210\",\n",
    "        \"eta\": \"Delivered December 5, 2025\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# FAQ Database (for RAG)\n",
    "class FAQEntry(TypedDict):\n",
    "    id: int\n",
    "    question: str\n",
    "    answer: str\n",
    "    category: str\n",
    "    embedding: Optional[List[float]]\n",
    "\n",
    "\n",
    "FAQ_DATABASE: List[FAQEntry] = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"question\": \"How do I reset my password?\",\n",
    "        \"answer\": \"Go to Settings > Security > Reset Password. You'll receive an email with a reset link that expires in 24 hours.\",\n",
    "        \"category\": \"Account\",\n",
    "        \"embedding\": None,\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"question\": \"What's your refund policy?\",\n",
    "        \"answer\": \"We offer full refunds within 30 days of purchase for unused items. Contact support with your order number to initiate a refund.\",\n",
    "        \"category\": \"Billing\",\n",
    "        \"embedding\": None,\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"question\": \"How do I cancel my subscription?\",\n",
    "        \"answer\": \"Go to Account Settings > Subscription > Cancel Subscription. Your access continues until the end of the current billing period.\",\n",
    "        \"category\": \"Billing\",\n",
    "        \"embedding\": None,\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"question\": \"What payment methods do you accept?\",\n",
    "        \"answer\": \"We accept Visa, Mastercard, American Express, PayPal, and Apple Pay. All transactions are securely processed.\",\n",
    "        \"category\": \"Billing\",\n",
    "        \"embedding\": None,\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"question\": \"How do I update my profile information?\",\n",
    "        \"answer\": \"Go to Account Settings > Profile. You can update your name, email, phone number, and address there.\",\n",
    "        \"category\": \"Account\",\n",
    "        \"embedding\": None,\n",
    "    },\n",
    "]\n",
    "\n",
    "QueryCategory = Literal[\"order_status\", \"faq\"]\n",
    "\n",
    "\n",
    "class ClassificationResult(TypedDict):\n",
    "    category: QueryCategory\n",
    "    confidence: str\n",
    "    reasoning: str\n",
    "\n",
    "\n",
    "class AgentResponse(TypedDict):\n",
    "    query: str\n",
    "    response: str\n",
    "    spanId: str\n",
    "    category: QueryCategory\n",
    "    sessionId: Optional[str]\n",
    "\n",
    "\n",
    "class SessionContext(TypedDict):\n",
    "    lastMentionedOrderId: Optional[str]\n",
    "    turnCount: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQD8A9E_7WD7"
   },
   "source": [
    "Example query with tool calling. Tools allow your agent to interact with databases, APIs, and external systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.semconv.trace import SpanAttributes\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookupOrderStatus\",\n",
    "            \"description\": \"Look up the current status of a customer order by order ID\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"orderId\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The order ID to look up (e.g., ORD-12345)\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"orderId\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Helper function to execute tools automatically\n",
    "def execute_tool_call(tool_call, database):\n",
    "    \"\"\"Execute a tool call and return the result.\"\"\"\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    with tracer.start_as_current_span(\n",
    "        function_name,\n",
    "        attributes={\n",
    "            SpanAttributes.OPENINFERENCE_SPAN_KIND: \"TOOL\",\n",
    "            SpanAttributes.TOOL_NAME: function_name,\n",
    "            SpanAttributes.TOOL_PARAMETERS: json.dumps(function_args),\n",
    "            SpanAttributes.INPUT_VALUE: json.dumps(function_args),\n",
    "        },\n",
    "    ) as tool_span:\n",
    "        if function_name == \"lookupOrderStatus\":\n",
    "            order_id = function_args.get(\"orderId\")\n",
    "            result = database.get(order_id, {\"error\": f\"Order {order_id} not found\"})\n",
    "        else:\n",
    "            result = {\"error\": f\"Unknown tool: {function_name}\"}\n",
    "\n",
    "        tool_span.set_attribute(SpanAttributes.OUTPUT_VALUE, json.dumps(result))\n",
    "        tool_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "        return result\n",
    "\n",
    "\n",
    "user_query = \"What is the status of ORD-12345?\"\n",
    "\n",
    "# Create a parent span to group all spans\n",
    "with tracer.start_as_current_span(\n",
    "    \"tool-call-example\",\n",
    "    attributes={\n",
    "        SpanAttributes.OPENINFERENCE_SPAN_KIND: \"CHAIN\",\n",
    "        SpanAttributes.INPUT_VALUE: user_query,\n",
    "    },\n",
    ") as parent_span:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful customer support agent. When customers ask about order status, use the lookupOrderStatus tool to get the information.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "    ]\n",
    "\n",
    "    result = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "    message = result.choices[0].message\n",
    "    messages.append(message)\n",
    "\n",
    "    # Execute tool if called, then get final response\n",
    "    if message.tool_calls:\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = execute_tool_call(tool_call, ORDER_DATABASE)\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(tool_result),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Final LLM call with tool result\n",
    "        final_result = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        final_response = final_result.choices[0].message.content\n",
    "    else:\n",
    "        final_response = message.content\n",
    "\n",
    "    parent_span.set_attribute(SpanAttributes.OUTPUT_VALUE, final_response)\n",
    "    parent_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "    print(f\"Query: {user_query}\")\n",
    "print(f\"Response: {final_response}\")\n",
    "print(\"‚úÖ Check Phoenix UI to see the full trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRUeaGJAtIUH"
   },
   "source": [
    "## Tracing RAG Pipelines\n",
    "\n",
    "Helper functions for embeddings and similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(a: List[float], b: List[float]) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    a_array = np.array(a)\n",
    "    b_array = np.array(b)\n",
    "    dot_product = np.dot(a_array, b_array)\n",
    "    magnitude_a = np.linalg.norm(a_array)\n",
    "    magnitude_b = np.linalg.norm(b_array)\n",
    "    return dot_product / (magnitude_a * magnitude_b)\n",
    "\n",
    "\n",
    "def initialize_faq_embeddings() -> None:\n",
    "    print(\"üìö Initializing FAQ embeddings...\")\n",
    "\n",
    "    for faq in FAQ_DATABASE:\n",
    "        response = client.embeddings.create(model=\"text-embedding-ada-002\", input=faq[\"question\"])\n",
    "        faq[\"embedding\"] = response.data[0].embedding\n",
    "\n",
    "    print(\"‚úÖ FAQ embeddings initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLH1ibSAAayS"
   },
   "source": [
    "Example RAG pipeline with tracing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, initialize embeddings (only need to do this once)\n",
    "initialize_faq_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"How do I reset my password?\"\n",
    "\n",
    "with tracer.start_as_current_span(\n",
    "    \"rag-example\",\n",
    "    attributes={\n",
    "        SpanAttributes.OPENINFERENCE_SPAN_KIND: \"CHAIN\",\n",
    "        SpanAttributes.INPUT_VALUE: user_query,\n",
    "    },\n",
    ") as parent_span:\n",
    "    # Step 1: Embed the query (automatically traced)\n",
    "    embedding_response = client.embeddings.create(model=\"text-embedding-ada-002\", input=user_query)\n",
    "    query_embedding = embedding_response.data[0].embedding\n",
    "\n",
    "    # Step 2: Find relevant FAQs using cosine similarity\n",
    "    faq_scores = []\n",
    "    for faq in FAQ_DATABASE:\n",
    "        if faq[\"embedding\"]:\n",
    "            score = cosine_similarity(query_embedding, faq[\"embedding\"])\n",
    "            faq_scores.append((faq, score))\n",
    "\n",
    "    relevant_faqs = sorted(faq_scores, key=lambda x: x[1], reverse=True)[:2]\n",
    "\n",
    "    with tracer.start_as_current_span(\n",
    "        \"faq-retrieval\",\n",
    "        attributes={\n",
    "            SpanAttributes.OPENINFERENCE_SPAN_KIND: \"RETRIEVER\",\n",
    "            SpanAttributes.INPUT_VALUE: user_query,\n",
    "        },\n",
    "    ) as retrieval_span:\n",
    "        for i, (faq, score) in enumerate(relevant_faqs):\n",
    "            retrieval_span.set_attribute(f\"retrieval.documents.{i}.document.id\", str(faq[\"id\"]))\n",
    "            retrieval_span.set_attribute(\n",
    "                f\"retrieval.documents.{i}.document.content\",\n",
    "                f\"Q: {faq['question']}\\nA: {faq['answer']}\",\n",
    "            )\n",
    "            retrieval_span.set_attribute(\n",
    "                f\"retrieval.documents.{i}.document.metadata\",\n",
    "                json.dumps({\"category\": faq[\"category\"], \"score\": score}),\n",
    "            )\n",
    "\n",
    "        retrieval_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "\n",
    "    # Step 3: Build context from retrieved FAQs\n",
    "    rag_context = \"\\n\\n\".join(\n",
    "        [f\"Q: {faq['question']}\\nA: {faq['answer']}\" for faq, _ in relevant_faqs]\n",
    "    )\n",
    "\n",
    "    # Step 4: Generate answer with retrieved context (automatically traced)\n",
    "    rag_result = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a helpful customer support agent. Answer the user's question using ONLY the information provided in the context below. Be friendly and concise.\\n\\nContext:\\n{rag_context}\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    final_response = rag_result.choices[0].message.content\n",
    "    parent_span.set_attribute(SpanAttributes.OUTPUT_VALUE, final_response)\n",
    "    parent_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "    print(f\"Query: {user_query}\")\n",
    "print(f\"Response: {final_response}\")\n",
    "print(\"\\n‚úÖ All RAG operations are traced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghs9YbAtIUI"
   },
   "source": [
    "## Grouping Operations with Parent Spans\n",
    "\n",
    "The complete support agent that wraps all operations in a parent span.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation import using_session\n",
    "from opentelemetry.trace import format_span_id\n",
    "\n",
    "\n",
    "def handle_support_query(\n",
    "    user_query: str,\n",
    "    session_id: Optional[str] = None,\n",
    "    conversation_history: List[Message] = None,\n",
    "    session_context: SessionContext = None,\n",
    ") -> AgentResponse:\n",
    "    \"\"\"\n",
    "    Handle a support query with optional session tracking.\n",
    "\n",
    "    Args:\n",
    "        user_query: The user's question\n",
    "        session_id: Optional session ID for multi-turn conversations\n",
    "        conversation_history: Previous messages in the conversation\n",
    "        session_context: Context from previous turns\n",
    "    \"\"\"\n",
    "    if conversation_history is None:\n",
    "        conversation_history = []\n",
    "    if session_context is None:\n",
    "        session_context = {\"lastMentionedOrderId\": None, \"turnCount\": 0}\n",
    "\n",
    "    def run_agent() -> AgentResponse:\n",
    "        with tracer.start_as_current_span(\n",
    "            \"support-agent\",\n",
    "            attributes={\n",
    "                SpanAttributes.OPENINFERENCE_SPAN_KIND: \"AGENT\",\n",
    "                SpanAttributes.INPUT_VALUE: user_query,\n",
    "                **({SpanAttributes.SESSION_ID: session_id} if session_id else {}),\n",
    "                \"conversation.turn\": session_context[\"turnCount\"] + 1,\n",
    "            },\n",
    "        ) as agent_span:\n",
    "            # Capture the span ID\n",
    "            span_id = format_span_id(agent_span.get_span_context().span_id)\n",
    "            category: QueryCategory = \"faq\"\n",
    "\n",
    "            try:\n",
    "                print(\"\\n\" + \"=\" * 60)\n",
    "                print(\"ü§ñ Support Agent Processing Query\")\n",
    "                print(\"=\" * 60)\n",
    "                print(f'üì® Query: \"{user_query}\"')\n",
    "                print(f\"   Span ID: {span_id}\")\n",
    "                if session_id:\n",
    "                    print(f\"   Session ID: {session_id}\")\n",
    "                    print(f\"   Turn: {session_context['turnCount'] + 1}\")\n",
    "\n",
    "                # Build conversation context for multi-turn support\n",
    "                conversation_context = (\n",
    "                    \"\\n\\nPrevious conversation:\\n\"\n",
    "                    + \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in conversation_history])\n",
    "                    if conversation_history\n",
    "                    else \"\"\n",
    "                )\n",
    "\n",
    "                # Check if we have a remembered order ID from previous turns\n",
    "                remembered_order_info = (\n",
    "                    f\"\\nNote: The customer previously mentioned order {session_context['lastMentionedOrderId']}.\"\n",
    "                    if session_context[\"lastMentionedOrderId\"]\n",
    "                    else \"\"\n",
    "                )\n",
    "\n",
    "                # Step 1: Classify the query\n",
    "                print(\"\\nüìã Step 1: Classifying query...\")\n",
    "\n",
    "                classification_prompt = f\"\"\"You are a support query classifier. Classify the user's query into one of these categories:\n",
    "\n",
    "1. \"order_status\" - Questions about order tracking, delivery status, shipping, where is my order, tracking numbers, ETAs\n",
    "2. \"faq\" - General questions about accounts, billing, refunds, passwords, subscriptions, payment methods\n",
    "{remembered_order_info}\n",
    "Respond with JSON only:\n",
    "{{\n",
    "  \"category\": \"order_status\" or \"faq\",\n",
    "  \"confidence\": \"high\" or \"medium\" or \"low\",\n",
    "  \"reasoning\": \"brief explanation\"\n",
    "}}\"\"\"\n",
    "\n",
    "                classification_response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": classification_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_query + conversation_context},\n",
    "                    ],\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "\n",
    "                classification_text = classification_response.choices[0].message.content\n",
    "\n",
    "                try:\n",
    "                    classification: ClassificationResult = json.loads(classification_text)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Default to FAQ if parsing fails\n",
    "                    classification = {\n",
    "                        \"category\": \"faq\",\n",
    "                        \"confidence\": \"low\",\n",
    "                        \"reasoning\": \"Failed to parse classification\",\n",
    "                    }\n",
    "\n",
    "                print(f\"   Category: {classification['category']}\")\n",
    "                print(f\"   Reasoning: {classification['reasoning']}\")\n",
    "\n",
    "                category = classification[\"category\"]\n",
    "                agent_span.set_attribute(\"classification.category\", classification[\"category\"])\n",
    "                agent_span.set_attribute(\"classification.confidence\", classification[\"confidence\"])\n",
    "\n",
    "                # Step 2: Route based on classification\n",
    "                if classification[\"category\"] == \"order_status\":\n",
    "                    print(\"\\nüîß Step 2: Deciding whether to use tool...\")\n",
    "\n",
    "                    order_prompt = (\n",
    "                        f'{user_query}\\n\\nNote: Earlier in this conversation, the customer mentioned order {session_context[\"lastMentionedOrderId\"]}. If they\\'re asking about \"that order\" or similar, use this order ID.'\n",
    "                        if session_context[\"lastMentionedOrderId\"]\n",
    "                        else user_query\n",
    "                    )\n",
    "\n",
    "                    # Define the tool for order lookup\n",
    "                    tools = [\n",
    "                        {\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"name\": \"lookupOrderStatus\",\n",
    "                                \"description\": \"Look up the current status of a customer order by order ID\",\n",
    "                                \"parameters\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"orderId\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"The order ID to look up (e.g., ORD-12345)\",\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"orderId\"],\n",
    "                                },\n",
    "                            },\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "                    tool_decision = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": \"You are a helpful customer support agent. When customers ask about order status, use the lookupOrderStatus tool to get the information. If no order ID is mentioned and none was mentioned earlier, ask for it politely. Always use the tool when an order ID is provided or referenced.\",\n",
    "                            },\n",
    "                            {\"role\": \"user\", \"content\": order_prompt},\n",
    "                        ],\n",
    "                        tools=tools,\n",
    "                        tool_choice=\"auto\",\n",
    "                    )\n",
    "\n",
    "                    # Check if tool was called\n",
    "                    message = tool_decision.choices[0].message\n",
    "                    order_info: Optional[Dict[str, Any]] = None\n",
    "\n",
    "                    if message.tool_calls:\n",
    "                        tool_call = message.tool_calls[0]\n",
    "                        function_name = tool_call.function.name\n",
    "                        function_args = json.loads(tool_call.function.arguments)\n",
    "                        order_id = function_args.get(\"orderId\")\n",
    "\n",
    "                        print(f\"   üîß Tool called: {function_name}({order_id})\")\n",
    "\n",
    "                        # Create a span for the tool call\n",
    "                        with tracer.start_as_current_span(\n",
    "                            function_name,\n",
    "                            attributes={\n",
    "                                SpanAttributes.OPENINFERENCE_SPAN_KIND: \"TOOL\",\n",
    "                                SpanAttributes.TOOL_NAME: function_name,\n",
    "                                SpanAttributes.TOOL_PARAMETERS: json.dumps(function_args),\n",
    "                                SpanAttributes.INPUT_VALUE: json.dumps(function_args),\n",
    "                            },\n",
    "                        ) as tool_span:\n",
    "                            order = ORDER_DATABASE.get(order_id)\n",
    "                            if not order:\n",
    "                                order_info = {\"error\": f\"Order {order_id} not found in our system\"}\n",
    "                                tool_span.set_attribute(\n",
    "                                    SpanAttributes.OUTPUT_VALUE, json.dumps(order_info)\n",
    "                                )\n",
    "                                tool_span.set_status(\n",
    "                                    trace.Status(trace.StatusCode.ERROR, \"Order not found\")\n",
    "                                )\n",
    "                            else:\n",
    "                                print(f\"   ‚úÖ Order found: {json.dumps(order)}\")\n",
    "                                order_info = {\"orderId\": order_id, **order}\n",
    "                                tool_span.set_attribute(\n",
    "                                    SpanAttributes.OUTPUT_VALUE, json.dumps(order_info)\n",
    "                                )\n",
    "                                tool_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "\n",
    "                    if order_info and \"error\" not in order_info:\n",
    "                        print(f\"   üì¶ Order info for response: {json.dumps(order_info)}\")\n",
    "                        print(\"\\nüí¨ Step 3: Generating response from tool result...\")\n",
    "\n",
    "                        final_response = client.chat.completions.create(\n",
    "                            model=\"gpt-4o-mini\",\n",
    "                            messages=[\n",
    "                                {\n",
    "                                    \"role\": \"system\",\n",
    "                                    \"content\": \"You are a helpful customer support agent. Summarize order information in a friendly way. Use the exact data provided - do not make up information.\",\n",
    "                                },\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": f\"\"\"Customer asked: \"{user_query}\"\n",
    "\n",
    "Here is the order information I found:\n",
    "- Order ID: {order_info[\"orderId\"]}\n",
    "- Status: {order_info[\"status\"]}\n",
    "- Carrier: {order_info[\"carrier\"]}\n",
    "- Tracking Number: {order_info[\"trackingNumber\"]}\n",
    "- Estimated Arrival: {order_info[\"eta\"]}\n",
    "\n",
    "Write a friendly 2-3 sentence response sharing this information with the customer.\"\"\",\n",
    "                                },\n",
    "                            ],\n",
    "                        )\n",
    "\n",
    "                        response = final_response.choices[0].message.content\n",
    "                    else:\n",
    "                        response = (\n",
    "                            message.content\n",
    "                            or \"I'd be happy to help you with your order status. Could you please provide your order ID? It should look like ORD-XXXXX.\"\n",
    "                        )\n",
    "\n",
    "                else:\n",
    "                    # Handle FAQ with RAG\n",
    "                    print(\"\\nüìö Step 2: Searching knowledge base (RAG)...\")\n",
    "\n",
    "                    # Embed the query\n",
    "                    embedding_response = client.embeddings.create(\n",
    "                        model=\"text-embedding-ada-002\", input=user_query\n",
    "                    )\n",
    "                    query_embedding = embedding_response.data[0].embedding\n",
    "\n",
    "                    # Find relevant FAQs\n",
    "                    faq_scores = []\n",
    "                    for faq in FAQ_DATABASE:\n",
    "                        if faq[\"embedding\"]:\n",
    "                            score = cosine_similarity(query_embedding, faq[\"embedding\"])\n",
    "                            faq_scores.append((faq, score))\n",
    "\n",
    "                    relevant_faqs = sorted(faq_scores, key=lambda x: x[1], reverse=True)[:2]\n",
    "\n",
    "                    print(\"   Found relevant FAQs\")\n",
    "\n",
    "                    # Create a retrieval span to track the retrieval operation\n",
    "                    with tracer.start_as_current_span(\n",
    "                        \"faq-retrieval\",\n",
    "                        attributes={\n",
    "                            SpanAttributes.OPENINFERENCE_SPAN_KIND: \"RETRIEVER\",\n",
    "                            SpanAttributes.INPUT_VALUE: user_query,\n",
    "                        },\n",
    "                    ) as retrieval_span:\n",
    "                        for i, (faq, score) in enumerate(relevant_faqs):\n",
    "                            retrieval_span.set_attribute(\n",
    "                                f\"retrieval.documents.{i}.document.id\", str(faq[\"id\"])\n",
    "                            )\n",
    "                            retrieval_span.set_attribute(\n",
    "                                f\"retrieval.documents.{i}.document.content\",\n",
    "                                f\"Q: {faq['question']}\\nA: {faq['answer']}\",\n",
    "                            )\n",
    "                            metadata_str = json.dumps(\n",
    "                                {\"category\": faq[\"category\"], \"score\": float(score)}\n",
    "                            )\n",
    "                            retrieval_span.set_attribute(\n",
    "                                f\"retrieval.documents.{i}.document.metadata\", metadata_str\n",
    "                            )\n",
    "\n",
    "                        retrieval_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "\n",
    "                    # Build context\n",
    "                    rag_context = \"\\n\\n\".join(\n",
    "                        [f\"Q: {faq['question']}\\nA: {faq['answer']}\" for faq, _ in relevant_faqs]\n",
    "                    )\n",
    "\n",
    "                    # Generate answer\n",
    "                    print(\"\\nüí¨ Step 3: Generating response...\")\n",
    "\n",
    "                    rag_result = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": f\"You are a helpful customer support agent. Answer the user's question using ONLY the information provided in the context below. Be friendly and concise.\\n\\nContext:\\n{rag_context}\",\n",
    "                            },\n",
    "                            {\"role\": \"user\", \"content\": user_query},\n",
    "                        ],\n",
    "                    )\n",
    "\n",
    "                    response = rag_result.choices[0].message.content\n",
    "\n",
    "                print(f\"\\nüì§ Response: {response}\")\n",
    "                print(\"=\" * 60)\n",
    "\n",
    "                agent_span.set_attribute(SpanAttributes.OUTPUT_VALUE, response)\n",
    "                agent_span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "\n",
    "                return {\n",
    "                    \"query\": user_query,\n",
    "                    \"response\": response,\n",
    "                    \"spanId\": span_id,\n",
    "                    \"category\": category,\n",
    "                    \"sessionId\": session_id,\n",
    "                }\n",
    "            except Exception as error:\n",
    "                agent_span.set_status(trace.Status(trace.StatusCode.ERROR, str(error)))\n",
    "                raise\n",
    "\n",
    "    # If we have a session ID, propagate it to all child spans\n",
    "    if session_id:\n",
    "        with using_session(session_id):\n",
    "            return run_agent()\n",
    "\n",
    "    return run_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure FAQ embeddings are initialized\n",
    "initialize_faq_embeddings()\n",
    "\n",
    "queries = [\n",
    "    \"What's the status of order ORD-12345?\",\n",
    "    \"How can I get a refund?\",\n",
    "    \"Where is my order ORD-67890?\",\n",
    "    \"I forgot my password\",\n",
    "    \"What's the status of order ORD-99999?\",\n",
    "    \"How do I upgrade to premium?\",\n",
    "    \"Can you help me with something?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Running Support Agent with Test Queries\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query in queries:\n",
    "    result = handle_support_query(query)\n",
    "    print(f\"\\n‚úÖ Query processed: {result['category']}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ All queries processed! Check Phoenix UI to see the traces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmmmQsCJtIUI"
   },
   "source": [
    "# Chapter 2: Annotations and Evaluation\n",
    "\n",
    "## Programmatic Annotations (User Feedback)\n",
    "\n",
    "### Get the Span ID from Running Code\n",
    "\n",
    "The support agent already captures span IDs. Now we'll collect user feedback and log it to Phoenix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.client.resources.spans import SpanAnnotationData\n",
    "\n",
    "\n",
    "def collect_user_feedback(responses: List[AgentResponse]) -> None:\n",
    "    \"\"\"\n",
    "    Collect interactive feedback from the user for each response.\n",
    "    Shows the query and response, then asks for thumbs up/down.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üëçüëé User Feedback Collection\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nFor each response, enter:\")\n",
    "    print(\"  'y' or '1' = üëç thumbs-up (good response)\")\n",
    "    print(\"  'n' or '0' = üëé thumbs-down (bad response)\")\n",
    "    print(\"  's' = skip (no feedback)\")\n",
    "    print(\"\")\n",
    "\n",
    "    annotations: List[SpanAnnotationData] = []\n",
    "\n",
    "    for i, resp in enumerate(responses):\n",
    "        print(f\"Response {i + 1} of {len(responses)}\")\n",
    "        print(f'Query: \"{resp[\"query\"]}\"')\n",
    "        print(f'Response: \"{resp[\"response\"]}\"')\n",
    "\n",
    "        answer = input(\"Was this response helpful? (y/n/s): \").strip().lower()\n",
    "\n",
    "        if answer in [\"y\", \"1\", \"yes\"]:\n",
    "            print(\"   ‚Üí üëç Recorded as thumbs-up\\n\")\n",
    "            annotations.append(\n",
    "                SpanAnnotationData(\n",
    "                    name=\"user_feedback\",\n",
    "                    span_id=resp[\"spanId\"],\n",
    "                    annotator_kind=\"HUMAN\",\n",
    "                    result={\"label\": \"thumbs-up\", \"score\": 1.0},\n",
    "                    metadata={\"category\": resp[\"category\"], \"source\": \"interactive_tutorial\"},\n",
    "                )\n",
    "            )\n",
    "        elif answer in [\"n\", \"0\", \"no\"]:\n",
    "            print(\"   ‚Üí üëé Recorded as thumbs-down\\n\")\n",
    "            annotations.append(\n",
    "                SpanAnnotationData(\n",
    "                    name=\"user_feedback\",\n",
    "                    span_id=resp[\"spanId\"],\n",
    "                    annotator_kind=\"HUMAN\",\n",
    "                    result={\"label\": \"thumbs-down\", \"score\": 0.0},\n",
    "                    metadata={\"category\": resp[\"category\"], \"source\": \"interactive_tutorial\"},\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\"   ‚Üí ‚è≠Ô∏è  Skipped\\n\")\n",
    "\n",
    "    if annotations:\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        try:\n",
    "            phoenix_client.spans.log_span_annotations(\n",
    "                span_annotations=annotations,\n",
    "                sync=False,\n",
    "            )\n",
    "            print(f\"‚úÖ Logged {len(annotations)} feedback annotations to Phoenix\")\n",
    "        except Exception as error:\n",
    "            print(f\"Failed to log feedback: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weM6pzBGCT62"
   },
   "source": [
    "Example: Collect feedback on support agent responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What's the status of order ORD-12345?\",\n",
    "    \"How can I get a refund?\",\n",
    "    \"I forgot my password\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Running Support Agent Queries\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "responses = []\n",
    "for query in queries:\n",
    "    result = handle_support_query(query)\n",
    "    responses.append(result)\n",
    "\n",
    "collect_user_feedback(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhj8DaJKDNgM"
   },
   "source": [
    "## LLM-as-a-Judge Evaluations\n",
    "\n",
    "### Install the Phoenix Evals Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix-evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9axAoXGwD2-j"
   },
   "source": [
    "### Tool Result Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkpye4qoD7H3"
   },
   "source": [
    "Did the tool call succeed or return an error? This is a simple code-based check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch spans from Phoenix\n",
    "spans = phoenix_client.spans.get_spans(\n",
    "    project_identifier=\"support-bot\",\n",
    "    limit=200,\n",
    ")\n",
    "\n",
    "# Filter for tool spans (lookupOrderStatus)\n",
    "tool_spans = [span for span in spans if span.get(\"name\") == \"lookupOrderStatus\"]\n",
    "\n",
    "print(f\"Found {len(tool_spans)} tool spans\")\n",
    "\n",
    "# Tool Result Evaluator - code-based check\n",
    "tool_annotations = []\n",
    "\n",
    "for span in tool_spans:\n",
    "    # Access span_id from context\n",
    "    context = span.get(\"context\", {})\n",
    "    span_id = context.get(\"span_id\", \"\") if isinstance(context, dict) else \"\"\n",
    "\n",
    "    # Access attributes (may be a dict or JSON string)\n",
    "    attributes = span.get(\"attributes\", {})\n",
    "    if isinstance(attributes, str):\n",
    "        attributes = json.loads(attributes)\n",
    "\n",
    "    output_value = attributes.get(\"output.value\", \"\")\n",
    "\n",
    "    # Simple check: does the output contain \"error\" or \"not found\"?\n",
    "    output_str = json.dumps(output_value) if not isinstance(output_value, str) else output_value\n",
    "    has_error = \"error\" in output_str.lower() or \"not found\" in output_str.lower()\n",
    "\n",
    "    status = \"‚ùå ERROR\" if has_error else \"‚úÖ SUCCESS\"\n",
    "\n",
    "    tool_annotations.append(\n",
    "        SpanAnnotationData(\n",
    "            name=\"tool_result\",\n",
    "            span_id=span_id,\n",
    "            annotator_kind=\"CODE\",\n",
    "            result={\n",
    "                \"label\": \"error\" if has_error else \"success\",\n",
    "                \"score\": 0.0 if has_error else 1.0,\n",
    "            },\n",
    "            metadata={\n",
    "                \"evaluator\": \"tool_result\",\n",
    "                \"type\": \"code\",\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluated {len(tool_annotations)} tool spans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smYkG6XdEO0_"
   },
   "source": [
    "### Retrieval Relevance Evaluator\n",
    "\n",
    "Was the retrieved context actually relevant to the question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import LLM, create_classifier\n",
    "\n",
    "# Filter for retrieval spans (RETRIEVER kind) - FAQ retrieval\n",
    "retrieval_spans = [\n",
    "    span\n",
    "    for span in spans\n",
    "    if span.get(\"span_kind\") == \"RETRIEVER\" or span.get(\"name\") == \"faq-retrieval\"\n",
    "]\n",
    "\n",
    "print(f\"Found {len(retrieval_spans)} FAQ retrieval spans\")\n",
    "\n",
    "# Create an LLM-as-Judge evaluator that determines if retrieved context was relevant\n",
    "llm = LLM(provider=\"openai\", model=\"gpt-5\")\n",
    "\n",
    "retrieval_relevance_evaluator = create_classifier(\n",
    "    name=\"retrieval_relevance\",\n",
    "    prompt_template=\"\"\"You are evaluating whether the retrieved context is relevant to answering the user's prompt.\n",
    "\n",
    "Classify the retrieval as:\n",
    "- RELEVANT: The context contains information that directly helps answer the question\n",
    "- IRRELEVANT: The context does NOT contain useful information for the question\n",
    "\n",
    "You are comparing the \"Context\" object and the \"prompt\" object.\n",
    "\n",
    "[Context and Prompt]: {input}\"\"\",\n",
    "    llm=llm,\n",
    "    choices={\"relevant\": 1, \"irrelevant\": 0},\n",
    ")\n",
    "\n",
    "# Evaluate each retrieval span\n",
    "rag_annotations = []\n",
    "\n",
    "for span in retrieval_spans:\n",
    "    # Access span_id from context\n",
    "    context = span.get(\"context\", {})\n",
    "    span_id = context.get(\"span_id\", \"\") if isinstance(context, dict) else \"\"\n",
    "\n",
    "    # Access attributes (may be a dict or JSON string)\n",
    "    attributes = span.get(\"attributes\", {})\n",
    "    if isinstance(attributes, str):\n",
    "        attributes = json.loads(attributes)\n",
    "\n",
    "    # Extract the query and retrieved documents\n",
    "    query = attributes.get(\"input.value\", \"\")\n",
    "\n",
    "    # Extract retrieved documents\n",
    "    documents = []\n",
    "    i = 0\n",
    "    while f\"retrieval.documents.{i}.document.content\" in attributes:\n",
    "        doc_content = attributes.get(f\"retrieval.documents.{i}.document.content\", \"\")\n",
    "        documents.append(doc_content)\n",
    "        i += 1\n",
    "\n",
    "    if not query or not documents:\n",
    "        span_id_short = span_id[:8] if span_id else \"unknown\"\n",
    "        print(f\"   Skipping span {span_id_short} - missing query or documents\")\n",
    "        continue\n",
    "\n",
    "    # Build input for evaluator: query + retrieved context\n",
    "    context_text = \"\\n\\n\".join(documents)\n",
    "    evaluation_input = f\"Query: {query}\\n\\nRetrieved Context:\\n{context_text}\"\n",
    "\n",
    "    try:\n",
    "        result = retrieval_relevance_evaluator.evaluate({\"input\": evaluation_input})\n",
    "        score_result = result[0] if isinstance(result, list) else result\n",
    "\n",
    "        status = \"‚úÖ RELEVANT\" if score_result.label == \"relevant\" else \"‚ùå IRRELEVANT\"\n",
    "        span_id_short = span_id[:8] if span_id else \"unknown\"\n",
    "        print(f\"   Retrieval span {span_id_short}... {status}\")\n",
    "\n",
    "        rag_annotations.append(\n",
    "            SpanAnnotationData(\n",
    "                name=\"retrieval_relevance\",\n",
    "                span_id=span_id,\n",
    "                annotator_kind=\"LLM\",\n",
    "                result={\n",
    "                    \"label\": score_result.label,\n",
    "                    \"score\": score_result.score\n",
    "                    if hasattr(score_result, \"score\")\n",
    "                    else (1.0 if score_result.label == \"relevant\" else 0.0),\n",
    "                },\n",
    "                metadata={\n",
    "                    \"model\": \"gpt-5\",\n",
    "                    \"evaluator\": \"retrieval_relevance\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        span_id_short = span_id[:8] if span_id else \"unknown\"\n",
    "        print(f\"   Error evaluating span {span_id_short}: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluated {len(rag_annotations)} retrieval spans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MylNVipuEstm"
   },
   "source": [
    "### Log Evaluations to Phoenix\n",
    "\n",
    "Log all evaluation annotations to Phoenix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_annotations = tool_annotations + rag_annotations\n",
    "\n",
    "if all_eval_annotations:\n",
    "    print(f\"\\nüì§ Logging {len(all_eval_annotations)} evaluation annotations to Phoenix...\")\n",
    "\n",
    "    try:\n",
    "        phoenix_client.spans.log_span_annotations(\n",
    "            span_annotations=all_eval_annotations,\n",
    "            sync=False,\n",
    "        )\n",
    "        print(f\"‚úÖ Logged {len(all_eval_annotations)} evaluation annotations\")\n",
    "        print(f\"   - {len(tool_annotations)} tool_result annotations\")\n",
    "        print(f\"   - {len(rag_annotations)} retrieval_relevance annotations\")\n",
    "    except Exception as error:\n",
    "        print(f\"‚ùå Failed to log evaluations: {error}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No annotations to log. Make sure you've run the support agent first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7p3dsAytIUI"
   },
   "source": [
    "# Chapter 3: Sessions\n",
    "\n",
    "## Setting Up Sessions\n",
    "\n",
    "### Add Session Tracking to Your Agent\n",
    "\n",
    "The support agent already supports sessions. Here's how to run multi-turn conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationTurn(TypedDict):\n",
    "    userMessage: str\n",
    "    expectedBehavior: str\n",
    "\n",
    "\n",
    "class ConversationScenario(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    turns: List[ConversationTurn]\n",
    "\n",
    "\n",
    "def run_multi_turn_conversation(scenario: ConversationScenario) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run a multi-turn conversation with session tracking.\n",
    "    Each conversation gets a unique session ID, and all turns are linked together.\n",
    "    \"\"\"\n",
    "    session_id = str(uuid.uuid4())\n",
    "    responses: List[AgentResponse] = []\n",
    "    conversation_history: List[Message] = []\n",
    "    session_context: SessionContext = {\"lastMentionedOrderId\": None, \"turnCount\": 0}\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"üó£Ô∏è  Conversation: {scenario['name']}\")\n",
    "    print(f\"üìù {scenario['description']}\")\n",
    "    print(f\"üîë Session ID: {session_id}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for turn in scenario[\"turns\"]:\n",
    "        print(f'\\nüí¨ Turn {session_context[\"turnCount\"] + 1}: \"{turn[\"userMessage\"]}\"')\n",
    "        print(f\"   Expected: {turn['expectedBehavior']}\")\n",
    "\n",
    "        # Run the agent with session context\n",
    "        result = handle_support_query(\n",
    "            turn[\"userMessage\"], session_id, conversation_history, session_context\n",
    "        )\n",
    "\n",
    "        responses.append(result)\n",
    "\n",
    "        # Update conversation history for next turn\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": turn[\"userMessage\"]})\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": result[\"response\"]})\n",
    "\n",
    "        # Update session context - extract order ID if mentioned\n",
    "        order_id_match = re.search(r\"ORD-\\d+\", turn[\"userMessage\"], re.IGNORECASE)\n",
    "        if not order_id_match:\n",
    "            order_id_match = re.search(r\"ORD-\\d+\", result[\"response\"], re.IGNORECASE)\n",
    "        if order_id_match:\n",
    "            session_context[\"lastMentionedOrderId\"] = order_id_match.group(0).upper()\n",
    "        session_context[\"turnCount\"] += 1\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(f\"‚úÖ Conversation complete: {len(scenario['turns'])} turns\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    return {\"sessionId\": session_id, \"responses\": responses}\n",
    "\n",
    "\n",
    "def run_sessions_demo() -> None:\n",
    "    \"\"\"Run the multi-turn sessions demo with several conversation scenarios.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Phoenix Tracing Tutorial - Sessions Demo\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nThis demo shows multi-turn conversations tracked as sessions.\")\n",
    "    print(\"Each conversation has a unique session ID that links all turns together.\")\n",
    "    print(\"View them in Phoenix UI under the 'Sessions' tab.\\n\")\n",
    "\n",
    "    # Initialize FAQ embeddings first\n",
    "    initialize_faq_embeddings()\n",
    "\n",
    "    # Define conversation scenarios\n",
    "    scenarios: List[ConversationScenario] = [\n",
    "        {\n",
    "            \"name\": \"Order Inquiry - Successful Resolution\",\n",
    "            \"description\": \"Customer asks about order, gets status, asks follow-up\",\n",
    "            \"turns\": [\n",
    "                {\n",
    "                    \"userMessage\": \"What's the status of order ORD-12345?\",\n",
    "                    \"expectedBehavior\": \"Tool call ‚Üí Returns shipped status\",\n",
    "                },\n",
    "                {\n",
    "                    \"userMessage\": \"When will it arrive?\",\n",
    "                    \"expectedBehavior\": \"Agent remembers order ‚Üí Provides ETA from previous lookup\",\n",
    "                },\n",
    "                {\n",
    "                    \"userMessage\": \"What's the tracking number?\",\n",
    "                    \"expectedBehavior\": \"Agent remembers order ‚Üí Provides tracking number\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"FAQ Conversation\",\n",
    "            \"description\": \"Customer asks multiple FAQ questions in one session\",\n",
    "            \"turns\": [\n",
    "                {\n",
    "                    \"userMessage\": \"How do I reset my password?\",\n",
    "                    \"expectedBehavior\": \"RAG ‚Üí Password reset instructions\",\n",
    "                },\n",
    "                {\n",
    "                    \"userMessage\": \"And what about refunds?\",\n",
    "                    \"expectedBehavior\": \"RAG ‚Üí Refund policy info\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mixed Conversation - Context Test\",\n",
    "            \"description\": \"Customer switches between order and FAQ topics\",\n",
    "            \"turns\": [\n",
    "                {\n",
    "                    \"userMessage\": \"Check my order ORD-67890\",\n",
    "                    \"expectedBehavior\": \"Tool call ‚Üí Processing status\",\n",
    "                },\n",
    "                {\n",
    "                    \"userMessage\": \"How do I cancel my subscription?\",\n",
    "                    \"expectedBehavior\": \"RAG ‚Üí Cancellation instructions (different topic)\",\n",
    "                },\n",
    "                {\n",
    "                    \"userMessage\": \"Back to my order - what's the carrier?\",\n",
    "                    \"expectedBehavior\": \"Agent should remember ORD-67890 from earlier\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Run all conversation scenarios\n",
    "    all_responses: List[AgentResponse] = []\n",
    "    session_ids: List[str] = []\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        result = run_multi_turn_conversation(scenario)\n",
    "        all_responses.extend(result[\"responses\"])\n",
    "        session_ids.append(result[\"sessionId\"])\n",
    "\n",
    "    # Flush traces\n",
    "    print(\"\\n‚è≥ Flushing traces...\")\n",
    "    tracer_provider.force_flush()\n",
    "    print(\"‚úÖ Traces flushed!\")\n",
    "\n",
    "    # Collect feedback\n",
    "    collect_user_feedback(all_responses)\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä Sessions Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\n   Conversations: {len(scenarios)}\")\n",
    "    print(f\"   Total turns: {len(all_responses)}\")\n",
    "    print(\"\\n   Session IDs:\")\n",
    "    for i, session_id in enumerate(session_ids):\n",
    "        print(f\"   {i + 1}. {session_id} ({scenarios[i]['name']})\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"## Viewing and Analyzing Sessions\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nWhat to look for:\")\n",
    "    print(\"   1. Click the 'Sessions' tab in your project\")\n",
    "    print(\"   2. You'll see each conversation as a separate session\")\n",
    "    print(\"   3. Click into a session to see the chatbot-like history\")\n",
    "    print(\"   4. Notice how all turns share the same session ID\")\n",
    "    print(\"   5. Check token usage and latency across the conversation\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2xgmKqptIUJ"
   },
   "source": [
    "## Running Multi-Turn Conversations\n",
    "\n",
    "Run the multi-turn sessions demo to see how conversations are tracked as cohesive units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sessions_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpg7zEt_NS1r"
   },
   "source": [
    "### Session-Level Evaluations\n",
    "\n",
    "Instead of manually reviewing every session, use LLM-as-Judge evaluation to automatically assess entire conversations. This helps answer questions like: Does the agent remember context? Are issues getting resolved? Where do conversations break down?\n",
    "\n",
    "#### Conversation Coherence Evaluator\n",
    "\n",
    "This evaluator checks if the agent maintained context throughout the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import LLM, create_classifier\n",
    "\n",
    "llm = LLM(provider=\"openai\", model=\"gpt-5\")\n",
    "\n",
    "conversation_coherence_evaluator = create_classifier(\n",
    "    name=\"conversation_coherence\",\n",
    "    prompt_template=\"\"\"You are evaluating whether a customer support agent maintained context throughout a multi-turn conversation.\n",
    "\n",
    "A conversation is COHERENT if:\n",
    "- The agent remembers information from earlier turns\n",
    "- The agent doesn't ask for information already provided\n",
    "- Responses build on previous context appropriately\n",
    "- The conversation flows naturally\n",
    "\n",
    "A conversation is INCOHERENT if:\n",
    "- The agent \"forgets\" things the customer said earlier\n",
    "- The agent asks for the same information multiple times\n",
    "- Responses seem disconnected from previous turns\n",
    "- The customer has to repeat themselves\n",
    "\n",
    "[Full Conversation]:\n",
    "{input}\n",
    "\n",
    "Did the agent maintain context throughout this conversation?\"\"\",\n",
    "    llm=llm,\n",
    "    choices={\"coherent\": 1, \"incoherent\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIjw-R2sNou0"
   },
   "source": [
    "#### Resolution Evaluator\n",
    "\n",
    "This evaluator determines if the customer's issue was actually resolved:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_evaluator = create_classifier(\n",
    "    name=\"resolution_status\",\n",
    "    prompt_template=\"\"\"You are evaluating whether a customer's issue was resolved in a support conversation.\n",
    "\n",
    "The issue is RESOLVED if:\n",
    "- The customer got the information they needed\n",
    "- Their question was answered\n",
    "- The conversation ended with the customer's needs met\n",
    "\n",
    "The issue is UNRESOLVED if:\n",
    "- The customer didn't get what they needed\n",
    "- Questions went unanswered\n",
    "- The agent couldn't help with the request\n",
    "\n",
    "[Full Conversation]:\n",
    "{input}\n",
    "\n",
    "Was the customer's issue resolved?\"\"\",\n",
    "    llm=llm,\n",
    "    choices={\"resolved\": 1, \"unresolved\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SQFrZczNvSN"
   },
   "source": [
    "### Running Session Evaluations\n",
    "Fetch spans from Phoenix, group them by session ID, and evaluate each session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.client.resources.sessions import SessionAnnotationData\n",
    "\n",
    "# Fetch all agent spans\n",
    "spans = phoenix_client.spans.get_spans(\n",
    "    project_identifier=\"support-bot\",\n",
    "    limit=200,\n",
    ")\n",
    "\n",
    "# Filter to agent spans and group by session ID\n",
    "agent_spans = [span for span in spans if span.get(\"name\") == \"support-agent\"]\n",
    "\n",
    "session_groups: Dict[str, List[Any]] = {}\n",
    "for span in agent_spans:\n",
    "    # Access attributes (may be a dict or JSON string)\n",
    "    attributes = span.get(\"attributes\", {})\n",
    "    if isinstance(attributes, str):\n",
    "        attributes = json.loads(attributes)\n",
    "\n",
    "    session_id = attributes.get(\"session.id\") or attributes.get(SpanAttributes.SESSION_ID)\n",
    "    if session_id:\n",
    "        if session_id not in session_groups:\n",
    "            session_groups[session_id] = []\n",
    "        session_groups[session_id].append(span)\n",
    "\n",
    "print(f\"Found {len(session_groups)} sessions\")\n",
    "\n",
    "# Evaluate each session\n",
    "session_annotations = []\n",
    "\n",
    "for session_id, session_spans in session_groups.items():\n",
    "    # Sort by turn number\n",
    "    session_spans.sort(\n",
    "        key=lambda s: (\n",
    "            json.loads(s.get(\"attributes\", \"{}\"))\n",
    "            if isinstance(s.get(\"attributes\"), str)\n",
    "            else s.get(\"attributes\", {})\n",
    "        ).get(\"conversation.turn\", 0)\n",
    "    )\n",
    "\n",
    "    # Build conversation transcript\n",
    "    transcript_parts = []\n",
    "    for i, span in enumerate(session_spans):\n",
    "        # Access attributes\n",
    "        attributes = span.get(\"attributes\", {})\n",
    "        if isinstance(attributes, str):\n",
    "            attributes = json.loads(attributes)\n",
    "\n",
    "        input_value = attributes.get(\"input.value\", \"\")\n",
    "        output_value = attributes.get(\"output.value\", \"\")\n",
    "        turn_num = attributes.get(\"conversation.turn\", i + 1)\n",
    "\n",
    "        transcript_parts.append(f\"Turn {turn_num}:\\nUser: {input_value}\\nAgent: {output_value}\")\n",
    "\n",
    "    transcript = \"\\n\\n\".join(transcript_parts)\n",
    "\n",
    "    if not transcript.strip():\n",
    "        continue\n",
    "\n",
    "    coherence_result = conversation_coherence_evaluator.evaluate({\"input\": transcript})\n",
    "    coherence_score = (\n",
    "        coherence_result[0] if isinstance(coherence_result, list) else coherence_result\n",
    "    )\n",
    "\n",
    "    resolution_result = resolution_evaluator.evaluate({\"input\": transcript})\n",
    "    resolution_score = (\n",
    "        resolution_result[0] if isinstance(resolution_result, list) else resolution_result\n",
    "    )\n",
    "\n",
    "    session_annotations.append(\n",
    "        SessionAnnotationData(\n",
    "            session_id=session_id,\n",
    "            name=\"conversation_coherence\",\n",
    "            annotator_kind=\"LLM\",\n",
    "            result={\n",
    "                \"label\": coherence_score.label,\n",
    "                \"score\": coherence_score.score\n",
    "                if hasattr(coherence_score, \"score\")\n",
    "                else (1.0 if coherence_score.label == \"coherent\" else 0.0),\n",
    "            },\n",
    "            metadata={\"model\": \"gpt-5\", \"turnCount\": len(session_spans)},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    session_annotations.append(\n",
    "        SessionAnnotationData(\n",
    "            session_id=session_id,\n",
    "            name=\"resolution_status\",\n",
    "            annotator_kind=\"LLM\",\n",
    "            result={\n",
    "                \"label\": resolution_score.label,\n",
    "                \"score\": resolution_score.score\n",
    "                if hasattr(resolution_score, \"score\")\n",
    "                else (1.0 if resolution_score.label == \"resolved\" else 0.0),\n",
    "            },\n",
    "            metadata={\"model\": \"gpt-5\", \"turnCount\": len(session_spans)},\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluated {len(session_groups)} sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5G1qQFbZN2Pk"
   },
   "source": [
    "### Log Session Annotations\n",
    "\n",
    "Log all session-level annotations to Phoenix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session_annotations:\n",
    "    print(f\"\\nüì§ Logging {len(session_annotations)} session annotations to Phoenix...\")\n",
    "\n",
    "    try:\n",
    "        phoenix_client.sessions.log_session_annotations(\n",
    "            session_annotations=session_annotations,\n",
    "            sync=False,\n",
    "        )\n",
    "        print(f\"‚úÖ Logged {len(session_annotations)} session annotations\")\n",
    "        print(f\"   - {len(session_annotations) // 2} sessions evaluated\")\n",
    "        print(\"   - Each session has 2 annotations: conversation_coherence and resolution_status\")\n",
    "    except Exception as error:\n",
    "        print(f\"‚ùå Failed to log session annotations: {error}\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\n‚ö†Ô∏è  No session annotations to log. Make sure you've run multi-turn conversations first.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
