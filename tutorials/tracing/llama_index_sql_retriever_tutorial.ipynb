{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">SQL Router Query Engine Example</h1>\n",
    "\n",
    "LlamaIndex provides high-level APIs that enable users to build powerful applications in a few lines of code. However, it can be challenging to understand what is going on under the hood and to pinpoint the cause of issues. Phoenix makes your LLM applications *observable* by visualizing the underlying structure of each call to your query engine and surfacing problematic `spans`` of execution based on latency, token count, or other evaluation metrics.\n",
    "\n",
    "In this tutorial, you will:\n",
    "- Build a query engine that uses both a SQL retriever and a VectorStoreIndex using LlamaIndex\n",
    "- Record trace data in [OpenInference tracing](https://github.com/Arize-ai/openinference) format using the global `arize_phoenix` handler\n",
    "- Observe how a more complex LlamaIndex application might perform retrieval\n",
    "\n",
    "‚ÑπÔ∏è This notebook requires an OpenAI API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies and Import Libraries\n",
    "\n",
    "Install Phoenix, LlamaIndex, and OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"arize-phoenix[evals]\" \"openai>=1\" gcsfs nest-asyncio \"llama-index>=0.10.3\" \"llama-index-core\" \"openinference-instrumentation-llama-index>=1.0.0\" \"llama-index-callbacks-arize-phoenix>=0.1.2\" \"llama-index-readers-wikipedia\" \"sqlalchemy\" wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "import wikipedia\n",
    "from llama_index.core import Document, Settings, set_global_handler\n",
    "from llama_index.core.indices import VectorStoreIndex\n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine, RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.utilities.sql_wrapper import SQLDatabase\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    text,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Launch Phoenix\n",
    "\n",
    "You can run Phoenix in the background to collect trace data emitted by any LlamaIndex application that has been instrumented with the `OpenInferenceTraceCallbackHandler`. Phoenix supports LlamaIndex's [one-click observability](https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/one_click_observability.html) which will automatically instrument your LlamaIndex application! You can consult our [integration guide](https://docs.arize.com/phoenix/integrations/llamaindex) for a more detailed explanation of how to instrument your LlamaIndex application.\n",
    "\n",
    "Launch Phoenix and follow the instructions in the cell output to open the Phoenix UI (the UI should be empty because we have yet to run the LlamaIndex application)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable Phoenix tracing within LlamaIndex by setting `arize_phoenix` as the global handler. This will mount Phoenix's [OpenInferenceTraceCallback](https://docs.arize.com/phoenix/integrations/llamaindex) as the global handler. Phoenix uses OpenInference traces - an open-source standard for capturing and storing LLM application traces that enables LLM applications to seamlessly integrate with LLM observability solutions such as Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Your OpenAI API Key\n",
    "\n",
    "Set your OpenAI API key if it is not already set as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "openai.api_key = openai_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare reference data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll download a dataset that contains technical details of various digital cameras and convert it into an in-memory SQL database. This dataset is provided by Kaggle and more details can be found [here](https://www.kaggle.com/datasets/crawford/1000-cameras-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_info = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-phoenix-assets/datasets/structured/camera-info/cameras.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Max resolution</th>\n",
       "      <th>Low resolution</th>\n",
       "      <th>Effective pixels</th>\n",
       "      <th>Zoom wide (W)</th>\n",
       "      <th>Zoom tele (T)</th>\n",
       "      <th>Normal focus range</th>\n",
       "      <th>Macro focus range</th>\n",
       "      <th>Storage included</th>\n",
       "      <th>Weight (inc. batteries)</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agfa ePhoto 1280</td>\n",
       "      <td>1997</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agfa ePhoto 1680</td>\n",
       "      <td>1998</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agfa ePhoto CL18</td>\n",
       "      <td>2000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agfa ePhoto CL30</td>\n",
       "      <td>1999</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agfa ePhoto CL30 Clik!</td>\n",
       "      <td>1999</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Release date  Max resolution  Low resolution  \\\n",
       "0        Agfa ePhoto 1280          1997          1024.0           640.0   \n",
       "1        Agfa ePhoto 1680          1998          1280.0           640.0   \n",
       "2        Agfa ePhoto CL18          2000           640.0             0.0   \n",
       "3        Agfa ePhoto CL30          1999          1152.0           640.0   \n",
       "4  Agfa ePhoto CL30 Clik!          1999          1152.0           640.0   \n",
       "\n",
       "   Effective pixels  Zoom wide (W)  Zoom tele (T)  Normal focus range  \\\n",
       "0               0.0           38.0          114.0                70.0   \n",
       "1               1.0           38.0          114.0                50.0   \n",
       "2               0.0           45.0           45.0                 0.0   \n",
       "3               0.0           35.0           35.0                 0.0   \n",
       "4               0.0           43.0           43.0                50.0   \n",
       "\n",
       "   Macro focus range  Storage included  Weight (inc. batteries)  Dimensions  \\\n",
       "0               40.0               4.0                    420.0        95.0   \n",
       "1                0.0               4.0                    420.0       158.0   \n",
       "2                0.0               2.0                      0.0         0.0   \n",
       "3                0.0               4.0                      0.0         0.0   \n",
       "4                0.0              40.0                    300.0       128.0   \n",
       "\n",
       "    Price  \n",
       "0   179.0  \n",
       "1   179.0  \n",
       "2   179.0  \n",
       "3   269.0  \n",
       "4  1299.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
    "camera_info.to_sql(\"cameras\", engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Agfa ePhoto 1280', 1997, 1024.0, 640.0, 0.0, 38.0, 114.0, 70.0, 40.0, 4.0, 420.0, 95.0, 179.0)\n",
      "('Agfa ePhoto 1680', 1998, 1280.0, 640.0, 1.0, 38.0, 114.0, 50.0, 0.0, 4.0, 420.0, 158.0, 179.0)\n",
      "('Agfa ePhoto CL18', 2000, 640.0, 0.0, 0.0, 45.0, 45.0, 0.0, 0.0, 2.0, 0.0, 0.0, 179.0)\n",
      "('Agfa ePhoto CL30', 1999, 1152.0, 640.0, 0.0, 35.0, 35.0, 0.0, 0.0, 4.0, 0.0, 0.0, 269.0)\n",
      "('Agfa ePhoto CL30 Clik!', 1999, 1152.0, 640.0, 0.0, 43.0, 43.0, 50.0, 0.0, 40.0, 300.0, 128.0, 1299.0)\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM cameras LIMIT 5\")).all()\n",
    "\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for more general queries about digital cameras, we'll download the Wikipedia page on Digital Cameras using the `wikipedia` SDK. We will convert this document into a LlamaIndex `VectorStoreIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Digital Camera wikipedia page\n",
    "page = wikipedia.page(pageid=52797)\n",
    "doc = Document(id_=page.pageid, text=page.content)\n",
    "\n",
    "vector_indices = []\n",
    "vector_index = VectorStoreIndex.from_documents([doc])\n",
    "vector_indices.append(vector_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build LlamaIndex Application\n",
    "\n",
    "Let's use a simple `RouterQueryEngine` using multiple query engine tools. We will either route to the SQL retriever or the vector index built over the \"Digital Camera\" Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(temperature=0.0, model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine, include_tables=[\"cameras\"])\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"cameras\"],\n",
    ")\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query over\"\n",
    "        \" a table containing technical details about specific digital camera models: Model,\"\n",
    "        \" Release date, Max resolution, Low resolution, Effective pixels, Zoom wide (W),\"\n",
    "        \" Zoom tele (T), Normal focus range, Macro focus range, Storage included,\"\n",
    "        \" Weight (inc. batteries), Dimensions, Price\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_query_engines = [index.as_query_engine() for index in vector_indices]\n",
    "vector_tools = []\n",
    "for query_engine in vector_query_engines:\n",
    "    vector_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=query_engine,\n",
    "        description=\"Useful for answering generic questions about digital cameras.\",\n",
    "    )\n",
    "    vector_tools.append(vector_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=([sql_tool] + vector_tools),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Queries and Use Phoenix to view Spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most expensive digital camera is the Canon EOS-1Ds, priced at $7999.00.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the most expensive digital camera?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query asked for specific details about a camera, and routed to the SQL retriever to get context for the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history of digital camera sensors began with the invention of the first semiconductor image sensor, the charge-coupled device (CCD), by Willard S. Boyle and George E. Smith at Bell Labs in 1969. This was based on MOS capacitor technology. Later, in 1985, the NMOS active-pixel sensor was invented by Tsutomu Nakamura's team at Olympus, leading to the development of the CMOS active-pixel sensor (CMOS sensor) at the NASA Jet Propulsion Laboratory in 1993. \n",
      "\n",
      "In the early days, digital cameras were used mainly for military, scientific, medical, and news applications. The first fully digital camera, which recorded digital images using a semiconductor memory card, was introduced by Fujifilm at Photokina 1988. This camera's memory card had a capacity of 2 MB of SRAM and could hold up to ten photographs. \n",
      "\n",
      "The first commercial camera phone was the Kyocera Visual Phone VP-210, released in Japan in May 1999. It had a 110,000-pixel front-facing camera and could store up to 20 JPEG digital images. By the mid-2000s, higher-end cell phones had an integrated digital camera, and by the early 2010s, almost all smartphones had an integrated digital camera.\n",
      "\n",
      "The two major types of digital image sensors are CCD and CMOS. A CCD sensor has one amplifier for all the pixels, while each pixel in a CMOS active-pixel sensor has its own amplifier. Compared to CCDs, CMOS sensors use less power. Cameras with a small sensor use a back-side-illuminated CMOS (BSI-CMOS) sensor. The image processing capabilities of the camera determine the outcome of the final image quality much more than the sensor type.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the history of digital camera sensors.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More general queries are routed to the vector index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Thoughts\n",
    "\n",
    "LLM Traces and the accompanying OpenInference Tracing specification is designed to be a category of telemetry data that is used to understand the execution of LLMs and the surrounding application context. This is especially useful when understanding the behavior of more complex RAG applications that might make use of multiple context retrieval strategies, such as mixing a SQL retriever with more-common vector indexes.\n",
    "\n",
    "For more details on Phoenix, LLM Tracing, and LLM Evals, checkout our [documentation](https://docs.arize.com/phoenix/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
