{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uqqq \"arize-phoenix[llama-index]\" sentence-transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518f480fc2c324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331618113a05e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from datetime import datetime, timezone\n",
    "from time import sleep\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from phoenix.evals import OpenAIModel\n",
    "from phoenix.experiments import run_experiment\n",
    "from phoenix.experiments.evaluators import ConcisenessEvaluator\n",
    "from phoenix.experiments.types import EvaluationResult, Example, ExperimentRun\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87caccef77f34e23",
   "metadata": {},
   "source": [
    "# Instrument LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb97dda1f7ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider = trace_sdk.TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bb85777bad1bf",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a30f5b63b1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"input_messages\": [\n",
    "            [{\"role\": \"user\", \"content\": \"Which grad schools did the author apply for and why?\"}],\n",
    "            [{\"role\": \"user\", \"content\": \"What did the author do growing up?\"}],\n",
    "        ],\n",
    "        \"output_message\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The author applied to three grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which the author had visited because a friend went there and it was also home to Bill Woods, who had invented the type of parser the author used in his SHRDLU clone. The author chose these schools because he wanted to learn about AI and Lisp, and these schools were known for their expertise in these areas.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The author took a painting class at Harvard with Idelle Weber and later became her de facto studio assistant. Additionally, the author worked on several different projects, including writing essays, developing spam filters, and painting.\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ff2bb5c1e13f9",
   "metadata": {},
   "source": [
    "## Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955fb85754f5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = datetime.now(timezone.utc).isoformat()\n",
    "px.Client().upload_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    dataframe=df,\n",
    "    input_keys=(\"input_messages\",),\n",
    "    output_keys=(\"output_message\",),\n",
    ")\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0134d2057cddfbd",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a54e1924e8e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = px.Client().get_dataset(name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca2be0e7e37073",
   "metadata": {},
   "source": [
    "# Set Up Experiment Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ede677164d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metadata = {\n",
    "    \"llm\": \"gpt-4\",\n",
    "    \"embed_model\": \"text-embedding-3-small\",\n",
    "    \"reranker\": \"cross-encoder/ms-marco-MiniLM-L-2-v2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b64da7a25505e5",
   "metadata": {},
   "source": [
    "# Set Up LLamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19936f8ba68b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=experiment_metadata[\"llm\"])\n",
    "Settings.embed_model = OpenAIEmbedding(model=experiment_metadata[\"embed_model\"])\n",
    "reranker = SentenceTransformerRerank(model=experiment_metadata[\"reranker\"], top_n=2)\n",
    "\n",
    "essay = \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\"\n",
    "with tempfile.NamedTemporaryFile() as tf:\n",
    "    urlretrieve(essay, tf.name)\n",
    "    documents = SimpleDirectoryReader(input_files=[tf.name]).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65fb86bae6783d",
   "metadata": {},
   "source": [
    "# Set Up Capture of Retrieved Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9060086db8c0de",
   "metadata": {},
   "source": [
    "# Create Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9303735664c0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_reranker(input) -> str:\n",
    "    chat_engine = index.as_chat_engine(similarity_top_k=10, node_postprocessors=[reranker])\n",
    "    response = chat_engine.chat(input[\"input_messages\"][-1][\"content\"])\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc36b1a7427dea",
   "metadata": {},
   "source": [
    "# Define Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf19fe4ed8d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainsSubstring:\n",
    "    name = \"contains_substring\"\n",
    "    annotator_kind = \"CODE\"\n",
    "\n",
    "    def __init__(self, substring: str):\n",
    "        self.substring = substring\n",
    "\n",
    "    def evaluate(self, _: Example, exp_run: ExperimentRun) -> EvaluationResult:\n",
    "        result = exp_run.output.result\n",
    "        score = int(isinstance(result, str) and self.substring in result)\n",
    "        return EvaluationResult(\n",
    "            score=score,\n",
    "            explanation=f\"the substring `{repr(self.substring)}` was in the output\",\n",
    "        )\n",
    "\n",
    "    async def async_evaluate(self, _: Example, exp_run: ExperimentRun) -> EvaluationResult:\n",
    "        return self.evaluate(_, exp_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68341da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ConcisenessEvaluator.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6aadf43899bf6",
   "metadata": {},
   "source": [
    "# Run Experiment with Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12a5d4fe07387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIModel(model=\"gpt-4o\")\n",
    "\n",
    "experiment = run_experiment(\n",
    "    dataset=ds,\n",
    "    task=rag_with_reranker,\n",
    "    experiment_metadata=experiment_metadata,\n",
    "    evaluators=[ContainsSubstring(substring=\"school\"), ConcisenessEvaluator(model)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5c9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
