{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "<h1 align=\"center\">Model Comparison for a Text Extraction Service</h1>\n",
        "\n",
        "Imagine you're deploying a service that condenses emails into concise summaries. One challenge of using LLMs for summarization is that even the best models can miscategorize key details, or miss those details entirely.\n",
        "\n",
        "In this tutorial, you will construct a dataset and run experiments to engineer a prompt template that produces accurately summarizes your emails. You will:\n",
        "\n",
        "- Upload a **dataset** of **examples** containing emails to Phoenix\n",
        "- Define an **experiment task** that extracts and formats the key details from those emails\n",
        "- Devise an **evaluator** measuring Jaro-Winkler Similarity\n",
        "- Run **experiments** to iterate on your prompt template and to compare the summaries produced by different LLMs\n",
        "\n",
        "锔 This tutorial requires and OpenAI API key.\n",
        "\n",
        "Let's get started!\n"
      ],
      "metadata": {
        "id": "rO7X6VuWpHmG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pei7Grvp9XJq"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFUqJE8V6EdJ",
        "outputId": "0bf58a43-1fc9-44cb-cc79-2f0e05613b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arize-phoenix\n",
            "  Downloading arize_phoenix-4.6.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-benchmarks\n",
            "  Downloading langchain_benchmarks-0.0.12-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting jarowinkler\n",
            "  Downloading jarowinkler-2.0.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting aioitertools (from arize-phoenix)\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Collecting aiosqlite (from arize-phoenix)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Collecting alembic<2,>=1.3.0 (from arize-phoenix)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting arize-phoenix-evals>=0.13.1 (from arize-phoenix)\n",
            "  Downloading arize_phoenix_evals-0.13.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (5.3.3)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.64.1)\n",
            "Collecting hdbscan>=0.8.33 (from arize-phoenix)\n",
            "  Downloading hdbscan-0.8.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from arize-phoenix)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (3.1.4)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.25.2)\n",
            "Collecting openinference-instrumentation (from arize-phoenix)\n",
            "  Downloading openinference_instrumentation-0.1.7-py3-none-any.whl (8.4 kB)\n",
            "Collecting openinference-instrumentation-langchain>=0.1.12 (from arize-phoenix)\n",
            "  Downloading openinference_instrumentation_langchain-0.1.20-py3-none-any.whl (15 kB)\n",
            "Collecting openinference-instrumentation-llama-index>=1.2.0 (from arize-phoenix)\n",
            "  Downloading openinference_instrumentation_llama_index-2.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting openinference-instrumentation-openai>=0.1.4 (from arize-phoenix)\n",
            "  Downloading openinference_instrumentation_openai-0.1.6-py3-none-any.whl (22 kB)\n",
            "Collecting openinference-semantic-conventions>=0.1.9 (from arize-phoenix)\n",
            "  Downloading openinference_semantic_conventions-0.1.9-py3-none-any.whl (8.7 kB)\n",
            "Collecting opentelemetry-exporter-otlp (from arize-phoenix)\n",
            "  Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk (from arize-phoenix)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-semantic-conventions (from arize-phoenix)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (2.0.3)\n",
            "Requirement already satisfied: protobuf<6.0,>=3.20 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (14.0.2)\n",
            "Collecting python-multipart (from arize-phoenix)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (6.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy[asyncio]<3,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (2.0.31)\n",
            "Collecting sqlean-py>=3.45.1 (from arize-phoenix)\n",
            "  Downloading sqlean.py-3.45.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette (from arize-phoenix)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting strawberry-graphql==0.235.0 (from arize-phoenix)\n",
            "  Downloading strawberry_graphql-0.235.0-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (4.12.2)\n",
            "Collecting umap-learn (from arize-phoenix)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from arize-phoenix)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.14.1)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.235.0->arize-phoenix)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.235.0->arize-phoenix) (2.8.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting ipywidgets<9,>=8 (from langchain-benchmarks)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-benchmarks to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-benchmarks\n",
            "  Downloading langchain_benchmarks-0.0.11-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_benchmarks-0.0.10-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-benchmarks) (0.9.0)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai)\n",
            "  Downloading openai-1.35.9-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.5.2 (from jarowinkler)\n",
            "  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting Mako (from alembic<2,>=1.3.0->arize-phoenix)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting cython<3,>=0.27 (from hdbscan>=0.8.33->arize-phoenix)\n",
            "  Downloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.33->arize-phoenix) (1.4.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets<9,>=8->langchain-benchmarks)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->langchain-benchmarks) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->langchain-benchmarks) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets<9,>=8->langchain-benchmarks)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->langchain-benchmarks) (3.0.11)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->arize-phoenix) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx->arize-phoenix)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->arize-phoenix) (3.7)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->arize-phoenix)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->arize-phoenix) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->arize-phoenix) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->arize-phoenix) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->arize-phoenix) (2.1.5)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.25.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->arize-phoenix)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->arize-phoenix) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->arize-phoenix)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api->openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn->arize-phoenix) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->arize-phoenix)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->arize-phoenix) (8.1.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (4.9.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn->arize-phoenix) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.7.0->strawberry-graphql==0.235.0->arize-phoenix) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api->openinference-instrumentation-langchain>=0.1.12->arize-phoenix) (3.19.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets<9,>=8->langchain-benchmarks) (0.2.13)\n",
            "Installing collected packages: sqlean-py, widgetsnbextension, rapidfuzz, python-multipart, orjson, opentelemetry-proto, openinference-semantic-conventions, mypy-extensions, marshmallow, Mako, jsonpointer, jedi, importlib-metadata, h11, graphql-core, deprecated, cython, comm, aiosqlite, aioitertools, uvicorn, typing-inspect, tiktoken, strawberry-graphql, starlette, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, jarowinkler, httpcore, alembic, pynndescent, opentelemetry-semantic-conventions, opentelemetry-instrumentation, openinference-instrumentation, langsmith, ipywidgets, httpx, hdbscan, dataclasses-json, arize-phoenix-evals, umap-learn, opentelemetry-sdk, openinference-instrumentation-openai, openinference-instrumentation-llama-index, openinference-instrumentation-langchain, openai, langchain-core, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, opentelemetry-exporter-otlp, langchain, langchain-community, langchain-benchmarks, arize-phoenix\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.10\n",
            "    Uninstalling Cython-3.0.10:\n",
            "      Successfully uninstalled Cython-3.0.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed Mako-1.3.5 aioitertools-0.11.0 aiosqlite-0.20.0 alembic-1.13.2 arize-phoenix-4.6.3 arize-phoenix-evals-0.13.1 comm-0.2.2 cython-0.29.37 dataclasses-json-0.6.7 deprecated-1.2.14 graphql-core-3.2.3 h11-0.14.0 hdbscan-0.8.37 httpcore-1.0.5 httpx-0.27.0 importlib-metadata-7.1.0 ipywidgets-8.1.3 jarowinkler-2.0.1 jedi-0.19.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-benchmarks-0.0.10 langchain-community-0.2.6 langchain-core-0.2.11 langchain-openai-0.1.14 langchain-text-splitters-0.2.2 langsmith-0.1.83 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.35.9 openinference-instrumentation-0.1.7 openinference-instrumentation-langchain-0.1.20 openinference-instrumentation-llama-index-2.0.0 openinference-instrumentation-openai-0.1.6 openinference-semantic-conventions-0.1.9 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 orjson-3.10.6 pynndescent-0.5.13 python-multipart-0.0.9 rapidfuzz-3.9.4 sqlean-py-3.45.1 starlette-0.37.2 strawberry-graphql-0.235.0 tiktoken-0.7.0 typing-inspect-0.9.0 umap-learn-0.5.6 uvicorn-0.30.1 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "!pip install arize-phoenix langchain langchain-core langchain-community langchain-benchmarks langchain-openai nest_asyncio jarowinkler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqEaZvJs6EdK"
      },
      "source": [
        "# Set Up OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ieJUPMC-6EdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194d3065-123d-40e0-f130-bf98ed3bf44a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Enter your OpenAI API key: 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\" Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSLxWyFV6EdK"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jope0REY6EdK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tempfile\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import jarowinkler\n",
        "import nest_asyncio\n",
        "import pandas as pd\n",
        "import phoenix as px\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_benchmarks import download_public_dataset, registry\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "from phoenix.experiments import evaluate_experiment, run_experiment\n",
        "from phoenix.experiments.types import Example\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0WDhK_Y6EdK"
      },
      "source": [
        "# Launch Phoenix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yXTfs8lAdZh"
      },
      "source": [
        "First we have to set up our instance of Phoenix and our instrumentors to capture traces from our agent. We'll use both our Langchain and OpenAI auto instrumentors because while our task uses Langchain, our evaluation function will call OpenAI directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "mFrkdFZf6EdK",
        "outputId": "d9b508b5-8e07-49da-89bc-6477d1cbe441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " To view the Phoenix app in your browser, visit https://r6599g08ap1-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
            " For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<phoenix.session.session.ThreadSession at 0x7fcb3af2fa90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "px.launch_app()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCaNah-F6EdK"
      },
      "source": [
        "# Instrument LangChain and OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LIBdauvr6EdK"
      },
      "outputs": [],
      "source": [
        "endpoint = \"http://127.0.0.1:4317\"\n",
        "(tracer_provider := TracerProvider()).add_span_processor(\n",
        "    SimpleSpanProcessor(OTLPSpanExporter(endpoint))\n",
        ")\n",
        "\n",
        "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzvJVOZuBw6e"
      },
      "source": [
        "# Experiments in Phoenix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysmbKqO0BxXX"
      },
      "source": [
        "Experiments in Phoenix are made up of 3 elements: a dataset, a task, and an evaluator. The dataset is a collection of the inputs and expected outputs that we'll use to evaluate. The task is an operation that should be performed on each input. Finally, the evaluator compares the result against an expected output.\n",
        "\n",
        "For this example, here's what each looks like:\n",
        "*   Dataset - a dataframe of emails to analyze, and the expected output for our agent\n",
        "*   Task - a langchain agent that extracts key info from our input emails. The result of this task will then be compared against the expected output\n",
        "*   Eval - Jaro-Winkler distance calculation on the task's output and expected output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSLNHY6a6EdK"
      },
      "source": [
        "# Download JSON Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tpAcUSmAvOD"
      },
      "source": [
        "We've prepared some example emails and actual responses that we can use to evaluate our two models. Let's download those and save them to a temporary file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "23c0e2e29c1443e08dfeda81b8383ed1",
            "5b7212e1ed70496cbf64f9159cefd3fb",
            "53cf998a2e80400ba2b36dc1b6d31163",
            "4ec6257ea38140e6ab4708b9fe6954cc",
            "1cd3c9c420214ee19da5bc83842137bc",
            "0e99108df556418184960aac55ef31b8",
            "b9fee4b032e24cfd96bc3cf5d9243bed",
            "1c06fd82c7b2447a81c3346a02befec5",
            "9553474bbbe04a678aa6967ecd6c16d5",
            "271517f8ed794e54bb4d71363cb00dde",
            "dad19e00c2f04b75b0dad99c5a4bb642"
          ]
        },
        "id": "7m3IwRvQ6EdK",
        "outputId": "4ae16abd-bca7-4fca-fe8a-4d2a65acd217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching examples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/42 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23c0e2e29c1443e08dfeda81b8383ed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done fetching examples.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               inputs  \\\n",
              "25  {'input': '**iCloud** 锟斤拷  \n",
              "  \n",
              "# Failed to atte...   \n",
              "13  {'input': '---  \n",
              "  \n",
              "|\n",
              "\n",
              "We Passed the Stop Dang...   \n",
              "8   {'input': '####  Where sustainability meets st...   \n",
              "26  {'input': '|  |  |  |  |  |\n",
              "\n",
              "Hello Jacob, \n",
              "\n",
              " ...   \n",
              "4   {'input': 'Some travelers plan ahead; others p...   \n",
              "39  {'input': '---  \n",
              "|\n",
              "\n",
              "Costco  \n",
              "  \n",
              "---  \n",
              "  \n",
              "ANSWE...   \n",
              "19  {'input': 'Dear Jacob,  \n",
              "  \n",
              "Your opinion matte...   \n",
              "29  {'input': '_`I Am looking for a possible partn...   \n",
              "30  {'input': 'It's always been a hassle to get mo...   \n",
              "6   {'input': 'Your exclusive retreat at The Venet...   \n",
              "\n",
              "                                              outputs  \n",
              "25  {'output': {'tone': 'negative', 'topic': 'iClo...  \n",
              "13  {'output': {'tone': 'positive', 'topic': 'Stop...  \n",
              "8   {'output': {'tone': 'positive', 'topic': 'Prom...  \n",
              "26  {'output': {'tone': 'positive', 'topic': 'Busi...  \n",
              "4   {'output': {'tone': 'positive', 'topic': 'Trav...  \n",
              "39  {'output': {'tone': 'positive', 'topic': 'Invi...  \n",
              "19  {'output': {'tone': 'positive', 'topic': 'Invi...  \n",
              "29  {'output': {'tone': 'positive', 'topic': 'Inve...  \n",
              "30  {'output': {'tone': 'positive', 'topic': 'Busi...  \n",
              "6   {'output': {'tone': 'positive', 'topic': 'Excl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f5a8b62-9eb5-44b6-b362-be6a32e83087\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>outputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>{'input': '**iCloud** 锟斤拷  \n",
              "\n",
              "# Failed to atte...</td>\n",
              "      <td>{'output': {'tone': 'negative', 'topic': 'iClo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'input': '---  \n",
              "\n",
              "|\n",
              "\n",
              "We Passed the Stop Dang...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Stop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'input': '####  Where sustainability meets st...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Prom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>{'input': '|  |  |  |  |  |\n",
              "\n",
              "Hello Jacob, \n",
              "\n",
              " ...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Busi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'input': 'Some travelers plan ahead; others p...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Trav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>{'input': '---  \n",
              "|\n",
              "\n",
              "Costco  \n",
              "\n",
              "---  \n",
              "\n",
              "ANSWE...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Invi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>{'input': 'Dear Jacob,  \n",
              "\n",
              "Your opinion matte...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Invi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>{'input': '_`I Am looking for a possible partn...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Inve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>{'input': 'It's always been a hassle to get mo...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Busi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'input': 'Your exclusive retreat at The Venet...</td>\n",
              "      <td>{'output': {'tone': 'positive', 'topic': 'Excl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f5a8b62-9eb5-44b6-b362-be6a32e83087')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f5a8b62-9eb5-44b6-b362-be6a32e83087 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f5a8b62-9eb5-44b6-b362-be6a32e83087');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd28ff46-96c1-4299-9d3b-f7fb4d84b695\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd28ff46-96c1-4299-9d3b-f7fb4d84b695')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd28ff46-96c1-4299-9d3b-f7fb4d84b695 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9d0800d4-618a-46ad-b633-57133fde0a3e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9d0800d4-618a-46ad-b633-57133fde0a3e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"inputs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outputs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset_name = \"Email Extraction\"\n",
        "\n",
        "with tempfile.NamedTemporaryFile(suffix=\".json\") as f:\n",
        "    download_public_dataset(registry[dataset_name].dataset_id, path=f.name)\n",
        "    df = pd.read_json(f.name)[[\"inputs\", \"outputs\"]]\n",
        "df = df.sample(10, random_state=42)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dneIPyl6EdK"
      },
      "source": [
        "# Upload Dataset to Phoenix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk3F8h9lA4MR"
      },
      "source": [
        "Next, we'll upload our dataset to Phoenix. Once this is present in Phoenix, we can run multiple experiments with different models on this one dataset, and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "37XF1y7F6EdK",
        "outputId": "9ccce271-3510-46b1-c100-c431b5b739d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Uploading dataset...\n",
            " Examples uploaded: https://r6599g08ap2-496ff2e9c6d22116-6006-colab.googleusercontent.com/datasets/RGF0YXNldDox/examples\n",
            "锔 Dataset version ID: RGF0YXNldFZlcnNpb246MQ==\n"
          ]
        }
      ],
      "source": [
        "dataset = px.Client().upload_dataset(\n",
        "    dataset_name=f\"{dataset_name}{datetime.now(timezone.utc)}\",\n",
        "    inputs=df.inputs,\n",
        "    outputs=df.outputs.map(lambda obj: obj[\"output\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12cVoZ4t6EdK"
      },
      "source": [
        "# Set Up LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naKQx8TvBGno"
      },
      "source": [
        "Now we'll set up our Langchain agent. This is a straightforward agent that makes a call to our specified model and formats the response as JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5FZMw54Y6EdL"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-4o\"\n",
        "\n",
        "llm = ChatOpenAI(model=model).bind_functions(\n",
        "    functions=[registry[dataset_name].schema],\n",
        "    function_call=registry[dataset_name].schema.schema()[\"title\"],\n",
        ")\n",
        "output_parser = JsonOutputFunctionsParser()\n",
        "extraction_chain = registry[dataset_name].instructions | llm | output_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgMH06496EdL"
      },
      "source": [
        "# Define Task Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1-BCl1yBh_T"
      },
      "source": [
        "Next, we need to define a Task for our experiment to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gHwS9N5v6EdL"
      },
      "outputs": [],
      "source": [
        "def task(ex: Example) -> str:\n",
        "    return extraction_chain.invoke(ex.input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwA52YTd6EdL"
      },
      "source": [
        "# Check that the task is working by running it on at least one Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LYl5gXB6EdL",
        "outputId": "f7d7ac21-ae9c-4f7f-8021-33093a0ff96a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sender': 'The iCloud Team',\n",
              " 'sender_address': '6101 Long Prairie Rd, Ste 744 #511, Flower Mound, TX, 75028',\n",
              " 'action_items': ['Update your payment information'],\n",
              " 'topic': 'Failed payment attempt for iCloud storage subscription renewal',\n",
              " 'tone': 'negative'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "first_key = next(iter(dataset.examples))\n",
        "first_example = dataset.examples[first_key]\n",
        "\n",
        "task(first_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7QGQoSu6EdL"
      },
      "source": [
        "# Run Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdJn1XLQC-F9"
      },
      "source": [
        "Now we're ready to run our experiment. We'll specify our dataset and task, and generate responses for us to evaluate in the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ba77edf0386043cba71514462f8ab091",
            "e841eddee20e4b74b72cfcd4307bd6cd",
            "0eb1369f66e146039bdba12ab417daf2",
            "142a9dff14a34c03ac3c4642f79a6c75",
            "7e45d773bd8047618b4ff059c4eb3a97",
            "331094037e404cad8af99ef6fbba62f1",
            "00cc5ee81fcb4bb2827ee219df026e5a",
            "4673c694c6cf41b883a73022b815b1e6",
            "7eae9af4538049daad43f3c764372e77",
            "b0515bb060ba4b2e9b2ebaf7a05f19e1",
            "d7a2823b513e44bab09592bdd2b37c26"
          ]
        },
        "id": "bEXpSKkb6EdL",
        "outputId": "34f18982-f1e5-4399-d71c-82c2ceb7456a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "И Experiment started.\n",
            " View dataset experiments: https://r6599g08ap3-496ff2e9c6d22116-6006-colab.googleusercontent.com/datasets/RGF0YXNldDox/experiments\n",
            " View this experiment: https://r6599g08ap3-496ff2e9c6d22116-6006-colab.googleusercontent.com/datasets/RGF0YXNldDox/compare?experimentId=RXhwZXJpbWVudDox\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "running tasks |          | 0/10 (0.0%) |  00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba77edf0386043cba71514462f8ab091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MQ==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6Mg==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6Mw==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6NA==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6NQ==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6Ng==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6Nw==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6OA==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6OQ==', repetition 1\n",
            "\u001b[0m\n",
            "\u001b[91mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/phoenix/experiments/functions.py\", line 312, in async_run_experiment\n",
            "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
            "  File \"<ipython-input-9-3aba8caf609a>\", line 2, in task\n",
            "    return extraction_chain.invoke(ex.input)\n",
            "AttributeError: 'dict' object has no attribute 'input'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTA=', repetition 1\n",
            "\u001b[0m\n",
            " Task runs completed.\n",
            "\n",
            " View this experiment: https://r6599g08ap3-496ff2e9c6d22116-6006-colab.googleusercontent.com/datasets/RGF0YXNldDox/compare?experimentId=RXhwZXJpbWVudDox\n",
            "\n",
            "Tasks Summary (07/03/24 05:41 PM +0000)\n",
            "---------------------------------------\n",
            "|   n_examples |   n_runs |   n_errors | top_error                                                |\n",
            "|-------------:|---------:|-----------:|:---------------------------------------------------------|\n",
            "|           10 |       10 |         10 | AttributeError(\"'dict' object has no attribute 'input'\") |\n"
          ]
        }
      ],
      "source": [
        "experiment = run_experiment(dataset, task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-DR5rrR6EdL"
      },
      "source": [
        "# Define Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir2W6wW4DNHt"
      },
      "source": [
        "Finally, we need to define our evaluation function. Here we'll use a Jaro-Winkler similarity function that generates a score for how similar the output and expected text are. [Jaro-Winkler similarity](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) is technique for measuring edit distance between two strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI7aif_I6EdL"
      },
      "outputs": [],
      "source": [
        "def jarowinkler_similarity(output, expected) -> float:\n",
        "    return jarowinkler.jarowinkler_similarity(\n",
        "        json.dumps(output, sort_keys=True),\n",
        "        json.dumps(expected, sort_keys=True),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygypu6Ag6EdL"
      },
      "source": [
        "# Evaluate Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTy47qYe6EdL"
      },
      "outputs": [],
      "source": [
        "evaluate_experiment(experiment, jarowinkler_similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq4I-6tWDYvF"
      },
      "source": [
        "Now we have scores on how well GPT-4o does at extracting email facts. This is helpful, but doesn't mean much on its own. Let's compare it against another model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaEaKgAN_ZJh"
      },
      "source": [
        "# Re-run with GPT 3.5 Turbo and Compare Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIzXZ1TBDp3J"
      },
      "source": [
        "To compare results with another model, we simply need to redefine our task. Our dataset and evaluator can stay the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1hLsqlI_ghu"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "llm = ChatOpenAI(model=model).bind_functions(\n",
        "    functions=[registry[dataset_name].schema],\n",
        "    function_call=registry[dataset_name].schema.schema()[\"title\"],\n",
        ")\n",
        "extraction_chain = registry[dataset_name].instructions | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDtS-xbsD0dL"
      },
      "outputs": [],
      "source": [
        "def task(ex: Example) -> str:\n",
        "    return extraction_chain.invoke(ex.input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LInnPwi_wBk"
      },
      "outputs": [],
      "source": [
        "experiment = run_experiment(dataset, task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDzcTxx3_6N6"
      },
      "outputs": [],
      "source": [
        "evaluate_experiment(experiment, jarowinkler_similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrACT8XUD18x"
      },
      "source": [
        "# View results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoXL1uTAEaAK"
      },
      "source": [
        "Now if you check your Phoenix experiment, you can compare Jaro-Winkler scores on a per query basis, and view aggregate model performance results. The screenshot belows shows results from GPT-4o on the left and GPT-3.5-turbo on the far right. The higher the jarowinkler_similarity score, the closer the outputted value is to the actual value.\n",
        "\n",
        "You should see that GPT-4o outperforms its older cousin."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://storage.cloud.google.com/arize-assets/phoenix/assets/images/email-extraction-example.png)"
      ],
      "metadata": {
        "id": "R88DTSq_ogvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here you could try out different models or iterate on your prompt, then run the same experiment with a modified Task to compare results."
      ],
      "metadata": {
        "id": "iIi5yd9LsikE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23c0e2e29c1443e08dfeda81b8383ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b7212e1ed70496cbf64f9159cefd3fb",
              "IPY_MODEL_53cf998a2e80400ba2b36dc1b6d31163",
              "IPY_MODEL_4ec6257ea38140e6ab4708b9fe6954cc"
            ],
            "layout": "IPY_MODEL_1cd3c9c420214ee19da5bc83842137bc",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5b7212e1ed70496cbf64f9159cefd3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_0e99108df556418184960aac55ef31b8",
            "placeholder": "",
            "style": "IPY_MODEL_b9fee4b032e24cfd96bc3cf5d9243bed",
            "tabbable": null,
            "tooltip": null,
            "value": "100%"
          }
        },
        "53cf998a2e80400ba2b36dc1b6d31163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1c06fd82c7b2447a81c3346a02befec5",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9553474bbbe04a678aa6967ecd6c16d5",
            "tabbable": null,
            "tooltip": null,
            "value": 42
          }
        },
        "4ec6257ea38140e6ab4708b9fe6954cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_271517f8ed794e54bb4d71363cb00dde",
            "placeholder": "",
            "style": "IPY_MODEL_dad19e00c2f04b75b0dad99c5a4bb642",
            "tabbable": null,
            "tooltip": null,
            "value": "42/42[00:00&lt;00:00,1232.01it/s]"
          }
        },
        "1cd3c9c420214ee19da5bc83842137bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e99108df556418184960aac55ef31b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fee4b032e24cfd96bc3cf5d9243bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "1c06fd82c7b2447a81c3346a02befec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9553474bbbe04a678aa6967ecd6c16d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "271517f8ed794e54bb4d71363cb00dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad19e00c2f04b75b0dad99c5a4bb642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ba77edf0386043cba71514462f8ab091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e841eddee20e4b74b72cfcd4307bd6cd",
              "IPY_MODEL_0eb1369f66e146039bdba12ab417daf2",
              "IPY_MODEL_142a9dff14a34c03ac3c4642f79a6c75"
            ],
            "layout": "IPY_MODEL_7e45d773bd8047618b4ff059c4eb3a97",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e841eddee20e4b74b72cfcd4307bd6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_331094037e404cad8af99ef6fbba62f1",
            "placeholder": "",
            "style": "IPY_MODEL_00cc5ee81fcb4bb2827ee219df026e5a",
            "tabbable": null,
            "tooltip": null,
            "value": "runningtasks"
          }
        },
        "0eb1369f66e146039bdba12ab417daf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4673c694c6cf41b883a73022b815b1e6",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eae9af4538049daad43f3c764372e77",
            "tabbable": null,
            "tooltip": null,
            "value": 10
          }
        },
        "142a9dff14a34c03ac3c4642f79a6c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b0515bb060ba4b2e9b2ebaf7a05f19e1",
            "placeholder": "",
            "style": "IPY_MODEL_d7a2823b513e44bab09592bdd2b37c26",
            "tabbable": null,
            "tooltip": null,
            "value": "10/10(100.0%)|斥03:31&lt;00:00|8.08it/s"
          }
        },
        "7e45d773bd8047618b4ff059c4eb3a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331094037e404cad8af99ef6fbba62f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00cc5ee81fcb4bb2827ee219df026e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4673c694c6cf41b883a73022b815b1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eae9af4538049daad43f3c764372e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0515bb060ba4b2e9b2ebaf7a05f19e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a2823b513e44bab09592bdd2b37c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}