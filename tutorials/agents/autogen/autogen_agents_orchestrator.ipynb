{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMMdZ1vnxj8f"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se3M7GECJfpZ"
   },
   "source": [
    "# AutoGen Orchestrator Agent\n",
    "\n",
    "In this tutorial, we'll explore orchestrator agent workflows with [AutoGen GroupChats](https://microsoft.github.io/autogen/dev//user-guide/core-user-guide/design-patterns/group-chat.html).\n",
    "\n",
    "**Agent orchestration** enables collaboration among multiple specialized agents, activating only the most relevant one based on the current subtask context. Instead of relying on a fixed sequence, agents dynamically participate depending on the state of the conversation. At termination, results are synthesized together.\n",
    "\n",
    "Agent orchestrator workflows simplifies this routing pattern through a central orchestrator (`GroupChatManager`) that selectively delegates tasks to the appropriate agents. Each agent monitors the conversation but only contributes when their specific expertise is required. With Phoenix tracing, you get full visibility into the orchestration flow to see which agents engaged, when they were activated, and why.\n",
    "\n",
    "In this example, we'll build a smart trip planning assistant where subtasks like destination research, hotel booking, and activity suggestions are dynamically sent to the right specialized agent.\n",
    "\n",
    "By the end of this tutorial, youâ€™ll learn how to:\n",
    "\n",
    "- Set up multiple specialized AutoGen agents in a `GroupChat`\n",
    "\n",
    "- Use a `GroupChatManager` to enable dynamic agent routing\n",
    "\n",
    "- Incorporate human feedback in your agent set up\n",
    "\n",
    "- Trace and visualize agent interactions using Phoenix\n",
    "\n",
    "âš ï¸ You'll need an OpenAI Key for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2j6_RvFJfpa"
   },
   "source": [
    "## Set up Keys and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qq pyautogen==0.9 autogen-agentchat~=0.2 openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qqq arize-phoenix arize-phoenix-otel openinference-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import autogen\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"ðŸ”‘ Enter your Phoenix API key: \")\n",
    "\n",
    "if \"PHOENIX_COLLECTOR_ENDPOINT\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = getpass(\"ðŸ”‘ Enter your Phoenix Collector Endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibmucjY_QkaH"
   },
   "source": [
    "## Configure Tracing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "    project_name=\"autogen-agents\",\n",
    "    auto_instrument=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTVRWf0NJfpc"
   },
   "source": [
    "## Example Orchestrator Task: Travel Agent\n",
    "\n",
    "This example shows how to build a dynamic travel planning assistant. A `GroupChatManager` coordinates specialized agents to adapt to the user's evolving travel needs.\n",
    "\n",
    "**User Interaction**:\n",
    "A `UserProxyAgent` acts as the human user, configured with `human_input_mode=\"TERMINATE\" `and a custom `is_termination_msg` that ends the session when a message ends with TERMINATE.\n",
    "\n",
    "**Specialized Travel Agents**:\n",
    "Three AssistantAgents handle specific tasks.\n",
    "\n",
    "- Flight Planner â€” suggests flight options.\n",
    "\n",
    "- Hotel Finder â€” recommends accommodations.\n",
    "\n",
    "- Activity Suggester â€” proposes activities and attractions.\n",
    "\n",
    "**GroupChat Setup**:\n",
    "A GroupChat bundles the user and specialized agents, managing message flow with a maximum round limit (ex: 10 rounds).\n",
    "\n",
    "**Orchestrator**:\n",
    "The `GroupChatManager` oversees the conversation, routing tasks to the right agent based on context.\n",
    "\n",
    "![Diagram](https://storage.googleapis.com/arize-phoenix-assets/assets/images/autogen_orchestrator_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq5TvGKzO685"
   },
   "source": [
    "## Define Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpjxM6BGLGW0"
   },
   "source": [
    "The `llm_config` specifies the configuration used for all the assistant agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized LLM Agents\n",
    "flight_planner = autogen.AssistantAgent(\n",
    "    name=\"FlightPlanner\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a flight planning assistant. You help book flights and find the best travel routes. Focus on using freely accessible sources.\",\n",
    ")\n",
    "\n",
    "hotel_finder = autogen.AssistantAgent(\n",
    "    name=\"HotelFinder\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a hotel booking assistant. You help find the best accommodations. Focus on using freely accessible sources.\",\n",
    ")\n",
    "\n",
    "activity_suggester = autogen.AssistantAgent(\n",
    "    name=\"ActivitySuggester\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a travel activity expert. You suggest interesting activities and tours in a destination.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    system_message=\"A human user seeking travel planning assistance. Reply TERMINATE when the task is done.\",\n",
    ")\n",
    "\n",
    "agents = [user_proxy, flight_planner, hotel_finder, activity_suggester]\n",
    "\n",
    "group_chat = autogen.GroupChat(agents=agents, messages=[], max_round=10)\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are a coordinator managing a travel planning discussion between a user, a flight planner, a hotel finder, and an activity suggester.\n",
    "    Your goal is to ensure the user's request is fully addressed by coordinating the specialists.\n",
    "    Ensure each specialist contributes relevant information sequentially (e.g., flights first, then hotels, then activities, unless the user specifies otherwise).\n",
    "    Summarize the final plan. Be sure to reply TERMINATE when the plan is complete.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMH-RlkA_jEH"
   },
   "source": [
    "## Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.trace import StatusCode\n",
    "\n",
    "tracer = tracer_provider.get_tracer(__name__)\n",
    "with tracer.start_as_current_span(\n",
    "    \"TravelAgent\",\n",
    "    openinference_span_kind=\"agent\",\n",
    ") as agent_span:\n",
    "    agent_span.set_status(StatusCode.OK)\n",
    "    user_proxy.initiate_chat(\n",
    "        manager,\n",
    "        message=\"I want to plan a 2-day trip to Cabo sometime in October. I'm interested in good food. Find flight options from SFO, suggest mid-range hotels near the city center, and recommend some relevant activities.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's add some Evaluations (Evals)\n",
    "\n",
    "In this section we will evaluate Agent Trajectory. \n",
    "\n",
    "See https://arize.com/docs/ax/evaluate/agent-trajectory-evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.Client().get_spans_dataframe(project_name=\"autogen-agents\", timeout=None)\n",
    "llm_spans = df[df[\"span_kind\"] == \"LLM\"]\n",
    "root_ids = df[df[\"parent_id\"].isna()][\"context.trace_id\"].unique()\n",
    "llm_spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY_ACCURACY_PROMPT_WITHOUT_REFERENCE = \"\"\"\n",
    "You are a helpful AI bot that checks whether an AI agent's internal trajectory is accurate and effective.\n",
    "\n",
    "You will be given:\n",
    "1. The agent's actual trajectory of tool calls\n",
    "2. You will be given input data from a user that the agent used to make a decision\n",
    "3. You will be given a tool call definition, what the agent used to make the tool call\n",
    "\n",
    "An accurate trajectory:\n",
    "- Progresses logically from step to step\n",
    "- Follows the golden trajectory where reasonable\n",
    "- Shows a clear path toward completing a goal\n",
    "- Is reasonably efficient (doesn't take unnecessary detours)\n",
    "\n",
    "##\n",
    "\n",
    "Actual Trajectory:\n",
    "{tool_calls}\n",
    "\n",
    "Use Inputs:\n",
    "{attributes.input.value}\n",
    "\n",
    "Tool Definitions:\n",
    "{attributes.llm.tools}\n",
    "\n",
    "##\n",
    "\n",
    "Your response must be a single string, either `correct` or `incorrect`, and must not include any additional text.\n",
    "\n",
    "- Respond with `correct` if the agent's trajectory adheres to the rubric and accomplishes the task effectively.\n",
    "- Respond with `incorrect` if the trajectory is confusing, misaligned with the goal, inefficient, or does not accomplish the task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "def filter_spans_by_trace_criteria(\n",
    "    df: pd.DataFrame,\n",
    "    trace_filters: Dict[str, Dict[str, Any]],\n",
    "    span_filters: Dict[str, Dict[str, Any]],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Filter spans based on trace-level and span-level criteria.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with trace data\n",
    "        trace_filters: Dictionary of column names and filtering criteria for traces\n",
    "                      Format: {\"column_name\": {\"operator\": value}}\n",
    "                      Supported operators: \">=\", \"<=\", \"==\", \"!=\", \"contains\", \"notna\", \"isna\"\n",
    "        span_filters: Dictionary of column names and filtering criteria for spans\n",
    "                     Format: {\"column_name\": {\"operator\": value}}\n",
    "                     Same supported operators as trace_filters\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with filtered spans from traces that match trace_filters\n",
    "    \"\"\"\n",
    "    all_trace_ids = set(df[\"context.trace_id\"].unique())\n",
    "    print(f\"Total traces: {len(all_trace_ids)}\")\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    traces_df = df_copy.copy()\n",
    "    for column, criteria in trace_filters.items():\n",
    "        if column not in traces_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            if operator == \">=\":\n",
    "                matching_spans = traces_df[traces_df[column] >= value]\n",
    "            elif operator == \"<=\":\n",
    "                matching_spans = traces_df[traces_df[column] <= value]\n",
    "            elif operator == \"==\":\n",
    "                matching_spans = traces_df[traces_df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                matching_spans = traces_df[traces_df[column] != value]\n",
    "            elif operator == \"contains\":\n",
    "                matching_spans = traces_df[\n",
    "                    traces_df[column].str.contains(value, case=False, na=False)\n",
    "                ]\n",
    "            elif operator == \"isna\":\n",
    "                matching_spans = traces_df[traces_df[column].isna()]\n",
    "            elif operator == \"notna\":\n",
    "                matching_spans = traces_df[traces_df[column].notna()]\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "                continue\n",
    "\n",
    "            traces_df = matching_spans\n",
    "\n",
    "    matching_trace_ids = set(traces_df[\"context.trace_id\"].unique())\n",
    "    print(f\"Found {len(matching_trace_ids)} traces matching trace criteria\")\n",
    "\n",
    "    if not matching_trace_ids:\n",
    "        print(\"No matching traces found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    result_df = df[df[\"context.trace_id\"].isin(matching_trace_ids)].copy()\n",
    "\n",
    "    for column, criteria in span_filters.items():\n",
    "        if column not in result_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            if operator == \">=\":\n",
    "                result_df = result_df[result_df[column] >= value]\n",
    "            elif operator == \"<=\":\n",
    "                result_df = result_df[result_df[column] <= value]\n",
    "            elif operator == \"==\":\n",
    "                result_df = result_df[result_df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                result_df = result_df[result_df[column] != value]\n",
    "            elif operator == \"contains\":\n",
    "                result_df = result_df[result_df[column].str.contains(value, case=False, na=False)]\n",
    "            elif operator == \"isna\":\n",
    "                result_df = result_df[result_df[column].isna()]\n",
    "            elif operator == \"notna\":\n",
    "                result_df = result_df[result_df[column].notna()]\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Final result: {len(result_df)} spans from {len(matching_trace_ids)} traces\")\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def extract_tool_calls(output_messages):\n",
    "    if not output_messages:\n",
    "        return []\n",
    "\n",
    "    tool_calls = []\n",
    "    for message in output_messages:\n",
    "        if \"message.tool_calls\" in message:\n",
    "            for tool_call in message[\"message.tool_calls\"]:\n",
    "                tool_calls.append({\"name\": tool_call[\"tool_call.function.name\"]})\n",
    "    return tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "eval_traces = filter_spans_by_trace_criteria(\n",
    "    df=df,\n",
    "    trace_filters={\"name\": {\"contains\": \"agent\"}},\n",
    "    span_filters={\"attributes.openinference.span.kind\": {\"==\": \"LLM\"}},\n",
    ")\n",
    "\n",
    "eval_traces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_traces[\"tool_calls\"] = eval_traces[\"attributes.llm.output_messages\"].apply(extract_tool_calls)\n",
    "eval_traces.head()\n",
    "full_eval_spans = eval_traces[eval_traces[\"attributes.llm.tools\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import OpenAIModel, llm_classify\n",
    "from phoenix.trace import suppress_tracing\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "model = OpenAIModel(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "rails = [\"correct\", \"incorrect\"]\n",
    "\n",
    "with suppress_tracing():\n",
    "    eval_results = llm_classify(\n",
    "        dataframe=full_eval_spans,\n",
    "        template=TRAJECTORY_ACCURACY_PROMPT_WITHOUT_REFERENCE,\n",
    "        model=model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        verbose=False,\n",
    "        concurrency=20,\n",
    "    )\n",
    "\n",
    "eval_results[\"score\"] = eval_results[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.merge(full_eval_spans, eval_results, left_index=True, right_index=True)\n",
    "\n",
    "merged_df.rename(columns={\"context.trace_id\": \"context.span_id\"}, inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(\n",
    "        dataframe=merged_df,\n",
    "        eval_name=\"Agent Trajectory Accuracy\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwbMnN9EfGWF"
   },
   "source": [
    "## View Results in Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyS3R8I1fv0u"
   },
   "source": [
    "When viewing the traces in Phoenix, you can see how the `GroupChatManager` delegated subtasks to specialized agents step-by-step. The trace shows the order in which each agent responded, making it easy to verify the flow from flight planning to hotel booking to activity suggestions.\n",
    "\n",
    "![Results](https://storage.googleapis.com/arize-phoenix-assets/assets/images/autogen_routing_results.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eDcTShcgRF5"
   },
   "source": [
    "Run the cell below to see full tracing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"800\" height=\"600\" controls>\n",
    "  <source src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/autogen_router_agent.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
