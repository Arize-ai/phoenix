{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# Google GenAI SDK - Building an Evaluator-Optimizer Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai openinference-instrumentation-google-genai arize-phoenix-otel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Arize Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.environ['PHOENIX_API_KEY']}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com/\"\n",
    "\n",
    "tracer_provider = register(\n",
    "    auto_instrument=True, project_name=\"google-genai-evaluator-optimizer-agent\"\n",
    ")\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Google Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client using the Vertex AI API, you could also use the Google GenAI API instead here\n",
    "client = genai.Client(vertexai=True, project=\"<ADD YOUR GCP PROJECT ID>\", location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Instantiate the model(s) ---\n",
    "# The global `genai` configuration (or the `client` created in a previous\n",
    "# notebook cell) is already set up, so we can request models right away.\n",
    "story_model = \"gemini-2.0-flash-001\"\n",
    "critic_model = \"gemini-2.0-flash-001\"\n",
    "\n",
    "# --- Configuration for iterative improvement ---\n",
    "num_iterations = 2  # Set the number of critique/revision cycles\n",
    "\n",
    "\n",
    "# --- 2. Generate the initial short story ---\n",
    "@tracer.agent()\n",
    "def generate_story(story_model, client):\n",
    "    story_prompt = (\n",
    "        \"You are a creative short story writer.\\n\"\n",
    "        \"Write a brief, engaging story (3–4 paragraphs) about an unexpected \"\n",
    "        \"adventure.\\n\"\n",
    "        \"Be imaginative but concise.\\n\"\n",
    "        \"User Input: \"\n",
    "    )\n",
    "    story_response = client.models.generate_content(\n",
    "        model=story_model,\n",
    "        contents=story_prompt + input(\"Please enter a prompt or seed for your story: \"),\n",
    "    )\n",
    "    # Initialize the story variable that will be updated in the loop\n",
    "    current_story = story_response.text.strip()\n",
    "\n",
    "    print(\"=== Initial Story ===\\n\")\n",
    "    print(current_story)\n",
    "\n",
    "    # --- 3. Iteratively Critique and Improve the story ---\n",
    "    for i in range(num_iterations):\n",
    "        print(f\"\\n--- Iteration {i+1} ---\")\n",
    "\n",
    "        # --- 3a. Critique the current story ---\n",
    "        print(\"\\nGenerating critique...\")\n",
    "        critic_prompt = (\n",
    "            \"You are a literary critic.\\n\"\n",
    "            \"Analyze the provided story for its strengths and weaknesses.\\n\"\n",
    "            \"Comment on plot, characters, and overall impact.\\n\"\n",
    "            \"Provide 2–3 specific suggestions for improvement.\\n\\n\"\n",
    "            f\"Story:\\n{current_story}\"\n",
    "        )\n",
    "        critic_response = client.models.generate_content(model=critic_model, contents=critic_prompt)\n",
    "        story_critique = critic_response.text.strip()\n",
    "\n",
    "        # --- 3b. Display the critique ---\n",
    "        print(f\"\\n=== Critique {i+1} ===\\n\")\n",
    "        print(story_critique)\n",
    "\n",
    "        # --- 3c. Improve the story based on the critique ---\n",
    "        print(\"\\nGenerating revision...\")\n",
    "        revision_prompt = (\n",
    "            \"You are a creative short story writer.\\n\"\n",
    "            \"Revise the following story based *only* on the critique provided.\\n\"\n",
    "            \"Focus on addressing the specific suggestions mentioned in the critique.\\n\"\n",
    "            \"Do not introduce significant new elements not prompted by the critique.\\n\\n\"\n",
    "            f\"Critique:\\n{story_critique}\\n\\n\"\n",
    "            f\"Original Story:\\n{current_story}\\n\\n\"\n",
    "            \"Please produce an improved version of the story, addressing the suggestions.\\n\"\n",
    "            \"Output *only* the revised story.\"\n",
    "        )\n",
    "        revision_response = client.models.generate_content(\n",
    "            model=story_model, contents=revision_prompt\n",
    "        )\n",
    "        # Update the current story with the improved version for the next iteration\n",
    "        current_story = revision_response.text.strip()\n",
    "\n",
    "        # --- 3d. Display the improved story for this iteration ---\n",
    "        print(f\"\\n=== Improved Story {i+1} ===\\n\")\n",
    "        print(current_story)\n",
    "\n",
    "    print(\"\\n--- Final Story after Iterations ---\")\n",
    "    print(current_story)\n",
    "    return current_story\n",
    "\n",
    "\n",
    "generate_story(story_model, client)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
