{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# Google GenAI SDK - Building a Sequential Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai arize-phoenix-otel openinference-instrumentation-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from google import genai\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.environ['PHOENIX_API_KEY']}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com/\"\n",
    "\n",
    "tracer_provider = register(auto_instrument=True, project_name=\"google-genai-sequential-agent\")\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Google Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client using the Vertex AI API, you could also use the Google GenAI API instead here\n",
    "client = genai.Client(vertexai=True, project=\"sandbox-455622\", location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define helper methods ---\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    \"\"\"Instantiate and return a model.\"\"\"\n",
    "    return model_name\n",
    "\n",
    "\n",
    "def generate_story(client, model, user_input):\n",
    "    \"\"\"Generate a short story based on user input.\"\"\"\n",
    "    story_prompt = (\n",
    "        \"You are a creative short story writer.\\n\"\n",
    "        \"Write a brief, engaging story (3–4 paragraphs) about an unexpected \"\n",
    "        \"adventure.\\n\"\n",
    "        \"Be imaginative but concise.\\n\"\n",
    "        \"User Input: \"\n",
    "    )\n",
    "    story_response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=story_prompt + user_input,\n",
    "    )\n",
    "    return story_response.text.strip()\n",
    "\n",
    "\n",
    "def critique_story(client, model, story):\n",
    "    \"\"\"Analyze the provided story and provide critique.\"\"\"\n",
    "    critic_prompt = (\n",
    "        \"You are a literary critic.\\n\"\n",
    "        \"Analyze the provided story for its strengths and weaknesses.\\n\"\n",
    "        \"Comment on plot, characters, and overall impact.\\n\"\n",
    "        \"Provide 2–3 specific suggestions for improvement.\\n\\n\"\n",
    "        f\"Story:\\n{story}\"\n",
    "    )\n",
    "    critic_response = client.models.generate_content(model=model, contents=critic_prompt)\n",
    "    return critic_response.text.strip()\n",
    "\n",
    "\n",
    "def improve_story(client, model, original_story, critique):\n",
    "    \"\"\"Revise the story based on the critique.\"\"\"\n",
    "    revision_prompt = (\n",
    "        \"You are a creative short story writer.\\n\"\n",
    "        \"Revise the following story based on the critique provided.\\n\\n\"\n",
    "        f\"Critique:\\n{critique}\\n\\n\"\n",
    "        f\"Original Story:\\n{original_story}\\n\\n\"\n",
    "        \"Please produce an improved version of the story, addressing the suggestions.\\n\"\n",
    "    )\n",
    "    revision_response = client.models.generate_content(model=model, contents=revision_prompt)\n",
    "    return revision_response.text.strip()\n",
    "\n",
    "\n",
    "# --- 2. Main execution ---\n",
    "@tracer.agent()\n",
    "def run_agent(user_input):\n",
    "    # Instantiate the models\n",
    "    story_model = get_model(\"gemini-2.0-flash-001\")\n",
    "    critic_model = get_model(\"gemini-2.0-flash-001\")\n",
    "\n",
    "    # Generate the initial story\n",
    "    generated_story = generate_story(client, story_model, user_input)\n",
    "\n",
    "    # Critique the generated story\n",
    "    story_critique = critique_story(client, critic_model, generated_story)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"=== Generated Story ===\\n\")\n",
    "    print(generated_story)\n",
    "    print(\"\\n=== Critique ===\\n\")\n",
    "    print(story_critique)\n",
    "\n",
    "    # Improve the story based on the critique\n",
    "    improved_story = improve_story(client, story_model, generated_story, story_critique)\n",
    "\n",
    "    # Display the improved story\n",
    "    print(\"\\n=== Improved Story ===\\n\")\n",
    "    print(improved_story)\n",
    "    return improved_story\n",
    "\n",
    "\n",
    "run_agent(user_input=input(\"Please enter a prompt or seed for your story: \"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
