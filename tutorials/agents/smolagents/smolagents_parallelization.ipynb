{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMMdZ1vnxj8f"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se3M7GECJfpZ"
   },
   "source": [
    "# SmolAgents Prompt Chaining Agent\n",
    "\n",
    "In this tutorial, we'll explore **prompt chaining** with [Smolagents](https://huggingface.co/docs/smolagents/index) and how to trace using Phoenix.\n",
    "Prompt chaining is a method where a complex task is broken into smaller, linked subtasks, with the output of one step feeding into the next. This workflow is ideal when a task can be cleanly decomposed into fixed subtasks, making each LLM call simpler and more accurate â€” trading off latency for better overall performance.\n",
    "\n",
    "In this example, we'll create a multi-step resume analysis, from extracting keywords to summarizing the analysis â€” all automated and fully traceable.\n",
    "\n",
    "By the end of this tutorial, youâ€™ll learn how to:\n",
    "\n",
    "- Set up specialized Smolagents\n",
    "\n",
    "- Chain tasks across agents with carryover context\n",
    "\n",
    "- Improve task accuracy by simplifying each LLM call\n",
    "\n",
    "- Trace and visualize the full execution using Phoenix\n",
    "\n",
    "âš ï¸ You'll need an Hugging Face Token for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2j6_RvFJfpa"
   },
   "source": [
    "## Set up Keys and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openinference-instrumentation-smolagents smolagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from smolagents import CodeAgent, HfApiModel, tool\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "if \"HF_TOKEN\" not in os.environ:\n",
    "    os.environ[\"HF_TOKEN\"] = getpass(\"ðŸ”‘ Enter your Hugging Face Token: \")\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"ðŸ”‘ Enter your Phoenix API key: \")\n",
    "\n",
    "if \"PHOENIX_COLLECTOR_ENDPOINT\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = getpass(\"ðŸ”‘ Enter your Phoenix Collector Endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = HfApiModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibmucjY_QkaH"
   },
   "source": [
    "## Configure Tracing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_provider = register(\n",
    "    project_name=\"smolagents-prompt-chaining\",\n",
    "    protocol=\"http/protobuf\",\n",
    "    auto_instrument=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTVRWf0NJfpc"
   },
   "source": [
    "## Example Prompt Chaining Task: Resume Analysis\n",
    "\n",
    "This example demonstrates how to use Smolagents to do prompt chaining for resume analysis. The resume is analyzed for keywords, skills, and experiences and then the analysis is summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq5TvGKzO685"
   },
   "source": [
    "## Define Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the extract_keywords tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def extract_keywords(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts keywords from the input text.\n",
    "\n",
    "    Args:\n",
    "        text: The resume text to extract keywords from.\n",
    "\n",
    "    Returns:\n",
    "        A comma-separated string of keywords with more than 5 letters.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    keywords = [word.strip(\".,\") for word in words if len(word) > 5]\n",
    "    return \", \".join(keywords)\n",
    "\n",
    "\n",
    "# Create the agent with the custom tool\n",
    "agent = CodeAgent(tools=[extract_keywords], model=model)\n",
    "\n",
    "# Run the agent with a prompt that chains reasoning\n",
    "agent.run(\n",
    "    \"Extract keywords from this resume: 'Experienced software engineer with 5+ years in Python, \"\n",
    "    \"React, and cloud technologies. Led development of microservices architecture and implemented \"\n",
    "    \"CI/CD pipelines. Strong background in machine learning and data analysis.' \"\n",
    "    \"Then summarize what these keywords suggest about the candidate's technical expertise.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
