{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>"
      ],
      "metadata": {
        "id": "jXCU375BitSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph: Evaluator–Optimizer Loop\n",
        "In this tutorial, we’ll build a code generation feedback loop using LangGraph — where a generator LLM writes code and an evaluator LLM provides structured reviews. This iterative pattern is useful for refining outputs over multiple steps until they meet a defined success criterion.\n",
        "\n",
        "The workflow consists of:\n",
        "\n",
        "A **generator LLM** that produces or revises code based on feedback.\n",
        "\n",
        "An **evaluator LLM** that assigns a grade (pass or fail) and gives feedback if needed.\n",
        "\n",
        "A **LangGraph state machine** that loops the generator until the evaluator approves the result.\n",
        "\n",
        "To make this fully observable and production-grade, we’ve instrumented the graph with Phoenix tracing. This enables you to inspect each generation and evaluation step, see what the model produced, and understand why it did (or didn’t) pass."
      ],
      "metadata": {
        "id": "bB9zTru-iiQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain langchain_community \"arize-phoenix\" arize-phoenix-otel openinference-instrumentation-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-RBBOUj0eJU7",
        "outputId": "89f862d6-2c3e-4db9-8fbc-607ea27af5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: arize-phoenix in /usr/local/lib/python3.11/dist-packages (8.31.0)\n",
            "Requirement already satisfied: arize-phoenix-otel in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: openinference-instrumentation-langchain in /usr/local/lib/python3.11/dist-packages (0.1.42)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.58)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.66)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.3)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.38)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aioitertools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.12.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.21.0)\n",
            "Requirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.15.2)\n",
            "Requirement already satisfied: arize-phoenix-client in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.4.0)\n",
            "Requirement already satisfied: arize-phoenix-evals>=0.13.1 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.20.6)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.5.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.5.2)\n",
            "Requirement already satisfied: email-validator in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (2.2.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.115.12)\n",
            "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.15.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.71.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.28.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (3.1.6)\n",
            "Requirement already satisfied: openinference-instrumentation>=0.1.12 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.1.28)\n",
            "Requirement already satisfied: openinference-semantic-conventions>=0.1.12 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.1.17)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.53b1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.29.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (18.1.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.0.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.15.2)\n",
            "Requirement already satisfied: sqlean-py>=3.45.1 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (3.49.1)\n",
            "Requirement already satisfied: starlette>=0.46.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.46.2)\n",
            "Requirement already satisfied: strawberry-graphql>=0.262.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.266.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (4.13.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.17.2)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.11/dist-packages (from openinference-instrumentation-langchain) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.11/dist-packages (from openinference-instrumentation-langchain) (0.53b1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.17)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->arize-phoenix) (0.16.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from strawberry-graphql>=0.262.0->arize-phoenix) (3.2.6)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib->arize-phoenix) (43.0.3)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator->arize-phoenix) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->arize-phoenix) (3.0.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp->arize-phoenix) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->arize-phoenix) (8.1.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->arize-phoenix) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->arize-phoenix) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib->arize-phoenix) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWgelbXYeKE3",
        "outputId": "039eab7f-0370-47de-c51e-40ec94c7caa2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.58)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.76.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.3.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.10.17)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "import os, getpass"
      ],
      "metadata": {
        "id": "W2KtFpVJeKG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU8H5ob4eKJX",
        "outputId": "4e5e0af2-9a0c-4dbf-fc6b-50d14fb813c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure Phoenix Tracing\n",
        "\n",
        "Make sure you go to https://app.phoenix.arize.com/ and generate an API key. This will allow you to trace your Langgraph application with Phoenix."
      ],
      "metadata": {
        "id": "kE0uzv1ei0Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PHOENIX_API_KEY = getpass.getpass(\"Phoenix API Key:\")\n",
        "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
        "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCC6Pr7SeKLm",
        "outputId": "c1d33374-4965-436b-aa32-b530cb5c4241"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phoenix API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phoenix.otel import register\n",
        "\n",
        "tracer_provider = register(\n",
        "  project_name=\"Evaluator-Optimizer\",\n",
        "  auto_instrument=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R11GiJumeKN0",
        "outputId": "b0f47c38-f017-47e2-f7af-aef48863201f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔭 OpenTelemetry Tracing Details 🔭\n",
            "|  Phoenix Project: Evaluator-Optimizer\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {'api_key': '****'}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ⚠️ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluator‑Optimizer • Code‑Writing Loop\n",
        "---------------------------------------\n",
        "Input  : problem_spec (natural‑language description of the function/program)\n",
        "\n",
        "Output : refined, accepted code (Python string)\n"
      ],
      "metadata": {
        "id": "uCHt5qQzjQ84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7saoOK7d_gK",
        "outputId": "c13f27be-f522-4b71-d681-494b7845a409",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1630: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== FINAL CODE =====\n",
            "\n",
            "```javascript\n",
            "// JavaScript code for a complicated website with features\n",
            "\n",
            "// Function to display a welcome message\n",
            "function displayWelcomeMessage() {\n",
            "    alert(\"Welcome to our complicated website!\");\n",
            "}\n",
            "\n",
            "// Function to toggle a menu\n",
            "function toggleMenu() {\n",
            "    var menu = document.getElementById(\"menu\");\n",
            "    if (menu.style.display === \"none\") {\n",
            "        menu.style.display = \"block\";\n",
            "    } else {\n",
            "        menu.style.display = \"none\";\n",
            "    }\n",
            "}\n",
            "\n",
            "// Function to validate a form\n",
            "function validateForm() {\n",
            "    var name = document.getElementById(\"name\").value;\n",
            "    var email = document.getElementById(\"email\").value;\n",
            "\n",
            "    if (name === \"\" || email === \"\") {\n",
            "        alert(\"Please fill out all fields in the form.\");\n",
            "        return false;\n",
            "    }\n",
            "\n",
            "    return true;\n",
            "}\n",
            "\n",
            "// Event listener to trigger displayWelcomeMessage function on page load\n",
            "document.addEventListener(\"DOMContentLoaded\", function() {\n",
            "    displayWelcomeMessage();\n",
            "});\n",
            "\n",
            "// Event listener to trigger toggleMenu function when menu button is clicked\n",
            "document.getElementById(\"menuButton\").addEventListener(\"click\", function() {\n",
            "    toggleMenu();\n",
            "});\n",
            "\n",
            "// Event listener to trigger validateForm function when form is submitted\n",
            "document.getElementById(\"submitForm\").addEventListener(\"submit\", function(event) {\n",
            "    if (!validateForm()) {\n",
            "        event.preventDefault();\n",
            "    }\n",
            "});\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal, TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs\n",
        "----\n",
        "• generator_llm : writes / rewrites the code\n",
        "\n",
        "• evaluator_llm : grades the code via structured output"
      ],
      "metadata": {
        "id": "Kfy5KexRjeKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n"
      ],
      "metadata": {
        "id": "3TKsu5FAjcrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enable structured, reliable feedback from the evaluator LLM, we define a Pydantic schema called Review. This schema ensures that all evaluations include both a binary grade (pass or fail) and feedback if the code needs improvement.\n",
        "\n",
        "By binding this schema to the evaluator LLM, we guarantee consistent output formatting and make it easier to route logic in the graph. This step is essential for closing the feedback loop and driving iterative optimization."
      ],
      "metadata": {
        "id": "I3v2xmGCjlSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Review(BaseModel):\n",
        "    grade: Literal[\"pass\", \"fail\"] = Field(\n",
        "        description=\"Did the code fully solve the problem?\"\n",
        "    )\n",
        "    feedback: str = Field(\n",
        "        description=\"If grade=='fail', give concrete, actionable feedback.\"\n",
        "    )\n",
        "\n",
        "evaluator = evaluator_llm.with_structured_output(Review)\n"
      ],
      "metadata": {
        "id": "NCAiTw7gjkKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langgraph Shared State\n",
        "Defines the shared state for the evaluator-optimizer loop, tracking the problem description, generated code, feedback, and evaluation grade."
      ],
      "metadata": {
        "id": "fdfvi2tTjuTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    problem_spec: str\n",
        "    code: str\n",
        "    feedback: str\n",
        "    grade: str  # pass / fail\n"
      ],
      "metadata": {
        "id": "9lhNZ3nhjtg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Functions: Generator & Evaluator\n",
        "These nodes power the evaluator–optimizer loop. The code_generator node uses the generator LLM to produce or revise Python code based on the task and prior feedback. The code_evaluator node uses a structured evaluator LLM to simulate a code review — mentally testing the code against the spec and returning a binary grade along with constructive feedback if needed. This feedback is then looped back to the generator until the code passes."
      ],
      "metadata": {
        "id": "RHpxqUrwj1PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def code_generator(state: State):\n",
        "    \"\"\"Write or refine code based on feedback.\"\"\"\n",
        "    prompt = (\n",
        "        \"You are an expert Python developer.\\n\"\n",
        "        \"Write clear, efficient, PEP‑8 compliant code that solves the task below.\\n\"\n",
        "        \"If feedback is provided, revise the previous code accordingly.\\n\\n\"\n",
        "        f\"### Task\\n{state['problem_spec']}\\n\\n\"\n",
        "    )\n",
        "    if state.get(\"feedback\"):\n",
        "        prompt += f\"### Previous Reviewer Feedback\\n{state['feedback']}\\n\"\n",
        "\n",
        "    msg = generator_llm.invoke(prompt)\n",
        "    return {\"code\": msg.content}\n",
        "\n",
        "\n",
        "def code_evaluator(state: State):\n",
        "    \"\"\"LLM reviews the code solution.\"\"\"\n",
        "    review = evaluator.invoke(\n",
        "        [\n",
        "            SystemMessage(\n",
        "                content=(\n",
        "                    \"You are a strict code reviewer. \"\n",
        "                    \"Run mental tests / reasoning to decide whether the code meets the spec. \"\n",
        "                    \"If it fails, give concise actionable feedback.\"\n",
        "                )\n",
        "            ),\n",
        "            HumanMessage(\n",
        "                content=(\n",
        "                    f\"### Problem\\n{state['problem_spec']}\\n\\n\"\n",
        "                    f\"### Candidate Code\\n{state['code']}\"\n",
        "                )\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    return {\"grade\": review.grade, \"feedback\": review.feedback}\n",
        "\n"
      ],
      "metadata": {
        "id": "z5bBBoD1j0Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Routing Logic\n",
        "To support iterative refinement, we define a simple routing function called route. After the code is evaluated, this function checks the grade returned by the evaluator: if the code passes, the process ends; if it fails, control loops back to the generator for another revision. This logic ensures the LLM can continuously improve its output based on feedback until it meets the quality bar."
      ],
      "metadata": {
        "id": "azF5t0TYkFAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route(state: State):\n",
        "    return \"Accept\" if state[\"grade\"] == \"pass\" else \"Revise\"\n"
      ],
      "metadata": {
        "id": "kJH86Nq0j7fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the LangGraph\n",
        "We now define our LangGraph-based workflow. Each component — the generator and evaluator — is added as a node. Directed edges specify the flow: the graph starts with generation, then moves to evaluation. Conditional edges use the routing logic to either terminate the loop (if passed) or revisit the generator (if failed). This structure enables self-correcting behavior with every iteration traceable via Phoenix."
      ],
      "metadata": {
        "id": "AALHddZ5kJLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"code_generator\", code_generator)\n",
        "builder.add_node(\"code_evaluator\", code_evaluator)\n",
        "\n",
        "builder.add_edge(START, \"code_generator\")\n",
        "builder.add_edge(\"code_generator\", \"code_evaluator\")\n",
        "builder.add_conditional_edges(\n",
        "    \"code_evaluator\",\n",
        "    route,\n",
        "    {\n",
        "        \"Accept\": END,\n",
        "        \"Revise\": \"code_generator\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow = builder.compile()\n"
      ],
      "metadata": {
        "id": "WV8uBqsqkGve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Usage"
      ],
      "metadata": {
        "id": "9JAMsA_8kMAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem = \"\"\"\n",
        "Write code for a complicated website with javascript features.\n",
        "\"\"\"\n",
        "\n",
        "result_state = workflow.invoke({\"problem_spec\": problem})\n",
        "print(\"===== FINAL CODE =====\\n\")\n",
        "print(result_state[\"code\"])\n"
      ],
      "metadata": {
        "id": "FVfKHtF-kLNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure to check our your traces in Phoenix!"
      ],
      "metadata": {
        "id": "Dg72TE-ykNlN"
      }
    }
  ]
}