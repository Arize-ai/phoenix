{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>"
      ],
      "metadata": {
        "id": "9_FdPOuAkS5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langgraph - Parallel Evaluation"
      ],
      "metadata": {
        "id": "s79namx_lr87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parallel Evaluation in LangGraph\n",
        "In this tutorial, we‚Äôll build a parallel execution workflow using LangGraph ‚Äî ideal for scenarios where multiple evaluations or subtasks can run independently before being aggregated into a final decision.\n",
        "\n",
        "Our application generates a compelling product description and then runs three checks in parallel:\n",
        "\n",
        "- Safety Check: Is the content safe and non-violent?\n",
        "\n",
        "- Policy Compliance: Does it follow company policy?\n",
        "\n",
        "- Clarity Check: Is it understandable to a general audience?\n",
        "\n",
        "This pattern demonstrates how to fan out execution after a shared generation step, and aggregate results before producing a final output.\n",
        "\n",
        "We use Phoenix tracing to gain full visibility into each node execution, making it easy to debug or audit how decisions were made across the parallel branches."
      ],
      "metadata": {
        "id": "-xjm2ngLkTxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain langchain_community \"arize-phoenix\" arize-phoenix-otel openinference-instrumentation-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Alt6V24TYrlR",
        "outputId": "1fc19904-8fae-4188-bcc9-9be480b35976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: arize-phoenix in /usr/local/lib/python3.11/dist-packages (8.31.0)\n",
            "Requirement already satisfied: arize-phoenix-otel in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: openinference-instrumentation-langchain in /usr/local/lib/python3.11/dist-packages (0.1.42)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.56)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.66)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.3)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.38)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aioitertools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.12.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.21.0)\n",
            "Requirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.15.2)\n",
            "Requirement already satisfied: arize-phoenix-client in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.4.0)\n",
            "Requirement already satisfied: arize-phoenix-evals>=0.13.1 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.20.6)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.5.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.5.2)\n",
            "Requirement already satisfied: email-validator in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (2.2.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.115.12)\n",
            "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.15.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.71.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.28.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (3.1.6)\n",
            "Requirement already satisfied: openinference-instrumentation>=0.1.12 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.1.28)\n",
            "Requirement already satisfied: openinference-semantic-conventions>=0.1.12 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.1.17)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.53b1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.29.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (18.1.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.0.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.15.2)\n",
            "Requirement already satisfied: sqlean-py>=3.45.1 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (3.49.1)\n",
            "Requirement already satisfied: starlette>=0.46.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.46.2)\n",
            "Requirement already satisfied: strawberry-graphql>=0.262.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.266.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (4.13.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.17.2)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.11/dist-packages (from openinference-instrumentation-langchain) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.11/dist-packages (from openinference-instrumentation-langchain) (0.53b1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.17)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->arize-phoenix) (0.16.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from strawberry-graphql>=0.262.0->arize-phoenix) (3.2.6)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib->arize-phoenix) (43.0.3)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator->arize-phoenix) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->arize-phoenix) (3.0.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp->arize-phoenix) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->arize-phoenix) (8.1.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->arize-phoenix) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->arize-phoenix) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib->arize-phoenix) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "import os, getpass"
      ],
      "metadata": {
        "id": "8vaGO0UxYtiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyd5gwQ6Yuwt",
        "outputId": "39cbf73e-d781-4090-9167-05d6a13058c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure Phoenix Tracing\n",
        "\n",
        "Make sure you go to https://app.phoenix.arize.com/ and generate an API key. This will allow you to trace your Langgraph application with Phoenix."
      ],
      "metadata": {
        "id": "lzR6b-d7kgzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PHOENIX_API_KEY = getpass.getpass(\"Phoenix API Key:\")\n",
        "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
        "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiyQbc0UYwMr",
        "outputId": "4212fb98-5446-48f1-e956-629e9966dd57"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phoenix API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phoenix.otel import register\n",
        "\n",
        "tracer_provider = register(\n",
        "  project_name=\"Parallel\",\n",
        "  auto_instrument=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rQMLSKVYyWE",
        "outputId": "5b70c091-64ac-451e-d75b-95ac506b37ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî≠ OpenTelemetry Tracing Details üî≠\n",
            "|  Phoenix Project: Parallel\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {'api_key': '****'}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, Literal\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "3Yyi1YZ6Y2cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM of choice"
      ],
      "metadata": {
        "id": "p-3h3a5ikiou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmxMC-xHu9J0",
        "outputId": "c96575ed-cd24-4f12-c40a-2e37f64d7360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-2776d15c8cf1>:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph State Definition\n",
        "We define a State object to keep track of all data flowing through our LangGraph. This includes the input product name, the generated description, results of three independent evaluation checks, and the final aggregated output."
      ],
      "metadata": {
        "id": "Z3yGNuqrk3Tp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nuu-lBWlEJ6v"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    product: str\n",
        "    description: str\n",
        "    safety_check: str\n",
        "    policy_check: str\n",
        "    clarity_check: str\n",
        "    final_output: str"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node 1: Generate Product Description\n",
        "This node uses the LLM to write a compelling marketing-style description of the product. The output is stored in the description field of the graph state."
      ],
      "metadata": {
        "id": "TTOgjtPik8XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_description(state: State):\n",
        "    msg = llm.invoke(f\"Write a compelling product description for: {state['product']}\")\n",
        "    return {\"description\": msg.content}\n",
        "\n"
      ],
      "metadata": {
        "id": "vCGlA1crk6bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node 2‚Äì4: Parallel Evaluation Checks\n",
        "After the product description is created, we fan out to three evaluators, each performing an independent check in parallel:\n",
        "\n",
        "**Safety Check**: Is the language safe and non-violent?\n",
        "\n",
        "**Policy Compliance**: Does it align with company guidelines?\n",
        "\n",
        "**Clarity Check**: Is it understandable by a general audience?\n",
        "\n",
        "Each function receives the same description as input and returns a binary decision (\"yes\" or \"no\")."
      ],
      "metadata": {
        "id": "Q6ZH2SovlF4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_safety(state: State):\n",
        "    msg = llm.invoke(f\"Is this product description safe and non-violent? Answer yes or no.\\n\\n{state['description']}\")\n",
        "    return {\"safety_check\": msg.content}\n",
        "\n",
        "\n",
        "def check_policy(state: State):\n",
        "    msg = llm.invoke(f\"Does this product description comply with our company policy? Answer yes or no.\\n\\n{state['description']}\")\n",
        "    return {\"policy_check\": msg.content}\n",
        "\n",
        "\n",
        "def check_clarity(state: State):\n",
        "    msg = llm.invoke(f\"Is this description clear and understandable to a 10th-grade reader? Answer yes or no.\\n\\n{state['description']}\")\n",
        "    return {\"clarity_check\": msg.content}\n"
      ],
      "metadata": {
        "id": "KrdUg-b_lFI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node 5: Aggregate the Results\n",
        "Once the checks complete, this node gathers their responses. If all checks return \"yes\", the product description is approved. Otherwise, it‚Äôs flagged as rejected, along with reasons."
      ],
      "metadata": {
        "id": "--BmhL3tlMMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_results(state: State):\n",
        "    if (\n",
        "        \"yes\" in state[\"safety_check\"].strip().lower()\n",
        "        and \"yes\" in state[\"policy_check\"].strip().lower()\n",
        "        and \"yes\" in state[\"clarity_check\"].strip().lower()\n",
        "    ):\n",
        "        return {\"final_output\": state[\"description\"]}\n",
        "    return {\n",
        "        \"final_output\": \"REJECTED: One or more checks failed.\\n\"\n",
        "        f\"Safety: {state['safety_check']}, Policy: {state['policy_check']}, Clarity: {state['clarity_check']}\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "xHTOSh1AlLIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Parallel Evaluation Graph\n",
        "With all our nodes defined, we now assemble them into a LangGraph using StateGraph.\n",
        "\n",
        "**Start ‚Üí Description**: We begin by generating the product description.\n",
        "\n",
        "**Fan Out Checks**: The output fans out into three parallel paths ‚Äî safety, policy, and clarity checks ‚Äî enabling efficient, simultaneous validation.\n",
        "\n",
        "**Converge ‚Üí Aggregate**: Once all checks complete, the results converge into a final aggregation node that determines whether to approve or reject the description.\n",
        "\n",
        "**End**: The final result is produced.\n",
        "\n",
        "This setup showcases LangGraph‚Äôs ability to manage parallelism and convergence, streamlining complex workflows while remaining transparent and modular."
      ],
      "metadata": {
        "id": "pm-KYiZzlRxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"generate_description\", generate_description)\n",
        "builder.add_node(\"check_safety\", check_safety)\n",
        "builder.add_node(\"check_policy\", check_policy)\n",
        "builder.add_node(\"check_clarity\", check_clarity)\n",
        "builder.add_node(\"aggregate_results\", aggregate_results)\n",
        "\n",
        "# Description generation first\n",
        "builder.add_edge(START, \"generate_description\")\n",
        "\n",
        "# Then fan out for parallel checks\n",
        "builder.add_edge(\"generate_description\", \"check_safety\")\n",
        "builder.add_edge(\"generate_description\", \"check_policy\")\n",
        "builder.add_edge(\"generate_description\", \"check_clarity\")\n",
        "\n",
        "# All checks go to the aggregator\n",
        "builder.add_edge(\"check_safety\", \"aggregate_results\")\n",
        "builder.add_edge(\"check_policy\", \"aggregate_results\")\n",
        "builder.add_edge(\"check_clarity\", \"aggregate_results\")\n",
        "\n",
        "# Final result\n",
        "builder.add_edge(\"aggregate_results\", END)\n",
        "\n",
        "workflow = builder.compile()\n"
      ],
      "metadata": {
        "id": "-a147-dcGCVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Usage"
      ],
      "metadata": {
        "id": "m1-XyQI0lZDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = workflow.invoke({\"product\": \"Smart glasses that project your calendar\"})\n",
        "print(state[\"final_output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZjaN1FhYmaW",
        "outputId": "048bf17c-8329-40fb-ffd9-b5c535124aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Introducing VisionSync Smart Glasses: Your Calendar, Right Before Your Eyes!**\n",
            "\n",
            "Step into the future of productivity with VisionSync Smart Glasses, the revolutionary eyewear that seamlessly integrates your digital life with the real world. Imagine a pair of stylish glasses that not only enhance your vision but also keep you organized and on track‚Äîright in your line of sight!\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "- **Calendar Projection:** Effortlessly view your daily schedule, appointments, and reminders projected directly onto the lenses. No more fumbling with your phone or missing important meetings; everything you need is just a glance away.\n",
            "\n",
            "- **Sleek Design:** Crafted with a modern aesthetic, VisionSync Smart Glasses are lightweight and comfortable, making them perfect for all-day wear. Choose from a variety of colors and styles to match your personal taste.\n",
            "\n",
            "- **Voice Activation:** Stay hands-free and focused! With intuitive voice commands, you can easily navigate your calendar, set new appointments, or receive reminders‚Äîall without lifting a finger.\n",
            "\n",
            "- **Real-Time Notifications:** Stay connected with discreet notifications for emails, messages, and calendar alerts. Whether you‚Äôre in a meeting or on the go, you‚Äôll never miss an important update.\n",
            "\n",
            "- **Long Battery Life:** Designed for the busy professional, our smart glasses boast an impressive battery life that lasts all day, ensuring you stay organized from morning meetings to evening events.\n",
            "\n",
            "- **Compatibility:** Sync effortlessly with your favorite calendar apps, including Google Calendar, Outlook, and more. VisionSync Smart Glasses are designed to work with your existing digital ecosystem, making integration a breeze.\n",
            "\n",
            "**Why Choose VisionSync?**\n",
            "\n",
            "In today‚Äôs fast-paced world, staying organized is more crucial than ever. VisionSync Smart Glasses empower you to take control of your schedule while keeping your hands free and your focus sharp. Whether you‚Äôre a busy professional, a student juggling classes, or a multitasking parent, these smart glasses are your ultimate companion for a more efficient lifestyle.\n",
            "\n",
            "**Elevate Your Everyday Experience!**\n",
            "\n",
            "Don‚Äôt just see the world‚Äîexperience it with VisionSync Smart Glasses. Transform the way you manage your time and embrace a new era of productivity. Order now and step into a world where your calendar is always in sight, and your potential is limitless!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure to view your traces in Phoenix!"
      ],
      "metadata": {
        "id": "UQJDA2SNlbIn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p5dghZ5elc22"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}