{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_FdPOuAkS5O"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s79namx_lr87"
   },
   "source": [
    "# Langgraph - Parallel Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xjm2ngLkTxb"
   },
   "source": [
    "Parallel Evaluation in LangGraph\n",
    "In this tutorial, we’ll build a parallel execution workflow using LangGraph — ideal for scenarios where multiple evaluations or subtasks can run independently before being aggregated into a final decision.\n",
    "\n",
    "Our application generates a compelling product description and then runs three checks in parallel:\n",
    "\n",
    "- Safety Check: Is the content safe and non-violent?\n",
    "\n",
    "- Policy Compliance: Does it follow company policy?\n",
    "\n",
    "- Clarity Check: Is it understandable to a general audience?\n",
    "\n",
    "This pattern demonstrates how to fan out execution after a shared generation step, and aggregate results before producing a final output.\n",
    "\n",
    "We use Phoenix tracing to gain full visibility into each node execution, making it easy to debug or audit how decisions were made across the parallel branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph langchain langchain_community \"arize-phoenix\" arize-phoenix-otel openinference-instrumentation-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzR6b-d7kgzF"
   },
   "source": [
    "# Configure Phoenix Tracing\n",
    "\n",
    "Make sure you go to https://app.phoenix.arize.com/ and generate an API key. This will allow you to trace your Langgraph application with Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHOENIX_API_KEY = getpass.getpass(\"Phoenix API Key:\")\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(project_name=\"Parallel\", auto_instrument=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-3h3a5ikiou"
   },
   "source": [
    "# LLM of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3yGNuqrk3Tp"
   },
   "source": [
    "# Graph State Definition\n",
    "We define a State object to keep track of all data flowing through our LangGraph. This includes the input product name, the generated description, results of three independent evaluation checks, and the final aggregated output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    product: str\n",
    "    description: str\n",
    "    safety_check: str\n",
    "    policy_check: str\n",
    "    clarity_check: str\n",
    "    final_output: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTOgjtPik8XI"
   },
   "source": [
    "# Node 1: Generate Product Description\n",
    "This node uses the LLM to write a compelling marketing-style description of the product. The output is stored in the description field of the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description(state: State):\n",
    "    msg = llm.invoke(f\"Write a compelling product description for: {state['product']}\")\n",
    "    return {\"description\": msg.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6ZH2SovlF4v"
   },
   "source": [
    "# Node 2–4: Parallel Evaluation Checks\n",
    "After the product description is created, we fan out to three evaluators, each performing an independent check in parallel:\n",
    "\n",
    "**Safety Check**: Is the language safe and non-violent?\n",
    "\n",
    "**Policy Compliance**: Does it align with company guidelines?\n",
    "\n",
    "**Clarity Check**: Is it understandable by a general audience?\n",
    "\n",
    "Each function receives the same description as input and returns a binary decision (\"yes\" or \"no\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_safety(state: State):\n",
    "    msg = llm.invoke(\n",
    "        f\"Is this product description safe and non-violent? Answer yes or no.\\n\\n{state['description']}\"\n",
    "    )\n",
    "    return {\"safety_check\": msg.content}\n",
    "\n",
    "\n",
    "def check_policy(state: State):\n",
    "    msg = llm.invoke(\n",
    "        f\"Does this product description comply with our company policy? Answer yes or no.\\n\\n{state['description']}\"\n",
    "    )\n",
    "    return {\"policy_check\": msg.content}\n",
    "\n",
    "\n",
    "def check_clarity(state: State):\n",
    "    msg = llm.invoke(\n",
    "        f\"Is this description clear and understandable to a 10th-grade reader? Answer yes or no.\\n\\n{state['description']}\"\n",
    "    )\n",
    "    return {\"clarity_check\": msg.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--BmhL3tlMMU"
   },
   "source": [
    "# Node 5: Aggregate the Results\n",
    "Once the checks complete, this node gathers their responses. If all checks return \"yes\", the product description is approved. Otherwise, it’s flagged as rejected, along with reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results(state: State):\n",
    "    if (\n",
    "        \"yes\" in state[\"safety_check\"].strip().lower()\n",
    "        and \"yes\" in state[\"policy_check\"].strip().lower()\n",
    "        and \"yes\" in state[\"clarity_check\"].strip().lower()\n",
    "    ):\n",
    "        return {\"final_output\": state[\"description\"]}\n",
    "    return {\n",
    "        \"final_output\": \"REJECTED: One or more checks failed.\\n\"\n",
    "        f\"Safety: {state['safety_check']}, Policy: {state['policy_check']}, Clarity: {state['clarity_check']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm-KYiZzlRxE"
   },
   "source": [
    "# Building the Parallel Evaluation Graph\n",
    "With all our nodes defined, we now assemble them into a LangGraph using StateGraph.\n",
    "\n",
    "**Start → Description**: We begin by generating the product description.\n",
    "\n",
    "**Fan Out Checks**: The output fans out into three parallel paths — safety, policy, and clarity checks — enabling efficient, simultaneous validation.\n",
    "\n",
    "**Converge → Aggregate**: Once all checks complete, the results converge into a final aggregation node that determines whether to approve or reject the description.\n",
    "\n",
    "**End**: The final result is produced.\n",
    "\n",
    "This setup showcases LangGraph’s ability to manage parallelism and convergence, streamlining complex workflows while remaining transparent and modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"generate_description\", generate_description)\n",
    "builder.add_node(\"check_safety\", check_safety)\n",
    "builder.add_node(\"check_policy\", check_policy)\n",
    "builder.add_node(\"check_clarity\", check_clarity)\n",
    "builder.add_node(\"aggregate_results\", aggregate_results)\n",
    "\n",
    "# Description generation first\n",
    "builder.add_edge(START, \"generate_description\")\n",
    "\n",
    "# Then fan out for parallel checks\n",
    "builder.add_edge(\"generate_description\", \"check_safety\")\n",
    "builder.add_edge(\"generate_description\", \"check_policy\")\n",
    "builder.add_edge(\"generate_description\", \"check_clarity\")\n",
    "\n",
    "# All checks go to the aggregator\n",
    "builder.add_edge(\"check_safety\", \"aggregate_results\")\n",
    "builder.add_edge(\"check_policy\", \"aggregate_results\")\n",
    "builder.add_edge(\"check_clarity\", \"aggregate_results\")\n",
    "\n",
    "# Final result\n",
    "builder.add_edge(\"aggregate_results\", END)\n",
    "\n",
    "workflow = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1-XyQI0lZDD"
   },
   "source": [
    "# Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = workflow.invoke({\"product\": \"Smart glasses that project your calendar\"})\n",
    "print(state[\"final_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQJDA2SNlbIn"
   },
   "source": [
    "# Make sure to view your traces in Phoenix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
