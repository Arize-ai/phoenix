{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>"
      ],
      "metadata": {
        "id": "slXNX2PTqC-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph Router Pattern: Intent-Based Agent Routing\n",
        "In this tutorial, we'll explore the Router pattern using LangGraph, a framework for building dynamic, stateful LLM applications. We’ll build a smart support assistant that can route customer queries to the appropriate specialized agent—Billing, Tech Support, or General Info—based on the user’s intent.\n",
        "\n",
        "LangGraph enables this by letting us define a structured graph of logic, where a router node classifies the input, and conditional edges forward it to the correct sub-agent. Each agent uses local context (e.g., invoice history, troubleshooting tips) to respond intelligently.\n",
        "\n",
        "We also trace this application using Phoenix, which gives us complete visibility into routing decisions, tool usage, and model interactions. This is helpful for debugging routing accuracy and understanding how the graph executes end-to-end."
      ],
      "metadata": {
        "id": "lNmSeMhTp47g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain langchain_community \"arize-phoenix\" arize-phoenix-otel openinference-instrumentation-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2e9idduzRQj",
        "outputId": "8bbaf535-39c2-4c45-d898-0739b67134ce",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: arize-phoenix in /usr/local/lib/python3.11/dist-packages (8.31.0)\n",
            "Requirement already satisfied: arize-phoenix-otel in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: openinference-instrumentation-langchain in /usr/local/lib/python3.11/dist-packages (0.1.42)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.56)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.66)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.3)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.38)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aioitertools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.12.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.21.0)\n",
            "Requirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.15.2)\n",
            "Requirement already satisfied: arize-phoenix-client in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.4.0)\n",
            "Requirement already satisfied: arize-phoenix-evals>=0.13.1 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.20.6)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.5.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.5.2)\n",
            "Requirement already satisfied: email-validator in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (2.2.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.115.12)\n",
            "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.15.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.71.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.28.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (3.1.6)\n",
            "Requirement already satisfied: openinference-instrumentation>=0.1.12 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.1.28)\n",
            "Requirement already satisfied: openinference-semantic-conventions>=0.1.12 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.1.17)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.53b1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.29.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (18.1.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.0.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.15.2)\n",
            "Requirement already satisfied: sqlean-py>=3.45.1 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (3.49.1)\n",
            "Requirement already satisfied: starlette>=0.46.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.46.2)\n",
            "Requirement already satisfied: strawberry-graphql>=0.262.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.266.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (4.13.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix) (1.17.2)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.11/dist-packages (from openinference-instrumentation-langchain) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.11/dist-packages (from openinference-instrumentation-langchain) (0.53b1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.17)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->arize-phoenix) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->arize-phoenix) (0.16.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from strawberry-graphql>=0.262.0->arize-phoenix) (3.2.6)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib->arize-phoenix) (43.0.3)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator->arize-phoenix) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->arize-phoenix) (3.0.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp->arize-phoenix) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp->arize-phoenix) (1.32.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->arize-phoenix) (8.1.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->arize-phoenix) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->arize-phoenix) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib->arize-phoenix) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKyQLxtT5Zqy",
        "outputId": "d7e405ba-9e78-48db-ddc6-b80f11357eb7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.76.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.3.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.10.17)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed langchain-core-0.3.58 langchain_openai-0.3.16 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "import os, getpass"
      ],
      "metadata": {
        "id": "t5h0LMz1zR0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcpPSUbCzR6Q",
        "outputId": "bf538cf5-5da6-4049-e899-2011cd8396c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure Phoenix Tracing\n",
        "\n",
        "Make sure you go to https://app.phoenix.arize.com/ and generate an API key. This will allow you to trace your Langgraph application with Phoenix."
      ],
      "metadata": {
        "id": "64eGWAjjqJzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PHOENIX_API_KEY = getpass.getpass(\"Phoenix API Key:\")\n",
        "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
        "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY4463n0zR8j",
        "outputId": "3d5162a4-307b-4568-c629-8bbd7cfbd768"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phoenix API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phoenix.otel import register\n",
        "\n",
        "tracer_provider = register(\n",
        "  project_name=\"Router\",\n",
        "  auto_instrument=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Dpo2jkzR-x",
        "outputId": "800ce306-9d2b-4fbf-926a-6866c6cbf432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔭 OpenTelemetry Tracing Details 🔭\n",
            "|  Phoenix Project: Router\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {'api_key': '****'}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ⚠️ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, Literal\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "Kf4WCJoGzSAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM"
      ],
      "metadata": {
        "id": "5ttz1b_4qMo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)"
      ],
      "metadata": {
        "id": "8XlpzPAzzaBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A0U5BN0vqO3",
        "outputId": "b2b8ef6a-b4e9-4eb4-fc8e-99b461f1bf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal, TypedDict\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Router\n",
        "We define a Pydantic schema to structure the router’s output. This schema ensures the LLM returns one of three valid routing targets: \"billing\", \"tech_support\", or \"general_info\".\n",
        "We then wrap our LLM with with_structured_output, allowing LangGraph to enforce this structured response during routing."
      ],
      "metadata": {
        "id": "GsxvEUl9qcac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Route(BaseModel):\n",
        "    step: Literal[\"billing\", \"tech_support\", \"general_info\"] = Field(description=\"Classify the support request\")\n",
        "\n",
        "router = llm.with_structured_output(Route)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41bStR2Zy3zd",
        "outputId": "d65e620f-47e1-4681-978d-9660b5c9fc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1630: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Graph State\n",
        "This state schema captures the lifecycle of a routed request. It stores the original user input (input), the classification decision made by the router (decision), and the final response generated by the appropriate support handler (output). Each node in the graph will read from and write to this shared state."
      ],
      "metadata": {
        "id": "3uW4u7YVqyUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    input: str\n",
        "    decision: str\n",
        "    output: str"
      ],
      "metadata": {
        "id": "EtaLXu8Hy8CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Agent Nodes: Specialized Response Handlers\n",
        "This section defines three specialized LLM-powered agents, each responsible for handling a different category of user queries:\n",
        "\n",
        "**Billing Agent**: Uses user billing history and a billing policy context to respond to invoice or refund-related questions.\n",
        "\n",
        "**Tech Support Agent**: Answers common troubleshooting queries using a predefined support knowledge base.\n",
        "\n",
        "**General Info Agent**: Responds to account, subscription, and policy-related questions using general FAQs.\n",
        "\n",
        "Each agent reads the input field from the graph's state and returns a generated output tailored to its domain. These agents form the execution endpoints of the router graph."
      ],
      "metadata": {
        "id": "XSvmCZ3qrCSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Billing Agent\n",
        "billing_history_data = [\n",
        "    {\"invoice_id\": \"INV001\", \"date\": \"2024-11-01\", \"amount\": \"$29.99\"},\n",
        "    {\"invoice_id\": \"INV002\", \"date\": \"2024-12-01\", \"amount\": \"$29.99\"},\n",
        "    {\"invoice_id\": \"INV003\", \"date\": \"2025-01-01\", \"amount\": \"$39.99\"},\n",
        "]\n",
        "\n",
        "billing_general_context = (\n",
        "    \"Billing inquiries may include refunds, invoices, plan upgrades, or charges. \"\n",
        "    \"Our system charges users monthly based on their plan. Refunds are processed within 5–7 business days.\"\n",
        ")\n",
        "\n",
        "def billing_agent(state: State):\n",
        "    user_input = state[\"input\"]\n",
        "    invoice_summary = \"\\n\".join(\n",
        "        f\"• Invoice {item['invoice_id']} on {item['date']} for {item['amount']}\"\n",
        "        for item in billing_history_data\n",
        "    )\n",
        "    prompt = (\n",
        "        f\"You are a helpful billing assistant.\\n\"\n",
        "        f\"Here is the user's billing history:\\n{invoice_summary}\\n\\n\"\n",
        "        f\"General billing context:\\n{billing_general_context}\\n\\n\"\n",
        "        f\"User query:\\n{user_input}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt)\n",
        "    return {\"output\": result.content}\n",
        "\n",
        "\n",
        "# Tech Support Agent\n",
        "tech_support_kb = (\n",
        "    \"Common issues include login errors, app crashes, and network connectivity. \"\n",
        "    \"To fix login errors, check your email and reset your password. \"\n",
        "    \"For crashes, try reinstalling the app. If your connection is unstable, restart your router.\"\n",
        ")\n",
        "\n",
        "def tech_support_agent(state: State):\n",
        "    prompt = (\n",
        "        \"You are a tech support assistant. Use the knowledge base below to answer the user's question.\\n\\n\"\n",
        "        f\"Knowledge Base:\\n{tech_support_kb}\\n\\n\"\n",
        "        f\"User query:\\n{state['input']}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt)\n",
        "    return {\"output\": result.content}\n",
        "\n",
        "\n",
        "# General Info Agent\n",
        "general_info_kb = (\n",
        "    \"We offer 3 subscription plans: Basic, Pro, and Enterprise. \"\n",
        "    \"Support is available 24/7. You can cancel your subscription any time from the account settings page.\"\n",
        ")\n",
        "\n",
        "def general_info_agent(state: State):\n",
        "    prompt = (\n",
        "        \"You are a general info assistant. Use the knowledge base below to answer the user's question.\\n\\n\"\n",
        "        f\"Knowledge Base:\\n{general_info_kb}\\n\\n\"\n",
        "        f\"User query:\\n{state['input']}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt)\n",
        "    return {\"output\": result.content}\n",
        "\n"
      ],
      "metadata": {
        "id": "e4kL-fs5y-pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intent Classification & Routing Logic\n",
        "This section introduces the decision-making logic that powers the routing mechanism:\n",
        "\n",
        "**classify_intent Node**: Uses an LLM wrapped with a structured output schema to classify the user's query into one of three support categories — billing, tech_support, or general_info. The result is stored in the state's decision key.\n",
        "\n",
        "**route_to_agent Function**: A conditional router that examines the classification result and sends the request to the corresponding specialized agent node. This allows LangGraph to dynamically direct queries to the most relevant response module."
      ],
      "metadata": {
        "id": "n0mBMBNJravU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_intent(state: State):\n",
        "    decision = router.invoke(\n",
        "        [\n",
        "            SystemMessage(content=\"Classify this support request as billing, tech_support, or general_info.\"),\n",
        "            HumanMessage(content=state[\"input\"]),\n",
        "        ]\n",
        "    )\n",
        "    return {\"decision\": decision.step}\n",
        "\n",
        "def route_to_agent(state: State):\n",
        "    if state[\"decision\"] == \"billing\":\n",
        "        return \"billing_agent\"\n",
        "    elif state[\"decision\"] == \"tech_support\":\n",
        "        return \"tech_support_agent\"\n",
        "    elif state[\"decision\"] == \"general_info\":\n",
        "        return \"general_info_agent\"\n"
      ],
      "metadata": {
        "id": "4Zv_k3fTzA-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Routing Graph\n",
        "Here, we construct the complete LangGraph workflow by registering the nodes and defining their connections:\n",
        "\n",
        "**Node Registration**: All agents (billing_agent, tech_support_agent, general_info_agent) and the classify_intent node are added to the graph.\n",
        "\n",
        "**Conditional Routing**: After the graph starts at classify_intent, it uses the output of route_to_agent to forward the query to the appropriate agent node based on the classified intent.\n",
        "\n",
        "**Terminal Edges**: Each agent node directly leads to END, finalizing the workflow after responding to the query.\n",
        "\n",
        "This design reflects a typical customer support router architecture, enabling modular, extensible handling of diverse query types."
      ],
      "metadata": {
        "id": "sTJslcdprjvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"classify_intent\", classify_intent)\n",
        "builder.add_node(\"billing_agent\", billing_agent)\n",
        "builder.add_node(\"tech_support_agent\", tech_support_agent)\n",
        "builder.add_node(\"general_info_agent\", general_info_agent)\n",
        "\n",
        "builder.add_edge(START, \"classify_intent\")\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"classify_intent\",\n",
        "    route_to_agent,\n",
        "    {\n",
        "        \"billing_agent\": \"billing_agent\",\n",
        "        \"tech_support_agent\": \"tech_support_agent\",\n",
        "        \"general_info_agent\": \"general_info_agent\",\n",
        "    },\n",
        ")\n",
        "\n",
        "builder.add_edge(\"billing_agent\", END)\n",
        "builder.add_edge(\"tech_support_agent\", END)\n",
        "builder.add_edge(\"general_info_agent\", END)\n",
        "\n",
        "workflow = builder.compile()"
      ],
      "metadata": {
        "id": "Zk71ElA1zI7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's run some queries:"
      ],
      "metadata": {
        "id": "ZopT2jdFrtnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Why was I charged $39.99 this month?\",                    # billing\n",
        "    \"The app keeps crashing when I open it.\",                  # tech support\n",
        "    \"Can I cancel my subscription anytime?\",                   # general info\n",
        "    \"Can you show me all my past invoices?\",                   # billing\n",
        "    \"How do I fix login issues with my account?\"               # tech support\n",
        "]\n",
        "\n",
        "# Run each query through the router\n",
        "for i, query in enumerate(queries, start=1):\n",
        "    print(f\"\\n--- Query {i} ---\")\n",
        "    state = workflow.invoke({\"input\": query})\n",
        "    print(f\"Input: {query}\")\n",
        "    print(f\"Response:\\n{state['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Zett2408cg",
        "outputId": "1bc722d4-3c03-42d4-a19b-9f33dd01e2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Query 1 ---\n",
            "Input: Why was I charged $39.99 this month?\n",
            "Response:\n",
            "You were charged $39.99 this month for Invoice INV003, which was issued on January 1, 2025. This amount reflects a change in your billing plan or an upgrade that occurred, as your previous invoices were for $29.99 each. If you need more details about the change in your plan or if you believe this charge is incorrect, please let me know!\n",
            "\n",
            "--- Query 2 ---\n",
            "Input: The app keeps crashing when I open it.\n",
            "Response:\n",
            "It sounds like you're experiencing an app crash issue. To resolve this, try reinstalling the app. This often fixes any underlying problems that may be causing the crashes. If the issue persists after reinstalling, please let me know!\n",
            "\n",
            "--- Query 3 ---\n",
            "Input: Can I cancel my subscription anytime?\n",
            "Response:\n",
            "Yes, you can cancel your subscription anytime from the account settings page.\n",
            "\n",
            "--- Query 4 ---\n",
            "Input: Can you show me all my past invoices?\n",
            "Response:\n",
            "Sure! Here are your past invoices:\n",
            "\n",
            "1. **Invoice INV001**\n",
            "   - Date: 2024-11-01\n",
            "   - Amount: $29.99\n",
            "\n",
            "2. **Invoice INV002**\n",
            "   - Date: 2024-12-01\n",
            "   - Amount: $29.99\n",
            "\n",
            "3. **Invoice INV003**\n",
            "   - Date: 2025-01-01\n",
            "   - Amount: $39.99\n",
            "\n",
            "If you need any further assistance with these invoices or have any other questions, feel free to ask!\n",
            "\n",
            "--- Query 5 ---\n",
            "Input: How do I fix login issues with my account?\n",
            "Response:\n",
            "To fix login issues with your account, please follow these steps:\n",
            "\n",
            "1. Check your email to ensure you are using the correct email address associated with your account.\n",
            "2. If you are unsure of your password, try resetting it by following the password reset instructions provided on the login page.\n",
            "\n",
            "If you continue to experience issues after trying these steps, please let me know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure to view your traces in Phoenix!"
      ],
      "metadata": {
        "id": "_EbruW27rxxb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZLi4DnJrzfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}