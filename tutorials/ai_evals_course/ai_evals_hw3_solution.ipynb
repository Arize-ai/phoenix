{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# HW 3: LLM-as-Judge for Recipe Bot Evaluation with Arize\n",
        "\n",
        "## üéØ Assignment Overview\n",
        "\n",
        "In this assignment, we'll evaluate our Recipe Bot's adherence to dietary preferences using an LLM-as-Judge approach with Arize for tracing and evaluation.\n",
        "\n",
        "### Workflow:\n",
        "1. **üìä Load trace examples** - Choose between provided data or generate new traces\n",
        "2. **üè∑Ô∏è Create datasets** - Prepare data for labeling queue in Arize\n",
        "3. **üîç Label traces** - Use Arize UI to manually label examples  \n",
        "4. **‚öñÔ∏è Write eval prompt** - Create judge prompt in Arize Playground\n",
        "5. **üìà Run evaluation experiment** - Execute evaluation via Arize\n",
        "6. **üìä Calculate metrics** - Export and analyze results\n",
        "\n",
        "### Core Task: \"Adherence to Dietary Preferences\"\n",
        "**Example**: If a user asks for a \"vegan\" recipe, does the bot provide one that is actually vegan?\n",
        "\n",
        "Let's get started! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup and Environment Configuration\n",
        "\n",
        "First, let's import the required libraries and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "def install_packages():\n",
        "    packages = [\n",
        "        \"arize-phoenix[evals]\",\n",
        "        \"openai\",\n",
        "        \"pandas\",\n",
        "        \"openinference-instrumentation-openai\",\n",
        "        \"nest-asyncio\",\n",
        "        \"arize-phoenix[evals]\",\n",
        "        \"openai\", \n",
        "        \"pandas\",\n",
        "        \"numpy\",\n",
        "        \"scipy\",\n",
        "        \"openinference-instrumentation-openai\",\n",
        "        \"nest-asyncio\",\n",
        "        \"arize[AutoEmbeddings]\",  # For ArizeExportClient and ArizeDatasetsClient\n",
        "        \"opentelemetry-api\",\n",
        "        \"opentelemetry-sdk\",\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "\n",
        "# Uncomment to install packages\n",
        "# install_packages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import getpass\n",
        "from datetime import datetime\n",
        "from arize.exporter import ArizeExportClient\n",
        "from arize.utils.types import Environments\n",
        "from datetime import datetime, timedelta\n",
        "from arize.otel import register\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "from arize.experimental.datasets import ArizeDatasetsClient\n",
        "import pandas as pd\n",
        "from arize.experimental.datasets.utils.constants import GENERATIVE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîë API Key Configuration\n",
        "\n",
        "**Important**: For security, never hardcode API keys in notebooks. We'll use environment variables and secure input methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "Prompt for OpenAI API key if not set\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OPENAI_API_KEY: \")\n",
        "\n",
        "# Prompt for Arize API key if not set\n",
        "if \"ARIZE_API_KEY\" not in os.environ or not os.environ[\"ARIZE_API_KEY\"]:\n",
        "    os.environ[\"ARIZE_API_KEY\"] = getpass.getpass(\"Enter your ARIZE_API_KEY: \")\n",
        "\n",
        "# Prompt for Arize Space key if not set\n",
        "if \"ARIZE_SPACE_ID\" not in os.environ or not os.environ[\"ARIZE_SPACE_ID\"]:\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = getpass.getpass(\"Enter your ARIZE_SPACE_ID: \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tracing Setup\n",
        "\n",
        "We'll set up OpenTelemetry tracing to automatically capture LLM interactions and send them to Arize. This enables real-time monitoring and evaluation of our Recipe Bot's performance in production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI()\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî≠ OpenTelemetry Tracing Details üî≠\n",
            "|  Arize Project: RecipeBot\n",
            "|  Span Processor: BatchSpanProcessor\n",
            "|  Collector Endpoint: otlp.arize.com\n",
            "|  Transport: gRPC\n",
            "|  Transport Headers: {'authorization': '****', 'api_key': '****', 'arize-space-id': '****', 'space_id': '****', 'arize-interface': '****'}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Set up tracing\n",
        "tracer_provider = register(\n",
        "    space_id=os.environ[\"ARIZE_SPACE_ID\"],\n",
        "    project_name=\"RecipeBot\",  # name this to whatever you would like\n",
        ")\n",
        "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Part 1: Create Arize Dataset for Labeling \n",
        "\n",
        "We'll upload our split dataset to Arize for manual labeling of ground truth examples. This step is crucial for establishing the \"correct\" answers that our judge will be evaluated against.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>dietary_restriction</th>\n",
              "      <th>response</th>\n",
              "      <th>success</th>\n",
              "      <th>error</th>\n",
              "      <th>trace_id</th>\n",
              "      <th>query_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'm vegan but I really want to make something ...</td>\n",
              "      <td>vegan</td>\n",
              "      <td>Certainly! For a vegan yogurt breakfast that m...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1_8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm vegan but I really want to make something ...</td>\n",
              "      <td>vegan</td>\n",
              "      <td>Absolutely! While honey is a popular sweetener...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1_9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm vegan but I really want to make something ...</td>\n",
              "      <td>vegan</td>\n",
              "      <td>Certainly! Since you're vegan and craving a yo...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1_10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Need a quick gluten-free breakfast. I hate egg...</td>\n",
              "      <td>gluten-free</td>\n",
              "      <td>Certainly! For a quick, gluten-free breakfast ...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2_7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm vegan but I really want to make something ...</td>\n",
              "      <td>vegan</td>\n",
              "      <td>Absolutely! For a vegan breakfast that mimics ...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1_27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query dietary_restriction  \\\n",
              "0  I'm vegan but I really want to make something ...               vegan   \n",
              "1  I'm vegan but I really want to make something ...               vegan   \n",
              "2  I'm vegan but I really want to make something ...               vegan   \n",
              "3  Need a quick gluten-free breakfast. I hate egg...         gluten-free   \n",
              "4  I'm vegan but I really want to make something ...               vegan   \n",
              "\n",
              "                                            response  success  error trace_id  \\\n",
              "0  Certainly! For a vegan yogurt breakfast that m...     True    NaN      1_8   \n",
              "1  Absolutely! While honey is a popular sweetener...     True    NaN      1_9   \n",
              "2  Certainly! Since you're vegan and craving a yo...     True    NaN     1_10   \n",
              "3  Certainly! For a quick, gluten-free breakfast ...     True    NaN      2_7   \n",
              "4  Absolutely! For a vegan breakfast that mimics ...     True    NaN     1_27   \n",
              "\n",
              "   query_id  \n",
              "0         1  \n",
              "1         1  \n",
              "2         1  \n",
              "3         2  \n",
              "4         1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traces_path = Path(\"homeworks/hw3/data/raw_traces.csv\")\n",
        "\n",
        "traces_df = pd.read_csv(traces_path)\n",
        "\n",
        "traces_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sallyanndelucia/miniconda3/envs/recipe-bot-hw2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## let's create a test dataset \n",
        "datasets_client = ArizeDatasetsClient(api_key=os.environ[\"ARIZE_API_KEY\"])\n",
        "\n",
        "sample = traces_df.sample(n=100, random_state=42)\n",
        "\n",
        "# dataset_id = datasets_client.create_dataset(\n",
        "#     space_id=os.environ[\"ARIZE_SPACE_ID\"], \n",
        "#     dataset_name=\"RecipeBot\",\n",
        "#     data=sample,\n",
        "#     dataset_type=GENERATIVE\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative Option: Send in Traces\n",
        "Alternatively you can send in traces using `dietary_quereies.csv` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# from opentelemetry import trace\n",
        "\n",
        "\n",
        "# # Load dietary queries\n",
        "# queries_path = Path(\"homeworks/hw3/data/dietary_queries.csv\")\n",
        "# queries_df = pd.read_csv(queries_path)\n",
        "\n",
        "# # Example with a single query\n",
        "# single_query = queries_df['query'].iloc[1]  # Use a different example\n",
        "# dietary_restriction = queries_df['dietary_restriction'].iloc[1]\n",
        "\n",
        "# # Make the OpenAI call (which will be auto-instrumented)\n",
        "# single_response = client.chat.completions.create(\n",
        "#     model=\"gpt-4o-mini\",\n",
        "#     messages=[\n",
        "#         {\"role\": \"system\", \"content\": system_prompt},\n",
        "#         {\"role\": \"user\", \"content\": single_query}\n",
        "#     ],\n",
        "#     temperature=0.7\n",
        "# )\n",
        "\n",
        "# # Get the current span and add metadata to it\n",
        "# current_span = trace.get_current_span()\n",
        "# if current_span:\n",
        "#     current_span.set_attribute(\"dietary_restriction\", dietary_restriction)\n",
        "#     current_span.set_attribute(\"query_id\", int(queries_df['id'].iloc[1]))\n",
        "#     current_span.set_attribute(\"use_case\", \"alternative_approach\")\n",
        "\n",
        "# print(\"Query:\", single_query)\n",
        "# print(\"Dietary Restriction:\", dietary_restriction)\n",
        "# response_content = single_response.choices[0].message.content\n",
        "# if response_content:\n",
        "#     print(\"Response snippet:\", response_content[:200] + \"...\")\n",
        "# else:\n",
        "#     print(\"No response content available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Part 2: Prepare Data for Arize Labeling\n",
        "\n",
        "Take your traces and prepare them for manual labeling in Arize.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üìù Labeling Criteria - Dietary Adherence\n",
        "\n",
        "**CORRECT**: Recipe correctly follows all specified dietary restrictions  \n",
        "**INCORRECT**: Recipe violates any specified dietary restrictions\n",
        "\n",
        "**Examples:**\n",
        "- ‚úÖ CORRECT: 'vegan pasta' ‚Üí recipe with nutritional yeast (no dairy)\n",
        "- ‚ùå INCORRECT: 'vegan pasta' ‚Üí recipe suggests honey (not vegan)  \n",
        "- ‚úÖ CORRECT: 'gluten-free bread' ‚Üí recipe with almond flour\n",
        "- ‚ùå INCORRECT: 'gluten-free bread' ‚Üí recipe with regular flour\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Part 3: Create LLM as Judge Prompt\n",
        "\n",
        "üéØ **Complete these steps in Arize:**\n",
        "\n",
        "1. **üè∑Ô∏è Label Rows**: Review dataset and annotate rows.\n",
        "\n",
        "2. **‚öñÔ∏è Develop Judge Prompt**: Create evaluation prompt for dietary adherence\n",
        "\n",
        "3. **üß™ Test Evaluation**: Run judge prompt against ground truth labels in the playground\n",
        "\n",
        "4. **üöÄ Review Experiment**: Review evaluation experiment and iterate \n",
        "\n",
        "‚è≥ **Come back here after completing Arize work!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: Programmatic Evaluation with `llm_classify` and Experiments\n",
        "\n",
        "\n",
        "Instead of building and testing the eval in the Arize UI, you can use the [`llm_classify`](https://arize.com/docs/ax/evaluate/online-evals/log-evaluations-to-arize) function in code. \n",
        "\n",
        "You can also run a full evaluation experiment programmatically using the [Arize Experiments API](https://arize.com/docs/ax/develop/datasets-and-experiments/run-experiments), which lets you compare LLM judge results to ground truth and analyze performance‚Äîall in code.\n",
        "\n",
        "This approach is useful if you want to scale up, iterate quickly, or integrate evaluation into your ML pipeline.\n",
        "\n",
        "See the next code cell for an example of how to use `llm_classify`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from phoenix.evals import (\n",
        "#     llm_classify,\n",
        "# )\n",
        "\n",
        "# # The rails are used to hold the output to specific values based on the template\n",
        "# # It will remove text such as \",,,\" or \"...\"\n",
        "# # Will ensure the binary value expected from the template is returned\n",
        "# rails = [\"Correct\", \"Incorrect\"]\n",
        "# #MultiClass would be rails = [\"irrelevant\", \"relevant\", \"semi-relevant\"]\n",
        "# eval_df = llm_classify(\n",
        "#     dataframe=<YOUR_DATAFRAME_GOES_HERE>,\n",
        "#     template=CATEGORICAL_TEMPLATE,\n",
        "#     model=OpenAIModel('gpt-4o', api_key=''),\n",
        "#     rails=rails\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Part 4: Load Results & Calculate Metrics\n",
        "\n",
        "After running your evaluation experiment in Arize, we'll load the results and compute performance metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>dietary_restriction</th>\n",
              "      <th>response</th>\n",
              "      <th>success</th>\n",
              "      <th>error</th>\n",
              "      <th>trace_id</th>\n",
              "      <th>query_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>id</th>\n",
              "      <th>userannotation.VXNlcjoxMTE4NzpnUkY0.Correctness.label</th>\n",
              "      <th>userannotation.VXNlcjoxMTE4NzpnUkY0.Correctness.updated_by</th>\n",
              "      <th>userannotation.VXNlcjoxMTE4NzpnUkY0.Correctness.updated_at</th>\n",
              "      <th>latest.userannotation.Correctness.label</th>\n",
              "      <th>latest.userannotation.Correctness.updated_by</th>\n",
              "      <th>latest.userannotation.Correctness.updated_at</th>\n",
              "      <th>__index_level_0__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I eat pretty clean most of the time</td>\n",
              "      <td>whole30</td>\n",
              "      <td>Great! Since you enjoy eating clean, I recomme...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51_36</td>\n",
              "      <td>51</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>43897431-e017-4e28-b316-66c603e5c9b5</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754334e+12</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754334e+12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Low-carb dinner that doesn't require any cooki...</td>\n",
              "      <td>low-carb</td>\n",
              "      <td>Certainly! Here's a simple and delicious Low-C...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36_2</td>\n",
              "      <td>36</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>93a54576-6a78-41ee-add6-95f471b1c81f</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm pescatarian but shellfish makes me sick</td>\n",
              "      <td>pescatarian</td>\n",
              "      <td>Great! I recommend trying a **Lemon Garlic Bak...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55_15</td>\n",
              "      <td>55</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>7611f7d2-91d4-4891-a795-e5e8284ddc2c</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm dairy-free but pregnant and craving ice cr...</td>\n",
              "      <td>dairy-free</td>\n",
              "      <td>Certainly! Here's a delightful dairy-free, pre...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33_9</td>\n",
              "      <td>33</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>8088910c-5b1d-4b5c-9fbf-59ddd3feaeb6</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Low-carb dinner that doesn't require any cooki...</td>\n",
              "      <td>low-carb</td>\n",
              "      <td>Certainly! Here's a simple, low-carb, no-cook ...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36_12</td>\n",
              "      <td>36</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>1754271594950</td>\n",
              "      <td>0674dd25-8429-40ad-9939-a2222fee5c9a</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>Correct</td>\n",
              "      <td>SallyAnn DeLucia</td>\n",
              "      <td>1.754335e+12</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query dietary_restriction  \\\n",
              "0                I eat pretty clean most of the time             whole30   \n",
              "1  Low-carb dinner that doesn't require any cooki...            low-carb   \n",
              "2        I'm pescatarian but shellfish makes me sick         pescatarian   \n",
              "3  I'm dairy-free but pregnant and craving ice cr...          dairy-free   \n",
              "4  Low-carb dinner that doesn't require any cooki...            low-carb   \n",
              "\n",
              "                                            response success  error trace_id  \\\n",
              "0  Great! Since you enjoy eating clean, I recomme...    True    NaN    51_36   \n",
              "1  Certainly! Here's a simple and delicious Low-C...    True    NaN     36_2   \n",
              "2  Great! I recommend trying a **Lemon Garlic Bak...    True    NaN    55_15   \n",
              "3  Certainly! Here's a delightful dairy-free, pre...    True    NaN     33_9   \n",
              "4  Certainly! Here's a simple, low-carb, no-cook ...    True    NaN    36_12   \n",
              "\n",
              "   query_id     created_at     updated_at  \\\n",
              "0        51  1754271594950  1754271594950   \n",
              "1        36  1754271594950  1754271594950   \n",
              "2        55  1754271594950  1754271594950   \n",
              "3        33  1754271594950  1754271594950   \n",
              "4        36  1754271594950  1754271594950   \n",
              "\n",
              "                                     id  \\\n",
              "0  43897431-e017-4e28-b316-66c603e5c9b5   \n",
              "1  93a54576-6a78-41ee-add6-95f471b1c81f   \n",
              "2  7611f7d2-91d4-4891-a795-e5e8284ddc2c   \n",
              "3  8088910c-5b1d-4b5c-9fbf-59ddd3feaeb6   \n",
              "4  0674dd25-8429-40ad-9939-a2222fee5c9a   \n",
              "\n",
              "  userannotation.VXNlcjoxMTE4NzpnUkY0.Correctness.label  \\\n",
              "0                                            Correct      \n",
              "1                                            Correct      \n",
              "2                                            Correct      \n",
              "3                                            Correct      \n",
              "4                                            Correct      \n",
              "\n",
              "  userannotation.VXNlcjoxMTE4NzpnUkY0.Correctness.updated_by  \\\n",
              "0                                   SallyAnn DeLucia           \n",
              "1                                   SallyAnn DeLucia           \n",
              "2                                   SallyAnn DeLucia           \n",
              "3                                   SallyAnn DeLucia           \n",
              "4                                   SallyAnn DeLucia           \n",
              "\n",
              "   userannotation.VXNlcjoxMTE4NzpnUkY0.Correctness.updated_at  \\\n",
              "0                                       1.754334e+12            \n",
              "1                                       1.754335e+12            \n",
              "2                                       1.754335e+12            \n",
              "3                                       1.754335e+12            \n",
              "4                                       1.754335e+12            \n",
              "\n",
              "  latest.userannotation.Correctness.label  \\\n",
              "0                                 Correct   \n",
              "1                                 Correct   \n",
              "2                                 Correct   \n",
              "3                                 Correct   \n",
              "4                                 Correct   \n",
              "\n",
              "  latest.userannotation.Correctness.updated_by  \\\n",
              "0                             SallyAnn DeLucia   \n",
              "1                             SallyAnn DeLucia   \n",
              "2                             SallyAnn DeLucia   \n",
              "3                             SallyAnn DeLucia   \n",
              "4                             SallyAnn DeLucia   \n",
              "\n",
              "   latest.userannotation.Correctness.updated_at  __index_level_0__  \n",
              "0                                  1.754334e+12                  0  \n",
              "1                                  1.754335e+12                 98  \n",
              "2                                  1.754335e+12                 99  \n",
              "3                                  1.754335e+12                100  \n",
              "4                                  1.754335e+12                101  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_id = \"RGF0YXNldDozMDI0OTM6S3FsaA==\"\n",
        "dataset_data = datasets_client.get_dataset(os.environ[\"ARIZE_SPACE_ID\"], dataset_id=dataset_id)\n",
        "\n",
        "dataset_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "      <th>count</th>\n",
              "      <th>template</th>\n",
              "      <th>invocation_parameters</th>\n",
              "      <th>tool_choice</th>\n",
              "      <th>tool_options</th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_provider</th>\n",
              "      <th>eval.Label Match .label</th>\n",
              "      <th>eval.Label Match .score</th>\n",
              "      <th>eval.Label Match .explanation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"id\":\"chatcmpl-C1KTrLWpNUAKm8OY7pXRGDvae40zr\"...</td>\n",
              "      <td>43897431-e017-4e28-b316-66c603e5c9b5</td>\n",
              "      <td>EXP_ID_1877d7</td>\n",
              "      <td>1</td>\n",
              "      <td>[{\"role\":\"system\",\"content\":\"You are a dietary...</td>\n",
              "      <td>{}</td>\n",
              "      <td>\"required\"</td>\n",
              "      <td>[{\"type\":\"function\",\"function\":{\"name\":\"record...</td>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>openAI</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1. The Output contains a JSON object with a 'r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{\"id\":\"chatcmpl-C1KTr1Gns9nyibZc1r57dGMlXDMKP\"...</td>\n",
              "      <td>93a54576-6a78-41ee-add6-95f471b1c81f</td>\n",
              "      <td>EXP_ID_9a6a3d</td>\n",
              "      <td>1</td>\n",
              "      <td>[{\"role\":\"system\",\"content\":\"You are a dietary...</td>\n",
              "      <td>{}</td>\n",
              "      <td>\"required\"</td>\n",
              "      <td>[{\"type\":\"function\",\"function\":{\"name\":\"record...</td>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>openAI</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The Output contains two tool calls with differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{\"id\":\"chatcmpl-C1KTrQ6ulSr0mu4BaIt6qq8gep20b\"...</td>\n",
              "      <td>7611f7d2-91d4-4891-a795-e5e8284ddc2c</td>\n",
              "      <td>EXP_ID_ceeae5</td>\n",
              "      <td>1</td>\n",
              "      <td>[{\"role\":\"system\",\"content\":\"You are a dietary...</td>\n",
              "      <td>{}</td>\n",
              "      <td>\"required\"</td>\n",
              "      <td>[{\"type\":\"function\",\"function\":{\"name\":\"record...</td>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>openAI</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1. The Ground Truth label is 'Correct', indica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{\"id\":\"chatcmpl-C1KTrQV036WzL2gFH7rtBGEXRdx5Z\"...</td>\n",
              "      <td>8088910c-5b1d-4b5c-9fbf-59ddd3feaeb6</td>\n",
              "      <td>EXP_ID_777a98</td>\n",
              "      <td>1</td>\n",
              "      <td>[{\"role\":\"system\",\"content\":\"You are a dietary...</td>\n",
              "      <td>{}</td>\n",
              "      <td>\"required\"</td>\n",
              "      <td>[{\"type\":\"function\",\"function\":{\"name\":\"record...</td>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>openAI</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1. The Output from the LLM judge states that t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{\"id\":\"chatcmpl-C1KTrGRJrF3O3zN9KM5Ql6zz5EYCT\"...</td>\n",
              "      <td>0674dd25-8429-40ad-9939-a2222fee5c9a</td>\n",
              "      <td>EXP_ID_7553cd</td>\n",
              "      <td>1</td>\n",
              "      <td>[{\"role\":\"system\",\"content\":\"You are a dietary...</td>\n",
              "      <td>{}</td>\n",
              "      <td>\"required\"</td>\n",
              "      <td>[{\"type\":\"function\",\"function\":{\"name\":\"record...</td>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>openAI</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1. The Output provides an explanation that the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              output  \\\n",
              "0  {\"id\":\"chatcmpl-C1KTrLWpNUAKm8OY7pXRGDvae40zr\"...   \n",
              "1  {\"id\":\"chatcmpl-C1KTr1Gns9nyibZc1r57dGMlXDMKP\"...   \n",
              "2  {\"id\":\"chatcmpl-C1KTrQ6ulSr0mu4BaIt6qq8gep20b\"...   \n",
              "3  {\"id\":\"chatcmpl-C1KTrQV036WzL2gFH7rtBGEXRdx5Z\"...   \n",
              "4  {\"id\":\"chatcmpl-C1KTrGRJrF3O3zN9KM5Ql6zz5EYCT\"...   \n",
              "\n",
              "                             example_id             id  count  \\\n",
              "0  43897431-e017-4e28-b316-66c603e5c9b5  EXP_ID_1877d7      1   \n",
              "1  93a54576-6a78-41ee-add6-95f471b1c81f  EXP_ID_9a6a3d      1   \n",
              "2  7611f7d2-91d4-4891-a795-e5e8284ddc2c  EXP_ID_ceeae5      1   \n",
              "3  8088910c-5b1d-4b5c-9fbf-59ddd3feaeb6  EXP_ID_777a98      1   \n",
              "4  0674dd25-8429-40ad-9939-a2222fee5c9a  EXP_ID_7553cd      1   \n",
              "\n",
              "                                            template invocation_parameters  \\\n",
              "0  [{\"role\":\"system\",\"content\":\"You are a dietary...                    {}   \n",
              "1  [{\"role\":\"system\",\"content\":\"You are a dietary...                    {}   \n",
              "2  [{\"role\":\"system\",\"content\":\"You are a dietary...                    {}   \n",
              "3  [{\"role\":\"system\",\"content\":\"You are a dietary...                    {}   \n",
              "4  [{\"role\":\"system\",\"content\":\"You are a dietary...                    {}   \n",
              "\n",
              "  tool_choice                                       tool_options   model_name  \\\n",
              "0  \"required\"  [{\"type\":\"function\",\"function\":{\"name\":\"record...  gpt-4o-mini   \n",
              "1  \"required\"  [{\"type\":\"function\",\"function\":{\"name\":\"record...  gpt-4o-mini   \n",
              "2  \"required\"  [{\"type\":\"function\",\"function\":{\"name\":\"record...  gpt-4o-mini   \n",
              "3  \"required\"  [{\"type\":\"function\",\"function\":{\"name\":\"record...  gpt-4o-mini   \n",
              "4  \"required\"  [{\"type\":\"function\",\"function\":{\"name\":\"record...  gpt-4o-mini   \n",
              "\n",
              "  model_provider eval.Label Match .label  eval.Label Match .score  \\\n",
              "0         openAI                   match                      1.0   \n",
              "1         openAI                   match                      1.0   \n",
              "2         openAI                   match                      1.0   \n",
              "3         openAI                   match                      1.0   \n",
              "4         openAI                   match                      1.0   \n",
              "\n",
              "                       eval.Label Match .explanation  \n",
              "0  1. The Output contains a JSON object with a 'r...  \n",
              "1  The Output contains two tool calls with differ...  \n",
              "2  1. The Ground Truth label is 'Correct', indica...  \n",
              "3  1. The Output from the LLM judge states that t...  \n",
              "4  1. The Output provides an explanation that the...  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_id = \"RXhwZXJpbWVudDoyMjUyOToxNnpj\"\n",
        "# example usage\n",
        "experiments_data = datasets_client.get_experiment(os.environ[\"ARIZE_SPACE_ID\"], experiment_id=experiment_id)\n",
        "\n",
        "experiments_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Join experiments_data (aliased as e) and dataset_data (aliased as d) on e.example_id = d.id\n",
        "joined_df = experiments_data.merge(dataset_data, left_on='example_id', right_on='id', suffixes=('_e', '_d'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parsed_label</th>\n",
              "      <th>eval.Label Match .label</th>\n",
              "      <th>eval.Label Match .score</th>\n",
              "      <th>query</th>\n",
              "      <th>dietary_restriction</th>\n",
              "      <th>response</th>\n",
              "      <th>latest.userannotation.Correctness.label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>correct</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I eat pretty clean most of the time</td>\n",
              "      <td>whole30</td>\n",
              "      <td>Great! Since you enjoy eating clean, I recomme...</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>correct</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low-carb dinner that doesn't require any cooki...</td>\n",
              "      <td>low-carb</td>\n",
              "      <td>Certainly! Here's a simple and delicious Low-C...</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>correct</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I'm pescatarian but shellfish makes me sick</td>\n",
              "      <td>pescatarian</td>\n",
              "      <td>Great! I recommend trying a **Lemon Garlic Bak...</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>correct</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I'm dairy-free but pregnant and craving ice cr...</td>\n",
              "      <td>dairy-free</td>\n",
              "      <td>Certainly! Here's a delightful dairy-free, pre...</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correct</td>\n",
              "      <td>match</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low-carb dinner that doesn't require any cooki...</td>\n",
              "      <td>low-carb</td>\n",
              "      <td>Certainly! Here's a simple, low-carb, no-cook ...</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  parsed_label eval.Label Match .label  eval.Label Match .score  \\\n",
              "0      correct                   match                      1.0   \n",
              "1      correct                   match                      1.0   \n",
              "2      correct                   match                      1.0   \n",
              "3      correct                   match                      1.0   \n",
              "4      correct                   match                      1.0   \n",
              "\n",
              "                                               query dietary_restriction  \\\n",
              "0                I eat pretty clean most of the time             whole30   \n",
              "1  Low-carb dinner that doesn't require any cooki...            low-carb   \n",
              "2        I'm pescatarian but shellfish makes me sick         pescatarian   \n",
              "3  I'm dairy-free but pregnant and craving ice cr...          dairy-free   \n",
              "4  Low-carb dinner that doesn't require any cooki...            low-carb   \n",
              "\n",
              "                                            response  \\\n",
              "0  Great! Since you enjoy eating clean, I recomme...   \n",
              "1  Certainly! Here's a simple and delicious Low-C...   \n",
              "2  Great! I recommend trying a **Lemon Garlic Bak...   \n",
              "3  Certainly! Here's a delightful dairy-free, pre...   \n",
              "4  Certainly! Here's a simple, low-carb, no-cook ...   \n",
              "\n",
              "  latest.userannotation.Correctness.label  \n",
              "0                                 Correct  \n",
              "1                                 Correct  \n",
              "2                                 Correct  \n",
              "3                                 Correct  \n",
              "4                                 Correct  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def extract_label_from_output(output_str):\n",
        "    \"\"\"\n",
        "    Extract the 'response' field from the tool_calls in the output JSON.\n",
        "    Returns the first 'response' value found, or None if not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        output_json = json.loads(output_str)\n",
        "        # Traverse to choices[0].message.tool_calls\n",
        "        choices = output_json.get(\"choices\", [])\n",
        "        for choice in choices:\n",
        "            message = choice.get(\"message\", {})\n",
        "            tool_calls = message.get(\"tool_calls\", [])\n",
        "            for tool_call in tool_calls:\n",
        "                function = tool_call.get(\"function\", {})\n",
        "                arguments_str = function.get(\"arguments\", \"\")\n",
        "                # arguments is a JSON string, so parse it\n",
        "                try:\n",
        "                    arguments = json.loads(arguments_str)\n",
        "                    if \"response\" in arguments:\n",
        "                        return arguments[\"response\"]\n",
        "                except Exception:\n",
        "                    continue\n",
        "        return None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "joined_df['parsed_label'] = joined_df['output'].apply(extract_label_from_output)\n",
        "\n",
        "final_df = joined_df[['parsed_label', 'eval.Label Match .label','eval.Label Match .score','query','dietary_restriction','response','latest.userannotation.Correctness.label']]\n",
        "final_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Judge Performance Analysis\n",
        "\n",
        "Let's evaluate how well our LLM judge performed compared to human ground truth labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Judge Performance Metrics:\n",
            "   True Positive Rate (TPR): 0.931\n",
            "   True Negative Rate (TNR): 0.000\n",
            "   Accuracy: 0.900\n",
            "   Total number of valid label pairs: 30\n",
            "   True Positives: 27, True Negatives: 0\n",
            "   False Positives: 1, False Negatives: 2\n"
          ]
        }
      ],
      "source": [
        "# Calculate judge performance metrics using final_df\n",
        "\n",
        "def to_binary(label):\n",
        "    \"\"\"Convert text labels to binary (1 for correct/match, 0 for incorrect/mismatch)\"\"\"\n",
        "    if pd.isna(label):\n",
        "        return None\n",
        "    label_str = str(label).strip().lower()\n",
        "    # Handle both correctness labels and match/mismatch labels\n",
        "    if label_str in ['correct', 'match']:\n",
        "        return 1\n",
        "    elif label_str in ['incorrect', 'mismatch']:\n",
        "        return 0\n",
        "    return None\n",
        "\n",
        "# Extract ground truth from human annotations\n",
        "ground_truth_labels = final_df['latest.userannotation.Correctness.label']\n",
        "ground_truth = [to_binary(label) for label in ground_truth_labels]\n",
        "\n",
        "# Extract judge predictions from parsed_label (eval template output)\n",
        "judge_pred_labels = final_df['parsed_label']\n",
        "judge_preds = [to_binary(label) for label in judge_pred_labels]\n",
        "\n",
        "# Only keep valid pairs where both ground truth and predictions are available\n",
        "valid = [(gt, pred) for gt, pred in zip(ground_truth, judge_preds) if gt is not None and pred is not None]\n",
        "\n",
        "if valid:\n",
        "    gt, pred = zip(*valid)\n",
        "    tp = sum(1 for g, p in zip(gt, pred) if g == 1 and p == 1)\n",
        "    tn = sum(1 for g, p in zip(gt, pred) if g == 0 and p == 0)\n",
        "    fp = sum(1 for g, p in zip(gt, pred) if g == 0 and p == 1)\n",
        "    fn = sum(1 for g, p in zip(gt, pred) if g == 1 and p == 0)\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    accuracy = (tp + tn) / len(valid)\n",
        "    \n",
        "    print(\"üìä Judge Performance Metrics:\")\n",
        "    print(f\"   True Positive Rate (TPR): {tpr:.3f}\")\n",
        "    print(f\"   True Negative Rate (TNR): {tnr:.3f}\")\n",
        "    print(f\"   Accuracy: {accuracy:.3f}\")\n",
        "    print(f\"   Total number of valid label pairs: {len(valid)}\")\n",
        "    print(f\"   True Positives: {tp}, True Negatives: {tn}\")\n",
        "    print(f\"   False Positives: {fp}, False Negatives: {fn}\")\n",
        "    \n",
        "    metrics = {'tpr': tpr, 'tnr': tnr, 'accuracy': accuracy}\n",
        "else:\n",
        "    print(\"‚ùå No valid label pairs found in final_df\")\n",
        "    print(\"   Ground truth labels:\", ground_truth[:5])\n",
        "    print(\"   Judge predictions:\", judge_preds[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Evaluate Live Traces\n",
        "\n",
        "After testing and validating our evaluation template, we're ready to use it in a production setting.\n",
        "First, set up the online evaluation task in the platform using the template.\n",
        "Once that's done, you can send in traces, and the evaluation will run automatically on each trace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI()\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî≠ OpenTelemetry Tracing Details üî≠\n",
            "|  Arize Project: RecipeBot\n",
            "|  Span Processor: BatchSpanProcessor\n",
            "|  Collector Endpoint: otlp.arize.com\n",
            "|  Transport: gRPC\n",
            "|  Transport Headers: {'authorization': '****', 'api_key': '****', 'arize-space-id': '****', 'space_id': '****', 'arize-interface': '****'}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from arize.otel import register\n",
        "\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "\n",
        "# Set up tracing\n",
        "tracer_provider = register(\n",
        "    space_id=\"U3BhY2U6NzE5Mjp4V1Q1\",\n",
        "    project_name=\"RecipeBot\",  # name this to whatever you would like\n",
        ")\n",
        "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>dietary_restriction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm vegan but I really want to make something ...</td>\n",
              "      <td>vegan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Need a quick gluten-free breakfast. I hate egg...</td>\n",
              "      <td>gluten-free</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Keto breakfast that I can meal prep for the week</td>\n",
              "      <td>keto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>I'm dairy-free and also can't stand the taste ...</td>\n",
              "      <td>dairy-free</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Vegetarian pizza but I don't like mushrooms or...</td>\n",
              "      <td>vegetarian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              query dietary_restriction\n",
              "0   1  I'm vegan but I really want to make something ...               vegan\n",
              "1   2  Need a quick gluten-free breakfast. I hate egg...         gluten-free\n",
              "2   3   Keto breakfast that I can meal prep for the week                keto\n",
              "3   4  I'm dairy-free and also can't stand the taste ...          dairy-free\n",
              "4   5  Vegetarian pizza but I don't like mushrooms or...          vegetarian"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dietary queries\n",
        "queries_path = Path(\"homeworks/hw3/data/dietary_queries.csv\")\n",
        "queries_df = pd.read_csv(queries_path)\n",
        "\n",
        "queries_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a helpful, accurate, and creative recipe assistant. Your job is to generate easy-to-follow, reliable recipes and cooking advice tailored to the user query below.\n",
            "\n",
            "Core Responsibilities:\n",
            "- Always include an ingredient list with precise measurements in standard US or metric units.\n",
            "- Always include clear, numbered, step-by-step instructions that are logically ordered and easy to follow.\n",
            "- Always structure your response in Markdown.\n",
            "\n",
            "Ingredient Guidelines:\n",
            "- Never suggest rare, expensive, or difficult-to-obtain ingredients without clearly providing readily available substitutions.\n",
            "- Be specific with ingredients (e.g., ‚Äú1 cup unsweetened almond milk‚Äù instead of ‚Äúmilk‚Äù).\n",
            "\n",
            "Instructional Guidelines:\n",
            "- Do not skip steps or assume prior knowledge.\n",
            "- Use direct, instructional language.\n",
            "- Include preparation and cook time only if reliably known.\n",
            "\n",
            "Behavior & Ethics:\n",
            "- Never include unsafe, unethical, or harmful suggestions. Politely decline and explain briefly if a request cannot be fulfilled ‚Äî without being preachy or moralizing.\n",
            "- Never use offensive or derogatory language.\n",
            "- Use creative combinations when a direct recipe doesn‚Äôt exist, but clearly state when you're improvising.\n",
            "\n",
            "Style & Formatting:\n",
            "Structure all responses using the following Markdown format:\n",
            "\n",
            "Begin with:\n",
            "## Recipe Name\n",
            "\n",
            "A 1‚Äì3 sentence, enticing description of the dish and why or when it's great.\n",
            "\n",
            "### Ingredients\n",
            "* List all ingredients using bullet points, each with precise amounts and clear names.\n",
            "\n",
            "### Instructions\n",
            "1. Provide step-by-step instructions in logical cooking order.\n",
            "\n",
            "Optionally include, if relevant:\n",
            "### Notes\n",
            "Additional context or background information.\n",
            "\n",
            "### Tips\n",
            "Suggestions for technique, improvements, or best results.\n",
            "\n",
            "### Variations\n",
            "Common substitutions or flavor variations.\n",
            "\n",
            "User Query: {query}\n"
          ]
        }
      ],
      "source": [
        "from arize.experimental.prompt_hub import ArizePromptClient\n",
        "\n",
        "prompt_client = ArizePromptClient(space_id=\"U3BhY2U6MjI2MjA6ckZlZA==\", api_key=os.environ[\"ARIZE_API_KEY\"])\n",
        "\n",
        "prompt = prompt_client.pull_prompt(\n",
        "    prompt_name=\"RecipeBot System Prompt\"\n",
        ")\n",
        "\n",
        "system_prompt = prompt.messages[0]['content']\n",
        "\n",
        "print(system_prompt)\n",
        "\n",
        "#alternatively you can just assign the system prompt here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: Need a quick gluten-free breakfast. I hate eggs though.\n",
            "Dietary Restriction: gluten-free\n",
            "Response snippet: ## Quick Gluten-Free Banana Oatmeal Pancakes\n",
            "\n",
            "These fluffy banana oatmeal pancakes are a quick and delicious gluten-free breakfast option that doesn‚Äôt require eggs. They‚Äôre perfect for busy mornings a...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from opentelemetry import trace\n",
        "\n",
        "# Example with a single query\n",
        "single_query = queries_df['query'].iloc[1]  # Use a different example\n",
        "dietary_restriction = queries_df['dietary_restriction'].iloc[1]\n",
        "\n",
        "# Make the OpenAI call (which will be auto-instrumented)\n",
        "single_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": single_query}\n",
        "    ],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Get the current span and add metadata to it\n",
        "current_span = trace.get_current_span()\n",
        "if current_span:\n",
        "    current_span.set_attribute(\"dietary_restriction\", dietary_restriction)\n",
        "    current_span.set_attribute(\"query_id\", int(queries_df['id'].iloc[1]))\n",
        "    current_span.set_attribute(\"use_case\", \"alternative_approach\")\n",
        "\n",
        "print(\"Query:\", single_query)\n",
        "print(\"Dietary Restriction:\", dietary_restriction)\n",
        "response_content = single_response.choices[0].message.content\n",
        "if response_content:\n",
        "    print(\"Response snippet:\", response_content[:200] + \"...\")\n",
        "else:\n",
        "    print(\"No response content available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Processed 20/60 queries (batch 1)\n",
            "‚úÖ Processed 40/60 queries (batch 2)\n",
            "‚úÖ Processed 60/60 queries (batch 3)\n",
            "\n",
            "üöÄ Successfully processed 60 queries with custom metadata!\n",
            "üìä Average time per query: ~0.8 seconds (estimated)\n",
            "\n",
            "üìù Sample result:\n",
            "Query: I'm vegan but I really want to make something with honey - is there a good substitute? i am craving ...\n",
            "Dietary Restriction: vegan\n",
            "Response: ## Vegan Yogurt Breakfast Bowl with Agave Nectar\n",
            "\n",
            "If you're looking for a sweet and satisfying vegan breakfast, this yogurt bowl topped with fresh fru...\n"
          ]
        }
      ],
      "source": [
        "# Run on a sample of 500 queries with custom metadata - FAST async approach for Jupyter\n",
        "import asyncio\n",
        "from opentelemetry import trace\n",
        "\n",
        "# Create async OpenAI client\n",
        "async_client = openai.AsyncOpenAI()\n",
        "\n",
        "async def get_response_with_metadata(i, query, dietary_restriction, query_id):\n",
        "    \"\"\"Process a single query with custom metadata\"\"\"\n",
        "    # The OpenAI call will be auto-instrumented\n",
        "    response = await async_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    \n",
        "    # Get the current auto-instrumented span and add metadata to it\n",
        "    current_span = trace.get_current_span()\n",
        "    if current_span:\n",
        "        current_span.set_attribute(\"dietary_restriction\", dietary_restriction)\n",
        "        current_span.set_attribute(\"query_id\", query_id)\n",
        "        current_span.set_attribute(\"use_case\", \"batch_processing\")\n",
        "        current_span.set_attribute(\"batch_index\", i)\n",
        "    \n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"dietary_restriction\": dietary_restriction,\n",
        "        \"query_id\": query_id,\n",
        "        \"response\": response.choices[0].message.content\n",
        "    }\n",
        "\n",
        "# Process all queries with batching to avoid rate limits\n",
        "responses = []\n",
        "batch_size = 20  # Process 20 at a time to avoid rate limits\n",
        "\n",
        "for batch_start in range(0, len(queries_df), batch_size):\n",
        "    batch_end = min(batch_start + batch_size, len(queries_df))\n",
        "    batch_tasks = []\n",
        "    \n",
        "    # Create tasks for this batch\n",
        "    for i in range(batch_start, batch_end):\n",
        "        query = str(queries_df.iloc[i]['query'])\n",
        "        dietary_restriction = str(queries_df.iloc[i]['dietary_restriction'])\n",
        "        query_id = int(queries_df.iloc[i]['id'])\n",
        "        \n",
        "        task = get_response_with_metadata(i, query, dietary_restriction, query_id)\n",
        "        batch_tasks.append(task)\n",
        "    \n",
        "    # Process this batch concurrently\n",
        "    batch_responses = await asyncio.gather(*batch_tasks)\n",
        "    responses.extend(batch_responses)\n",
        "    \n",
        "    print(f\"‚úÖ Processed {len(responses)}/{queries_df.shape[0]} queries (batch {len(responses)//batch_size})\")\n",
        "\n",
        "print(f\"\\nüöÄ Successfully processed {len(responses)} queries with custom metadata!\")\n",
        "print(f\"üìä Average time per query: ~{50/len(responses):.1f} seconds (estimated)\")\n",
        "\n",
        "# Show a sample of the results\n",
        "if responses:\n",
        "    print(f\"\\nüìù Sample result:\")\n",
        "    sample_response = responses[0]\n",
        "    print(f\"Query: {sample_response['query'][:100]}...\")\n",
        "    print(f\"Dietary Restriction: {sample_response['dietary_restriction']}\")\n",
        "    print(f\"Response: {sample_response['response'][:150]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monitor Live Evaluation Results\n",
        "\n",
        "Navigate to the Arize UI and check the traces. You should see your online evaluation task automatically processing the new traces. Look for the evaluation scores and any patterns in the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Part 6: Statistical Analysis with Bias Correction üìä\n",
        "\n",
        "Now we'll apply statistical bias correction to get a reliable estimate of the Recipe Bot's true dietary adherence performance. This implements the same methodology as the 'judgy' library but using our Arize workflow.\n",
        "\n",
        "\n",
        "\n",
        "**What we're doing:**\n",
        "1. **Export live traces** from Arize that have been automatically evaluated by our judge\n",
        "2. **Use judge performance** (TPR/TNR) calculated from our labeled dataset above\n",
        "3. **Apply bias correction** to get a more accurate estimate of true performance\n",
        "4. **Calculate confidence intervals** to understand the reliability of our estimates\n",
        "\n",
        "This approach lets us evaluate real production performance using statistical methods to account for judge bias.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;21m  arize.utils.logging | INFO | Creating named session as 'python-sdk-arize_python_export_client-add6be4b-dc15-4f62-bdaf-4c2e11ab0955'.\u001b[0m\n",
            "\u001b[38;21m  arize.utils.logging | INFO | Fetching data...\u001b[0m\n",
            "\u001b[38;21m  arize.utils.logging | INFO | Starting exporting...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  exporting 151 rows: 100%|\u001b[38;2;0;128;0m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m| 151/151 [00:00, 295.58 row/s]\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['attributes.llm.cost.completion_details.reasoning',\n",
              "       'attributes.llm.token_count.completion',\n",
              "       'attributes.llm.token_count.prompt_details.audio',\n",
              "       'attributes.reranker.model_name', 'attributes.exception.message',\n",
              "       'eval.Dietary Restriction Adherence.score',\n",
              "       'attributes.llm.prompt_template.variables',\n",
              "       'attributes.llm.token_count.completion_details.reasoning',\n",
              "       'attributes.input.mime_type',\n",
              "       'attributes.llm.token_count.completion_details.output',\n",
              "       'eval.Dietary Restriction Adherence.label', 'attributes.llm.cost.total',\n",
              "       'attributes.llm.input_messages', 'end_time', 'name', 'context.trace_id',\n",
              "       'attributes.llm.provider',\n",
              "       'attributes.llm.token_count.completion_details.audio', 'time',\n",
              "       'attributes.exception.type', 'attributes.llm.prompt_template.template',\n",
              "       'attributes.llm.cost.prompt', 'attributes.llm.output_messages',\n",
              "       'latency_ms', 'attributes.llm.cost.completion',\n",
              "       'attributes.llm.token_count.prompt', 'attributes.tool.name',\n",
              "       'status_code', 'attributes.llm.invocation_parameters',\n",
              "       'attributes.output.mime_type',\n",
              "       'attributes.llm.cost.completion_details.audio', 'context.span_id',\n",
              "       'attributes.output.value',\n",
              "       'attributes.llm.token_count.prompt_details.cache_read',\n",
              "       'attributes.llm.model_name', 'attributes.reranker.query',\n",
              "       'attributes.llm.cost.prompt_details.cache_read',\n",
              "       'attributes.llm.system', 'attributes.embedding.model_name',\n",
              "       'start_time', 'attributes.openinference.span.kind',\n",
              "       'attributes.input.value', 'attributes.exception.stacktrace',\n",
              "       'status_message', 'attributes.llm.token_count.prompt_details.input',\n",
              "       'eval.Dietary Restriction Adherence.explanation',\n",
              "       'attributes.llm.token_count.total', 'attributes.tool.description',\n",
              "       'attributes.llm.cost.prompt_details.audio',\n",
              "       'attributes.llm.cost.completion_details.output',\n",
              "       'attributes.llm.cost.prompt_details.input',\n",
              "       'attributes.llm.prompt_template.version'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "export_client = ArizeExportClient(api_key=os.environ[\"ARIZE_API_KEY\"])\n",
        "\n",
        "# Set end_time to now and start_time to 24 hours ago\n",
        "end_time = datetime.now()\n",
        "start_time = end_time - timedelta(days=1)\n",
        "\n",
        "new_traces_df = export_client.export_model_to_df(\n",
        "    space_id=\"U3BhY2U6NzE5Mjp4V1Q1\",\n",
        "    # api_key=os.environ[\"ARIZE_API_KEY\"],\n",
        "    model_id='RecipeBot',\n",
        "    environment=Environments.TRACING,\n",
        "    start_time=start_time,\n",
        "    end_time=end_time,\n",
        "    # Optionally specify columns to improve query performance\n",
        "    # columns=['context.span_id', 'attributes.llm.input']\n",
        ")\n",
        "\n",
        "new_traces_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Available columns in new_traces_df:\n",
            "['eval.Dietary Restriction Adherence.score', 'eval.Dietary Restriction Adherence.label', 'eval.Dietary Restriction Adherence.explanation']\n",
            "\n",
            "Total traces: 151\n",
            "‚úÖ Using evaluation column: eval.Dietary Restriction Adherence.score\n",
            "\n",
            "üìà Judge Performance (from labeled data):\n",
            "   TPR (True Positive Rate): 0.931\n",
            "   TNR (True Negative Rate): 0.000\n",
            "\n",
            "üìä Live Traces Analysis:\n",
            "   Number of evaluated traces: 151\n",
            "   Raw pass rate (p_obs): 0.993\n",
            "\n",
            "üîß Applying Bias Correction:\n",
            "   Denominator (TPR + TNR - 1) = -0.069\n",
            "   Bias-corrected true success rate (Œ∏ÃÇ): 0.096\n",
            "   95% Confidence Interval: [0.000, 0.284]\n",
            "\n",
            "üéØ Final Interpretation:\n",
            "   Recipe Bot may be struggling to consistently adhere to dietary preferences.\n",
            "   Estimated true dietary adherence rate: 9.6%\n",
            "   95% Confidence Interval: 0.0% to 28.4%\n"
          ]
        }
      ],
      "source": [
        "# First, let's check what evaluation columns are available in new_traces_df\n",
        "print(\"üìä Available columns in new_traces_df:\")\n",
        "eval_columns = [col for col in new_traces_df.columns if 'eval' in col.lower()]\n",
        "print(eval_columns)\n",
        "print(f\"\\nTotal traces: {len(new_traces_df)}\")\n",
        "\n",
        "if not eval_columns:\n",
        "    print(\"‚ùå No evaluation columns found in new_traces_df. Make sure your online evaluation is running.\")\n",
        "    print(\"Available columns:\", list(new_traces_df.columns[:10]), \"...\")\n",
        "else:\n",
        "    # Find the evaluation score column\n",
        "    eval_score_col = None\n",
        "    for col in eval_columns:\n",
        "        if 'score' in col.lower():\n",
        "            eval_score_col = col\n",
        "            break\n",
        "    \n",
        "    if eval_score_col:\n",
        "        print(f\"‚úÖ Using evaluation column: {eval_score_col}\")\n",
        "        \n",
        "        # Get judge performance metrics from labeled data\n",
        "        TPR = metrics[\"tpr\"]  # True Positive Rate (sensitivity)\n",
        "        TNR = metrics[\"tnr\"]  # True Negative Rate (specificity)\n",
        "        \n",
        "        print(f\"\\nüìà Judge Performance (from labeled data):\")\n",
        "        print(f\"   TPR (True Positive Rate): {TPR:.3f}\")\n",
        "        print(f\"   TNR (True Negative Rate): {TNR:.3f}\")\n",
        "        \n",
        "        # Get judge predictions on live traces\n",
        "        live_scores = new_traces_df[eval_score_col].dropna()\n",
        "        if len(live_scores) == 0:\n",
        "            print(\"‚ùå No evaluation scores found in live traces\")\n",
        "        else:\n",
        "            # Calculate observed pass rate from live traces\n",
        "            p_obs = live_scores.mean()\n",
        "            n = len(live_scores)\n",
        "            \n",
        "            print(f\"\\nüìä Live Traces Analysis:\")\n",
        "            print(f\"   Number of evaluated traces: {n}\")\n",
        "            print(f\"   Raw pass rate (p_obs): {p_obs:.3f}\")\n",
        "            \n",
        "            # Check if we can apply bias correction\n",
        "            denom = TPR + TNR - 1\n",
        "            \n",
        "            if abs(denom) < 0.001:  # Close to zero\n",
        "                print(f\"\\n‚ö†Ô∏è  Warning: Cannot apply bias correction\")\n",
        "                print(f\"   Denominator (TPR + TNR - 1) = {denom:.3f} ‚âà 0\")\n",
        "                print(f\"   This happens when the judge performance is poor or unbalanced\")\n",
        "                print(f\"   Using raw pass rate as estimate: {p_obs:.3f}\")\n",
        "                theta_hat = p_obs\n",
        "                \n",
        "                # Simple confidence interval for proportion\n",
        "                se_p = np.sqrt(p_obs * (1 - p_obs) / n)\n",
        "                z = 1.96\n",
        "                ci_lower = max(0, p_obs - z * se_p)\n",
        "                ci_upper = min(1, p_obs + z * se_p)\n",
        "                \n",
        "                print(f\"   95% CI (no bias correction): [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"\\nüîß Applying Bias Correction:\")\n",
        "                print(f\"   Denominator (TPR + TNR - 1) = {denom:.3f}\")\n",
        "                \n",
        "                # Apply bias correction formula\n",
        "                theta_hat = (p_obs + TNR - 1) / denom\n",
        "                \n",
        "                # Calculate confidence interval using delta method\n",
        "                se_p_obs = np.sqrt(p_obs * (1 - p_obs) / n)\n",
        "                se_theta = se_p_obs / abs(denom)\n",
        "                z = 1.96\n",
        "                ci_lower = max(0, theta_hat - z * se_theta)\n",
        "                ci_upper = min(1, theta_hat + z * se_theta)\n",
        "                \n",
        "                print(f\"   Bias-corrected true success rate (Œ∏ÃÇ): {theta_hat:.3f}\")\n",
        "                print(f\"   95% Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
        "            \n",
        "            # Interpretation\n",
        "            if theta_hat > 0.9:\n",
        "                summary = \"Recipe Bot is performing very well in adhering to dietary preferences.\"\n",
        "            elif theta_hat > 0.75:\n",
        "                summary = \"Recipe Bot is generally adhering to dietary preferences, but there may be some room for improvement.\"\n",
        "            elif theta_hat > 0.5:\n",
        "                summary = \"Recipe Bot shows moderate adherence to dietary preferences with room for improvement.\"\n",
        "            else:\n",
        "                summary = \"Recipe Bot may be struggling to consistently adhere to dietary preferences.\"\n",
        "            \n",
        "            print(f\"\\nüéØ Final Interpretation:\")\n",
        "            print(f\"   {summary}\")\n",
        "            print(f\"   Estimated true dietary adherence rate: {theta_hat:.1%}\")\n",
        "            print(f\"   95% Confidence Interval: {ci_lower:.1%} to {ci_upper:.1%}\")\n",
        "            \n",
        "            if abs(denom) < 0.001:\n",
        "                print(f\"\\nüí° Note: No bias correction applied due to poor judge discriminability.\")\n",
        "                print(f\"   Consider improving the judge prompt or getting more diverse labeled data.\")\n",
        "    else:\n",
        "        print(\"‚ùå No evaluation score column found. Available eval columns:\", eval_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Assignment Complete!\n",
        "\n",
        "**What you accomplished:**\n",
        "- ‚úÖ Prepared trace data for evaluation testing\n",
        "- ‚úÖ Used Arize UI for manual labeling to establish ground truth\n",
        "- ‚úÖ Developed and tested LLM judge against human feedback\n",
        "- ‚úÖ Aligned judge performance with human annotations (TPR, TNR)\n",
        "- ‚úÖ Applied judge to evaluate \"production\" traces at scale\n",
        "- ‚úÖ Applied statistical bias correction to account for judge imperfections\n",
        "- ‚úÖ Generated comprehensive evaluation report with confidence intervals\n",
        "\n",
        "**Key insight:** By aligning the LLM judge with human feedback through the Arize UI testing workflow, we can now evaluate dietary adherence at scale while accounting for judge bias through statistical correction.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "recipe-bot-hw2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
