{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmwwTi0KUa1F"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "# <center>Getting Started with Llamatrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4-cym_JUfow"
   },
   "source": [
    "This guide demonstrates how to use Llamatrace, a collaboration between Arize and LlamaIndex to deliver hosted observability and evals with native support for LlamaIndex.\n",
    "\n",
    "ℹ️ This notebook requires an OpenAI API key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEFoI3zIUwt1"
   },
   "source": [
    "## Step 1: Install Dependencies 📚\n",
    "Let's get the notebook setup with dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "rUObjr_Eww9x"
   },
   "outputs": [],
   "source": [
    "%pip install arize-phoenix arize-phoenix-evals openai openinference-instrumentation-openai opentelemetry-sdk opentelemetry-exporter-otlp\n",
    "%pip install \"arize-phoenix[evals,llama-index]\" \"openai>=1\" gcsfs nest-asyncio \"openinference-instrumentation-llama-index>=2.0.0\"\n",
    "%pip install -U llama-index-callbacks-arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cg7wFg21JyyX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QklZGzIFJz4R"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (PHOENIX_API_KEY := os.getenv(\"PHOENIX_API_KEY\")):\n",
    "    PHOENIX_API_KEY = getpass(\"🔑 Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_API_KEY\"] = PHOENIX_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGTKOk-oU18k"
   },
   "source": [
    "## Step 2: Setup Tracing\n",
    "Let's send a trace to Hosted Phoenix! Notce the key lines below using `OTEL_EXPORTER_OTLP_HEADERS` and `app.phoenix.arize.com/v1/traces`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp9XJiJtO_Ji"
   },
   "outputs": [],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import os\n",
    "\n",
    "import llama_index.core\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://app.phoenix.arize.com/v1/traces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COGJEi8HoOaB"
   },
   "source": [
    "Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgF_PNZtTm1R"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from getpass import getpass\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from gcsfs import GCSFileSystem\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "nest_asyncio.apply()  # needed for concurrent evals in notebook environments\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxNUMLgwIRIm"
   },
   "source": [
    "Run LlamaIndex Query on Arize Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGL73FxeIOXZ"
   },
   "outputs": [],
   "source": [
    "file_system = GCSFileSystem(project=\"public-assets-275721\")\n",
    "index_path = \"arize-phoenix-assets/datasets/unstructured/llm/llama-index/arize-docs/index/\"\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    fs=file_system,\n",
    "    persist_dir=index_path,\n",
    ")\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "index = load_index_from_storage(\n",
    "    storage_context,\n",
    ")\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "queries_url = \"http://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/context-retrieval/arize_docs_queries.jsonl\"\n",
    "queries = []\n",
    "with urlopen(queries_url) as response:\n",
    "    for line in response:\n",
    "        line = line.decode(\"utf-8\").strip()\n",
    "        data = json.loads(line)\n",
    "        queries.append(data[\"query\"])\n",
    "queries[:5]\n",
    "\n",
    "for query in tqdm(queries[:5]):\n",
    "    query_engine.query(query)\n",
    "\n",
    "response = query_engine.query(\"What is Arize and how can it help me as an AI Engineer?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9dDee9_9ywx"
   },
   "source": [
    "## Step 3: Use the Phoenix SDK\n",
    "Set the `PHOENIX_CLIENT_HEADERS` and the `PHOENIX_COLLECTOR_ENDPOINT` to the appropriate values to start using hosted Phoenix!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD6-S9BY91Dp"
   },
   "outputs": [],
   "source": [
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n",
    "\n",
    "\n",
    "px_client = px.Client()\n",
    "phoenix_df = px_client.get_spans_dataframe()\n",
    "print(phoenix_df.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "llamatrace.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}