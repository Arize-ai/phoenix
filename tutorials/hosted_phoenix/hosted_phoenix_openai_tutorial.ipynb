{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmwwTi0KUa1F"
   },
   "source": [
    "<center> <img src=\"https://storage.cloud.google.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"300\"/> </center>\n",
    "\n",
    "# <center>Getting Started with Hosted Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4-cym_JUfow"
   },
   "source": [
    "This guide demonstrates how to use hosted phoenix, our solution for AI developers to trace and evaluate their LLM applications without setting up infrastructure. Read more about Phoenix [here](https://docs.arize.com/phoenix/).\n",
    "\n",
    "‚ÑπÔ∏è This notebook requires an OpenAI API key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEFoI3zIUwt1"
   },
   "source": [
    "## Step 1: Install Dependencies üìö\n",
    "Let's get the notebook setup with dependencies. It does NOT require installing arize-phoenix to log traces, as we are compliant with OpenTelemetry tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-otel openinference-instrumentation-openai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (PHOENIX_API_KEY := os.getenv(\"PHOENIX_API_KEY\")):\n",
    "    PHOENIX_API_KEY = getpass(\"üîë Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_API_KEY\"] = PHOENIX_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGTKOk-oU18k"
   },
   "source": [
    "## Step 2: Setup Tracing\n",
    "Let's send a trace to Hosted Phoenix! Notce the key lines below using `OTEL_EXPORTER_OTLP_HEADERS` and `app.phoenix.arize.com/v1/traces`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize_otel import Endpoints, register_otel\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "# Setup OTEL tracing for hosted Phoenix\n",
    "register_otel(endpoints=[Endpoints.HOSTED_PHOENIX], api_key=PHOENIX_API_KEY)\n",
    "\n",
    "# Turn on instrumentation for OpenAI\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COGJEi8HoOaB"
   },
   "source": [
    "Send query to Hosted Phoenix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_client = openai.OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a haiku.\"}],\n",
    "    max_tokens=20,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9dDee9_9ywx"
   },
   "source": [
    "## Step 3: Use the Phoenix SDK\n",
    "First, install the right python packages to setup phoenix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"arize-phoenix[evals]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EhmOQJpyHEq"
   },
   "source": [
    "Set the `PHOENIX_CLIENT_HEADERS` and the `PHOENIX_COLLECTOR_ENDPOINT` to the appropriate values to start using hosted Phoenix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com/\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "# Initiate Phoenix client\n",
    "px_client = px.Client()\n",
    "\n",
    "# Get spans from the last 7 days only\n",
    "start = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Get spans to exclude the last 24 hours\n",
    "end = datetime.now() - timedelta(days=0)\n",
    "\n",
    "phoenix_df = px_client.query_spans(start_time=start, end_time=end)\n",
    "print(phoenix_df.head())\n",
    "px_client.get_spans_dataframe(project_name=\"rechat\", root_spans_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBcnGURRDIE5"
   },
   "source": [
    "Use our latest and greatest features around datasets on the latest Phoenix version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"question\": \"What is Paul Graham known for?\",\n",
    "            \"answer\": \"Co-founding Y Combinator and writing on startups and techology.\",\n",
    "            \"metadata\": {\"topic\": \"tech\"},\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "phoenix_client = px.Client()\n",
    "dataset = phoenix_client.upload_dataset(\n",
    "    dataframe=df,\n",
    "    dataset_name=\"test-dataset-2\",\n",
    "    input_keys=[\"question\"],\n",
    "    output_keys=[\"answer\"],\n",
    "    metadata_keys=[\"metadata\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
