{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- SPDX-License-Identifier: CC-BY-NC-SA-4.0 -->\n",
    "\n",
    "*This notebook is ¬© [Braintrust Cookbook](https://www.braintrust.dev/docs/cookbook/recipes/Text2SQL-Data) and licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/9e6101d95936f4bd4d390efc9ce646dc6937fb2d/images/socal/github-large-banner-phoenix.jpg\" width=\"1000\"/>\n",
    "        <br>\n",
    "        <br>\n",
    "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Evals that Work</h1>\n",
    "\n",
    "Building great AI native products requires a rigorous evaluation process. While the idea of evaluation-driven development may seem novel to some, it really is the scientific method in disguise.  Just as scientists meticulously record experiments and take detailed notes to advance their understanding, AI systems require rigorous observation through tracing, annotations, and experimentation to reach their full potential. The goal of AI-native products is to build tools that empower humans, and it requires careful human judgment to align AI with human preferences and values.\n",
    "\n",
    "This notebook is inspired by [Eugene Yan's \"A Process for LLM Evaluation\"](https://eugeneyan.com/writing/eval-process/) and ¬© [Braintrust Cookbook](https://www.braintrust.dev/docs/cookbook/recipes/Text2SQL-Data), licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).\n",
    "\n",
    " <p style=\"text-align:center\">\n",
    "  <img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/scientific_method.png\" width=\"60%\" style=\"float: left\">\n",
    "  <img alt=\"AI dev as scientific method\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/gifs/20250524_1125_Forest%20Robots%20Interaction_simple_compose_01jw1n770bep1a829kw3cvvcsc.gif\" width=\"40%\" style=\"float: right\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"arize-phoenix>=10.0.0\" openai 'httpx<0.28' duckdb datasets pyarrow \"pydantic>=2.0.0\" nest_asyncio openinference-instrumentation-openai --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes you have a locally running Phoenix server. We can think of phoenix like a video recorder, observing every activity of your AI application.\n",
    "\n",
    "```shell\n",
    "phoenix serve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also setup tracing for OpenAI as we will be using their API to perform the synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: movie-app\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "    project_name=\"movie-app\",\n",
    "    auto_instrument=True,  # Start recording traces via OpenAIInstrumentor\n",
    ")\n",
    "\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we can run async code in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's make sure we have our openai API key set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"üîë Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "We are going to use a movie dataset that contains recent titles and their ratings. We will use DuckDB as our database so that we can run the queries directly in the notebook, but you can imagine that this could be a pre-existing SQL database with business-specific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x319c79130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"wykonos/movies\")[\"train\"]\n",
    "\n",
    "conn = duckdb.connect(database=\":memory:\", read_only=False)\n",
    "conn.register(\"movies\", data.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 385687, 'title': 'Fast X', 'genres': 'Action-Crime-Thriller', 'original_language': 'en', 'overview': \"Over many missions and against impossible odds Dom Toretto and his family have outsmarted out-nerved and outdriven every foe in their path. Now they confront the most lethal opponent they've ever faced: A terrifying threat emerging from the shadows of the past who's fueled by blood revenge and who is determined to shatter this family and destroy everything‚Äîand everyone‚Äîthat Dom loves forever.\", 'popularity': 6682.1, 'production_companies': 'Universal Pictures-Original Film-One Race-Perfect Storm Entertainment', 'release_date': '2023-05-17', 'budget': 340000000.0, 'revenue': 686700000.0, 'runtime': 142.0, 'status': 'Released', 'tagline': 'The end of the road begins.', 'vote_average': 7.331, 'vote_count': 1856.0, 'credits': 'Vin Diesel-Michelle Rodriguez-Tyrese Gibson-Ludacris-John Cena-Nathalie Emmanuel-Jordana Brewster-Sung Kang-Jason Momoa-Scott Eastwood-Daniela Melchior-Alan Ritchson-Helen Mirren-Brie Larson-Jason Statham-Charlize Theron-Rita Moreno-Joaquim de Almeida-Leo A. Perry-Luis Da Silva Jr.-Jaz Hutchins-Luka Hays-Alexander Capon-Pete Davidson-Shadrach Agozino-Ludmilla-Miraj Grbiƒá-Meadow Walker Thornton-Allan-Michael Irby-Shahir Figueira-Ben-Hur Santos-Debby Ann Ryan-Josh Dun-Robert Bastens-Dwayne Johnson-Gal Gadot', 'keywords': 'sequel-revenge-racing-family-cars', 'poster_path': '/fiVW06jE7z9YnO4trhaMEdclSiC.jpg', 'backdrop_path': '/4XM8DUTQb3lhLemJC51Jx4a2EuA.jpg', 'recommendations': '19603-445954-697843-603692-781009-502356-747355-640146-569094-1070777-536437-121342-325358-667538-960033-496450-447365-1037644-298618-713704-1121116'}\n",
      "{'id': 758323, 'title': \"The Pope's Exorcist\", 'genres': 'Horror-Mystery-Thriller', 'original_language': 'en', 'overview': \"Father Gabriele Amorth Chief Exorcist of the Vatican investigates a young boy's terrifying possession and ends up uncovering a centuries-old conspiracy the Vatican has desperately tried to keep hidden.\", 'popularity': 5953.227, 'production_companies': 'Screen Gems-2.0 Entertainment-Jesus & Mary-Worldwide Katz-Loyola Productions-FFILME.RO', 'release_date': '2023-04-05', 'budget': 18000000.0, 'revenue': 65675816.0, 'runtime': 103.0, 'status': 'Released', 'tagline': 'Inspired by the actual files of Father Gabriele Amorth, Chief Exorcist of the Vatican.', 'vote_average': 7.433, 'vote_count': 545.0, 'credits': \"Russell Crowe-Daniel Zovatto-Alex Essoe-Franco Nero-Peter DeSouza-Feighoney-Laurel Marsden-Cornell John-Ryan O'Grady-Bianca Bardoe-Santi Bay√≥n-Paloma Bloyd-Alessandro Gruttadauria-River Hawkins-Jordi Collet-Carrie Munro-Marc Velasco-Edward Harper-Jones-Matthew Sim-Victor Sol√©-Tom Bonington-Andrea Dugoni-Ed White-Laila Barwick-Gennaro Diana-Pablo Raybould-Ralph Ineson-Derek Carroll-Ella Cannon\", 'keywords': 'spain-rome italy-vatican-pope-pig-possession-conspiracy-devil-exorcist-skepticism-catholic priest-1980s-supernatural horror', 'poster_path': '/9JBEPLTPSm0d1mbEcLxULjJq9Eh.jpg', 'backdrop_path': '/hiHGRbyTcbZoLsYYkO4QiCLYe34.jpg', 'recommendations': '713704-296271-502356-1076605-1084225-1008005-916224-1023313-1033219-980078-842945-943822-816904-804150-638974-649609-603692-849869-809787-776835-1104040'}\n",
      "{'id': 640146, 'title': 'Ant-Man and the Wasp: Quantumania', 'genres': 'Action-Adventure-Science Fiction', 'original_language': 'en', 'overview': \"Super-Hero partners Scott Lang and Hope van Dyne along with with Hope's parents Janet van Dyne and Hank Pym and Scott's daughter Cassie Lang find themselves exploring the Quantum Realm interacting with strange new creatures and embarking on an adventure that will push them beyond the limits of what they thought possible.\", 'popularity': 4425.387, 'production_companies': 'Marvel Studios-Kevin Feige Productions', 'release_date': '2023-02-15', 'budget': 200000000.0, 'revenue': 475766228.0, 'runtime': 125.0, 'status': 'Released', 'tagline': 'Witness the beginning of a new dynasty.', 'vote_average': 6.507, 'vote_count': 2811.0, 'credits': \"Paul Rudd-Evangeline Lilly-Jonathan Majors-Kathryn Newton-Michelle Pfeiffer-Michael Douglas-Corey Stoll-Bill Murray-William Jackson Harper-David Dastmalchian-Jamie Andrew Cutler-Katy O'Brian-Mark Weinman-Randall Park-Ross Mullan-Tom Clark-Leon Cooke-Nathan Blees-Durassie Kiangangu-Liran Nathan-Sam Symons-Grahame Fox-Nicola Peluso-Harrison Daniels-Brahmdeo Shannon Ramana-Russell Balogh-Leonardo Taiwo-Osian Roberts-Lucas Gerstel-Mia Gerstel-Tracy Jeffrey-Dinah Jeffrey-Judy Jeffrey-John Nayagam-Greta Nayagam-Cathy Chan-Adam Sai-Jamie Sai-Jakari Fraser-Patricia Belcher-Mark Oliver Everett-Ruben Rabasa-Melanie Garcia-Gregg Turkington-Sierra Katow-Ryan Bergara-Marielle Scott-Jake Millgard-Dey Young-Briza Covarrubias-Tess Aubert-David J. Castillo-Sir Cornwell-Alan Heitz-Esther McAuley-Aisling Maria Andreica-Milton Lopes-Roger Craig Smith-Matthew Wood-Loveday Smith-John Townsend-Tom Hiddleston-Owen Wilson-Abby Ryder Fortson\", 'keywords': 'hero-ant-sequel-superhero-based on comic-family-superhero team-aftercreditsstinger-duringcreditsstinger-marvel cinematic universe (mcu)', 'poster_path': '/qnqGbB22YJ7dSs4o6M7exTpNxPz.jpg', 'backdrop_path': '/m8JTwHFwX7I7JY5fPe4SjqejWag.jpg', 'recommendations': '823999-676841-868759-734048-267805-965839-1033219-1035806-946310-811948-842942-772515-1058949-1105283-938992-1077280-76600-677179-802401-461191-980078'}\n",
      "{'id': 677179, 'title': 'Creed III', 'genres': 'Drama-Action', 'original_language': 'en', 'overview': 'After dominating the boxing world Adonis Creed has been thriving in both his career and family life. When a childhood friend and former boxing prodigy Damien Anderson resurfaces after serving a long sentence in prison he is eager to prove that he deserves his shot in the ring. The face-off between former friends is more than just a fight. To settle the score Adonis must put his future on the line to battle Damien ‚Äî a fighter who has nothing to lose.', 'popularity': 3994.342, 'production_companies': 'Metro-Goldwyn-Mayer-Proximity Media-Balboa Productions-Outlier Society Productions-Chartoff-Winkler Productions', 'release_date': '2023-03-01', 'budget': 75000000.0, 'revenue': 269000000.0, 'runtime': 116.0, 'status': 'Released', 'tagline': \"You can't run from your past.\", 'vote_average': 7.262, 'vote_count': 1129.0, 'credits': \"Michael B. Jordan-Tessa Thompson-Jonathan Majors-Wood Harris-Phylicia RashƒÅd-Mila Davis-Kent-Jos√© Benavidez Jr.-Selenis Leyva-Florian Munteanu-Thaddeus J. Mixson-Spence Moore II-Tony Bellew-Patrice Harris-Ann Najjar-Jacob 'Stitch' Duran-Terence Crawford-Bobby Hernandez-Yahya McClain-Lamont Lankford-Corey Calliet-Kenny Bayless-Todd Grisham-Jessica McCaskill-Maya Page-Jimmy Lennon Jr.-Russell Mora-Al Bernstein-Mauro Ranallo-Brianna Valeria Gonzalez Vazquez-Shayra Medal-Kimberly Dawn Davis-David Diamante-Tony Weeks-Chris Mannix-Andreia Gibau-Soraya Yd-Stephen A. Smith-Barry Pepper-Jessica Holmes-Canelo √Ålvarez-Fernanda Gomez-Kehlani-Jeremy Lee Stone-Aaron D. Alexander-Brian Neal-Corey Hibbert-James Harden-Jove Edmond-Engle Files-Michael A. Jordan-Natasha Ofili-Rose Eshay-Alan Boell-Eli Joshua Ad√©-Butch Locsin-Stefni Valencia-Bella Dee-Anastasia Wilson-Beth Scherr-Michelle Davidson-Leah Haile-Te√≥fimo L√≥pez-Pete Penuel\", 'keywords': 'philadelphia pennsylvania-husband wife relationship-deaf-sports-sequel-orphan-former best friend-ex-con-childhood friends-juvenile detention center-boxing-prodigy', 'poster_path': '/cvsXj3I9Q2iyyIo95AecSd1tad7.jpg', 'backdrop_path': '/5i6SjyDbDWqyun8klUuCxrlFbyw.jpg', 'recommendations': '965839-267805-943822-842942-1035806-823999-1077280-1058949-772515-937278-640146-758009-536554-1011679-315162-934433-785084-631842-82856-100088-436270'}\n",
      "{'id': 502356, 'title': 'The Super Mario Bros. Movie', 'genres': 'Animation-Family-Adventure-Fantasy-Comedy', 'original_language': 'en', 'overview': 'While working underground to fix a water main Brooklyn plumbers‚Äîand brothers‚ÄîMario and Luigi are transported down a mysterious pipe and wander into a magical new world. But when the brothers are separated Mario embarks on an epic quest to find Luigi.', 'popularity': 3859.926, 'production_companies': 'Universal Pictures-Illumination-Nintendo', 'release_date': '2023-04-05', 'budget': 100000000.0, 'revenue': 1278766975.0, 'runtime': 92.0, 'status': 'Released', 'tagline': None, 'vote_average': 7.764, 'vote_count': 4042.0, 'credits': 'Chris Pratt-Charlie Day-Anya Taylor-Joy-Jack Black-Keegan-Michael Key-Seth Rogen-Fred Armisen-Khary Payton-Sebastian Maniscalco-Charles Martinet-Kevin Michael Richardson-Juliet Jelenic-Rino Romano-John DiMaggio-Jessica DiCicco-Eric Bauza-Scott Menville-Jason Broad-Carlos Alazraqui-Ashly Burch-Rachel Butera-Cathy Cavadini-Will Collyer-Django Craig-Willow Geer-Aaron Hendry-Andy Hirsch-Phil LaMarr-Jeremy Maxwell-Daniel Mora-Eric Osmond-Noreen Reardon-Lee Shorten-Cree Summer-Nisa Ward-Nora Wyman-Barbara Harris-Kazumi Totaka', 'keywords': 'video game-gorilla-plumber-magic mushroom-anthropomorphism-based on video game-toad-aftercreditsstinger-duringcreditsstinger-damsel in distress-piano-white gloves-brother brother relationship', 'poster_path': '/qNBAXBIQlnOThrVvA6mA2B5ggV6.jpg', 'backdrop_path': '/2klQ1z1fcHGgQPevbEQdkCnzyuS.jpg', 'recommendations': '713704-385687-640146-60898-758323-1008005-493529-677179-603692-594767-977177-552688-76600-385647-860867-447365-1084226-1106739-325358-868759-868985'}\n",
      "{'id': 631842, 'title': 'Knock at the Cabin', 'genres': 'Horror-Mystery-Thriller', 'original_language': 'en', 'overview': 'While vacationing at a remote cabin a young girl and her two fathers are taken hostage by four armed strangers who demand that the family make an unthinkable choice to avert the apocalypse. With limited access to the outside world the family must decide what they believe before all is lost.', 'popularity': 3422.537, 'production_companies': 'Blinding Edge Pictures-Universal Pictures-FilmNation Entertainment-Wishmore-Perfect World Pictures', 'release_date': '2023-02-01', 'budget': 20000000.0, 'revenue': 52000000.0, 'runtime': 100.0, 'status': 'Released', 'tagline': 'Save your family or save humanity. Make the choice.', 'vote_average': 6.457, 'vote_count': 888.0, 'credits': \"Dave Bautista-Jonathan Groff-Ben Aldridge-Kristen Cui-Nikki Amuka-Bird-Rupert Grint-Abby Quinn-Clare Louise Frost-McKenna Kerrigan-Odera Adimorah-M. Night Shyamalan-Ian Merrill Peakes-Denise Nakano-Rose Luardo-Billy Vargus-Satomi Hofmann-Kelvin Leung-Lee Avant-Katy Murphy-Kittson O'Neill-Lya Yanne-Hanna Gaffney-Monica Fleurette-Saria Chen\", 'keywords': 'based on novel or book-sacrifice-cabin-faith-end of the world-apocalypse-home invasion-lgbt-aftercreditsstinger-adopted child-adopted daughter-shot on film-gay-same sex relationship-religious symbolism', 'poster_path': '/dm06L9pxDOL9jNSK4Cb6y139rrG.jpg', 'backdrop_path': '/zWDMQX0sPaW2u0N2pJaYA8bVVaJ.jpg', 'recommendations': '1058949-646389-772515-505642-143970-667216-1048522-785084-1058617-986054-640146-937278-1001500-717980-677179-935906-536554-945703-82856-100088-1003580'}\n",
      "{'id': 603692, 'title': 'John Wick: Chapter 4', 'genres': 'Action-Thriller-Crime', 'original_language': 'en', 'overview': 'With the price on his head ever increasing John Wick uncovers a path to defeating The High Table. But before he can earn his freedom Wick must face off against a new enemy with powerful alliances across the globe and forces that turn old friends into foes.', 'popularity': 2808.342, 'production_companies': 'Thunder Road-87Eleven-Summit Entertainment-Studio Babelsberg', 'release_date': '2023-03-22', 'budget': 90000000.0, 'revenue': 431769198.0, 'runtime': 170.0, 'status': 'Released', 'tagline': 'No way back, one way out.', 'vote_average': 7.904, 'vote_count': 3039.0, 'credits': 'Keanu Reeves-Donnie Yen-Bill Skarsg√•rd-Ian McShane-Laurence Fishburne-Lance Reddick-Clancy Brown-Hiroyuki Sanada-Rina Sawayama-Scott Adkins-Aim√©e Kwan-Marko Zaror-Natalia Tena-Shamier Anderson-George Georgiou-Yoshinori Tashiro-Hiroki Sumi-Daiki Suzuki-Julia Asuka Riedl-Milena Rend√≥n-Ivy Quainoo-Irina Trifanov-Iryna Fedorova-Andrej Kaminsky-Sven Marquardt-Raicho Vasilev-Marie Pierra Kakoma-Gina Aponte-Christoph Hofmann', 'keywords': 'new york city-martial arts-hitman-sequel-organized crime-osaka japan-aftercreditsstinger-hunted-professional assassin-neo-noir-berlin', 'poster_path': '/vZloFAK7NmvMGKE7VkF5UHaz0I.jpg', 'backdrop_path': '/1inZm0xxXrpRfN0LxwE2TXzyLN6.jpg', 'recommendations': '1098239-802401-24791-502356-385687-525644-1076605-1103694-384093-203579-649336-325358-347196-1033219-1007938-493529-1084225-594767-762338-840326-804150'}\n",
      "{'id': 840326, 'title': 'Sisu', 'genres': 'Action-War', 'original_language': 'fi', 'overview': 'Deep in the wilderness of Lapland Aatami Korpi is searching for gold but after he stumbles upon Nazi patrol a breathtaking and gold-hungry chase through the destroyed and mined Lapland wilderness begins.', 'popularity': 2634.212, 'production_companies': 'Subzero Film Entertainment-Good Chaos-Stage 6 Films', 'release_date': '2023-01-27', 'budget': 6200000.0, 'revenue': 10568631.0, 'runtime': 91.0, 'status': 'Released', 'tagline': 'Vengeance is golden.', 'vote_average': 7.393, 'vote_count': 261.0, 'credits': 'Jorma Tommila-Aksel Hennie-Jack Doolan-Mimosa Willamo-Onni Tommila-Tatu Sinisalo-Wilhelm Enckell-Vincent Willestrand-Arttu Kapulainen-Elina Saarela-Ilkka Koivula-Max Ovaska-Joel Hirvonen-Pekka Huotari-Severi Saarinen-Aamu Milonoff-Joonas Brilli-Nicholas Francett-Kevin Francett-Eemeli Franssi-Jussi Kaila-Jarkko Klemetti-Henri Koljonen-Pekka Laakso-Martti N√§√§t√§ Leinonen-Joosua Oja-Pietari Paappanen-Oskari Skytt√§-Tomi Lampinen-Mila Lepp√§l√§-Jasmi M√§enp√§√§-Nora Nevia-Jenna Tyni-Anssi-Pekka Fredriksson-Jarmo Hietam√§ki-Wellu Mikkonen-Akseli Hakovirta-Juho-Lauri Hakovirta-Iisko Hirvasvuopio-Sakari Maliniemi-Jukka Vuorela-Ari Joki-Nikita Makkojev-Jasmin Valjas-Linnea Vilppunen-Hannu Anttila-Mario Esposito-Tarmo Hassinen-Miia Heikkinen-Kimmo Henriksson-Arto Kairaj√§rvi-Risto Korhonen-Mirva Korvala-Steven Madlin-Julia Malmsten-Annika Moisio-Kari Parkkinen-Tommi Pelkonen-Arto Peltom√§ki-Leena Sormunen-Pekka Virkkunen-Jukka Virtanen-Tinwelindon Belbog', 'keywords': 'world war ii-nordic mythology-lapland-finnish mythology', 'poster_path': '/tELs0h3PPicRbsuu5cQ8UFcBQno.jpg', 'backdrop_path': '/94TIUEhuwv8PhdIADEvSuwPljS5.jpg', 'recommendations': '552688-713704-882569-296271-502356-605886-868985-758323-826753-385687-620705-916224-1079078-977223-804150-493529-878361-964980-809787-876969-447365'}\n",
      "{'id': 646389, 'title': 'Plane', 'genres': 'Action-Adventure-Thriller', 'original_language': 'en', 'overview': 'After a heroic job of successfully landing his storm-damaged aircraft in a war zone a fearless pilot finds himself between the agendas of multiple militias planning to take the plane and its passengers hostage.', 'popularity': 2618.646, 'production_companies': 'MadRiver Pictures-Di Bonaventura Pictures-G-BASE-Olive Hill Media-Riverstone Pictures', 'release_date': '2023-01-12', 'budget': 25000000.0, 'revenue': 51000000.0, 'runtime': 107.0, 'status': 'Released', 'tagline': 'Survive together or die alone.', 'vote_average': 6.901, 'vote_count': 785.0, 'credits': 'Gerard Butler-Mike Colter-Yoson An-Tony Goldwyn-Daniella Pineda-Paul Ben-Victor-Remi Adeleke-Joey Slotnick-Evan Dane Taylor-Claro de los Reyes-Kelly Gale-Haleigh Hekking-Lilly Krug-Oliver Trevena-Tara Westwood-Mark Labella-Quinn McPherson-Kate Rachesky-Amber Rivera-Otis Winston-Modesto Lacen-Jeff Francisco-Jeffrey Holsman-Ariel Felix-Rose Eshay-Jessica Nam-Thomas A. Curran-Ricky Robles Cruz-Matthew Vale√±a-Natalia Rom√°n Garc√≠a-√Ångel Fabi√°n Rivera-Heather Seiffert-Kate Bisset', 'keywords': 'pilot-airplane-philippines-held hostage-plane crash', 'poster_path': '/qi9r5xBgcc9KTxlOLjssEbDgO0J.jpg', 'backdrop_path': '/9Rq14Eyrf7Tu1xk0Pl7VcNbNh1n.jpg', 'recommendations': '505642-758769-864692-631842-1058949-925943-758009-315162-615777-707610-922830-1013870-536554-1035806-58087-996727'}\n",
      "{'id': 569094, 'title': 'Spider-Man: Across the Spider-Verse', 'genres': 'Action-Adventure-Animation-Science Fiction', 'original_language': 'en', 'overview': 'After reuniting with Gwen Stacy Brooklyn‚Äôs full-time friendly neighborhood Spider-Man is catapulted across the Multiverse where he encounters the Spider Society a team of Spider-People charged with protecting the Multiverse‚Äôs very existence. But when the heroes clash on how to handle a new threat Miles finds himself pitted against the other Spiders and must set out on his own to save those he loves most.', 'popularity': 2550.738, 'production_companies': 'Columbia Pictures-Sony Pictures Animation-Lord Miller-Pascal Pictures-Arad Productions', 'release_date': '2023-05-31', 'budget': 100000000.0, 'revenue': 512609552.0, 'runtime': 140.0, 'status': 'Released', 'tagline': \"It's how you wear the mask that matters\", 'vote_average': 8.64, 'vote_count': 1684.0, 'credits': \"Shameik Moore-Hailee Steinfeld-Brian Tyree Henry-Luna Lauren Velez-Jake Johnson-Oscar Isaac-Jason Schwartzman-Issa Rae-Daniel Kaluuya-Karan Soni-Shea Whigham-Greta Lee-Mahershala Ali-Amandla Stenberg-Jharrel Jerome-Andy Samberg-Jack Quaid-Rachel Dratch-Ziggy Marley-Jorma Taccone-J.K. Simmons-Donald Glover-Elizabeth Perkins-Kathryn Hahn-Ayo Edebiri-Nicole Delaney-Antonina Lentini-Atsuko Okatsuka-Peter Sohn-Melissa Sturm-Lorraine Velez-Nic Novicki-Taran Killam-Metro Boomin-Josh Keaton-Sofia Barclay-Danielle Perez-Yuri Lowenthal-Rita Rani Ahuja-Ismail Bashey-Oscar Camacho-Freddy Ferrari-Kerry Gutierrez-Kamal Khan-Angelo Sekou Kouyate-Andrew Leviton-David Michie-Sumit Naig-Juan Pacheco-Chrystee Pharris-Ben Pronsky-Al Rodrigo-Jaswant Dev Shrestha-Libby Thomas Dickey-Ruth Zalduondo-Jasper Johannes Andrews-Gredel Berrios Calladine-Natalia Castellanos-Russell Tyre Francis-Deepti Gupta-Sohm Kapila-Pradnya Kuwadekar-Ashley London-Christopher Miller-Andrea Navedo-Lakshmi Patel-Jacqueline Pinol-Eliyas Qureshi-Lashana Rodriguez-Dennis Singletary-Amanda Troop-Sitara Attaie-Mayuri Bhandari-June Christopher-Michelle Jubilee Gonzalez-Marabina Jaimes-Rez Kempton-Lex Lang-Phil Lord-Richard Miro-Doug Nicholas-Shakira Ja'nai Paye-James Pirri-Marley Ralph-Michelle Ruff-Narender Sood-Cedric L. Williams-Kimberly Bailey-Sanjay Chandani-Melanie Duke-Jorge R. Gutierrez-Miguel Jiron-Deepti Kingra-Mickelsen-Luisa Leschin-Caitlin McKenna-Richard Andrew Morgado-Arthur Ortiz-Eliana A. Perez-Juan Pope-Mike Rianda-Stan Sellers-Warren Sroka-Jason Linere-White-Kimiko Glenn-Peggy Lu-John Mulaney-Andrew Garfield-Denis Leary-Tobey Maguire-Cliff Robertson-Alfred Molina-Post Malone\", 'keywords': 'sacrifice-villain-comic book-sequel-superhero-based on comic-alternate dimension-alternate version-super power-brooklyn new york city-superhero team-spider bite-super villain-cliffhanger-teen superhero-alternate universe-female superhero-cartoon spider', 'poster_path': '/8Vt6mWEReuy4Of61Lnj5Xj704m8.jpg', 'backdrop_path': '/4HodYYKEIsGOdinkGi2Ucz6X9i0.jpg', 'recommendations': '496450-667538-385687-603692-298618-447277-976573-598331-324857-447365-462883-536437-979296-313369-537210-1106591-532408-502356-1140706-820707-462376'}\n"
     ]
    }
   ],
   "source": [
    "records = conn.query(\"SELECT * FROM movies LIMIT 10\").to_df().to_dict(orient=\"records\")\n",
    "\n",
    "for record in records:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Text2SQL\n",
    "\n",
    "Let's start by implementing a simple logic to take human questions and to convert it into a sql query. Note that we prompt the llm to just respond with the sql so that we can plug it directly into duckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "from phoenix.client import Client\n",
    "from phoenix.client.types import PromptVersion\n",
    "\n",
    "phoenix_client = Client()\n",
    "client = openai.AsyncClient()\n",
    "\n",
    "columns = conn.query(\"DESCRIBE movies\").to_df().to_dict(orient=\"records\")\n",
    "\n",
    "# We will use GPT4o to start\n",
    "TASK_MODEL = \"gpt-4o\"\n",
    "CONFIG = {\"model\": TASK_MODEL}\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are a SQL expert, and you are given a table named `movies` with the following columns:\n",
    "\n",
    "{\",\".join(column[\"column_name\"] + \": \" + column[\"column_type\"] for column in columns)}\n",
    "\n",
    "Write a SQL query corresponding to the user's request. Return just the SQL query\n",
    "with no formatting (no backticks, no markdown, etc.).\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = phoenix_client.prompts.create(\n",
    "    name=\"text2sql\",\n",
    "    version=PromptVersion(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"{{question}}\",\n",
    "            },\n",
    "        ],\n",
    "        description=\"Initial prompt for text2sql\",\n",
    "        model_name=TASK_MODEL,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "@tracer.chain\n",
    "async def generate_query(question):\n",
    "    prompt = prompt_template.format(variables={\"question\": question}, sdk=\"openai\")\n",
    "    response = await client.chat.completions.create(\n",
    "        **prompt,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT title FROM movies ORDER BY revenue DESC LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "query = await generate_query(\"What is the top grossing movie?\")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, looks like the LLM is producing SQL! let's try running the query against the database and see if we get the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Avatar'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tracer.tool\n",
    "def execute_query(query):\n",
    "    return conn.query(query).fetchdf().to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "execute_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the pieces together and see if we can create a movie agent. Here we are performing very simple RAG where the sql query results are being passed to an LLM to synthesize a human-friently answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.chain\n",
    "async def text2sql(question):  # noqa: F811\n",
    "    query = await generate_query(question)\n",
    "    results = None\n",
    "    error = None\n",
    "    try:\n",
    "        results = execute_query(query)\n",
    "    except duckdb.Error as e:\n",
    "        error = str(e)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"results\": results,\n",
    "        \"error\": error,\n",
    "    }\n",
    "\n",
    "\n",
    "synthesis_system_prompt = \"\"\"\n",
    "You are a helpful assistant that can answer questions about movies.\n",
    "\n",
    "Answer the question based on the sql results. Do not rely on your internal knowledge.\n",
    "\n",
    "Do not use sql or abbriviations for genres or languages. Use an informative, concise voice.\n",
    "Your response should be purely in natural language, do not include any sql or other technical details.\n",
    "\n",
    "If the sql results are empty, say you don't know.\n",
    "\"\"\"\n",
    "\n",
    "synthesis_prompt_template = \"\"\"\n",
    "Answer the question based on the sql results.\n",
    "\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[Question]: {question}\n",
    "************\n",
    "[SQL Results]: {results}\n",
    "************\n",
    "[END DATA]\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "@tracer.agent\n",
    "async def movie_agent(question):\n",
    "    sql_response = await text2sql(question)\n",
    "    if sql_response[\"error\"]:\n",
    "        raise Exception(sql_response[\"error\"])\n",
    "    results = sql_response[\"results\"]\n",
    "    answer = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": synthesis_system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": synthesis_prompt_template.format(question=question, results=results)\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return answer.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The top grossing movie is \"Avatar.\"'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await movie_agent(\"What is the top grossing movie?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a working movie expert. Or do we? Let's double check. Let's run the agent over some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Which Brad Pitt movie received the highest rating?\",\n",
    "    \"What is the top grossing Marvel movie?\",\n",
    "    \"What foreign-language fantasy movie was the most popular?\",\n",
    "    \"what are the best sci-fi movies of 2017?\",\n",
    "    \"What anime topped the box office in the 2010s?\",\n",
    "    \"Recommend a romcom that stars Paul Rudd.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Which Brad Pitt movie received the highest rating?\n",
      "Answer:  The Brad Pitt movie \"Voom Portraits\" received the highest rating with a vote average of 10.0.\n",
      "\n",
      "\n",
      "Question:  What is the top grossing Marvel movie?\n",
      "Answer:  The top grossing Marvel movie is \"Avengers: Endgame,\" with a revenue of approximately $2,799,439,100.\n",
      "\n",
      "\n",
      "Question:  What foreign-language fantasy movie was the most popular?\n",
      "Answer:  The foreign-language fantasy movie titled \"The Nights Belong to Monsters\" was the most popular.\n",
      "\n",
      "\n",
      "Question:  what are the best sci-fi movies of 2017?\n",
      "Answer:  I don't know.\n",
      "\n",
      "\n",
      "Question:  What anime topped the box office in the 2010s?\n",
      "Answer:  I don't know which anime topped the box office in the 2010s based on the given data.\n",
      "\n",
      "\n",
      "Question:  Recommend a romcom that stars Paul Rudd.\n",
      "Answer:  I recommend the romantic comedy \"Clueless,\" which stars Paul Rudd.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.trace import using_project\n",
    "\n",
    "with using_project(project_name=\"movie-agent-baseline\"):\n",
    "    for question in questions:\n",
    "        try:\n",
    "            answer = await movie_agent(question)\n",
    "            print(\"Question: \", question)\n",
    "            print(\"Answer: \", answer)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data and annotate it to see what the issues might be. Go to Settings > Annotations and add a correctness annotation config. Configure it as a categorical annotation with two categories, `correct` and `incorrect`. We can now quickly annotate the 7 traces (e.g. the agent spans) above as `correct` or `incorrect`. Once we've annotated some data we can bring it back into the notebook to analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_name</th>\n",
       "      <th>annotator_kind</th>\n",
       "      <th>metadata</th>\n",
       "      <th>identifier</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>result.label</th>\n",
       "      <th>...</th>\n",
       "      <th>status_code</th>\n",
       "      <th>status_message</th>\n",
       "      <th>events</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>attributes.output.mime_type</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.input.mime_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680faf992ac440b4</th>\n",
       "      <td>correctness</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>U3BhbkFubm90YXRpb246NA==</td>\n",
       "      <td>2025-07-01T06:12:59+00:00</td>\n",
       "      <td>2025-07-01T06:12:59+00:00</td>\n",
       "      <td>APP</td>\n",
       "      <td>None</td>\n",
       "      <td>correct</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>680faf992ac440b4</td>\n",
       "      <td>791bc2011e7c8ebf7ca2ba09f28f424e</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>The top grossing Marvel movie is \"Avengers: En...</td>\n",
       "      <td>What is the top grossing Marvel movie?</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58dea9e47c4e6b82</th>\n",
       "      <td>correctness</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>U3BhbkFubm90YXRpb246Mw==</td>\n",
       "      <td>2025-07-01T06:12:34+00:00</td>\n",
       "      <td>2025-07-01T06:12:34+00:00</td>\n",
       "      <td>APP</td>\n",
       "      <td>None</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>58dea9e47c4e6b82</td>\n",
       "      <td>dff72850f370d70d78e816c4114a45d8</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>what are the best sci-fi movies of 2017?</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acaeaa0e67bcbb72</th>\n",
       "      <td>correctness</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>U3BhbkFubm90YXRpb246Mg==</td>\n",
       "      <td>2025-07-01T06:12:26+00:00</td>\n",
       "      <td>2025-07-01T06:12:26+00:00</td>\n",
       "      <td>APP</td>\n",
       "      <td>None</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>acaeaa0e67bcbb72</td>\n",
       "      <td>133bd69fe9339a1b699f5854ee7fd789</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>I don't know which anime topped the box office...</td>\n",
       "      <td>What anime topped the box office in the 2010s?</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd5563093e84769e</th>\n",
       "      <td>correctness</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>U3BhbkFubm90YXRpb246MQ==</td>\n",
       "      <td>2025-07-01T06:12:18+00:00</td>\n",
       "      <td>2025-07-01T06:12:18+00:00</td>\n",
       "      <td>APP</td>\n",
       "      <td>None</td>\n",
       "      <td>correct</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>cd5563093e84769e</td>\n",
       "      <td>52bc08dc81a94e85d135f7a95fcaa727</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>I recommend the romantic comedy \"Clueless,\" wh...</td>\n",
       "      <td>Recommend a romcom that stars Paul Rudd.</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 annotation_name annotator_kind metadata identifier  \\\n",
       "680faf992ac440b4     correctness          HUMAN       {}              \n",
       "58dea9e47c4e6b82     correctness          HUMAN       {}              \n",
       "acaeaa0e67bcbb72     correctness          HUMAN       {}              \n",
       "cd5563093e84769e     correctness          HUMAN       {}              \n",
       "\n",
       "                                        id                 created_at  \\\n",
       "680faf992ac440b4  U3BhbkFubm90YXRpb246NA==  2025-07-01T06:12:59+00:00   \n",
       "58dea9e47c4e6b82  U3BhbkFubm90YXRpb246Mw==  2025-07-01T06:12:34+00:00   \n",
       "acaeaa0e67bcbb72  U3BhbkFubm90YXRpb246Mg==  2025-07-01T06:12:26+00:00   \n",
       "cd5563093e84769e  U3BhbkFubm90YXRpb246MQ==  2025-07-01T06:12:18+00:00   \n",
       "\n",
       "                                 updated_at source user_id result.label  ...  \\\n",
       "680faf992ac440b4  2025-07-01T06:12:59+00:00    APP    None      correct  ...   \n",
       "58dea9e47c4e6b82  2025-07-01T06:12:34+00:00    APP    None    incorrect  ...   \n",
       "acaeaa0e67bcbb72  2025-07-01T06:12:26+00:00    APP    None    incorrect  ...   \n",
       "cd5563093e84769e  2025-07-01T06:12:18+00:00    APP    None      correct  ...   \n",
       "\n",
       "                  status_code status_message events   context.span_id  \\\n",
       "680faf992ac440b4           OK                    []  680faf992ac440b4   \n",
       "58dea9e47c4e6b82           OK                    []  58dea9e47c4e6b82   \n",
       "acaeaa0e67bcbb72           OK                    []  acaeaa0e67bcbb72   \n",
       "cd5563093e84769e           OK                    []  cd5563093e84769e   \n",
       "\n",
       "                                  context.trace_id  \\\n",
       "680faf992ac440b4  791bc2011e7c8ebf7ca2ba09f28f424e   \n",
       "58dea9e47c4e6b82  dff72850f370d70d78e816c4114a45d8   \n",
       "acaeaa0e67bcbb72  133bd69fe9339a1b699f5854ee7fd789   \n",
       "cd5563093e84769e  52bc08dc81a94e85d135f7a95fcaa727   \n",
       "\n",
       "                 attributes.openinference.span.kind  \\\n",
       "680faf992ac440b4                              AGENT   \n",
       "58dea9e47c4e6b82                              AGENT   \n",
       "acaeaa0e67bcbb72                              AGENT   \n",
       "cd5563093e84769e                              AGENT   \n",
       "\n",
       "                 attributes.output.mime_type  \\\n",
       "680faf992ac440b4                  text/plain   \n",
       "58dea9e47c4e6b82                  text/plain   \n",
       "acaeaa0e67bcbb72                  text/plain   \n",
       "cd5563093e84769e                  text/plain   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "680faf992ac440b4  The top grossing Marvel movie is \"Avengers: En...   \n",
       "58dea9e47c4e6b82                                      I don't know.   \n",
       "acaeaa0e67bcbb72  I don't know which anime topped the box office...   \n",
       "cd5563093e84769e  I recommend the romantic comedy \"Clueless,\" wh...   \n",
       "\n",
       "                                          attributes.input.value  \\\n",
       "680faf992ac440b4          What is the top grossing Marvel movie?   \n",
       "58dea9e47c4e6b82        what are the best sci-fi movies of 2017?   \n",
       "acaeaa0e67bcbb72  What anime topped the box office in the 2010s?   \n",
       "cd5563093e84769e        Recommend a romcom that stars Paul Rudd.   \n",
       "\n",
       "                 attributes.input.mime_type  \n",
       "680faf992ac440b4                 text/plain  \n",
       "58dea9e47c4e6b82                 text/plain  \n",
       "acaeaa0e67bcbb72                 text/plain  \n",
       "cd5563093e84769e                 text/plain  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.client import Client\n",
    "from phoenix.client.types.spans import SpanQuery\n",
    "\n",
    "phoenix_client = Client()\n",
    "query = SpanQuery().where(\"name == 'movie_agent'\")\n",
    "\n",
    "spans_df = phoenix_client.spans.get_spans_dataframe(\n",
    "    project_identifier=\"movie-agent-baseline\", query=query\n",
    ")\n",
    "annotations_df = phoenix_client.spans.get_span_annotations_dataframe(\n",
    "    spans_dataframe=spans_df, project_identifier=\"movie-agent-baseline\"\n",
    ")\n",
    "\n",
    "combined_df = annotations_df.join(spans_df, how=\"inner\")\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_name</th>\n",
       "      <th>result.label</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.output.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680faf992ac440b4</th>\n",
       "      <td>correctness</td>\n",
       "      <td>correct</td>\n",
       "      <td>What is the top grossing Marvel movie?</td>\n",
       "      <td>The top grossing Marvel movie is \"Avengers: En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58dea9e47c4e6b82</th>\n",
       "      <td>correctness</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>what are the best sci-fi movies of 2017?</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acaeaa0e67bcbb72</th>\n",
       "      <td>correctness</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>What anime topped the box office in the 2010s?</td>\n",
       "      <td>I don't know which anime topped the box office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd5563093e84769e</th>\n",
       "      <td>correctness</td>\n",
       "      <td>correct</td>\n",
       "      <td>Recommend a romcom that stars Paul Rudd.</td>\n",
       "      <td>I recommend the romantic comedy \"Clueless,\" wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 annotation_name result.label  \\\n",
       "680faf992ac440b4     correctness      correct   \n",
       "58dea9e47c4e6b82     correctness    incorrect   \n",
       "acaeaa0e67bcbb72     correctness    incorrect   \n",
       "cd5563093e84769e     correctness      correct   \n",
       "\n",
       "                                          attributes.input.value  \\\n",
       "680faf992ac440b4          What is the top grossing Marvel movie?   \n",
       "58dea9e47c4e6b82        what are the best sci-fi movies of 2017?   \n",
       "acaeaa0e67bcbb72  What anime topped the box office in the 2010s?   \n",
       "cd5563093e84769e        Recommend a romcom that stars Paul Rudd.   \n",
       "\n",
       "                                            attributes.output.value  \n",
       "680faf992ac440b4  The top grossing Marvel movie is \"Avengers: En...  \n",
       "58dea9e47c4e6b82                                      I don't know.  \n",
       "acaeaa0e67bcbb72  I don't know which anime topped the box office...  \n",
       "cd5563093e84769e  I recommend the romantic comedy \"Clueless,\" wh...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expamples_df = combined_df[\n",
    "    [\"annotation_name\", \"result.label\", \"attributes.input.value\", \"attributes.output.value\"]\n",
    "].head()\n",
    "expamples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can create an LLM judge that aligns with our human evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert evaluator of question and answer pairs. You will be given a human question and an answer from a model.\n",
      "Your job is to determine if the answer is \"correct\" or \"incorrect\".\n",
      "\n",
      "Here are some examples of correct and incorrect answers:\n",
      "Question: What is the top grossing Marvel movie?\n",
      "Answer: The top grossing Marvel movie is \"Avengers: Endgame,\" with a revenue of approximately $2,799,439,100.\n",
      "Label: correct\n",
      "\n",
      "Question: what are the best sci-fi movies of 2017?\n",
      "Answer: I don't know.\n",
      "Label: incorrect\n",
      "\n",
      "Question: What anime topped the box office in the 2010s?\n",
      "Answer: I don't know which anime topped the box office in the 2010s based on the given data.\n",
      "Label: incorrect\n",
      "\n",
      "Question: Recommend a romcom that stars Paul Rudd.\n",
      "Answer: I recommend the romantic comedy \"Clueless,\" which stars Paul Rudd.\n",
      "Label: correct\n",
      "\n",
      "## Evaluation\n",
      "Provide your answer in the following format:\n",
      "Question: <question>\n",
      "Answer: <answer>\n",
      "Explanation: <explanation>\n",
      "Label: <correct|incorrect>\n",
      "\n",
      "Question: {attributes.input.value}\n",
      "Answer: {attributes.output.value}\n",
      "Explanation:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"\"\"\n",
    "You are an expert evaluator of question and answer pairs. You will be given a human question and an answer from a model.\n",
    "Your job is to determine if the answer is \"correct\" or \"incorrect\".\n",
    "\n",
    "Here are some examples of correct and incorrect answers:\n",
    "{'\\n\\n'.join([f\"Question: {example['attributes.input.value']}\\nAnswer: {example['attributes.output.value']}\\nLabel: {example['result.label']}\" for example in expamples_df.to_dict(orient=\"records\")])}\n",
    "\n",
    "## Evaluation\n",
    "Provide your answer in the following format:\n",
    "Question: <question>\n",
    "Answer: <answer>\n",
    "Explanation: <explanation>\n",
    "Label: <correct|incorrect>\n",
    "\n",
    "Question: {{attributes.input.value}}\n",
    "Answer: {{attributes.output.value}}\n",
    "Explanation:\n",
    "\"\"\"\n",
    "\n",
    "print(eval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.output.value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0dffcd95160b817f</th>\n",
       "      <td>Which Brad Pitt movie received the highest rat...</td>\n",
       "      <td>The Brad Pitt movie \"Voom Portraits\" received ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680faf992ac440b4</th>\n",
       "      <td>What is the top grossing Marvel movie?</td>\n",
       "      <td>The top grossing Marvel movie is \"Avengers: En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b80a04760108be5</th>\n",
       "      <td>What foreign-language fantasy movie was the mo...</td>\n",
       "      <td>The foreign-language fantasy movie titled \"The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58dea9e47c4e6b82</th>\n",
       "      <td>what are the best sci-fi movies of 2017?</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acaeaa0e67bcbb72</th>\n",
       "      <td>What anime topped the box office in the 2010s?</td>\n",
       "      <td>I don't know which anime topped the box office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             attributes.input.value  \\\n",
       "context.span_id                                                       \n",
       "0dffcd95160b817f  Which Brad Pitt movie received the highest rat...   \n",
       "680faf992ac440b4             What is the top grossing Marvel movie?   \n",
       "1b80a04760108be5  What foreign-language fantasy movie was the mo...   \n",
       "58dea9e47c4e6b82           what are the best sci-fi movies of 2017?   \n",
       "acaeaa0e67bcbb72     What anime topped the box office in the 2010s?   \n",
       "\n",
       "                                            attributes.output.value  \n",
       "context.span_id                                                      \n",
       "0dffcd95160b817f  The Brad Pitt movie \"Voom Portraits\" received ...  \n",
       "680faf992ac440b4  The top grossing Marvel movie is \"Avengers: En...  \n",
       "1b80a04760108be5  The foreign-language fantasy movie titled \"The...  \n",
       "58dea9e47c4e6b82                                      I don't know.  \n",
       "acaeaa0e67bcbb72  I don't know which anime topped the box office...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_df[[\"attributes.input.value\", \"attributes.output.value\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c361385b1c48d28b3d309355c50dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/6 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751350424.187736 7044701 chttp2_transport.cc:1154] ipv6:%5B::1%5D:4317: Got goaway [11] err=UNAVAILABLE:GOAWAY received; Error code: 11; Debug Text: ping_timeout {created_time:\"2025-07-01T00:13:44.187723-06:00\", http2_error:11, grpc_status:14}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0dffcd95160b817f</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer states that \"Voom Portraits\" receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680faf992ac440b4</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The answer correctly identifies 'Avengers: End...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b80a04760108be5</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer provided, \"The Nights Belong to Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58dea9e47c4e6b82</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer 'I don't know' does not provide any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acaeaa0e67bcbb72</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer does not provide the information re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  score  \\\n",
       "context.span_id                      \n",
       "0dffcd95160b817f  incorrect      0   \n",
       "680faf992ac440b4    correct      1   \n",
       "1b80a04760108be5  incorrect      0   \n",
       "58dea9e47c4e6b82  incorrect      0   \n",
       "acaeaa0e67bcbb72  incorrect      0   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "0dffcd95160b817f  The answer states that \"Voom Portraits\" receiv...  \n",
       "680faf992ac440b4  The answer correctly identifies 'Avengers: End...  \n",
       "1b80a04760108be5  The answer provided, \"The Nights Belong to Mon...  \n",
       "58dea9e47c4e6b82  The answer 'I don't know' does not provide any...  \n",
       "acaeaa0e67bcbb72  The answer does not provide the information re...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.evals import llm_classify\n",
    "from phoenix.evals.models import OpenAIModel\n",
    "from phoenix.evals.templates import PromptTemplate\n",
    "\n",
    "evals_df = llm_classify(\n",
    "    data=spans_df,\n",
    "    model=OpenAIModel(model=\"gpt-4o\"),\n",
    "    rails=[\"correct\", \"incorrect\"],\n",
    "    template=PromptTemplate(\n",
    "        template=eval_prompt,\n",
    "    ),\n",
    "    exit_on_error=False,\n",
    "    provide_explanation=True,\n",
    ")\n",
    "\n",
    "## Assign 1 to correct and 0 to incorrect\n",
    "evals_df[\"score\"] = evals_df[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)\n",
    "evals_df[[\"label\", \"score\", \"explanation\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeldking/anaconda3/envs/phoenix/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (11.2.0) and client (11.1.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(\n",
    "        dataframe=evals_df,\n",
    "        eval_name=\"llm_correctness\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"https://eugeneyan.com/assets/ai-monitoring.webp\" width=\"800\">\n",
    "<cite data-cite=\"yan2025\">(Yan, 2025)</cite>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "\n",
    "<p style=\"text-align: center\">\n",
    "<img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/evaluator.png\" width=\"800\">\n",
    "</p>\n",
    "\n",
    "The velocity AI application development is bottlenecked by high quality evaluations because engineers are often faced with hard tradeoffs: which prompt or LLM best balances performance, latency, and cost. Quality Evaluations are critical as they help answer these types of questions with greater confidence.\n",
    "\n",
    "Evaluation consists of three parts ‚Äî data, task, and scores. We'll start with data.\n",
    "\n",
    "<p style=\"text-align: center\">\n",
    "<img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/experiment_analogy.png\" width=\"800\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the movie questions we created above as a versioned dataset in phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n",
      "üíæ Examples uploaded: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246OA==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeldking/anaconda3/envs/phoenix/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (11.2.0) and client (11.1.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "ds = px.Client().upload_dataset(\n",
    "    dataset_name=\"movie-example-questions\",\n",
    "    dataframe=pd.DataFrame([{\"question\": question} for question in questions]),\n",
    "    input_keys=[\"question\"],\n",
    "    output_keys=[],\n",
    ")\n",
    "\n",
    "# If you have already uploaded the dataset, you can fetch it using the following line\n",
    "# ds = px.Client().get_dataset(name=\"movie-example-questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the task. The task is to generate SQL queries from natural language questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.chain\n",
    "async def text2sql(question):  # noqa: F811\n",
    "    query = await generate_query(question)\n",
    "    results = None\n",
    "    error = None\n",
    "    try:\n",
    "        results = execute_query(query)\n",
    "    except duckdb.Error as e:\n",
    "        error = str(e)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"results\": results,\n",
    "        \"error\": error,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define the evaluators. We'll use the following simple functions that produce 1 for true and 0 for false to see if the generated SQL queries are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if there are no sql execution errors\n",
    "def no_error(output):\n",
    "    return 1.0 if output.get(\"error\") is None else 0.0\n",
    "\n",
    "\n",
    "# Test if the query has results\n",
    "def has_results(output):\n",
    "    results = output.get(\"results\")\n",
    "    has_results = results is not None and len(results) > 0\n",
    "    return 1.0 if has_results else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the experiment. To run the experiment, we pass the dataset of exaples, the task which runs the sql generation, and the evals described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/experiments\n",
      "üîó View this experiment: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNg==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeldking/anaconda3/envs/phoenix/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (11.2.0) and client (11.1.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4790c47ff64860b25e63e98a751568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running tasks |          | 0/6 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task runs completed.\n",
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217efa956d1a48469ff47742131bdf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/12 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNg==\n",
      "\n",
      "Experiment Summary (07/01/25 12:14 AM -0600)\n",
      "--------------------------------------------\n",
      "| evaluator   |   n |   n_scores |   avg_score |\n",
      "|:------------|----:|-----------:|------------:|\n",
      "| has_results |   6 |          6 |    0.666667 |\n",
      "| no_error    |   6 |          6 |    1        |\n",
      "\n",
      "Tasks Summary (07/01/25 12:14 AM -0600)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|            6 |        6 |          0 |\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "\n",
    "# Define the task to run text2sql on the input question\n",
    "def task(input):\n",
    "    return text2sql(input[\"question\"])\n",
    "\n",
    "\n",
    "experiment = run_experiment(\n",
    "    ds,\n",
    "    task=task,\n",
    "    evaluators=[no_error, has_results],\n",
    "    experiment_metadata=CONFIG,\n",
    "    experiment_name=\"baseline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Not looking very good. It looks like only 4 out 6 of our questions are yielding results. Let's dig in to see how we can fix these.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the results\n",
    "\n",
    "Now that we ran the initial evaluation, it looks like 2 of the results are empty due to getting the genre wrong.\n",
    "\n",
    "- `Sci-Fi` needs to be queried as `Science Fiction`\n",
    "- `Anime` needs to be queries as `Animation` + language specification. \n",
    "\n",
    "These two issues would probably be improved by showing a sample of the data to the model (e.g. few shot example) since the data will show the LLM what is queryable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve the prompt with few-shot examples and see if we can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = conn.query(\"SELECT * FROM movies LIMIT 5\").to_df().to_dict(orient=\"records\")\n",
    "\n",
    "example_row = \"\\n\".join(\n",
    "    f\"{column['column_name']} | {column['column_type']} | {samples[0][column['column_name']]}\"\n",
    "    for column in columns\n",
    ")\n",
    "\n",
    "column_header = \" | \".join(column[\"column_name\"] for column in columns)\n",
    "\n",
    "few_shot_examples = \"\\n\".join(\n",
    "    \" | \".join(str(sample[column[\"column_name\"]]) for column in columns) for sample in samples\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a SQL expert, and you are given a single table named `movies` with the following columns:\\n\\n\"\n",
    "    \"Column | Type | Example\\n\"\n",
    "    \"-------|------|--------\\n\"\n",
    "    f\"{example_row}\\n\"\n",
    "    \"\\n\"\n",
    "    \"Examples:\\n\"\n",
    "    f\"{column_header}\\n\"\n",
    "    f\"{few_shot_examples}\\n\"\n",
    "    \"\\n\"\n",
    "    \"Write a DuckDB SQL query corresponding to the user's request. \"\n",
    "    \"Return just the query text, with no formatting (backticks, markdown, etc.).\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template = phoenix_client.prompts.create(\n",
    "    name=\"text2sql\",\n",
    "    version=PromptVersion(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"{{question}}\",\n",
    "            },\n",
    "        ],\n",
    "        description=\"Add few shot examples to the prompt\",\n",
    "        model_name=TASK_MODEL,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT title, MAX(vote_average) AS max_vote_average\n",
      "FROM movies\n",
      "WHERE genres LIKE '%Science Fiction%'\n",
      "GROUP BY title\n",
      "ORDER BY max_vote_average DESC\n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "print(await generate_query(\"What is the best Sci-Fi movie?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking much better! Since the prompt shows that \"Sci-Fi\" is represented as \"Science Fiction\", the LLM is able to synthesize the right where clause. \n",
    "\n",
    "Let's run the experiment again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/experiments\n",
      "üîó View this experiment: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNw==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeldking/anaconda3/envs/phoenix/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (11.2.0) and client (11.1.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daea17b55a614f84ae971a1ee9b0899f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running tasks |          | 0/6 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task runs completed.\n",
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c207764e0d640bc9fe2ece3d5b835e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/12 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNw==\n",
      "\n",
      "Experiment Summary (07/01/25 12:14 AM -0600)\n",
      "--------------------------------------------\n",
      "| evaluator   |   n |   n_scores |   avg_score |\n",
      "|:------------|----:|-----------:|------------:|\n",
      "| has_results |   6 |          6 |           1 |\n",
      "| no_error    |   6 |          6 |           1 |\n",
      "\n",
      "Tasks Summary (07/01/25 12:14 AM -0600)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|            6 |        6 |          0 |\n"
     ]
    }
   ],
   "source": [
    "experiment = run_experiment(\n",
    "    ds,\n",
    "    experiment_name=\"with examples\",\n",
    "    task=task,\n",
    "    evaluators=[has_results, no_error],\n",
    "    experiment_metadata=CONFIG,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much improved. It looks like we've eliminated the errors, and got a result for the incorrect queries. But just because we are getting info out of the DB doesn't mean these answers are correct. Let's construct an LLM judge to validate the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Evaluation started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16bd0dfcd2f41c789a1f50ac6ca8ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running experiment evaluations |          | 0/6 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: http://127.0.0.1:6006/datasets/RGF0YXNldDo4/compare?experimentId=RXhwZXJpbWVudDoxNw==\n",
      "\n",
      "Experiment Summary (07/01/25 12:14 AM -0600)\n",
      "--------------------------------------------\n",
      "| evaluator      |   n |   n_scores |   avg_score |   n_labels | top_2_labels                 |\n",
      "|:---------------|----:|-----------:|------------:|-----------:|:-----------------------------|\n",
      "| qa_correctness |   6 |          6 |    0.833333 |          6 | {'correct': 5, 'invalid': 1} |\n",
      "\n",
      "Experiment Summary (07/01/25 12:14 AM -0600)\n",
      "--------------------------------------------\n",
      "| evaluator   |   n |   n_scores |   avg_score |\n",
      "|:------------|----:|-----------:|------------:|\n",
      "| has_results |   6 |          6 |           1 |\n",
      "| no_error    |   6 |          6 |           1 |\n",
      "\n",
      "Tasks Summary (07/01/25 12:14 AM -0600)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|            6 |        6 |          0 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RanExperiment(id='RXhwZXJpbWVudDoxNw==', dataset_id='RGF0YXNldDo4', dataset_version_id='RGF0YXNldFZlcnNpb246OA==', repetitions=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from phoenix.experiments import evaluate_experiment\n",
    "from phoenix.experiments.evaluators import create_evaluator\n",
    "from phoenix.experiments.types import EvaluationResult\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "judge_instructions = \"\"\"\n",
    "You are a judge that determines if a given question can be answered with the provided SQL query and results.\n",
    "Make sure to ensure that the SQL query maps to the question accurately.\n",
    "\n",
    "Provide the label `correct` if the SQL query and results accurately answer the question.\n",
    "Provide the label `invalid` if the SQL query does not map to the question or is not valid.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@create_evaluator(name=\"qa_correctness\", kind=\"llm\")\n",
    "def qa_correctness(input, output):\n",
    "    question = input.get(\"question\")\n",
    "    query = output.get(\"query\")\n",
    "    results = output.get(\"results\")\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": judge_instructions},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {question}\\nSQL Query: {query}\\nSQL Results: {results}\",\n",
    "            },\n",
    "        ],\n",
    "        tool_choice=\"required\",\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"qa_correctness\",\n",
    "                    \"description\": \"Determine if the SQL query and results accurately answer the question.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"explanation\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Explain why the label is correct or invalid.\",\n",
    "                            },\n",
    "                            \"label\": {\"type\": \"string\", \"enum\": [\"correct\", \"invalid\"]},\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    if response.choices[0].message.tool_calls is None:\n",
    "        raise ValueError(\"No tool call found in response\")\n",
    "    args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "    label = args[\"label\"]\n",
    "    explanation = args[\"explanation\"]\n",
    "    score = 1 if label == \"correct\" else 0\n",
    "    return EvaluationResult(score=score, label=label, explanation=explanation)\n",
    "\n",
    "\n",
    "evaluate_experiment(experiment, evaluators=[qa_correctness])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM judge's scoring closely matches our manual evaluation, demonstrating its effectiveness as an automated evaluation method. This approach is particularly valuable when traditional rule-based scoring functions are difficult to implement. \n",
    "\n",
    "The LLM judge also shows an advantage in nuanced understanding - for example, it correctly identifies that 'Anime' and 'Animation' are distinct genres, a subtlety our code-based evaluators missed. This highlights why developing custom LLM judges tailored to your specific task requirements is crucial for accurate evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now have a simple text2sql pipeline that can be used to generate SQL queries from natural language questions. Since Phoenix has been tracing the entire pipeline, we can now use the Phoenix UI to convert the spans that generated successful queries into examples to use in **Golden Dataset** for regression testing as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it all together\n",
    "\n",
    "Now that we've seen the experiment improve our outcome, let's put it to a test given the evals we built out earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Brad Pitt movie that received the highest rating is \"Voom Portraits\" with a rating of 10.0.\n",
      "The top-grossing Marvel movie is \"Avengers: Endgame,\" with a revenue of approximately 2.799 billion dollars.\n",
      "The most popular foreign-language fantasy movie is \"The Nights Belong to Monsters\" with a popularity score of 742.199.\n",
      "In 2017, some of the highest-rated science fiction movies, each with a perfect score of 10.0, were \"T&A Time Travelers,\" \"H. P. Lovecraft Film Festival Best of 2017,\" \"Anukul,\" \"Satria Heroes: Revenge of Darkness,\" \"Ready Jet Go! Back to Bortron 7,\" \"Electric Sandwich,\" \"Uchuu Sentai Kyuranger: Episode of Stinger,\" \"Navy SEALS v Demons,\" \"Roam - Short Film,\" \"Moon Men,\" \"Toxic Tutu,\" \"The Aalto Natives,\" \"Zombie City,\" \"Blade Of Honor,\" \"The Idol,\" \"I Am the Doorway,\" \"Eureka!!,\" \"X-Manas,\" \"Femaliens: Seduction of the Species,\" \"Lucas Chronicle,\" and \"Among Us - In the Land of Our Shadows.\" These films stood out in 2017 for their high viewer ratings.\n",
      "I don't know.\n",
      "I recommend the romantic comedy \"Clueless\" which stars Paul Rudd. The film is about the socially successful Cher, who considers herself a matchmaker, and her journey in understanding relationships and popularity in high school. It's a classic romcom with a mix of humor and romance.\n"
     ]
    }
   ],
   "source": [
    "from phoenix.trace import using_project\n",
    "\n",
    "\n",
    "@tracer.agent\n",
    "async def movie_agent_improved(question):\n",
    "    sql_response = await text2sql(question)\n",
    "    if sql_response[\"error\"]:\n",
    "        raise Exception(sql_response[\"error\"])\n",
    "    results = sql_response[\"results\"]\n",
    "    answer = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": synthesis_system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": synthesis_prompt_template.format(question=question, results=results),\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return answer.choices[0].message.content\n",
    "\n",
    "\n",
    "with using_project(project_name=\"movie-agent-improved\"):\n",
    "    for question in questions:\n",
    "        try:\n",
    "            answer = await movie_agent_improved(question)\n",
    "            print(\"Question: \", question)\n",
    "            print(\"Answer: \", answer)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>status_code</th>\n",
       "      <th>status_message</th>\n",
       "      <th>events</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>attributes.output.mime_type</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.input.mime_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9c66b61c2cf52502</th>\n",
       "      <td>movie_agent_improved</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-07-01 06:14:51.803067+00:00</td>\n",
       "      <td>2025-07-01 06:14:53.117168+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>9c66b61c2cf52502</td>\n",
       "      <td>ca223f4d90f76412af4a5d6c7f819c57</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>The Brad Pitt movie that received the highest ...</td>\n",
       "      <td>Which Brad Pitt movie received the highest rat...</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55a8b854d602f733</th>\n",
       "      <td>movie_agent_improved</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-07-01 06:14:53.118755+00:00</td>\n",
       "      <td>2025-07-01 06:14:54.688625+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>55a8b854d602f733</td>\n",
       "      <td>e8ce61899e4b12e8ed29b39f4192164e</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>The top-grossing Marvel movie is \"Avengers: En...</td>\n",
       "      <td>What is the top grossing Marvel movie?</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c150fc600402bc7</th>\n",
       "      <td>movie_agent_improved</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-07-01 06:14:54.692647+00:00</td>\n",
       "      <td>2025-07-01 06:14:56.342621+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>2c150fc600402bc7</td>\n",
       "      <td>5640d03ddee4c1a4733affef4e1ebae3</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>The most popular foreign-language fantasy movi...</td>\n",
       "      <td>What foreign-language fantasy movie was the mo...</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86b36e81f8a12b0e</th>\n",
       "      <td>movie_agent_improved</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-07-01 06:14:56.343718+00:00</td>\n",
       "      <td>2025-07-01 06:15:02.652487+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>86b36e81f8a12b0e</td>\n",
       "      <td>b3b8f774901c166a0b76441d093d7d62</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>In 2017, some of the highest-rated science fic...</td>\n",
       "      <td>what are the best sci-fi movies of 2017?</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03610eb2d13d7f12</th>\n",
       "      <td>movie_agent_improved</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-07-01 06:15:02.654279+00:00</td>\n",
       "      <td>2025-07-01 06:15:04.477173+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>03610eb2d13d7f12</td>\n",
       "      <td>d7eb7b890af9895cc5eccfe166d838fc</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>What anime topped the box office in the 2010s?</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name span_kind parent_id  \\\n",
       "context.span_id                                              \n",
       "9c66b61c2cf52502  movie_agent_improved     AGENT      None   \n",
       "55a8b854d602f733  movie_agent_improved     AGENT      None   \n",
       "2c150fc600402bc7  movie_agent_improved     AGENT      None   \n",
       "86b36e81f8a12b0e  movie_agent_improved     AGENT      None   \n",
       "03610eb2d13d7f12  movie_agent_improved     AGENT      None   \n",
       "\n",
       "                                       start_time  \\\n",
       "context.span_id                                     \n",
       "9c66b61c2cf52502 2025-07-01 06:14:51.803067+00:00   \n",
       "55a8b854d602f733 2025-07-01 06:14:53.118755+00:00   \n",
       "2c150fc600402bc7 2025-07-01 06:14:54.692647+00:00   \n",
       "86b36e81f8a12b0e 2025-07-01 06:14:56.343718+00:00   \n",
       "03610eb2d13d7f12 2025-07-01 06:15:02.654279+00:00   \n",
       "\n",
       "                                         end_time status_code status_message  \\\n",
       "context.span_id                                                                \n",
       "9c66b61c2cf52502 2025-07-01 06:14:53.117168+00:00          OK                  \n",
       "55a8b854d602f733 2025-07-01 06:14:54.688625+00:00          OK                  \n",
       "2c150fc600402bc7 2025-07-01 06:14:56.342621+00:00          OK                  \n",
       "86b36e81f8a12b0e 2025-07-01 06:15:02.652487+00:00          OK                  \n",
       "03610eb2d13d7f12 2025-07-01 06:15:04.477173+00:00          OK                  \n",
       "\n",
       "                 events   context.span_id                  context.trace_id  \\\n",
       "context.span_id                                                               \n",
       "9c66b61c2cf52502     []  9c66b61c2cf52502  ca223f4d90f76412af4a5d6c7f819c57   \n",
       "55a8b854d602f733     []  55a8b854d602f733  e8ce61899e4b12e8ed29b39f4192164e   \n",
       "2c150fc600402bc7     []  2c150fc600402bc7  5640d03ddee4c1a4733affef4e1ebae3   \n",
       "86b36e81f8a12b0e     []  86b36e81f8a12b0e  b3b8f774901c166a0b76441d093d7d62   \n",
       "03610eb2d13d7f12     []  03610eb2d13d7f12  d7eb7b890af9895cc5eccfe166d838fc   \n",
       "\n",
       "                 attributes.openinference.span.kind  \\\n",
       "context.span_id                                       \n",
       "9c66b61c2cf52502                              AGENT   \n",
       "55a8b854d602f733                              AGENT   \n",
       "2c150fc600402bc7                              AGENT   \n",
       "86b36e81f8a12b0e                              AGENT   \n",
       "03610eb2d13d7f12                              AGENT   \n",
       "\n",
       "                 attributes.output.mime_type  \\\n",
       "context.span_id                                \n",
       "9c66b61c2cf52502                  text/plain   \n",
       "55a8b854d602f733                  text/plain   \n",
       "2c150fc600402bc7                  text/plain   \n",
       "86b36e81f8a12b0e                  text/plain   \n",
       "03610eb2d13d7f12                  text/plain   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "context.span_id                                                       \n",
       "9c66b61c2cf52502  The Brad Pitt movie that received the highest ...   \n",
       "55a8b854d602f733  The top-grossing Marvel movie is \"Avengers: En...   \n",
       "2c150fc600402bc7  The most popular foreign-language fantasy movi...   \n",
       "86b36e81f8a12b0e  In 2017, some of the highest-rated science fic...   \n",
       "03610eb2d13d7f12                                      I don't know.   \n",
       "\n",
       "                                             attributes.input.value  \\\n",
       "context.span_id                                                       \n",
       "9c66b61c2cf52502  Which Brad Pitt movie received the highest rat...   \n",
       "55a8b854d602f733             What is the top grossing Marvel movie?   \n",
       "2c150fc600402bc7  What foreign-language fantasy movie was the mo...   \n",
       "86b36e81f8a12b0e           what are the best sci-fi movies of 2017?   \n",
       "03610eb2d13d7f12     What anime topped the box office in the 2010s?   \n",
       "\n",
       "                 attributes.input.mime_type  \n",
       "context.span_id                              \n",
       "9c66b61c2cf52502                 text/plain  \n",
       "55a8b854d602f733                 text/plain  \n",
       "2c150fc600402bc7                 text/plain  \n",
       "86b36e81f8a12b0e                 text/plain  \n",
       "03610eb2d13d7f12                 text/plain  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.client import Client\n",
    "from phoenix.client.types.spans import SpanQuery\n",
    "\n",
    "phoenix_client = Client()\n",
    "query = SpanQuery().where(\"name == 'movie_agent_improved'\")\n",
    "\n",
    "spans_df = phoenix_client.spans.get_spans_dataframe(\n",
    "    project_identifier=\"movie-agent-improved\", query=query\n",
    ")\n",
    "\n",
    "spans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3a62106eae400eb3e9dfb7d2f8d498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/6 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9c66b61c2cf52502</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Voom Portraits\" is not a widely recognized Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55a8b854d602f733</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The answer correctly identifies \"Avengers: End...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c150fc600402bc7</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer claims that \"The Nights Belong to M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86b36e81f8a12b0e</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer lists several movies with perfect s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03610eb2d13d7f12</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer 'I don't know' does not provide any...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  score  \\\n",
       "context.span_id                      \n",
       "9c66b61c2cf52502  incorrect      0   \n",
       "55a8b854d602f733    correct      1   \n",
       "2c150fc600402bc7  incorrect      0   \n",
       "86b36e81f8a12b0e  incorrect      0   \n",
       "03610eb2d13d7f12  incorrect      0   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "9c66b61c2cf52502  \"Voom Portraits\" is not a widely recognized Br...  \n",
       "55a8b854d602f733  The answer correctly identifies \"Avengers: End...  \n",
       "2c150fc600402bc7  The answer claims that \"The Nights Belong to M...  \n",
       "86b36e81f8a12b0e  The answer lists several movies with perfect s...  \n",
       "03610eb2d13d7f12  The answer 'I don't know' does not provide any...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.evals import llm_classify\n",
    "from phoenix.evals.models import OpenAIModel\n",
    "from phoenix.evals.templates import PromptTemplate\n",
    "\n",
    "evals_df = llm_classify(\n",
    "    data=spans_df,\n",
    "    model=OpenAIModel(model=\"gpt-4o\"),\n",
    "    rails=[\"correct\", \"incorrect\"],\n",
    "    template=PromptTemplate(\n",
    "        template=eval_prompt,\n",
    "    ),\n",
    "    exit_on_error=False,\n",
    "    provide_explanation=True,\n",
    ")\n",
    "\n",
    "## Assign 1 to correct and 0 to incorrect\n",
    "evals_df[\"score\"] = evals_df[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)\n",
    "evals_df[[\"label\", \"score\", \"explanation\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeldking/anaconda3/envs/phoenix/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (11.2.0) and client (11.1.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(\n",
    "        dataframe=evals_df,\n",
    "        eval_name=\"llm_correctness\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our improved agent now is able to answers all 6 questions but our `llm_correctness` eval was able to spot that the agent responses are not very good:\n",
    "\n",
    "- querying for `Anime` and responding with `Frozen II` misses the mark on anime being a japanese form of animation\n",
    "- the LLM thinks \"top\" or \"best\" means rating but doesn't take into account the number of votes. \n",
    "\n",
    "Our `txt2sql` prompt still needs more instructions if we want to improve it's performance. But we're on the right track and can find more ways to guide the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "This tutorial demonstrated the core principles of building **evals that work** for AI applications. Here are the key concepts you should take away:\n",
    "\n",
    "1. **Build & Trace**: Instrument your AI application with tracing from day one\n",
    "2. **Annotate**: Use human judgment to label traces with simple heuristics like correct/incorrect  \n",
    "3. **Create Evaluators**: Build both simple programmatic evals as well as LLM judges\n",
    "4. **Experiment**: Run systematic experiments to compare different approaches\n",
    "5. **Iterate**: Use evaluation results to improve prompts, models, or architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Bibliography\n",
    "\n",
    "<cite id=\"aires2024\">Aires, A. R. (2024). *Movies Dataset*. Hugging Face Datasets. https://huggingface.co/AiresPucrs</cite>\n",
    "\n",
    "<cite id=\"goyal2024\">Goyal, A. (2024). *LLM Eval for TxtToSql Notebook*. Braintrust Cookbook. https://www.braintrust.dev/docs/cookbook/recipes/Text2SQL-Data</cite>\n",
    "\n",
    "<cite id=\"yan2025\">Yan, Z. (2025). An LLM-as-Judge Won't Save The Product‚ÄîFixing Your Process Will. *eugeneyan.com*. https://eugeneyan.com/writing/eval-process/</cite>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
