{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYET8LC-3koX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E3qLx9JwjMuj"
   },
   "outputs": [],
   "source": [
    "!pip install -qq arize-phoenix llama-index \"openai>=1\" gcsfs nest_asyncio langchain langchain-community cohere llama-index-postprocessor-cohere-rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EejzP1ov3wgw"
   },
   "source": [
    "Set up environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfHrgDaHjkFP",
    "outputId": "4f28de04-c240-42bb-e49a-a8abe892bd10"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "if not (cohere_api_key := os.getenv(\"COHERE_API_KEY\")):\n",
    "    cohere_api_key = getpass(\"ðŸ”‘ Enter your Cohere API key: \")\n",
    "os.environ[\"COHERE_API_KEY\"] = cohere_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrRN-Tur32Qd"
   },
   "source": [
    "## Launch Phoenix and Instrumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RDmiCpAlK3Wd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/arize/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ig1vG4l5co7-"
   },
   "outputs": [],
   "source": [
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OP5ELmg4LeS"
   },
   "source": [
    "## Parse Phoenix Documentation into Llama-Index Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6cVWlJGjsMO",
    "outputId": "649293f3-48a6-470e-f9e1-0de741667746"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [langchain_community.utils.user_agent] USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# The nest_asyncio module enables the nesting of asynchronous functions within an already running async loop.\n",
    "# This is necessary because Jupyter notebooks inherently operate in an asynchronous loop.\n",
    "# By applying nest_asyncio, we can run additional async functions within this existing loop without conflicts.\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import GitbookLoader\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWDCQJN1co7-"
   },
   "source": [
    "Enable Phoenix tracing via `LlamaIndexInstrumentor`. Phoenix uses OpenInference traces - an open-source standard for capturing and storing LLM application traces that enables LLM applications to seamlessly integrate with LLM observability solutions such as Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9mFzfnlj2rV",
    "outputId": "b52d862f-bb3c-41f6-b07a-3ad0e18c5cc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/arize/lib/python3.12/html/parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "Fetching pages: 100%|##########| 126/126 [00:45<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fetches the Arize documentation from Gitbook and serializes it into LangChain format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_gitbook_docs(docs_url: str):\n",
    "    \"\"\"Loads documents from a Gitbook URL.\n",
    "\n",
    "    Args:\n",
    "        docs_url (str): URL to Gitbook docs.\n",
    "\n",
    "    Returns:\n",
    "        List[LangChainDocument]: List of documents in LangChain format.\n",
    "    \"\"\"\n",
    "    loader = GitbookLoader(\n",
    "        docs_url,\n",
    "        load_all_paths=True,\n",
    "    )\n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# fetch documentation\n",
    "docs_url = \"https://docs.arize.com/phoenix\"\n",
    "embedding_model_name = \"text-embedding-ada-002\"\n",
    "docs = load_gitbook_docs(docs_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B5KT9icyk_Lh"
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for doc in docs:\n",
    "    documents.append(Document(metadata=doc.metadata, text=doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CemnegejgI7f",
    "outputId": "1f7e434f-4e1b-4937-9478-aa1f0cedc2e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://docs.arize.com/phoenix/', 'title': 'Arize Phoenix'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lAPNcG-RHWL2"
   },
   "outputs": [],
   "source": [
    "# Convert documents to a JSON serializable format (if needed)\n",
    "documents_json = [doc.to_dict() for doc in documents]\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"llama_index_documents.json\", \"w\") as file:\n",
    "    json.dump(documents_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3pYhJwq4VwX"
   },
   "source": [
    "## Set Up VectorStore and Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4S8pfGvFluIg"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "# Define an LLM\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Build index with a chunk_size of 1024\n",
    "# node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "# nodes = node_parser.get_nodes_from_documents(documents)\n",
    "splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=250)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOmyBVoSco7-"
   },
   "source": [
    "Build a QueryEngine and start querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OB49Cghco7-",
    "outputId": "95c7afd2-4d6c-41dc-f1ce-e636e1516a24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/arize/lib/python3.12/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "cohere_rerank = CohereRerank(api_key=cohere_api_key, top_n=2)\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmlw_irPco7_"
   },
   "source": [
    "## Import Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "21s8Kk3znqJ-"
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_parquet(\"PhoenixRAGUseCaseQuestions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "qKpbdBFwsKuC",
    "outputId": "cd5feb82-1643-440b-dd21-9294cdb09394"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt/ Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens if I send the same traces twice?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which frameworks and LLM providers are support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can users create and manage datasets for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does Arize Phoenix use OpenTelemetry?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What is the Data retention policy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Will hosted Phoenix be on the latest version o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Is Hosted Phoenix free?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Can I persist data in the notebook?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Prompt/ Question\n",
       "0                    How do I send traces to Phoenix?\n",
       "1      What happens if I send the same traces twice? \n",
       "2   Which frameworks and LLM providers are support...\n",
       "3   How can users create and manage datasets for p...\n",
       "4           How does Arize Phoenix use OpenTelemetry?\n",
       "..                                                ...\n",
       "95                 What is the Data retention policy?\n",
       "96  Will hosted Phoenix be on the latest version o...\n",
       "97                            Is Hosted Phoenix free?\n",
       "98                Can I persist data in the notebook?\n",
       "99               Can I use gRPC for trace collection?\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc7hbkyu5zr3"
   },
   "source": [
    "## Generate Answers for all of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HmTkFYJsLq4",
    "outputId": "c6c18359-d7e1-4180-f194-2d67b27b6c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How do I send traces to Phoenix?\n",
      "Answer: To send traces to Phoenix, you can configure your application to log traces to a remote instance of Phoenix by setting the host and port where the traces will be sent. This can be done by using the environment variables PHOENIX_HOST and PHOENIX_PORT, or by setting the PHOENIX_COLLECTOR_ENDPOINT environment variable. By configuring your instrumentation in this way, your application will be able to send traces to the specified Phoenix instance for collection and visualization.\n",
      "\n",
      "Question: What happens if I send the same traces twice? \n",
      "Answer: Tracing records the paths taken by requests as they move through multiple steps. Sending the same traces twice would likely result in duplicate records of the paths taken by those requests, potentially leading to redundant information being captured in the tracing system.\n",
      "\n",
      "Question: Which frameworks and LLM providers are supported by Arize Phoenix for seamless integration?\n",
      "Answer: Arize Phoenix supports a variety of frameworks and LLM providers for seamless integration, including OpenAI, LangChain, MistralAI, VertexAI, DSPy, AWS Bedrock, Guardrails AI, Haystack, and CrewAI.\n",
      "\n",
      "Question: How can users create and manage datasets for prompt testing and fine-tuning in Arize Phoenix?\n",
      "Answer: Users can create and manage datasets for prompt testing and fine-tuning in Arize Phoenix by utilizing the tools provided for data exploration, cleaning, and labeling. These tools enable teams to curate high-quality data that covers a wide range of use cases and edge conditions, facilitating effective prompt testing and fine-tuning processes within the platform.\n",
      "\n",
      "Question: How does Arize Phoenix use OpenTelemetry?\n",
      "Answer: Arize Phoenix uses OpenTelemetry for instrumentation and tracing purposes.\n",
      "\n",
      "Question: How can users visualize embeddings in Arize Phoenix?\n",
      "Answer: Users can visualize embeddings in Arize Phoenix by projecting the embeddings into a lower dimensional space (3 dimensions) using a dimension reduction algorithm called UMAP (Uniform Manifold Approximation and Projection). This allows users to understand how their embeddings have encoded semantic meaning in a visually understandable way. Additionally, users can assign colors to the UMAP point-cloud by dimension, performance, and inference to explore the point-cloud from different perspectives.\n",
      "\n",
      "Question: What are the main objectives of Arize Phoenix?\n",
      "Answer: The main objectives of Arize Phoenix are to provide an open-source observability library for AI Engineers and Data Scientists to visualize data, evaluate performance, track down issues, and export data to improve their AI models.\n",
      "\n",
      "Question: What are the steps to set up Arize Phoenix in a local environment?\n",
      "Answer: To set up Arize Phoenix in a local environment, you can follow these steps:\n",
      "\n",
      "1. Install Phoenix using pip or conda, or pull the Phoenix server image from Docker Hub.\n",
      "2. Launch Phoenix locally using command line, Docker, or within a notebook.\n",
      "3. Customize your deployment based on your use-case.\n",
      "4. Connect your application to your Phoenix instance by pointing it to the local Phoenix server.\n",
      "5. Optionally, you can configure external storage for data persistence using SQLite or Postgres.\n",
      "6. Ensure Docker is installed and running on your system if using Docker for local setup.\n",
      "\n",
      "Question: What types of traces can be collected using Arize Phoenix?\n",
      "Answer: Traces for debugging, experimentation, prompt tracking, and search and retrieval can be collected using Arize Phoenix.\n",
      "\n",
      "Question: What can I expect to see in an Arize Phoenix trace?\n",
      "Answer: You can expect to see detailed insights into the execution flow, specific spans, performance metrics, logs, and metadata in an Arize Phoenix trace.\n",
      "\n",
      "Question: What are the different types of spans?\n",
      "Answer: CHAIN, RETRIEVER, RERANKER, LLM, EMBEDDING, TOOL, AGENT\n",
      "\n",
      "Question: Why I am seeing X span in my trace?\n",
      "Answer: You are seeing X span in your trace because the span represents a unit of work or operation that tracks specific operations made during the execution of a request. Spans provide detailed information about the operations they track, including attributes, time-related data, and structured log messages. Each span in a trace contributes to painting a picture of what occurred during the time in which that operation was executed.\n",
      "\n",
      "Question: How do I get the last 7 days of traces?\n",
      "Answer: To get the last 7 days of traces, you can utilize the timestamp information associated with the traces. By filtering the trace data based on the timestamps within the last 7 days, you can extract the relevant traces for that specific time period.\n",
      "\n",
      "Question: How do I get spans with no evaluations?\n",
      "Answer: To get spans with no evaluations, you can apply a filter in your query using the syntax \"evals['correctness'].label is None\". This filter will help you retrieve spans that do not have any evaluation attached yet.\n",
      "\n",
      "Question: How do I run an evaluation?\n",
      "Answer: You can run evaluations by using cron to execute the evaluation script as a cron job periodically. This script will augment the evaluations in Phoenix by continuously querying a LangChain application to send new traces and spans to your Phoenix session, running evaluations such as Hallucination, Q&A Correctness, and Relevance, and logging the evaluations back to Phoenix for visualization in the UI.\n",
      "\n",
      "Question: What is an evaluation?\n",
      "Answer: An evaluation is a process of assessing the quality of generated results or retrieval in LLM development. It involves measuring whether the response matches the retrieved context or query, determining the relevance of retrieved sources, and checking for correctness, hallucinations, or toxicity in AI responses. Evaluations can be done using a combination of input (query), output (response), and context, and can provide valuable feedback on the performance of an LLM application.\n",
      "\n",
      "Question: What is a trace?\n",
      "Answer: A trace records the paths taken by requests as they move through multiple steps, providing visibility into the journey of a request from start to finish. Tracing is crucial for understanding the flow of requests within an application or system, especially in scenarios where performance issues need to be diagnosed and resolved effectively.\n",
      "\n",
      "Question: What are prompts?\n",
      "Answer: Prompts are templates that can be instrumented with variables to track and visualize changes. They can be used to measure performance changes driven by each prompt and are commonly used in conjunction with experiments. Prompts consist of a template (a non-empty string), a version (a non-empty string), and variables (a dictionary with string keys). These prompts are serialized to JSON when saved to the OpenTelemetry Context and remain a JSON string when sent as span attributes.\n",
      "\n",
      "Question: What are prompt templates?\n",
      "Answer: Prompt templates are used to track and visualize prompt changes. They can be combined with Experiments to measure the performance changes driven by each prompt. Prompt templates consist of a template (non-empty string), version (non-empty string), and variables (a dictionary with string keys). These templates are added to the current OpenTelemetry Context using a context manager or decorator, allowing for the generation of spans with specific attributes related to the prompt template, version, and variables.\n",
      "\n",
      "Question: What is a prompt variable?\n",
      "Answer: A prompt variable is a key-value pair that represents specific information within a prompt template. It consists of a key, which is a string that identifies the information, and a corresponding value, which provides the specific data associated with that key.\n",
      "\n",
      "Question: What is Phoenix for?\n",
      "Answer: Phoenix is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows AI Engineers and Data Scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\n",
      "\n",
      "Question: How is Phoenix different than other observability platforms?\n",
      "Answer: Phoenix offers a comprehensive observability platform designed specifically for AI Engineers and Data Scientists to visualize data, evaluate performance, track down issues, and export data to improve. It provides essential tools for debugging, experimentation, evaluation, prompt tracking, and search and retrieval, making it stand out as a specialized observability solution tailored for AI applications.\n",
      "\n",
      "Question: When do I use Phoenix vs. Arize?\n",
      "Answer: You use Phoenix for experimentation, evaluation, and troubleshooting, allowing AI Engineers and Data Scientists to visualize data, evaluate performance, track down issues, and export data to improve. On the other hand, Arize, the enterprise counterpart of Phoenix, works hand-in-hand with Phoenix to share embeddings data easily for further investigation or to kickoff retraining workflows.\n",
      "\n",
      "Question: What can I do with the Phoenix API?\n",
      "Answer: With the Phoenix API, you can visualize data, evaluate performance, track down issues, and export data for further analysis and improvement.\n",
      "\n",
      "Question: Can you explain llm_classify?\n",
      "Answer: llm_classify is a function used to classify data based on a provided template using an LLM model. It takes in a dataframe, a template, the LLM model, a list of rails, and a flag to provide an explanation. The function outputs a Dataframe with columns 'label' and 'explanation'.\n",
      "\n",
      "Question: What is run_evals?\n",
      "Answer: run_evals is a function that evaluates a pandas dataframe using a set of user-specified evaluators that assess each row for relevance of retrieved documents, hallucinations, toxicity, etc. It outputs a list of dataframes, one for each evaluator, that contain the labels, scores, and optional explanations from the corresponding evaluator applied to the input dataframe.\n",
      "\n",
      "Question: What pre-built evaluators does Phoenix support?\n",
      "Answer: Phoenix supports pre-built evaluators for Retrieval Eval, Hallucination Eval, Toxicity Eval, Q&A Eval, Summarization Eval, and Code Generation Eval.\n",
      "\n",
      "Question: What is LLM as a judge?\n",
      "Answer: LLM as a judge involves using a Language Model (LLM) to evaluate the output of another system or model. This approach combines human-like assessment with machine efficiency to assess various criteria such as hallucination, toxicity, accuracy, and other characteristics in a more scalable and efficient manner.\n",
      "\n",
      "Question: How do I enable explanations for evals?\n",
      "Answer: Enable explanations for evals by setting the flag `provide_explanation` to True when using any of the templates or your own custom templates.\n",
      "\n",
      "Question: How do I get started?\n",
      "Answer: To get started, you should check out the development guide, code of conduct, and Contribution License Agreement. Additionally, it is recommended to pick a GitHub issue labeled with the tag \"good first issue\" to familiarize yourself with the codebase as a first-time contributor.\n",
      "\n",
      "Question: Should I use quantitative or qualitative data types for evals?\n",
      "Answer: You should use qualitative data types for evals.\n",
      "\n",
      "Question: How do I send in an evaluation?\n",
      "Answer: You can send in an evaluation by using the `log_evaluations` function provided by the Phoenix client. The evaluation must have a name specified and its DataFrame should contain identifiers for the subject of evaluation, such as a span or a document, along with values under the `score`, `label`, or `explanation` columns. The name of the evaluation must be supplied through the `eval_name=` parameter when sending the evaluation to Phoenix.\n",
      "\n",
      "Question: Tell me about datasets\n",
      "Answer: Datasets are collections of examples that provide inputs and, optionally, expected reference outputs for assessing applications. Each example within a dataset represents a single data point, consisting of an inputs dictionary, an optional output dictionary, and an optional metadata dictionary. Datasets allow for the collection of data from various sources like production, staging, evaluations, and manual inputs. They are used to run experiments and evaluations to track improvements in applications. Datasets can be created manually, from historical logs, or through synthetic data generation. They are integral to evaluation in AI development, helping developers understand the impact of changes on performance and enabling them to make informed decisions based on tangible feedback.\n",
      "\n",
      "Question: What is a dataset?\n",
      "Answer: A dataset is a collection of examples that provide inputs and, optionally, expected reference outputs for assessing an application. Each example within a dataset represents a single data point, consisting of an inputs dictionary, an optional output dictionary, and an optional metadata dictionary. Datasets are integral to evaluation and experimentation, allowing data collection from various sources like production, staging, evaluations, and manual inputs. They are used to run experiments and evaluations to track improvements in applications.\n",
      "\n",
      "Question: What is an experiment?\n",
      "Answer: An experiment involves defining/uploading a dataset, creating a task, defining evaluators, and running the experiment. It is a process where tasks are performed on examples from a dataset to evaluate the output and track improvements in the application being developed.\n",
      "\n",
      "Question: When do I use experiments?\n",
      "Answer: You use experiments in AI development to understand how a change will affect performance, helping to distill the indeterminism of LLMs into tangible feedback that assists in shipping a more reliable product.\n",
      "\n",
      "Question: How do I add data to a dataset?\n",
      "Answer: You can add data to a dataset in Phoenix by either manually curating examples, using historical logs from your application, generating synthetic data, or uploading data from spans traced using instrumentation in the Phoenix UI.\n",
      "\n",
      "Question: What is RAG?\n",
      "Answer: RAG stands for Retrieval Augmented Generation. It is a technique that dynamically incorporates specific data as context during the generation process without altering the training data of Language Model Models (LLMs). This allows the model to access and utilize real-time data to provide more tailored and contextually relevant responses.\n",
      "\n",
      "Question: How do I debug retrieval?\n",
      "Answer: To debug retrieval, you can start by logging your retrievals from your vector store to Phoenix and running evaluations. This involves collecting samples from your vector store to compare against later, logging prompt/response pairs from the deployed application, and then running evaluations on the retrieved data. By following these steps, you can identify any issues such as sections not being retrieved or sections receiving excessive traffic, allowing you to optimize your retrieval process effectively.\n",
      "\n",
      "Question: How do I improve my RAG system?\n",
      "Answer: To improve your RAG system, you can focus on enhancing the stages within the RAG pipeline. This includes optimizing the loading process to efficiently bring in your data from various sources, ensuring effective indexing by creating robust data structures for querying, implementing efficient storing mechanisms to avoid unnecessary re-indexing, refining querying strategies to leverage LLMs and data structures effectively, and conducting thorough evaluations to measure the accuracy, faithfulness, and speed of your responses to queries. Additionally, you can explore advanced techniques in RAG such as incorporating more sophisticated metadata strategies, refining the retrieval process for better context relevance, and continuously iterating on your RAG pipeline based on evaluation results to enhance its overall performance.\n",
      "\n",
      "Question: What is hosted Phoenix?\n",
      "Answer: Hosted Phoenix is a version of Phoenix that is hosted by the service provider, allowing developers to trace their LLM applications without the need to set up their own infrastructure. It runs the latest version of the open-source package and requires users to create an account, add API keys for data access and user authentication, and use 3rd party analytics tools for measuring application usage.\n",
      "\n",
      "Question: What are the deployment options for Phoenix?\n",
      "Answer: The deployment options for Phoenix include self-hosting Phoenix as a container, deploying an LLM application with Phoenix observability, setting up a persistent disc or database, deploying Phoenix on Kubernetes, and deploying Phoenix using Docker.\n",
      "\n",
      "Question: Tell me about sessions\n",
      "Answer: Sessions in Phoenix refer to instances that maintain the state of the Phoenix app. These sessions can be launched with specific configurations, such as primary and reference inferences or a single dataset. An active session can be obtained using the `active_session()` method, and it can be used to open the Phoenix UI within a notebook or in a separate browser tab or window. Additionally, sessions can be closed using the `close_app()` method.\n",
      "\n",
      "Question: How do I configure projects?\n",
      "Answer: To configure projects in Phoenix, you can set the project name using the `PHOENIX_PROJECT_NAME` environment variable. This variable allows you to group traces under specific projects. In a notebook environment, you can set the project name before adding instrumentation or running any code. Additionally, when using Phoenix as a collector and running your application separately, you can set the project name in the Resource attributes for the trace provider.\n",
      "\n",
      "Question: How does tracing work?\n",
      "Answer: Tracing works by instrumenting an application to emit traces for analysis. This can be done manually or automatically through plugins called instrumentors. These instrumentors collect spans for the application, which are then exported to a collector by an exporter. The Phoenix server acts as the collector and UI for troubleshooting, receiving spans from applications via the OpenTelemetry Protocol (OTLP) over HTTP.\n",
      "\n",
      "Question: What is auto-instrumentation?\n",
      "Answer: Auto-instrumentation is the process of automatically collecting traces from frameworks and libraries within a system to make it observable. This involves emitting traces from the components of the system's code.\n",
      "\n",
      "Question: What is manual-instrumentation?\n",
      "Answer: Manual instrumentation refers to the process of directly adding code to an application to collect specific tracing data for monitoring and analyzing the performance of the application. This involves manually inserting code snippets or libraries into the application's codebase to track and record various metrics, such as span IDs, start and end times, status codes, attributes, events, and resource details.\n",
      "\n",
      "Question: Can you tell me about openinference?\n",
      "Answer: OpenInference is an open standard that encompasses model inference and LLM application tracing. It includes specifications for capturing the execution of an application that results in invocations of an LLM, as well as capturing inference logs from various model types and use-cases. Additionally, OpenInference facilitates automatic instrumentation of applications to make the system observable by emitting traces from the system's components.\n",
      "\n",
      "Question: What is open telemetry?\n",
      "Answer: OpenTelemetry is a protocol that allows traces to be sent from your application to the Phoenix collector. It is currently supported over HTTP and is the means by which traces arrive at the Phoenix collector for analysis and visualization.\n",
      "\n",
      "Question: What providers are supported with openinference?\n",
      "Answer: NodeTracerProvider\n",
      "\n",
      "Question: How do I create a custom evaluator?\n",
      "Answer: To create a custom evaluator, you can write a Python function that takes the output of an experiment run as an argument. This function can return a boolean or numeric value, which will be recorded as the evaluation score. For example, you can create a simple evaluator like checking if the output falls within a specific range, such as checking if a numeric value is between 1 and 100. More complex evaluators can utilize additional information by defining functions with specific parameter names that are bound to special values, such as input, output, expected, reference, or metadata. These parameters can be used in any combination and order to write custom complex evaluators. Additionally, you can use libraries like editdistance to calculate the similarity between the output and the expected value. To further customize how your evaluations show up in the Experiments UI, you can use the create_evaluator decorator.\n",
      "\n",
      "Question: Where can I get help with Phoenix?\n",
      "Answer: You can get help with Phoenix by joining the Phoenix Slack community.\n",
      "\n",
      "Question: Who can I ask for help?\n",
      "Answer: You can ask for help by reaching out to the support team or community forums related to the platform or tool you are using.\n",
      "\n",
      "Question: If I am using both llamaindex and langchain in the same application, can I set up instrumentation for both of them?\n",
      "Answer: Yes, you can set up instrumentation for both LlamaIndex and LangChain in the same application. Each module provides instructions on how to instrument them within your application, allowing you to collect and display traces from both LlamaIndex and LangChain in Arize Phoenix.\n",
      "\n",
      "Question: Is there any document for the search query syntax on phoenix UI? Is it possible to search for values in children spans?\n",
      "Answer: Yes, there is documentation available on how to query spans in Phoenix using the query DSL. You can search for specific values in children spans by filtering for the desired span kind and selecting the attributes you want to extract from those spans.\n",
      "\n",
      "Question: Is there a limit on the amount of messages we can send to the UI? \n",
      "Answer: There is no specific information provided in the context regarding a limit on the amount of messages that can be sent to the UI.\n",
      "\n",
      "Question: What model types are supported by Phoenix?\n",
      "Answer: Phoenix supports model types such as LLM, NLP, CV, and Tabular.\n",
      "\n",
      "Question: How can you make sure that chains are going to be nested? \n",
      "Answer: By ensuring that the LangChain is instrumented before running the application code, you can make sure that chains are going to be nested.\n",
      "\n",
      "Question: Explain the process of setting up custom evaluations in Arize Phoenix for a specific LLM task. How can the results from these evaluations inform model fine-tuning and dataset adjustments?\n",
      "Answer: To set up custom evaluations in Arize Phoenix for a specific LLM task, you first need to choose a metric that best suits your use case. Then, build a golden dataset that represents the type of data the LLM evaluation will encounter, ensuring it has ground truth labels for performance measurement. Next, decide which LLM to use for evaluation, which can differ from the one used in your application. After that, build the evaluation template by defining the input, the question being asked, and the possible output formats.\n",
      "\n",
      "Once the custom evaluation template is created, you can run the evaluation on your golden dataset to generate metrics such as overall accuracy, precision, recall, and F1 score. These metrics provide insights into the performance of the LLM model for the specific task. By analyzing these results, you can identify areas where the model may need fine-tuning or where the dataset may require adjustments to improve performance. This iterative process of evaluating, analyzing metrics, and making improvements based on the results helps enhance the model's accuracy and effectiveness for the given task.\n",
      "\n",
      "Question: What configuration steps are needed to set up Arize Phoenix for a new project?\n",
      "Answer: To set up Arize Phoenix for a new project, you need to create an account on phoenix.arize.com, obtain API keys from your Phoenix application, install necessary libraries, set up authentication and endpoint with the API key as an environment variable, and start instrumentation using the provided Python code. Additionally, you may need to add API keys as environment variables during tracing and when using the Client SDK for data collection and dataset uploads.\n",
      "\n",
      "Question: How can datasets be exported from Arize Phoenix?\n",
      "Answer: Datasets can be exported from Arize Phoenix by clicking the export button on the Embeddings and Inferences pages, which will generate a code snippet that can be copied into a Python environment and Phoenix installed. Alternatively, users can also query Arize for data directly using the Arize Python export client, after becoming more comfortable with the in-platform export functionality.\n",
      "\n",
      "Question: Which LLM providers are supported by Arize Phoenix?\n",
      "Answer: Arize Phoenix supports a variety of LLM providers such as OpenAI, Vertex AI, Azure Open AI, Anthropic, Mixtral/Mistral, AWS Bedrock, Falcon, Code Llama, Llama3, Deepseek, Deberta, DBRX, and Qwen.\n",
      "\n",
      "Question: How can users perform custom task evaluations in Arize Phoenix? \n",
      "Answer: Users can perform custom task evaluations in Arize Phoenix by utilizing the feature provided for evaluating traces.\n",
      "\n",
      "Question: How can users join the Arize Phoenix community for support?\n",
      "Answer: Users can join the Phoenix Slack community to ask questions, share findings, provide feedback, and connect with other developers for support.\n",
      "\n",
      "Question: What makes Arize Phoenix vendor-agnostic?\n",
      "Answer: Arize Phoenix is vendor-agnostic because it works with OpenTelemetry and OpenInference instrumentation, allowing it to be compatible with various environments and services regardless of the vendor.\n",
      "\n",
      "Question: Where should I look to learn how to use ragas with Phoenix?\n",
      "Answer: You should look into the tutorial that covers Ragas for synthetic test data generation and evaluation, as well as the sections on building a RAG pipeline and evaluating it with Phoenix Evals.\n",
      "\n",
      "Question: What steps are needed to set up automatic instrumentation in Arize Phoenix?\n",
      "Answer: To set up automatic instrumentation in Arize Phoenix, you need to install the OpenTelemetry SDK and the specific OpenInference instrumentation for the LLM framework you are using. First, install the OpenTelemetry SDK by running the provided npm command. Then, install the OpenInference instrumentation you want to use by running the respective npm command. Finally, load the desired instrumentation by specifying it in the registerInstrumentations call along with any additional instrumentation you wish to enable. Remember that the instrumentation must run before any other code in your application to capture spans effectively.\n",
      "\n",
      "Question: How can users import their inference data into Arize Phoenix?\n",
      "Answer: Users can import their inference data into Arize Phoenix by following the steps outlined in the documentation.\n",
      "\n",
      "Question: What are the key components of a schema in Arize Phoenix?\n",
      "Answer: The key components of a schema in Arize Phoenix are embeddings data, which can be easily shared to allow data science teams to investigate further insights or initiate retraining workflows.\n",
      "\n",
      "Question: How can users export inference data from Arize Phoenix?\n",
      "Answer: Users can export inference data from Arize Phoenix by clicking the export button on the Embeddings and Inferences pages. This action will generate a code snippet that can be copied into a Python environment after installing Phoenix. The code snippet will include the selected date range and inferences from the Arize platform.\n",
      "\n",
      "Question: What formats are supported for exporting inference data?\n",
      "Answer: Inference data can be exported in either a Parquet file format or as a dataframe in your session.\n",
      "\n",
      "Question: What formats are supported for exporting trace data?\n",
      "Answer: You can export trace data in the form of a dataframe from the session. Additionally, you have the option to apply a filter if you wish to export only a subset of spans.\n",
      "\n",
      "Question: How can users create a new session in Arize Phoenix?\n",
      "Answer: Users can create a new session in Arize Phoenix by running the command to install the library in their Jupyter or Colab environment.\n",
      "\n",
      "Question: How does Arize Phoenix Evals help in assessing the performance of LLM applications?\n",
      "Answer: Arize Phoenix Evals helps in assessing the performance of LLM applications by providing support for pre-tested evaluation templates, custom evaluation templates, data science rigor in benchmarking evaluations for reproducible results, designed for high throughput on batches of evaluation data, and the ability to run evaluations in different environments such as notebooks, Python pipelines, and LangChain/LlamaIndex callbacks. Additionally, Phoenix Evals allows evaluations to be conducted on both span and chain levels, ensuring a comprehensive assessment of LLM application performance.\n",
      "\n",
      "Question: How can users create custom evaluations in Arize Phoenix?\n",
      "Answer: Users can create custom evaluations in Arize Phoenix by utilizing the Custom Task Evaluation feature provided in the platform.\n",
      "\n",
      "Question: Where can users find detailed documentation on using Arize Phoenix Evals?\n",
      "Answer: Users can find detailed documentation on using Arize Phoenix Evals on the Arize website under the Evaluation Models and How to: Evals sections.\n",
      "\n",
      "Question: Is there a way to log_evaluation to hosted phoenix?\n",
      "Answer: Yes, there is a way to log evaluations to hosted Phoenix.\n",
      "\n",
      "Question: Is there a way to reduce NOT_PARSABLE responses during relevance evaluation?\n",
      "Answer: Yes, there is a way to reduce NOT_PARSABLE responses during relevance evaluation.\n",
      "\n",
      "Question: Is there any document for the search query syntax on phoenix UI?\n",
      "Answer: Phoenix UI does not have a specific document for search query syntax.\n",
      "\n",
      "Question: Is it possible to search for values in children spans?\n",
      "Answer: Yes, it is possible to search for values in children spans by using specific filtering criteria in the queries.\n",
      "\n",
      "Question: How can I export data from Arize to Phoenix?\n",
      "Answer: You can export data from Arize to Phoenix by clicking the export button on the Embeddings and Inferences pages, which will provide a code snippet to copy into a Python environment and install Phoenix. Another way is to query Arize for data directly using the Arize Python export client, where you can manually enter the data ranges and data you want to export.\n",
      "\n",
      "Question: How does tracing help in monitoring LLM applications?\n",
      "Answer: Tracing helps in monitoring LLM applications by allowing users to track application latency, token usage, runtime exceptions, retrieved documents, embeddings, LLM parameters, prompt templates, tool descriptions, and LLM function calls. This detailed tracing capability provides insights into the performance, behavior, and interactions within the LLM application, enabling users to identify and address issues effectively.\n",
      "\n",
      "Question: How do spans and traces differ in Arize Phoenix?\n",
      "Answer: Spans represent units of work or operations within a trace, tracking specific operations made during a request. They provide detailed information about what happened during the time a particular operation was executed. On the other hand, traces in Arize Phoenix are a collection of spans that together form a complete picture of the journey of a request through a system or application. Traces encompass multiple spans and provide a holistic view of the flow of operations and interactions within a request.\n",
      "\n",
      "Question: What are the benefits of using OpenTelemetry with Arize Phoenix?\n",
      "Answer: Using OpenTelemetry with Arize Phoenix provides the benefit of enabling seamless integration with a variety of frameworks and SDKs across Python and JavaScript. This allows for easy auto-instrumentation, which enhances observability and evaluation capabilities for AI Engineers and Data Scientists using Phoenix.\n",
      "\n",
      "Question: What customization options are available for tracing?\n",
      "Answer: Customization options available for tracing include logging to a specific project, switching projects in a notebook, adding custom metadata to spans, setting custom attributes and semantic attributes to child spans, setting metadata, tags, user information, prompt template attributes, and reading attributes from context.\n",
      "\n",
      "Question: How is trace data stored in Arize Phoenix?\n",
      "Answer: Trace data in Arize Phoenix can be stored by saving the traces to a designated location within the Phoenix instance or to an external file. The traces can be saved to a default Phoenix trace directory or to a specific directory by specifying the directory path when using the save method. When loading trace data, one can retrieve the saved traces by providing the trace ID and the directory path where the trace was stored.\n",
      "\n",
      "Question: How do I import existing traces?\n",
      "Answer: To import existing traces, you can either re-launch the app using trace data or load traces into an existing Phoenix instance.\n",
      "\n",
      "Question: How do I create a custom dataset?\n",
      "Answer: To create a custom dataset, you can start by manually curating examples based on the types of inputs your application is expected to handle and what desirable responses look like. Another approach is to leverage historical logs from your application to capture valuable information on how users interact with it. Additionally, you can consider generating synthetic data once you have a few initial examples to quickly expand your dataset. By following these steps, you can create a custom dataset tailored to your specific use case and application requirements.\n",
      "\n",
      "Question: How do I export datasets?\n",
      "Answer: You can export datasets by fine-tuning models to achieve higher quality results, train on more examples, save on tokens, and reduce latency requests. Phoenix natively supports exporting OpenAI Fine-Tuning JSONL and OpenAI Evals format as JSONL for evaluating large language models or building systems using LLMs.\n",
      "\n",
      "Question: How can I contribute to Phoenix?\n",
      "Answer: To contribute to Phoenix, you can start by checking out the development guide, code of conduct, and Contribution License Agreement. Pick a GitHub issue labeled with the tag \"good first issue\" to familiarize yourself with the codebase. Submit your code by forking the Phoenix repository, creating a new branch, and opening a Pull Request (PR) once your work is ready for review. In the PR template, describe the change, including the motivation/context, test coverage, and any other relevant information. A Core reviewer will review your PR, provide feedback, and once approved, your contribution will be merged into Phoenix.\n",
      "\n",
      "Question: How do I setup Phoenix in the Terminal?\n",
      "Answer: To set up Phoenix in the Terminal, you can run the following command:\n",
      "```\n",
      "python3 -m phoenix.server.main serve\n",
      "```\n",
      "This command will start the Phoenix server on port 6006. If you are running your instrumented notebook or application on the same machine, traces should automatically be exported to http://127.0.0.1:6006. If the server is running remotely, you will need to modify the environment variable PHOENIX_COLLECTOR_ENDPOINT to point to that machine.\n",
      "\n",
      "Question: Does Phoenix support JavaScript?\n",
      "Answer: Phoenix supports JavaScript, specifically TypeScript / JavaScript.\n",
      "\n",
      "Question: What coding languages does Phoenix support?\n",
      "Answer: Phoenix supports Python and TypeScript/JavaScript for auto-instrumentation.\n",
      "\n",
      "Question: How do I setup Phoenix as a Container?\n",
      "Answer: To set up Phoenix as a Container, you can start a long-running collector by pulling the Phoenix server image from Docker Hub and then running the image you pulled. Make sure to expose port 6006 so you can view the Phoenix UI at localhost:6006. If you are interested in hosted Phoenix, you can reach out for more information.\n",
      "\n",
      "Question: How do I setup Phoenix in a Notebook?\n",
      "Answer: To set up Phoenix in a Notebook, you can run the following code snippet:\n",
      "\n",
      "import phoenix as px\n",
      "\n",
      "session = px.launch_app()\n",
      "\n",
      "This code will initiate a local Phoenix server in the Notebook environment.\n",
      "\n",
      "Question: What is the Data retention policy?\n",
      "Answer: The data retention policy allows users to persist data in the notebook by setting the use_temp_dir flag to false in px.launch_app, which will store the data in SQLite on the disk at the PHOENIX_WORKING_DIR. Alternatively, users can deploy a Phoenix instance and point to it via PHOENIX_COLLECTOR_ENDPOINT.\n",
      "\n",
      "Question: Will hosted Phoenix be on the latest version of Phoenix?\n",
      "Answer: Hosted Phoenix will always be on the latest version of Phoenix.\n",
      "\n",
      "Question: Is Hosted Phoenix free?\n",
      "Answer: Hosted Phoenix is free for all developers, with plans to introduce a paid tier in the future that will offer increased data retention and additional storage access.\n",
      "\n",
      "Question: Can I persist data in the notebook?\n",
      "Answer: Persistence for notebooks (a.k.a. launch_app) is disabled by default. To enable persistence in notebooks, set the use_temp_dir to false. This will allow you to persist data in the notebook by storing it in SQLite on your disk at the PHOENIX_WORKING_DIR. Alternatively, you can deploy a Phoenix instance and point to it via PHOENIX_COLLECTOR_ENDPOINT.\n",
      "\n",
      "Question: Can I use gRPC for trace collection?\n",
      "Answer: Phoenix does natively support gRPC for trace collection post 4.0 release.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop over the questions and generate the answers\n",
    "for i, row in questions_df.iterrows():\n",
    "    if i in [25, 50, 75]:\n",
    "        time.sleep(30)\n",
    "    question = row[\"Prompt/ Question\"]\n",
    "    response_vector = query_engine.query(question)\n",
    "    print(f\"Question: {question}\\nAnswer: {response_vector.response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd6tXZk-59VT"
   },
   "source": [
    "## Phoenix Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "6iwW7y2Bco8H",
    "outputId": "49df3b47-4999-4a52-b4e6-d46da4e1654f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>document_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">87326ee6473536e6</th>\n",
       "      <th>0</th>\n",
       "      <td>7992e68b92676ddd307af12e9109d8d0</td>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "      <td>Tracing Core Concepts\\nHow to log traces\\nTo l...</td>\n",
       "      <td>0.841724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7992e68b92676ddd307af12e9109d8d0</td>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "      <td>How does Tracing Work?\\nThe components behind ...</td>\n",
       "      <td>0.840770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7992e68b92676ddd307af12e9109d8d0</td>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "      <td>Quickstart: Tracing\\nInspect the inner-working...</td>\n",
       "      <td>0.831993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7992e68b92676ddd307af12e9109d8d0</td>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "      <td>Save and Load Traces\\nHow to manually save and...</td>\n",
       "      <td>0.821883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7992e68b92676ddd307af12e9109d8d0</td>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "      <td>Quickstart: Deployment\\nHow to use phoenix out...</td>\n",
       "      <td>0.821791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6f1f37a94447966a</th>\n",
       "      <th>0</th>\n",
       "      <td>6fe13e1545c6ed73fc1e755f6c401f57</td>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "      <td>Use Cases: Tracing\\nThe following. guides serv...</td>\n",
       "      <td>0.773752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6fe13e1545c6ed73fc1e755f6c401f57</td>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "      <td>Overview: Tracing\\nTracing the execution of LL...</td>\n",
       "      <td>0.772057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6fe13e1545c6ed73fc1e755f6c401f57</td>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "      <td>How does Tracing Work?\\nThe components behind ...</td>\n",
       "      <td>0.767665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6fe13e1545c6ed73fc1e755f6c401f57</td>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "      <td>os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...</td>\n",
       "      <td>0.767380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6fe13e1545c6ed73fc1e755f6c401f57</td>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "      <td>tracer_provider \\n=\\n trace_sdk\\n.\\nTracerProv...</td>\n",
       "      <td>0.766101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    context.trace_id  \\\n",
       "context.span_id  document_position                                     \n",
       "87326ee6473536e6 0                  7992e68b92676ddd307af12e9109d8d0   \n",
       "                 1                  7992e68b92676ddd307af12e9109d8d0   \n",
       "                 2                  7992e68b92676ddd307af12e9109d8d0   \n",
       "                 3                  7992e68b92676ddd307af12e9109d8d0   \n",
       "                 4                  7992e68b92676ddd307af12e9109d8d0   \n",
       "...                                                              ...   \n",
       "6f1f37a94447966a 0                  6fe13e1545c6ed73fc1e755f6c401f57   \n",
       "                 1                  6fe13e1545c6ed73fc1e755f6c401f57   \n",
       "                 2                  6fe13e1545c6ed73fc1e755f6c401f57   \n",
       "                 3                  6fe13e1545c6ed73fc1e755f6c401f57   \n",
       "                 4                  6fe13e1545c6ed73fc1e755f6c401f57   \n",
       "\n",
       "                                                                   input  \\\n",
       "context.span_id  document_position                                         \n",
       "87326ee6473536e6 0                      How do I send traces to Phoenix?   \n",
       "                 1                      How do I send traces to Phoenix?   \n",
       "                 2                      How do I send traces to Phoenix?   \n",
       "                 3                      How do I send traces to Phoenix?   \n",
       "                 4                      How do I send traces to Phoenix?   \n",
       "...                                                                  ...   \n",
       "6f1f37a94447966a 0                  Can I use gRPC for trace collection?   \n",
       "                 1                  Can I use gRPC for trace collection?   \n",
       "                 2                  Can I use gRPC for trace collection?   \n",
       "                 3                  Can I use gRPC for trace collection?   \n",
       "                 4                  Can I use gRPC for trace collection?   \n",
       "\n",
       "                                                                            reference  \\\n",
       "context.span_id  document_position                                                      \n",
       "87326ee6473536e6 0                  Tracing Core Concepts\\nHow to log traces\\nTo l...   \n",
       "                 1                  How does Tracing Work?\\nThe components behind ...   \n",
       "                 2                  Quickstart: Tracing\\nInspect the inner-working...   \n",
       "                 3                  Save and Load Traces\\nHow to manually save and...   \n",
       "                 4                  Quickstart: Deployment\\nHow to use phoenix out...   \n",
       "...                                                                               ...   \n",
       "6f1f37a94447966a 0                  Use Cases: Tracing\\nThe following. guides serv...   \n",
       "                 1                  Overview: Tracing\\nTracing the execution of LL...   \n",
       "                 2                  How does Tracing Work?\\nThe components behind ...   \n",
       "                 3                  os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...   \n",
       "                 4                  tracer_provider \\n=\\n trace_sdk\\n.\\nTracerProv...   \n",
       "\n",
       "                                    document_score  \n",
       "context.span_id  document_position                  \n",
       "87326ee6473536e6 0                        0.841724  \n",
       "                 1                        0.840770  \n",
       "                 2                        0.831993  \n",
       "                 3                        0.821883  \n",
       "                 4                        0.821791  \n",
       "...                                            ...  \n",
       "6f1f37a94447966a 0                        0.773752  \n",
       "                 1                        0.772057  \n",
       "                 2                        0.767665  \n",
       "                 3                        0.767380  \n",
       "                 4                        0.766101  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_retrieved_documents\n",
    "\n",
    "retrieved_documents_df = get_retrieved_documents(px.Client())\n",
    "retrieved_documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "QzKMthtAxzsU",
    "outputId": "a65f625e-b1c5-4e51-ac9c-00ff0f3efbb9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ff4fb7579db0ee52</th>\n",
       "      <td>How do I send traces to Phoenix?</td>\n",
       "      <td>To send traces to Phoenix, you can configure y...</td>\n",
       "      <td>Tracing Core Concepts\\nHow to log traces\\nTo l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bdb657ba242734d</th>\n",
       "      <td>What happens if I send the same traces twice?</td>\n",
       "      <td>Tracing records the paths taken by requests as...</td>\n",
       "      <td>The reply half may be formatted for response p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245ef4388ed13f47</th>\n",
       "      <td>Which frameworks and LLM providers are support...</td>\n",
       "      <td>Arize Phoenix supports a variety of frameworks...</td>\n",
       "      <td>Arize\\nPhoenix works hand-in-hand with Arize, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e83f9dfcf0a0bbfd</th>\n",
       "      <td>How can users create and manage datasets for p...</td>\n",
       "      <td>Users can create and manage datasets for promp...</td>\n",
       "      <td>Arize\\nPhoenix works hand-in-hand with Arize, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8dcbbaa9b2d8dc0e</th>\n",
       "      <td>How does Arize Phoenix use OpenTelemetry?</td>\n",
       "      <td>Arize Phoenix uses OpenTelemetry for instrumen...</td>\n",
       "      <td>Arize Phoenix\\nAI Observability and Evaluation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5b8a027df5d99ba9</th>\n",
       "      <td>What is the Data retention policy?</td>\n",
       "      <td>The data retention policy allows users to pers...</td>\n",
       "      <td>Email Extraction\\nComing soon\\nPrevious\\nSumma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ced27f258bc7927d</th>\n",
       "      <td>Will hosted Phoenix be on the latest version o...</td>\n",
       "      <td>Hosted Phoenix will always be on the latest ve...</td>\n",
       "      <td>Deployment\\nHow to self-host a phoenix instanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f659caf9e7d6c944</th>\n",
       "      <td>Is Hosted Phoenix free?</td>\n",
       "      <td>Hosted Phoenix is free for all developers, wit...</td>\n",
       "      <td>Hosted Phoenix\\nWe now offer a hosted version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2c3e892839cc3ea</th>\n",
       "      <td>Can I persist data in the notebook?</td>\n",
       "      <td>Persistence for notebooks (a.k.a. launch_app) ...</td>\n",
       "      <td>os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6af288f0a1425951</th>\n",
       "      <td>Can I use gRPC for trace collection?</td>\n",
       "      <td>Phoenix does natively support gRPC for trace c...</td>\n",
       "      <td>Use Cases: Tracing\\nThe following. guides serv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              input  \\\n",
       "context.span_id                                                       \n",
       "ff4fb7579db0ee52                   How do I send traces to Phoenix?   \n",
       "8bdb657ba242734d     What happens if I send the same traces twice?    \n",
       "245ef4388ed13f47  Which frameworks and LLM providers are support...   \n",
       "e83f9dfcf0a0bbfd  How can users create and manage datasets for p...   \n",
       "8dcbbaa9b2d8dc0e          How does Arize Phoenix use OpenTelemetry?   \n",
       "...                                                             ...   \n",
       "5b8a027df5d99ba9                 What is the Data retention policy?   \n",
       "ced27f258bc7927d  Will hosted Phoenix be on the latest version o...   \n",
       "f659caf9e7d6c944                            Is Hosted Phoenix free?   \n",
       "a2c3e892839cc3ea                Can I persist data in the notebook?   \n",
       "6af288f0a1425951               Can I use gRPC for trace collection?   \n",
       "\n",
       "                                                             output  \\\n",
       "context.span_id                                                       \n",
       "ff4fb7579db0ee52  To send traces to Phoenix, you can configure y...   \n",
       "8bdb657ba242734d  Tracing records the paths taken by requests as...   \n",
       "245ef4388ed13f47  Arize Phoenix supports a variety of frameworks...   \n",
       "e83f9dfcf0a0bbfd  Users can create and manage datasets for promp...   \n",
       "8dcbbaa9b2d8dc0e  Arize Phoenix uses OpenTelemetry for instrumen...   \n",
       "...                                                             ...   \n",
       "5b8a027df5d99ba9  The data retention policy allows users to pers...   \n",
       "ced27f258bc7927d  Hosted Phoenix will always be on the latest ve...   \n",
       "f659caf9e7d6c944  Hosted Phoenix is free for all developers, wit...   \n",
       "a2c3e892839cc3ea  Persistence for notebooks (a.k.a. launch_app) ...   \n",
       "6af288f0a1425951  Phoenix does natively support gRPC for trace c...   \n",
       "\n",
       "                                                          reference  \n",
       "context.span_id                                                      \n",
       "ff4fb7579db0ee52  Tracing Core Concepts\\nHow to log traces\\nTo l...  \n",
       "8bdb657ba242734d  The reply half may be formatted for response p...  \n",
       "245ef4388ed13f47  Arize\\nPhoenix works hand-in-hand with Arize, ...  \n",
       "e83f9dfcf0a0bbfd  Arize\\nPhoenix works hand-in-hand with Arize, ...  \n",
       "8dcbbaa9b2d8dc0e  Arize Phoenix\\nAI Observability and Evaluation...  \n",
       "...                                                             ...  \n",
       "5b8a027df5d99ba9  Email Extraction\\nComing soon\\nPrevious\\nSumma...  \n",
       "ced27f258bc7927d  Deployment\\nHow to self-host a phoenix instanc...  \n",
       "f659caf9e7d6c944  Hosted Phoenix\\nWe now offer a hosted version ...  \n",
       "a2c3e892839cc3ea  os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...  \n",
       "6af288f0a1425951  Use Cases: Tracing\\nThe following. guides serv...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_qa_with_reference\n",
    "\n",
    "queries_df = get_qa_with_reference(px.active_session())\n",
    "queries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFECnz04co8H"
   },
   "source": [
    "Let's now use Phoenix's LLM Evals to evaluate the relevance of the retrieved documents with regards to the query. Note, we've turned on `explanations` which prompts the LLM to explain it's reasoning. This can be useful for debugging and for figuring out potential corrective actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8648201ffcab4023a1a54dde1b964b8b",
      "df7e8713256a48c2992f3dce61c702d1",
      "d9af102cb64142b3ac7ea6a75027e6a7",
      "59a894868a0344789e8458549f8aa894",
      "2c6eb911b6354343a46fca08b0b85f03",
      "88978e8ddc704d8e9d4048095047615a",
      "44f75a3f6c48404990251849a9be33ca",
      "ae22d487bb1b442cad9018897a53e623",
      "c6aab3035f8247b6a3e276b2e86fe79b",
      "99e5a5eeb1ef41d68f41bbd3cb98d544",
      "d946d51d35344047add12d14c8445f46"
     ]
    },
    "id": "Hq4sr_zIco8H",
    "outputId": "176a349e-727e-4a4c-c305-176fc34ae23a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 (100.0%) | â³ 01:58<00:00 |  3.15it/s"
     ]
    }
   ],
   "source": [
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "\n",
    "eval_model = OpenAIModel(model=\"gpt-4\")\n",
    "relevance_evaluator = RelevanceEvaluator(eval_model)\n",
    "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
    "qa_evaluator = QAEvaluator(eval_model)\n",
    "\n",
    "retrieved_documents_relevance_df = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=retrieved_documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "3363dcebe07847be99e7b41b3840d042",
      "90412f8febda4ab1bb22fe56e2392274",
      "f7654cf0da3f47da801c21b947fda6da",
      "82e8f507e44841f88be5c66c91b27f48",
      "8aeca790868b44babe415849afba77db",
      "5f8024635af64b0a99855ae3adef558d",
      "aed1f2822d114ce4be7dcddfbc2dfc20",
      "aea78f53909e44b195de5886df74fad1",
      "fcf5b6ce6ca94b48b80ed2aa8ced55d5",
      "d10322222cb3435fafdbbdc4d98e5059",
      "d1d54e8e26a54881b1380b02159203ad"
     ]
    },
    "id": "Pe9J4-zYwuCl",
    "outputId": "b3424ecb-9536-4230-92ce-debaf19e690b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 (100.0%) | â³ 01:59<00:00 |  4.19it/s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "run_evals |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 (100.0%) | â³ 01:07<00:00 |  1.33it/s"
     ]
    }
   ],
   "source": [
    "hallucination_eval_df, qa_eval_df = run_evals(\n",
    "    dataframe=queries_df,\n",
    "    evaluators=[hallucination_evaluator, qa_evaluator],\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "RaZwCSFico8I",
    "outputId": "14ef12b7-af63-4ab1-ec14-c9b7d198ed54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_position</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87326ee6473536e6</th>\n",
       "      <td>0</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about how to send traces to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87326ee6473536e6</th>\n",
       "      <td>1</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about how to send traces to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87326ee6473536e6</th>\n",
       "      <td>2</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about how to send traces to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87326ee6473536e6</th>\n",
       "      <td>3</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The question asks about how to send traces to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87326ee6473536e6</th>\n",
       "      <td>4</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about how to send traces to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f1f37a94447966a</th>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The question asks about the possibility of usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f1f37a94447966a</th>\n",
       "      <td>1</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The question asks about the possibility of usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f1f37a94447966a</th>\n",
       "      <td>2</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The question is asking about the possibility o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f1f37a94447966a</th>\n",
       "      <td>3</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks if gRPC can be used for trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f1f37a94447966a</th>\n",
       "      <td>4</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks if gRPC can be used for trac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  document_position      label  score  \\\n",
       "context.span_id                                         \n",
       "87326ee6473536e6                  0   relevant      1   \n",
       "87326ee6473536e6                  1   relevant      1   \n",
       "87326ee6473536e6                  2   relevant      1   \n",
       "87326ee6473536e6                  3  unrelated      0   \n",
       "87326ee6473536e6                  4   relevant      1   \n",
       "...                             ...        ...    ...   \n",
       "6f1f37a94447966a                  0  unrelated      0   \n",
       "6f1f37a94447966a                  1  unrelated      0   \n",
       "6f1f37a94447966a                  2  unrelated      0   \n",
       "6f1f37a94447966a                  3   relevant      1   \n",
       "6f1f37a94447966a                  4   relevant      1   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "87326ee6473536e6  The question asks about how to send traces to ...  \n",
       "87326ee6473536e6  The question asks about how to send traces to ...  \n",
       "87326ee6473536e6  The question asks about how to send traces to ...  \n",
       "87326ee6473536e6  The question asks about how to send traces to ...  \n",
       "87326ee6473536e6  The question asks about how to send traces to ...  \n",
       "...                                                             ...  \n",
       "6f1f37a94447966a  The question asks about the possibility of usi...  \n",
       "6f1f37a94447966a  The question asks about the possibility of usi...  \n",
       "6f1f37a94447966a  The question is asking about the possibility o...  \n",
       "6f1f37a94447966a  The question asks if gRPC can be used for trac...  \n",
       "6f1f37a94447966a  The question asks if gRPC can be used for trac...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents_relevance_df = retrieved_documents_relevance_df.reset_index().set_index(\n",
    "    \"context.span_id\"\n",
    ")\n",
    "retrieved_documents_relevance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "cCPWGtd0zPIl",
    "outputId": "cc6e820f-7b58-4f84-dd9e-2a926f48b163"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ff4fb7579db0ee52</th>\n",
       "      <td>factual</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text provides information on how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bdb657ba242734d</th>\n",
       "      <td>hallucinated</td>\n",
       "      <td>1</td>\n",
       "      <td>The query asks about the consequences of sendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245ef4388ed13f47</th>\n",
       "      <td>hallucinated</td>\n",
       "      <td>1</td>\n",
       "      <td>The query asks about the frameworks and LLM pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e83f9dfcf0a0bbfd</th>\n",
       "      <td>factual</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text provides information on how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8dcbbaa9b2d8dc0e</th>\n",
       "      <td>factual</td>\n",
       "      <td>0</td>\n",
       "      <td>The query asks about how Arize Phoenix uses Op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  score  \\\n",
       "context.span_id                         \n",
       "ff4fb7579db0ee52       factual      0   \n",
       "8bdb657ba242734d  hallucinated      1   \n",
       "245ef4388ed13f47  hallucinated      1   \n",
       "e83f9dfcf0a0bbfd       factual      0   \n",
       "8dcbbaa9b2d8dc0e       factual      0   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "ff4fb7579db0ee52  The reference text provides information on how...  \n",
       "8bdb657ba242734d  The query asks about the consequences of sendi...  \n",
       "245ef4388ed13f47  The query asks about the frameworks and LLM pr...  \n",
       "e83f9dfcf0a0bbfd  The reference text provides information on how...  \n",
       "8dcbbaa9b2d8dc0e  The query asks about how Arize Phoenix uses Op...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbH5A6cS6fd-"
   },
   "source": [
    "## Log the Evals into Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Xbs-D5W-zkDZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_evals |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 (100.0%) | â³ 01:08<00:00 |  2.93it/s\n",
      "/usr/local/Caskroom/mambaforge/base/envs/arize/lib/python3.12/site-packages/phoenix/trace/dsl/query.py:746: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_attributes = pd.DataFrame.from_records(\n"
     ]
    }
   ],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Hallucination\", dataframe=hallucination_eval_df),\n",
    "    SpanEvaluations(eval_name=\"QA Correctness\", dataframe=qa_eval_df),\n",
    "    SpanEvaluations(eval_name=\"Retrieval Relevance\", dataframe=retrieved_documents_relevance_df),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O2-3FxRc4ukO",
    "outputId": "1193ef27-1de3-400c-ed40-901784b879d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“º Opening a view to the Phoenix app. The app is running at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:6006/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15b81a180>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5IS5dvf6lkD"
   },
   "source": [
    "## Save the Trace and Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "id": "qG-RDMTsY5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Trace dataset saved to under ID: 6ba5bfd7-06f7-4df0-b56a-8de017b787fc\n",
      "ðŸ“‚ Trace dataset path: my_saved_traces/trace_dataset-6ba5bfd7-06f7-4df0-b56a-8de017b787fc.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify and Create the Directory for Trace Dataset\n",
    "directory = \"saved_traces_and_evals\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the Trace Dataset\n",
    "trace_id = px.Client().get_trace_dataset().save(directory=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2c6eb911b6354343a46fca08b0b85f03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3363dcebe07847be99e7b41b3840d042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90412f8febda4ab1bb22fe56e2392274",
       "IPY_MODEL_f7654cf0da3f47da801c21b947fda6da",
       "IPY_MODEL_82e8f507e44841f88be5c66c91b27f48"
      ],
      "layout": "IPY_MODEL_8aeca790868b44babe415849afba77db"
     }
    },
    "44f75a3f6c48404990251849a9be33ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59a894868a0344789e8458549f8aa894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99e5a5eeb1ef41d68f41bbd3cb98d544",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d946d51d35344047add12d14c8445f46",
      "value": "â€‡500/500â€‡(100.0%)â€‡|â€‡â³â€‡02:06&lt;00:00â€‡|â€‡â€‡1.63it/s"
     }
    },
    "5f8024635af64b0a99855ae3adef558d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82e8f507e44841f88be5c66c91b27f48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d10322222cb3435fafdbbdc4d98e5059",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d1d54e8e26a54881b1380b02159203ad",
      "value": "â€‡200/200â€‡(100.0%)â€‡|â€‡â³â€‡01:13&lt;00:00â€‡|â€‡â€‡2.21it/s"
     }
    },
    "8648201ffcab4023a1a54dde1b964b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df7e8713256a48c2992f3dce61c702d1",
       "IPY_MODEL_d9af102cb64142b3ac7ea6a75027e6a7",
       "IPY_MODEL_59a894868a0344789e8458549f8aa894"
      ],
      "layout": "IPY_MODEL_2c6eb911b6354343a46fca08b0b85f03"
     }
    },
    "88978e8ddc704d8e9d4048095047615a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aeca790868b44babe415849afba77db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90412f8febda4ab1bb22fe56e2392274": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f8024635af64b0a99855ae3adef558d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_aed1f2822d114ce4be7dcddfbc2dfc20",
      "value": "run_evalsâ€‡"
     }
    },
    "99e5a5eeb1ef41d68f41bbd3cb98d544": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae22d487bb1b442cad9018897a53e623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aea78f53909e44b195de5886df74fad1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aed1f2822d114ce4be7dcddfbc2dfc20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6aab3035f8247b6a3e276b2e86fe79b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d10322222cb3435fafdbbdc4d98e5059": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d54e8e26a54881b1380b02159203ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d946d51d35344047add12d14c8445f46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9af102cb64142b3ac7ea6a75027e6a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae22d487bb1b442cad9018897a53e623",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6aab3035f8247b6a3e276b2e86fe79b",
      "value": 500
     }
    },
    "df7e8713256a48c2992f3dce61c702d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88978e8ddc704d8e9d4048095047615a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_44f75a3f6c48404990251849a9be33ca",
      "value": "run_evalsâ€‡"
     }
    },
    "f7654cf0da3f47da801c21b947fda6da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aea78f53909e44b195de5886df74fad1",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fcf5b6ce6ca94b48b80ed2aa8ced55d5",
      "value": 200
     }
    },
    "fcf5b6ce6ca94b48b80ed2aa8ced55d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
