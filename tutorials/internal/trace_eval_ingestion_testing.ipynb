{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c5245e6d7811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from phoenix.experimental.evals.functions import llm_classify\n",
    "from phoenix.experimental.evals.models import OpenAIModel\n",
    "from phoenix.experimental.evals.templates.default_templates import (\n",
    "    HALLUCINATION_PROMPT_RAILS_MAP,\n",
    "    HALLUCINATION_PROMPT_TEMPLATE,\n",
    "    QA_PROMPT_RAILS_MAP,\n",
    "    QA_PROMPT_TEMPLATE,\n",
    "    RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
    "    RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
    ")\n",
    "from phoenix.session.evaluation import add_evaluations, get_retrieved_documents\n",
    "from phoenix.trace.exporter import HttpExporter\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43166d02c26e8d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Start Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = px.load_example_traces(\"llama_index_rag\")\n",
    "px.launch_app(trace=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362576ff0fe4e2c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extract Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c45b85c6644735",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = get_retrieved_documents(px.active_session())\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac938a5c199dc82",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Set Up OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14465175520ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import openai\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "openai.api_key = openai_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9664171d3e33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIModel(model_name=\"gpt-4-1106-preview\")\n",
    "model(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694213dcf35676f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate Document Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516dc273735ad00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents_eval = llm_classify(\n",
    "    retrieved_documents,\n",
    "    model,\n",
    "    RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
    "    list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
    "    provide_explanation=True,\n",
    ")\n",
    "retrieved_documents_eval[\"score\"] = (\n",
    "    retrieved_documents_eval.label[~retrieved_documents_eval.label.isna()] == \"relevant\"\n",
    ").astype(int)\n",
    "retrieved_documents_eval.to_parquet(\"llama_index_rag_with_rerank.documents_eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341795ae24ca024",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents_eval = pd.read_parquet(\"llama_index_rag_with_rerank.documents_eval.parquet\")\n",
    "retrieved_documents_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fe94b02b22a6b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Merge Data to Compute Ranking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd04b678c9d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([retrieved_documents, retrieved_documents_eval.add_prefix(\"eval_\")], axis=1)\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162eccd6c69aa7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Compute NDCG@2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9fdebd46d268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_ndcg(df: pd.DataFrame, k: int):\n",
    "    \"\"\"Compute NDCG@k in the presence of missing values (e.g. as a result of keyboard interrupt).\"\"\"\n",
    "    eval_scores = [np.nan] * k\n",
    "    pred_scores = [np.nan] * k\n",
    "    for i in range(k):\n",
    "        if i >= len(df.eval_score):\n",
    "            break\n",
    "        eval_scores[i] = df.eval_score[i]\n",
    "        pred_scores[i] = df.document_score[i]\n",
    "    try:\n",
    "        return ndcg_score([eval_scores], [pred_scores])\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "ndcg_at_2 = pd.DataFrame({\"score\": combined.groupby(\"context.span_id\").apply(_compute_ndcg, k=2)})\n",
    "ndcg_at_2.to_parquet(\"llama_index_rag_with_rerank.ndcg_at_2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032851d13b63d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_at_2 = pd.read_parquet(\"llama_index_rag_with_rerank.ndcg_at_2.parquet\")\n",
    "ndcg_at_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5816954fbaa4d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Compute Precision@3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167f4675c7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_3 = pd.DataFrame(\n",
    "    {\n",
    "        \"score\": combined.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:3].sum(skipna=False) / 3\n",
    "        )\n",
    "    }\n",
    ")\n",
    "precision_at_3.to_parquet(\"llama_index_rag_with_rerank.precision_at_3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d31d1d1c95429",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_3 = pd.read_parquet(\"llama_index_rag_with_rerank.precision_at_3.parquet\")\n",
    "precision_at_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819b377e7602361",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Merge Documents from Retrieval Spans to Q&A Spans (to Compute Q&A Correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27fd4724e0e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = (\n",
    "    px.active_session()\n",
    "    .get_spans_dataframe(\"output.value is not None\", root_spans_only=True)\n",
    "    .set_index(\"context.trace_id\")[\n",
    "        [\"attributes.input.value\", \"attributes.output.value\", \"context.span_id\"]\n",
    "    ]\n",
    "    .rename({\"attributes.input.value\": \"input\", \"attributes.output.value\": \"output\"}, axis=1)\n",
    ")\n",
    "qa_df[\"reference\"] = retrieved_documents.groupby(\"context.trace_id\").apply(\n",
    "    lambda x: \"\\n\\n\".join(x.reference)\n",
    ")\n",
    "qa_df.set_index(\"context.span_id\", inplace=True)\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4084449c986aed8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate Q&A Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae507af54ce886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_correctness_eval = llm_classify(\n",
    "    qa_df,\n",
    "    model,\n",
    "    QA_PROMPT_TEMPLATE,\n",
    "    list(QA_PROMPT_RAILS_MAP.values()),\n",
    "    provide_explanation=True,\n",
    ")\n",
    "qa_correctness_eval[\"score\"] = (\n",
    "    qa_correctness_eval.label[~qa_correctness_eval.label.isna()] == \"correct\"\n",
    ").astype(int)\n",
    "qa_correctness_eval.to_parquet(\"llama_index_rag_with_rerank.qa_correctness_eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041d2dcc7d02322",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_correctness_eval = pd.read_parquet(\"llama_index_rag_with_rerank.qa_correctness_eval.parquet\")\n",
    "qa_correctness_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f90ea9c24832b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b5aad5d72c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_eval = llm_classify(\n",
    "    qa_df,\n",
    "    model,\n",
    "    HALLUCINATION_PROMPT_TEMPLATE,\n",
    "    list(HALLUCINATION_PROMPT_RAILS_MAP.values()),\n",
    "    provide_explanation=True,\n",
    ")\n",
    "hallucination_eval[\"score\"] = (\n",
    "    hallucination_eval.label[~hallucination_eval.label.isna()] == \"factual\"\n",
    ").astype(int)\n",
    "hallucination_eval.to_parquet(\"llama_index_rag_with_rerank.hallucination_eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1a6d7143c986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_eval = pd.read_parquet(\"llama_index_rag_with_rerank.hallucination_eval.parquet\")\n",
    "hallucination_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4d1c641fb5e15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ingest Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed5bc68320bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter = HttpExporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a5e74b469a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_evaluations(exporter, retrieved_documents_eval, \"Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc931d1529f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_evaluations(exporter, ndcg_at_2, \"NDCG@2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48a5daae9d5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_evaluations(exporter, precision_at_3, \"Precision@2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848420ee90e10f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_evaluations(exporter, qa_correctness_eval, \"Q&A Correctness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dde5802ed98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_evaluations(exporter, hallucination_eval, \"Hallucination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd4cd21c966504",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# End Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842da4238a93554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.active_session().end()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
