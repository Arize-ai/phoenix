{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arize-phoenix[llama-index] llama-index-embeddings-ollama llama-index-llms-ollama llama-index-llms-openai llama-index-agent-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331618113a05e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from datetime import datetime, timezone\n",
    "from time import sleep\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.postprocessor.types import BaseNodePostprocessor\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from phoenix.datasets.decorators import monkey_patch\n",
    "from phoenix.datasets.experiments import run_experiment\n",
    "from phoenix.datasets.types import Example\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87caccef77f34e23",
   "metadata": {},
   "source": [
    "# Optional: Instrument LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb97dda1f7ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider = trace_sdk.TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bb85777bad1bf",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a30f5b63b1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"input_messages\": [\n",
    "            [{\"role\": \"user\", \"content\": \"Which grad schools did the author apply for and why?\"}],\n",
    "            [{\"role\": \"user\", \"content\": \"What did the author do growing up?\"}],\n",
    "        ],\n",
    "        \"output_message\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The author applied to three grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which the author had visited because a friend went there and it was also home to Bill Woods, who had invented the type of parser the author used in his SHRDLU clone. The author chose these schools because he wanted to learn about AI and Lisp, and these schools were known for their expertise in these areas.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The author took a painting class at Harvard with Idelle Weber and later became her de facto studio assistant. Additionally, the author worked on several different projects, including writing essays, developing spam filters, and painting.\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ff2bb5c1e13f9",
   "metadata": {},
   "source": [
    "## Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955fb85754f5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = (datetime.now(timezone.utc).isoformat(),)\n",
    "px.Client().upload_dataset_examples(\n",
    "    df,\n",
    "    input_keys=(\"input_messages\",),\n",
    "    output_keys=(\"output_message\",),\n",
    "    name=dataset_name,\n",
    ")\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0134d2057cddfbd",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a54e1924e8e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = px.Client().get_dataset(name=dataset_name)\n",
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca2be0e7e37073",
   "metadata": {},
   "source": [
    "# Set Up Experiment Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ede677164d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metadata = {\n",
    "    \"llm\": Ollama(model=\"llama3\"),\n",
    "    \"embed_model\": OllamaEmbedding(model_name=\"mxbai-embed-large\"),\n",
    "    \"reranker\": SentenceTransformerRerank(model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b64da7a25505e5",
   "metadata": {},
   "source": [
    "# Set Up LLamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19936f8ba68b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = experiment_metadata[\"llm\"]\n",
    "Settings.embed_model = experiment_metadata[\"embed_model\"]\n",
    "reranker = experiment_metadata[\"reranker\"]\n",
    "\n",
    "essay = \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\"\n",
    "with tempfile.NamedTemporaryFile() as tf:\n",
    "    urlretrieve(essay, tf.name)\n",
    "    documents = SimpleDirectoryReader(input_files=[tf.name]).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65fb86bae6783d",
   "metadata": {},
   "source": [
    "# Set Up Capture of Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594523fcd2fc692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = {\n",
    "    BaseNodePostprocessor.postprocess_nodes: dict(\n",
    "        identifier=\"documents\",\n",
    "        transform_output=lambda nodes: [node.text for node in nodes],\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9060086db8c0de",
   "metadata": {},
   "source": [
    "# Create Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9303735664c0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_reranker(example: Example) -> str:\n",
    "    chat_engine = index.as_chat_engine(similarity_top_k=10, node_postprocessors=[reranker])\n",
    "    response = chat_engine.chat(example.input[\"input_messages\"][-1][\"content\"])\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67decaf02764dc",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821a566a1353e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with monkey_patch(patches):\n",
    "    run_experiment(\n",
    "        dataset=ds,\n",
    "        fn=rag_with_reranker,\n",
    "        experiment_metadata=experiment_metadata,\n",
    "        repetitions=1,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
