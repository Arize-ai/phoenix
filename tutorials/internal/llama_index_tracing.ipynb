{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install LlamaIndex and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix gcsfs llama-index tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from phoenix.experimental.callbacks.llama_index_trace_callback_handler import (\n",
    "    OpenInferenceTraceCallbackHandler,\n",
    ")\n",
    "from gcsfs import GCSFileSystem\n",
    "from IPython.display import YouTubeVideo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index import LLMPredictor, ServiceContext, StorageContext, load_index_from_storage\n",
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.callbacks.open_inference_callback import as_dataframe\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.graph_stores.simple import SimpleGraphStore\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Your OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "if os.environ[\"OPENAI_API_KEY\"] is None:\n",
    "    openai_api_key = getpass.getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "    openai.api_key = openai_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Your Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download your pre-built index from cloud storage and instantiate your storage context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_system = GCSFileSystem(project=\"public-assets-275721\")\n",
    "index_path = \"arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/\"\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    fs=file_system,\n",
    "    persist_dir=index_path,\n",
    "    graph_store=SimpleGraphStore(),  # prevents unauthorized request to GCS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip a pre-built knowledge base index consisting of chunks of the Arize documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Your Question-Answering Service\n",
    "\n",
    "ðŸ’­ Start a LlamaIndex application from your downloaded index. Use the `OpenInferenceTraceCallbackHandler` to store your data in [OpenInference format](https://github.com/Arize-ai/open-inference-spec), an open standard for capturing and storing AI model inferences that enables production LLMapp servers to seamlessly integrate with LLM observability solutions such as Arize and Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_handler = OpenInferenceTraceCallbackHandler()\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=LLMPredictor(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)),\n",
    "    embed_model=OpenAIEmbedding(model=\"text-embedding-ada-002\"),\n",
    "    callback_manager=CallbackManager(handlers=[callback_handler]),\n",
    ")\n",
    "index = load_index_from_storage(\n",
    "    storage_context,\n",
    "    service_context=service_context,\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’­ Ask questions of your question-answering service and view the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load queries from GCS - these are commonly asked questions about Arize\n",
    "queries_url = \"http://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/llm/context-retrieval/arize_docs_queries.jsonl\"\n",
    "queries = []\n",
    "with urlopen(queries_url) as response:\n",
    "    for line in response:\n",
    "        line = line.decode(\"utf-8\").strip()\n",
    "        data = json.loads(line)\n",
    "        queries.append(data[\"query\"])\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in tqdm(queries):\n",
    "    response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.span_json_encoder import spans_to_jsonl\n",
    "from phoenix.trace.trace_dataset import TraceDataset\n",
    "from phoenix.trace.utils import json_lines_to_df\n",
    "from phoenix import TraceDataset\n",
    "\n",
    "ds = TraceDataset.from_spans(list(callback_handler.get_spans()))\n",
    "\n",
    "px.launch_app(trace=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the contents to a file for safe keeping\n",
    "from phoenix.trace.span_json_encoder import spans_to_jsonl\n",
    "\n",
    "export_trace = False\n",
    "if export_trace:\n",
    "    with open(\"trace.jsonl\", \"w\") as f:\n",
    "        f.write(spans_to_jsonl(callback_handler._tracer.span_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
