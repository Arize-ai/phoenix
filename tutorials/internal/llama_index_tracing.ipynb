{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"arize llama-index logos\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/docs/notebooks/llama-index-knowledge-base-tutorial/arize_llamaindex.png\" width=\"400\">\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Tracing the execution of your LlamaIndex application</h1>\n",
    "\n",
    "Imagine you're an engineer at Arize AI and you've built and deployed a documentation question-answering service using LlamaIndex. Users send questions about Arize's core product via a chat interface, and your service retrieves documents from your documentation in order to generate a response to the user. As the engineer in charge of evaluating and maintaining this system, you want to evaluate the quality of the responses from your service.\n",
    "\n",
    "Parts of this notebook require an [OpenAI API key](https://platform.openai.com/account/api-keys) to run. If you don't have an OpenAI key, you can still run Phoenix by skipping cells preceded by the ðŸ’­ emoji.\n",
    "\n",
    "\n",
    "## Chatbot Architecture\n",
    "\n",
    "Your chatbot was built using LlamaIndex's low-level API. The architecture of your chatbot is shown below and can be explained in five steps.\n",
    "\n",
    "![llama-index chatbot architecture](http://storage.googleapis.com/arize-assets/phoenix/assets/docs/notebooks/llama-index-knowledge-base-tutorial/llama_index_chatbot_architecture.png)\n",
    "\n",
    "1. The user sends a query about Arize to your service.\n",
    "1. `langchain.embeddings.OpenAIEmbeddings` makes a request to the OpenAI embeddings API to embed the user query using the `text-embedding-ada-002` model.\n",
    "1. `llama_index.retrievers.RetrieverQueryEngine` does a similarity search against the entries of your index knowledge base for the two most similar pieces of context by cosine similarity.\n",
    "1. `llama_index.indices.query.ResponseSynthesizer` generates a response by formatting the query and retrieved context into a single prompt and sending a request to OpenAI chat completions API with the `gpt-3.5-turbo`.\n",
    "2. The response is returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install LlamaIndex and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gcsfs llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from phoenix.experimental.callbacks.llama_index_trace_callback_handler import (\n",
    "    OpenInferenceTraceCallbackHandler,\n",
    ")\n",
    "from gcsfs import GCSFileSystem\n",
    "from IPython.display import YouTubeVideo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index import LLMPredictor, ServiceContext, StorageContext, load_index_from_storage\n",
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.callbacks.open_inference_callback import as_dataframe\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.graph_stores.simple import SimpleGraphStore\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Your OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "if os.environ[\"OPENAI_API_KEY\"] is None:\n",
    "    openai_api_key = getpass.getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "    openai.api_key = openai_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Your Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download your pre-built index from cloud storage and instantiate your storage context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_system = GCSFileSystem(project=\"public-assets-275721\")\n",
    "index_path = \"arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/\"\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    fs=file_system,\n",
    "    persist_dir=index_path,\n",
    "    graph_store=SimpleGraphStore(),  # prevents unauthorized request to GCS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip a pre-built knowledge base index consisting of chunks of the Arize documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Your Question-Answering Service\n",
    "\n",
    "ðŸ’­ Start a LlamaIndex application from your downloaded index. Use the `OpenInferenceCallbackHandler` to store your data in [OpenInference format](https://github.com/Arize-ai/open-inference-spec), an open standard for capturing and storing AI model inferences that enables production LLMapp servers to seamlessly integrate with LLM observability solutions such as Arize and Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_handler = OpenInferenceTraceCallbackHandler()\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=LLMPredictor(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)),\n",
    "    embed_model=OpenAIEmbedding(model=\"text-embedding-ada-002\"),\n",
    "    callback_manager=CallbackManager(handlers=[callback_handler]),\n",
    ")\n",
    "index = load_index_from_storage(\n",
    "    storage_context,\n",
    "    service_context=service_context,\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’­ Ask a few questions of your question-answering service and view the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line_length = 80\n",
    "for query in [\n",
    "    \"Why is arize so expensive?\",\n",
    "    \"Is my model doing okay?\",\n",
    "    \"How do I need to format timestamps?\",\n",
    "    \"What is the price of the Arize platform\",\n",
    "]:\n",
    "    print(\"Query\")\n",
    "    print(\"=====\")\n",
    "    print()\n",
    "    print(textwrap.fill(query, max_line_length))\n",
    "    print()\n",
    "    response = query_engine.query(query)\n",
    "    print(\"Response\")\n",
    "    print(\"========\")\n",
    "    print()\n",
    "    print(textwrap.fill(str(response), max_line_length))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.span_json_encoder import spans_to_jsonl\n",
    "from phoenix.trace.trace_dataset import TraceDataset\n",
    "from phoenix.trace.utils import json_lines_to_df\n",
    "from phoenix import TraceDataset\n",
    "\n",
    "ds = TraceDataset.from_spans(list(callback_handler.get_spans()))\n",
    "\n",
    "px.launch_app(trace=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
