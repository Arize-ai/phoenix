{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8648201ffcab4023a1a54dde1b964b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df7e8713256a48c2992f3dce61c702d1",
              "IPY_MODEL_d9af102cb64142b3ac7ea6a75027e6a7",
              "IPY_MODEL_59a894868a0344789e8458549f8aa894"
            ],
            "layout": "IPY_MODEL_2c6eb911b6354343a46fca08b0b85f03"
          }
        },
        "df7e8713256a48c2992f3dce61c702d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88978e8ddc704d8e9d4048095047615a",
            "placeholder": "​",
            "style": "IPY_MODEL_44f75a3f6c48404990251849a9be33ca",
            "value": "run_evals "
          }
        },
        "d9af102cb64142b3ac7ea6a75027e6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae22d487bb1b442cad9018897a53e623",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6aab3035f8247b6a3e276b2e86fe79b",
            "value": 500
          }
        },
        "59a894868a0344789e8458549f8aa894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e5a5eeb1ef41d68f41bbd3cb98d544",
            "placeholder": "​",
            "style": "IPY_MODEL_d946d51d35344047add12d14c8445f46",
            "value": " 500/500 (100.0%) | ⏳ 02:06&lt;00:00 |  1.63it/s"
          }
        },
        "2c6eb911b6354343a46fca08b0b85f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88978e8ddc704d8e9d4048095047615a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f75a3f6c48404990251849a9be33ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae22d487bb1b442cad9018897a53e623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6aab3035f8247b6a3e276b2e86fe79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99e5a5eeb1ef41d68f41bbd3cb98d544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d946d51d35344047add12d14c8445f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3363dcebe07847be99e7b41b3840d042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90412f8febda4ab1bb22fe56e2392274",
              "IPY_MODEL_f7654cf0da3f47da801c21b947fda6da",
              "IPY_MODEL_82e8f507e44841f88be5c66c91b27f48"
            ],
            "layout": "IPY_MODEL_8aeca790868b44babe415849afba77db"
          }
        },
        "90412f8febda4ab1bb22fe56e2392274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8024635af64b0a99855ae3adef558d",
            "placeholder": "​",
            "style": "IPY_MODEL_aed1f2822d114ce4be7dcddfbc2dfc20",
            "value": "run_evals "
          }
        },
        "f7654cf0da3f47da801c21b947fda6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea78f53909e44b195de5886df74fad1",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcf5b6ce6ca94b48b80ed2aa8ced55d5",
            "value": 200
          }
        },
        "82e8f507e44841f88be5c66c91b27f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10322222cb3435fafdbbdc4d98e5059",
            "placeholder": "​",
            "style": "IPY_MODEL_d1d54e8e26a54881b1380b02159203ad",
            "value": " 200/200 (100.0%) | ⏳ 01:13&lt;00:00 |  2.21it/s"
          }
        },
        "8aeca790868b44babe415849afba77db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8024635af64b0a99855ae3adef558d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed1f2822d114ce4be7dcddfbc2dfc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aea78f53909e44b195de5886df74fad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf5b6ce6ca94b48b80ed2aa8ced55d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d10322222cb3435fafdbbdc4d98e5059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d54e8e26a54881b1380b02159203ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "wYET8LC-3koX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E3qLx9JwjMuj"
      },
      "outputs": [],
      "source": [
        "!pip install -qq arize-phoenix llama-index \"openai>=1\" gcsfs nest_asyncio langchain langchain-community cohere llama-index-postprocessor-cohere-rerank"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Environment Variables\n"
      ],
      "metadata": {
        "id": "EejzP1ov3wgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
        "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "if not (cohere_api_key := os.getenv(\"COHERE_API_KEY\")):\n",
        "    cohere_api_key = getpass(\"🔑 Enter your Cohere API key: \")\n",
        "os.environ[\"COHERE_API_KEY\"] = cohere_api_key"
      ],
      "metadata": {
        "id": "SfHrgDaHjkFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f28de04-c240-42bb-e49a-a8abe892bd10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔑 Enter your OpenAI API key: ··········\n",
            "🔑 Enter your Cohere API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Launch Phoenix and Setup instrumentation"
      ],
      "metadata": {
        "id": "nrRN-Tur32Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import phoenix as px"
      ],
      "metadata": {
        "id": "RDmiCpAlK3Wd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0iVU1yQKco79",
        "outputId": "78105daf-dcbf-4ef3-9335-feb2632112fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit https://9zpo69ffpri12-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
            "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
          ]
        }
      ],
      "source": [
        "session = px.launch_app()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ig1vG4l5co7-"
      },
      "outputs": [],
      "source": [
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
        "\n",
        "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Pheonix Documentation into Llama-index Documents"
      ],
      "metadata": {
        "id": "7OP5ELmg4LeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The nest_asyncio module enables the nesting of asynchronous functions within an already running async loop.\n",
        "# This is necessary because Jupyter notebooks inherently operate in an asynchronous loop.\n",
        "# By applying nest_asyncio, we can run additional async functions within this existing loop without conflicts.\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import nest_asyncio\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import pandas as pd\n",
        "from langchain.docstore.document import Document as LangChainDocument\n",
        "from langchain.document_loaders import GitbookLoader\n",
        "from llama_index.core import Document, VectorStoreIndex\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.llms.openai import OpenAI"
      ],
      "metadata": {
        "id": "w6cVWlJGjsMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649293f3-48a6-470e-f9e1-0de741667746"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNI [langchain_community.utils.user_agent] USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWDCQJN1co7-"
      },
      "source": [
        "Enable Phoenix tracing via `LlamaIndexInstrumentor`. Phoenix uses OpenInference traces - an open-source standard for capturing and storing LLM application traces that enables LLM applications to seamlessly integrate with LLM observability solutions such as Phoenix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Fetches the Arize documentation from Gitbook and serializes it into LangChain format.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def load_gitbook_docs(docs_url: str):\n",
        "    \"\"\"Loads documents from a Gitbook URL.\n",
        "\n",
        "    Args:\n",
        "        docs_url (str): URL to Gitbook docs.\n",
        "\n",
        "    Returns:\n",
        "        List[LangChainDocument]: List of documents in LangChain format.\n",
        "    \"\"\"\n",
        "    loader = GitbookLoader(\n",
        "        docs_url,\n",
        "        load_all_paths=True,\n",
        "    )\n",
        "    return loader.load()\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "    # fetch documentation\n",
        "docs_url = \"https://docs.arize.com/phoenix\"\n",
        "embedding_model_name = \"text-embedding-ada-002\"\n",
        "docs = load_gitbook_docs(docs_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9mFzfnlj2rV",
        "outputId": "b52d862f-bb3c-41f6-b07a-3ad0e18c5cc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  k = self.parse_starttag(i)\n",
            "Fetching pages: 100%|##########| 126/126 [00:57<00:00,  2.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "for doc in docs:\n",
        "  documents.append(Document(metadata=doc.metadata, text=doc.page_content))"
      ],
      "metadata": {
        "id": "B5KT9icyk_Lh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CemnegejgI7f",
        "outputId": "1f7e434f-4e1b-4937-9478-aa1f0cedc2e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'https://docs.arize.com/phoenix/', 'title': 'Arize Phoenix'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Convert documents to a JSON serializable format (if needed)\n",
        "documents_json = [doc.to_dict() for doc in documents]\n",
        "\n",
        "# Save to a JSON file\n",
        "with open('llama_index_documents.json', 'w') as file:\n",
        "    json.dump(documents_json, file, indent=4)\n"
      ],
      "metadata": {
        "id": "lAPNcG-RHWL2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup VectorStore and Query Engine"
      ],
      "metadata": {
        "id": "a3pYhJwq4VwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
        "\n",
        "# Define an LLM\n",
        "llm = OpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Build index with a chunk_size of 1024\n",
        "# node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "# nodes = node_parser.get_nodes_from_documents(documents)\n",
        "splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=250)\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "4S8pfGvFluIg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOmyBVoSco7-"
      },
      "source": [
        "Build a QueryEngine and start querying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3OB49Cghco7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c7afd2-4d6c-41dc-f1ce-e636e1516a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
            "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
            "* 'smart_union' has been removed\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
        "cohere_rerank = CohereRerank(api_key=cohere_api_key, top_n=2)\n",
        "\n",
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=5,\n",
        "    node_postprocessors=[cohere_rerank],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmlw_irPco7_"
      },
      "source": [
        "## Import Questions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df = pd.read_parquet(\"/content/PhoenixRAGUseCaseQuestions.parquet\")"
      ],
      "metadata": {
        "id": "21s8Kk3znqJ-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qKpbdBFwsKuC",
        "outputId": "cd5feb82-1643-440b-dd21-9294cdb09394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Prompt/ Question\n",
              "0                    How do I send traces to Phoenix?\n",
              "1      What happens if I send the same traces twice? \n",
              "2   Which frameworks and LLM providers are support...\n",
              "3   How can users create and manage datasets for p...\n",
              "4           How does Arize Phoenix use OpenTelemetry?\n",
              "..                                                ...\n",
              "95                 What is the Data retention policy?\n",
              "96  Will hosted Phoenix be on the latest version o...\n",
              "97                            Is Hosted Phoenix free?\n",
              "98                Can I persist data in the notebook?\n",
              "99               Can I use gRPC for trace collection?\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7890c53b-691d-45de-a31b-6004eade1d2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt/ Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What happens if I send the same traces twice?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which frameworks and LLM providers are support...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can users create and manage datasets for p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does Arize Phoenix use OpenTelemetry?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>What is the Data retention policy?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Will hosted Phoenix be on the latest version o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Is Hosted Phoenix free?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Can I persist data in the notebook?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7890c53b-691d-45de-a31b-6004eade1d2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7890c53b-691d-45de-a31b-6004eade1d2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7890c53b-691d-45de-a31b-6004eade1d2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9917150a-7c40-4f64-8579-deab6f5e86a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9917150a-7c40-4f64-8579-deab6f5e86a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9917150a-7c40-4f64-8579-deab6f5e86a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f194e658-eb04-42a2-b90b-b0d100df0896\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('questions_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f194e658-eb04-42a2-b90b-b0d100df0896 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('questions_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "questions_df",
              "summary": "{\n  \"name\": \"questions_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Prompt/ Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"What are the benefits of using OpenTelemetry with Arize Phoenix?\",\n          \"If I am using both llamaindex and langchain in the same application, can I set up instrumentation for both of them?\",\n          \"What formats are supported for exporting inference data?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B0-Stmks5zOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Answers for all of the questions"
      ],
      "metadata": {
        "id": "jc7hbkyu5zr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over the questions and generate the answers\n",
        "for i, row in questions_df.iterrows():\n",
        "    if i in [25, 50, 75]:\n",
        "        time.sleep(30)\n",
        "    question = row[\"Prompt/ Question\"]\n",
        "    response_vector = query_engine.query(question)\n",
        "    print(f\"Question: {question}\\nAnswer: {response_vector.response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HmTkFYJsLq4",
        "outputId": "c6c18359-d7e1-4180-f194-2d67b27b6c0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How do I send traces to Phoenix?\n",
            "Answer: You can send traces to Phoenix by instrumenting your application either manually or automatically. Once the application is instrumented, the spans created via instrumentation are exported to a collector using an exporter. The Phoenix server acts as the collector and receives the spans from any application(s) that is exporting spans to it. The OpenTelemetry Protocol (OTLP) is used to transmit the traces from your application to the Phoenix collector, with Phoenix currently supporting OTLP over HTTP.\n",
            "\n",
            "Question: What happens if I send the same traces twice? \n",
            "Answer: Tracing records the paths taken by requests as they move through multiple steps. Sending the same traces twice would likely result in duplicate records of the paths taken by those requests, potentially leading to redundant information being captured in the tracing system.\n",
            "\n",
            "Question: Which frameworks and LLM providers are supported by Arize Phoenix for seamless integration?\n",
            "Answer: Arize Phoenix supports a variety of frameworks and LLM providers for seamless integration, including OpenAI, LangChain, MistralAI, VertexAI, DSPy, AWS Bedrock, Haystack, and CrewAI.\n",
            "\n",
            "Question: How can users create and manage datasets for prompt testing and fine-tuning in Arize Phoenix?\n",
            "Answer: Users can create and manage datasets for prompt testing and fine-tuning in Arize Phoenix by utilizing the tools provided for data exploration, cleaning, and labeling. These tools enable teams to curate representative data covering a wide range of use cases and edge conditions, facilitating the process of testing and fine-tuning prompts effectively within the platform.\n",
            "\n",
            "Question: How does Arize Phoenix use OpenTelemetry?\n",
            "Answer: Arize Phoenix uses OpenTelemetry for instrumentation in order to connect applications to Phoenix instances.\n",
            "\n",
            "Question: How can users visualize embeddings in Arize Phoenix?\n",
            "Answer: Users can visualize embeddings in Arize Phoenix by projecting the embeddings into a lower dimensional space (3 dimensions) using a dimension reduction algorithm called UMAP (Uniform Manifold Approximation and Projection). This allows users to understand how their embeddings have encoded semantic meaning in a visually understandable way. Additionally, users can assign colors to the UMAP point-cloud by dimension, performance, and inference to explore the point-cloud from different perspectives.\n",
            "\n",
            "Question: What are the main objectives of Arize Phoenix?\n",
            "Answer: The main objectives of Arize Phoenix are to provide an open-source observability library for AI Engineers and Data Scientists to visualize data, evaluate performance, track down issues, and export data to improve their AI models.\n",
            "\n",
            "Question: What are the steps to set up Arize Phoenix in a local environment?\n",
            "Answer: To set up Arize Phoenix in a local environment, you can follow these steps:\n",
            "1. Install Phoenix using pip or conda, or use Docker to pull the Phoenix server image.\n",
            "2. Launch Phoenix locally using command line, Docker, or within a notebook.\n",
            "3. Connect your application to your Phoenix instance by installing the necessary packages and setting up the connection using the provided code snippets.\n",
            "4. Customize your deployment based on your use case and preferences, ensuring persistence if needed.\n",
            "5. Optionally, you can use Docker Compose to run Phoenix locally with Postgres or SQLite backend for data storage.\n",
            "\n",
            "Question: What types of traces can be collected using Arize Phoenix?\n",
            "Answer: Traces for debugging, experimentation, prompt tracking, and search and retrieval can be collected using Arize Phoenix.\n",
            "\n",
            "Question: What can I expect to see in an Arize Phoenix trace?\n",
            "Answer: You can expect to see detailed insights into the execution flow, specific spans, performance metrics, and access to relevant logs and metadata in an Arize Phoenix trace.\n",
            "\n",
            "Question: What are the different types of spans?\n",
            "Answer: CHAIN, RETRIEVER, RERANKER, LLM, EMBEDDING, TOOL, AGENT\n",
            "\n",
            "Question: Why I am seeing X span in my trace?\n",
            "Answer: You are seeing a specific span in your trace because it represents a unit of work or operation that was executed during the time the request was made. Spans track specific operations, providing a detailed picture of what occurred within that operation. Each span contains information such as the name of the operation, time-related data, structured log messages, and metadata to give insights into the tracked operation.\n",
            "\n",
            "Question: How do I get the last 7 days of traces?\n",
            "Answer: To get the last 7 days of traces, you can utilize the timestamp information associated with each trace. By filtering the traces based on their timestamp and selecting those that fall within the last 7 days, you can extract the desired data.\n",
            "\n",
            "Question: How do I get spans with no evaluations?\n",
            "Answer: To get spans with no evaluations, you can apply a filter in your query using the syntax \"evals['correctness'].label is None\". This filter will help you retrieve spans that do not have any evaluation attached to them yet.\n",
            "\n",
            "Question: How do I run an evaluation?\n",
            "Answer: You can run an evaluation by using cron to execute the evaluation script as a cron job. This script will continuously query a LangChain application to send new traces and spans to your Phoenix session, run evaluations such as Hallucination, Q&A Correctness, and Relevance, and log the evaluations back to Phoenix for visualization in the UI.\n",
            "\n",
            "Question: What is an evaluation?\n",
            "Answer: An evaluation is a process of assessing the quality of generated results or retrieval in LLM development. It involves measuring the performance of an LLM application by checking if the response matches the retrieved context or query, evaluating the relevance of retrieved sources, and determining criteria such as QA correctness, hallucinations, and toxicity. Evaluations can be done using a combination of input (query), output (response), and context to understand how well the LLM application is functioning.\n",
            "\n",
            "Question: What is a trace?\n",
            "Answer: A trace records the paths taken by requests as they move through multiple steps, providing visibility into the journey of a request from start to finish. It helps in understanding the flow of operations within a system and is crucial for diagnosing performance issues and debugging complex behaviors in applications.\n",
            "\n",
            "Question: What are prompts?\n",
            "Answer: Prompts are templates that can be instrumented with variables to track and visualize changes. They can be used to measure performance changes driven by each prompt and are commonly used in experiments to analyze the impact of different prompts on outcomes.\n",
            "\n",
            "Question: What are prompt templates?\n",
            "Answer: Prompt templates are used to track and visualize prompt changes. They can be combined with Experiments to measure the performance changes driven by each prompt. Prompt templates consist of a template (non-empty string), version (non-empty string), and variables (a dictionary with string keys). The template, version, and variables are added to the current OpenTelemetry Context using a context manager or decorator, allowing for the generation of spans with specific attributes related to the prompt template.\n",
            "\n",
            "Question: What is a prompt variable?\n",
            "Answer: A prompt variable is a key-value pair that represents specific information within a prompt template.\n",
            "\n",
            "Question: What is Phoenix for?\n",
            "Answer: Phoenix is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows AI Engineers and Data Scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\n",
            "\n",
            "Question: How is Phoenix different than other observability platforms?\n",
            "Answer: Phoenix offers a comprehensive observability platform designed specifically for LLM-based systems, providing visibility into every layer of the application, prompt, and response. It empowers teams to build, optimize, and maintain high-quality applications efficiently by offering essential tools for debugging, experimentation, evaluation, prompt tracking, and search and retrieval. Phoenix's tracing and span analysis capabilities, along with its evaluation framework and embeddings visualizer, set it apart from other observability platforms by providing detailed insights into execution flow, performance metrics, and data representation.\n",
            "\n",
            "Question: When do I use Phoenix vs. Arize?\n",
            "Answer: You use Phoenix for experimentation, evaluation, and troubleshooting, allowing AI Engineers and Data Scientists to visualize data, evaluate performance, track down issues, and export data to improve. On the other hand, Arize, the enterprise counterpart of Phoenix, works hand-in-hand with Phoenix to share embeddings data easily for further investigation or to kickoff retraining workflows.\n",
            "\n",
            "Question: What can I do with the Phoenix API?\n",
            "Answer: You can use the Phoenix API to visualize data, evaluate performance, track down issues, and export data for improvement.\n",
            "\n",
            "Question: Can you explain llm_classify?\n",
            "Answer: llm_classify is a function that takes in a dataframe, a template, a model, a list of rails, and a flag to provide explanations. It produces relevance classifications based on the input data and the specified parameters. The output of llm_classify is a Dataframe with columns for 'label' and 'explanation', which can be used to understand why the LLM responds in a specific way.\n",
            "\n",
            "Question: What is run_evals?\n",
            "Answer: run_evals is a function that evaluates a pandas dataframe using a set of user-specified evaluators that assess each row for relevance of retrieved documents, hallucinations, toxicity, etc. It outputs a list of dataframes, one for each evaluator, that contain the labels, scores, and optional explanations from the corresponding evaluator applied to the input dataframe.\n",
            "\n",
            "Question: What pre-built evaluators does Phoenix support?\n",
            "Answer: Phoenix supports pre-built evaluators for Retrieval Eval, Hallucination Eval, Toxicity Eval, Q&A Eval, Summarization Eval, and Code Generation Eval.\n",
            "\n",
            "Question: What is LLM as a judge?\n",
            "Answer: LLM as a judge is a method that utilizes a Large Language Model (LLM) to evaluate the output of another system or model. This approach combines human-like assessment with machine efficiency to assess the performance of tasks that involve complex and diverse criteria.\n",
            "\n",
            "Question: How do I enable explanations for evals?\n",
            "Answer: Enable explanations for evals by setting the flag `provide_explanation` to True when calling the `llm_classify` function with the desired template or custom templates.\n",
            "\n",
            "Question: How do I get started?\n",
            "Answer: To get started, you should check out the development guide, code of conduct, and Contribution License Agreement. Additionally, you are encouraged to pick a GitHub issue labeled with the tag \"good first issue\" to familiarize yourself with the codebase as a first-time contributor. Once you are ready to submit your code, fork the Phoenix repository, create a new branch on your fork, and open a Pull Request (PR) for review. In the PR template, describe the change, including the motivation/context, test coverage, and any other relevant information. A Core reviewer will then review your PR, provide feedback, and once approved, your contribution will be merged into Phoenix.\n",
            "\n",
            "Question: Should I use quantitative or qualitative data types for evals?\n",
            "Answer: You should use qualitative data types for evals.\n",
            "\n",
            "Question: How do I send in an evaluation?\n",
            "Answer: You can send in an evaluation by using the `log_evaluations` function provided by the Phoenix client. The evaluation must have a name and its DataFrame must contain identifiers for the subject of evaluation, such as a span or a document, along with values under either the score, label, or explanation columns. The name of the evaluation must be supplied through the `eval_name=` parameter when sending the evaluation to Phoenix.\n",
            "\n",
            "Question: Tell me about datasets\n",
            "Answer: Datasets are collections of examples that provide inputs and, optionally, expected reference outputs for assessing applications. Each example within a dataset represents a single data point, consisting of an inputs dictionary, an optional output dictionary, and an optional metadata dictionary. Datasets allow for the collection of data from various sources like production, staging, evaluations, and manual inputs. These examples are then used to run experiments and evaluations to track improvements in applications. Datasets can be created manually, from historical logs, or by generating synthetic data. They are integral to evaluation in AI development, helping developers understand the impact of changes, compare specific examples, and avoid guesswork in improving their applications.\n",
            "\n",
            "Question: What is a dataset?\n",
            "Answer: A dataset is a collection of examples that provide inputs and, optionally, expected reference outputs for assessing an application. Each example within a dataset represents a single data point, consisting of an inputs dictionary, an optional output dictionary, and an optional metadata dictionary. Datasets are integral to evaluation and experimentation, allowing data collection from various sources like production, staging, evaluations, and manual inputs. They are used to run experiments and evaluations to track improvements in applications.\n",
            "\n",
            "Question: What is an experiment?\n",
            "Answer: An experiment involves defining/uploading a dataset, creating a task, defining evaluators, and running the experiment to evaluate the output for each example. It helps in understanding how a change will affect performance and provides tangible feedback to improve the reliability of the product.\n",
            "\n",
            "Question: When do I use experiments?\n",
            "Answer: Experiments are used in AI development to understand how a change will affect performance, helping to distill the indeterminism of LLMs into tangible feedback that assists in shipping more reliable products.\n",
            "\n",
            "Question: How do I add data to a dataset?\n",
            "Answer: You can add data to a dataset in a few ways. One method is by manually curating examples, where you can start by building high-quality examples for your application. Another approach is to use historical logs to capture valuable information on how users are interacting with your application. Additionally, you can generate synthetic data to quickly create a large number of data points. Lastly, if your application is traced using instrumentation, you can add spans or groups of spans to a dataset through the Phoenix UI.\n",
            "\n",
            "Question: What is RAG?\n",
            "Answer: RAG stands for Retrieval Augmented Generation. It is a technique that dynamically incorporates specific data as context during the generation process without altering the training data of language models. This allows models to access and utilize real-time data to provide more tailored and contextually relevant responses. RAG involves loading and preparing data for queries, indexing the data for efficient querying, and utilizing this context along with user queries to generate responses.\n",
            "\n",
            "Question: How do I debug retrieval?\n",
            "Answer: To debug retrieval, you can start by logging your retrievals from your vector datastore to Phoenix and running evaluations. This involves logging knowledge base samples, logging retrieval and response pairs, and then running evaluations on your retrievals using frameworks like LangChain and LlamaIndex. By following these steps, you can analyze the performance of your retrieval system and identify any issues that may need debugging.\n",
            "\n",
            "Question: How do I improve my RAG system?\n",
            "Answer: To improve your RAG system, you can focus on enhancing the stages within the RAG pipeline. This can involve optimizing the loading process to efficiently bring in your data, refining the indexing stage to create a robust data structure for querying, ensuring proper storage of your index to avoid re-indexing, implementing effective querying strategies to leverage LLMs and data structures, and conducting thorough evaluations to measure the accuracy, faithfulness, and speed of your responses to queries. By continuously refining and optimizing each stage of the RAG pipeline, you can enhance the performance and effectiveness of your RAG system.\n",
            "\n",
            "Question: What is hosted Phoenix?\n",
            "Answer: Hosted Phoenix is a version of Phoenix that is hosted by the service provider, making it easier for developers to trace their LLM applications without the need to set up their own infrastructure. It runs the latest version of the open source package and requires users to create an account, add API keys for data access and authentication, and uses 3rd party analytics tools to enhance services.\n",
            "\n",
            "Question: What are the deployment options for Phoenix?\n",
            "Answer: The deployment options for Phoenix include running it as a container using different image tags such as arizephoenix/phoenix:latest, arizephoenix/phoenix:latest-nonroot, arizephoenix/phoenix:latest-debug, arizephoenix/phoenix:version-X.X.X, arizephoenix/phoenix:version-X.X.X-nonroot, and arizephoenix/phoenix:version-X.X.X-debug.\n",
            "\n",
            "Question: Tell me about sessions\n",
            "Answer: Sessions in Phoenix refer to instances that maintain the state of the Phoenix app. These sessions can be launched with specific inferences or datasets and can be used to open the Phoenix UI within a notebook or in a separate browser tab or window. Additionally, there is a method to obtain the active session and another method to close the running session if needed.\n",
            "\n",
            "Question: How do I configure projects?\n",
            "Answer: To configure projects in Phoenix, you can set the project name using the `PHOENIX_PROJECT_NAME` environment variable. This variable allows you to group traces into specific projects. In a notebook environment, you can set the project name before adding instrumentation or running any code. Additionally, when using Phoenix as a collector and running your application separately, you can set the project name in the Resource attributes for the trace provider.\n",
            "\n",
            "Question: How does tracing work?\n",
            "Answer: Tracing works by instrumenting an application to emit traces for analysis. This can be done manually or automatically through plugins called instrumentors. These instrumentors collect spans for the application, which are then exported to a collector via an exporter. The Phoenix server acts as the collector and UI for troubleshooting, receiving spans from applications that export them. The OpenTelemetry Protocol (OTLP) is used to transmit traces from the application to the Phoenix collector.\n",
            "\n",
            "Question: What is auto-instrumentation?\n",
            "Answer: Auto-instrumentation is the process of automatically collecting traces from frameworks and libraries within a system's components to make the system observable.\n",
            "\n",
            "Question: What is manual-instrumentation?\n",
            "Answer: Manual instrumentation refers to the process of directly adding code to an application to trace and monitor its behavior. This involves manually inserting code snippets or libraries into the application's source code to collect specific data points, such as performance metrics, error logs, or user interactions, for analysis and monitoring purposes.\n",
            "\n",
            "Question: Can you tell me about openinference?\n",
            "Answer: OpenInference is an open standard that covers model inference and LLM application tracing. It includes specifications for capturing the execution of an application resulting in LLM invocations and for collecting inference logs from various model types and use-cases.\n",
            "\n",
            "Question: What is open telemetry?\n",
            "Answer: OpenTelemetry is a protocol that allows traces to be sent from your application to the Phoenix collector. It is currently supported over HTTP and is the means by which traces arrive at the Phoenix collector for analysis and visualization.\n",
            "\n",
            "Question: What providers are supported with openinference?\n",
            "Answer: NodeTracerProvider\n",
            "\n",
            "Question: How do I create a custom evaluator?\n",
            "Answer: To create a custom evaluator, you can write a Python function that takes the output of an experiment run as an argument. This function can return a boolean or numeric value, which will be recorded as the evaluation score. For example, you can create a simple evaluator like checking if the output falls within a specific range, such as checking if a numeric output is between 1 and 100. More complex evaluators can utilize additional information by defining functions with specific parameter names that are bound to special values, such as input, output, expected, reference, or metadata. These parameters can be used in any combination and order to write custom complex evaluators. Additionally, you can use libraries like editdistance to calculate the similarity between the output and the expected value. To further customize how your evaluations show up in the Experiments UI, you can use the create_evaluator decorator.\n",
            "\n",
            "Question: Where can I get help with Phoenix?\n",
            "Answer: You can get help with Phoenix by joining the Phoenix Slack community.\n",
            "\n",
            "Question: Who can I ask for help?\n",
            "Answer: You can ask for help by reaching out to the support team or community forums associated with the platform or tool you are using.\n",
            "\n",
            "Question: If I am using both llamaindex and langchain in the same application, can I set up instrumentation for both of them?\n",
            "Answer: Yes, you can set up instrumentation for both LlamaIndex and LangChain in the same application. Each module provides instructions on how to instrument them within your application, allowing you to collect and display traces from both LlamaIndex and LangChain in Arize Phoenix.\n",
            "\n",
            "Question: Is there any document for the search query syntax on phoenix UI? Is it possible to search for values in children spans?\n",
            "Answer: Yes, there is documentation available for querying spans in Phoenix UI. You can search for values in children spans by using the query DSL (domain specific language) to filter for specific span kinds and extract the desired attributes from those spans.\n",
            "\n",
            "Question: Is there a limit on the amount of messages we can send to the UI? \n",
            "Answer: There is no specific information provided in the context regarding a limit on the amount of messages that can be sent to the UI.\n",
            "\n",
            "Question: What model types are supported by Phoenix?\n",
            "Answer: Phoenix supports model types such as LLM, NLP, CV, and Tabular.\n",
            "\n",
            "Question: How can you make sure that chains are going to be nested? \n",
            "Answer: Manually instrument the LangChain module to ensure that chains are nested.\n",
            "\n",
            "Question: Explain the process of setting up custom evaluations in Arize Phoenix for a specific LLM task. How can the results from these evaluations inform model fine-tuning and dataset adjustments?\n",
            "Answer: To set up custom evaluations in Arize Phoenix for a specific LLM task, you first need to choose a metric that best suits your use case. Then, you should build a golden dataset that represents the type of data the LLM evaluation will encounter, with ground truth labels for performance measurement. Next, decide which LLM to use for evaluation, which may differ from the one used in your application. After that, build the evaluation template by defining the input, the question being asked, and the possible output formats.\n",
            "\n",
            "Once the custom evaluation template is created, you can run the evaluation on your golden dataset to generate metrics such as overall accuracy, precision, recall, and F1 score. These metrics provide insights into the model's performance and can inform fine-tuning adjustments by highlighting areas where the model may be underperforming. Additionally, the evaluation results can guide dataset adjustments by identifying patterns or shortcomings in the data that may be affecting the model's performance.\n",
            "\n",
            "Question: What configuration steps are needed to set up Arize Phoenix for a new project?\n",
            "Answer: To set up Arize Phoenix for a new project, you need to install the necessary packages using pip or conda, launch Phoenix locally using command line, Docker, or a notebook, connect your application to your Phoenix instance by importing the required modules and setting up the tracer provider, span exporter, and span processor, and finally, configure Phoenix by customizing it using environment variables as needed.\n",
            "\n",
            "Question: How can datasets be exported from Arize Phoenix?\n",
            "Answer: Datasets can be exported from Arize Phoenix by clicking the export button on the Embeddings and Inferences pages, which will generate a code snippet that can be copied into a Python environment after installing Phoenix. Another way is to query Arize directly for data using the Arize Python export client, where users can manually enter the data ranges and data they want to export.\n",
            "\n",
            "Question: Which LLM providers are supported by Arize Phoenix?\n",
            "Answer: Arize Phoenix supports a variety of LLM providers such as OpenAI, Vertex AI, Azure Open AI, Anthropic, Mixtral/Mistral, AWS Bedrock, Falcon, Code Llama, Llama3, Deepseek, Deberta, DBRX, and Qwen.\n",
            "\n",
            "Question: How can users perform custom task evaluations in Arize Phoenix? \n",
            "Answer: Users can perform custom task evaluations in Arize Phoenix by utilizing the feature provided for evaluating custom tasks within the platform.\n",
            "\n",
            "Question: How can users join the Arize Phoenix community for support?\n",
            "Answer: Users can join the Phoenix Slack community to ask questions, share findings, provide feedback, and connect with other developers for support.\n",
            "\n",
            "Question: What makes Arize Phoenix vendor-agnostic?\n",
            "Answer: Arize Phoenix is vendor-agnostic because it works with OpenTelemetry and OpenInference instrumentation, allowing it to be compatible with a variety of different environments and services without being tied to any specific vendor or platform.\n",
            "\n",
            "Question: Where should I look to learn how to use ragas with Phoenix?\n",
            "Answer: You should look into the tutorial that covers Ragas for synthetic test data generation and evaluation, which includes information on using Phoenix for tracing, visualization, and cluster analysis.\n",
            "\n",
            "Question: What steps are needed to set up automatic instrumentation in Arize Phoenix?\n",
            "Answer: To set up automatic instrumentation in Arize Phoenix, you will need to install the OpenTelemetry SDK and the specific OpenInference instrumentation for the framework you are using. First, install the OpenTelemetry SDK by running the provided npm command. Then, install the OpenInference instrumentation you want to use by running the respective npm command. Additionally, if you plan on manually instrumenting your application, you will also need to install the OpenInference Semantic Conventions. Finally, load the desired instrumentation by specifying it in the registerInstrumentations call along with any additional instrumentation you wish to enable. Remember that the instrumentation must run before any other code in your application to capture spans effectively.\n",
            "\n",
            "Question: How can users import their inference data into Arize Phoenix?\n",
            "Answer: Users can import their inference data into Arize Phoenix by following the steps outlined in the documentation.\n",
            "\n",
            "Question: What are the key components of a schema in Arize Phoenix?\n",
            "Answer: The key components of a schema in Arize Phoenix include embeddings data, models, and the ability to export data to Phoenix for further analysis and evaluation.\n",
            "\n",
            "Question: How can users export inference data from Arize Phoenix?\n",
            "Answer: Users can export inference data from Arize Phoenix by clicking the export button on the Embeddings and Inferences pages. This action will generate a code snippet that can be copied into a Python environment after installing Phoenix. The code snippet includes the selected date range and inferences from the Arize platform. Additionally, users can also query Arize directly for data using the Arize Python export client, which requires manual entry of data ranges and the specific data to be exported.\n",
            "\n",
            "Question: What formats are supported for exporting inference data?\n",
            "Answer: Your data can be exported as a Parquet file or as a dataframe.\n",
            "\n",
            "Question: What formats are supported for exporting trace data?\n",
            "Answer: The formats supported for exporting trace data include exporting a dataframe from the session and applying a filter if you would like to export only a sub-set of spans.\n",
            "\n",
            "Question: How can users create a new session in Arize Phoenix?\n",
            "Answer: Users can create a new session in Arize Phoenix by running the command to install the library in their Jupyter or Colab environment.\n",
            "\n",
            "Question: How does Arize Phoenix Evals help in assessing the performance of LLM applications?\n",
            "Answer: Arize Phoenix Evals helps in assessing the performance of LLM applications by providing support for pre-tested evaluation templates, custom evaluation templates, and rigorous benchmarking for reproducible results. It is designed to run evaluations as fast as possible on batches of evaluation data, maximizing throughput and API key usage. Additionally, Phoenix Evals allows evaluations to be run on different environments such as dataframes, Python pipelines, and LangChain & LlamaIndex callbacks, supporting evaluations at both span and chain levels.\n",
            "\n",
            "Question: How can users create custom evaluations in Arize Phoenix?\n",
            "Answer: Users can create custom evaluations in Arize Phoenix by utilizing the \"Custom Task Evaluation\" feature provided in the platform.\n",
            "\n",
            "Question: Where can users find detailed documentation on using Arize Phoenix Evals?\n",
            "Answer: Users can find detailed documentation on using Arize Phoenix Evals on the Arize website under the \"Evaluation Models\" and \"How to: Evals\" sections.\n",
            "\n",
            "Question: Is there a way to log_evaluation to hosted phoenix?\n",
            "Answer: Yes, there is a way to log evaluations to hosted Phoenix.\n",
            "\n",
            "Question: Is there a way to reduce NOT_PARSABLE responses during relevance evaluation?\n",
            "Answer: Yes.\n",
            "\n",
            "Question: Is there any document for the search query syntax on phoenix UI?\n",
            "Answer: Phoenix UI provides a search and retrieval optimization tool that includes an embeddings visualizer to help teams understand how their data is represented and clustered. This visual insight can guide decisions on indexing strategies, similarity measures, and data organization to improve the relevance and efficiency of search results.\n",
            "\n",
            "Question: Is it possible to search for values in children spans?\n",
            "Answer: Yes, it is possible to search for values in children spans by using specific filtering criteria and syntax within the SpanQuery method.\n",
            "\n",
            "Question: How can I export data from Arize to Phoenix?\n",
            "Answer: You can export data from Arize to Phoenix by clicking the export button on the Embeddings and Inferences pages, which will generate a code snippet for you to copy into a Python environment and install Phoenix. Alternatively, you can also query Arize for data directly using the Arize Python export client, where you will need to manually enter the data ranges and data you want to export.\n",
            "\n",
            "Question: How does tracing help in monitoring LLM applications?\n",
            "Answer: Tracing helps in monitoring LLM applications by allowing users to track application latency, token usage, runtime exceptions, retrieved documents, embeddings, LLM parameters, prompt templates, tool descriptions, and LLM function calls. This enables users to identify and address issues such as slow invocations, token consumption, critical exceptions, document retrieval details, prompt templates, and function call information within the LLM application.\n",
            "\n",
            "Question: How do spans and traces differ in Arize Phoenix?\n",
            "Answer: Spans represent units of work or operations within a trace, tracking specific operations made during a request. They contain detailed information about the operation they track, such as name, time-related data, log messages, and metadata. On the other hand, traces provide a broader picture by connecting multiple spans together to show the sequence of operations and events that occurred during the execution of a request. Traces encompass the entire journey of a request, while spans focus on individual units of work within that journey.\n",
            "\n",
            "Question: What are the benefits of using OpenTelemetry with Arize Phoenix?\n",
            "Answer: Using OpenTelemetry with Arize Phoenix allows for seamless integration and instrumentation with a variety of frameworks and SDKs across Python and JavaScript. This integration enables easy monitoring, evaluation, and troubleshooting of AI models, providing AI Engineers and Data Scientists with the ability to visualize data, evaluate performance, track down issues, and export data for improvement.\n",
            "\n",
            "Question: What customization options are available for tracing?\n",
            "Answer: Customization options available for tracing include logging to a specific project, switching projects in a notebook, adding custom metadata to spans, setting custom attributes and semantic attributes to child spans, setting metadata, tags, user information, prompt template attributes, and reading attributes from context.\n",
            "\n",
            "Question: How is trace data stored in Arize Phoenix?\n",
            "Answer: Trace data in Arize Phoenix can be stored by saving the traces present in a Phoenix instance to a designated location. This can be done by using the `save` method with the option to specify a directory where the trace data will be saved. Additionally, trace data can also be loaded from a specific directory by providing the trace ID and the path to the directory where the trace was stored.\n",
            "\n",
            "Question: How do I import existing traces?\n",
            "Answer: To import existing traces, you can either re-launch the app using trace data by utilizing the `px.launch_app` function with the `px.TraceDataset(df)` parameter, or load traces into an existing Phoenix instance by logging the traces with the `px.Client().log_traces` function and passing the `px.TraceDataset(df)` parameter.\n",
            "\n",
            "Question: How do I create a custom dataset?\n",
            "Answer: You can create a custom dataset by starting with manually curated examples, using historical logs from your application usage, and incorporating synthetic data generation. It is recommended to begin with high-quality curated examples, then leverage insights from user interactions to identify valuable data points for inclusion. Additionally, you can artificially generate examples once you have a foundation of handcrafted examples.\n",
            "\n",
            "Question: How do I export datasets?\n",
            "Answer: You can export datasets by fine-tuning models to achieve higher quality results, train on more examples, save on tokens, and reduce latency requests. Phoenix natively exports OpenAI Fine-Tuning JSONL if the dataset contains compatible inputs and outputs. Additionally, you can export OpenAI Evals format as JSONL for evaluating large language models or systems built using LLMs.\n",
            "\n",
            "Question: How can I contribute to Phoenix?\n",
            "Answer: To contribute to Phoenix, you can start by checking out the development guide, code of conduct, and Contribution License Agreement. It is recommended to pick a GitHub issue labeled with the tag \"good first issue\" to familiarize yourself with the codebase. To submit your code, fork the Phoenix repository, create a new branch, and open a Pull Request (PR) once your work is ready for review. In the PR template, describe the change, including the motivation/context, test coverage, and any other relevant information. A Core reviewer will review your PR, provide feedback, and once approved, your contribution will be merged into Phoenix.\n",
            "\n",
            "Question: How do I setup Phoenix in the Terminal?\n",
            "Answer: To set up Phoenix in the Terminal, you can run the following command:\n",
            "```\n",
            "python3 -m phoenix.server.main serve\n",
            "```\n",
            "This command will start the Phoenix server on port 6006. If you are running your instrumented notebook or application on the same machine, traces should automatically be exported to http://127.0.0.1:6006 without any additional configuration. However, if the server is running remotely, you will need to modify the environment variable PHOENIX_COLLECTOR_ENDPOINT to point to that machine (e.g. http://<my-remote-machine>:<port>).\n",
            "\n",
            "Question: Does Phoenix support JavaScript?\n",
            "Answer: Phoenix supports JavaScript by allowing manual instrumentation for tracing in JavaScript applications.\n",
            "\n",
            "Question: What coding languages does Phoenix support?\n",
            "Answer: Phoenix supports Python and JavaScript coding languages.\n",
            "\n",
            "Question: How do I setup Phoenix as a Container?\n",
            "Answer: To set up Phoenix as a Container, you can follow these steps:\n",
            "1. Pull the Phoenix image you want to run from Docker Hub.\n",
            "2. Run the pulled image while exposing port 6006 so you can access the Phoenix UI.\n",
            "3. Access the Phoenix UI at localhost:6006 to interact with the Phoenix server running in the container.\n",
            "\n",
            "Question: How do I setup Phoenix in a Notebook?\n",
            "Answer: To set up Phoenix in a Notebook, you can start by importing Phoenix as 'px' and launching the app using the 'px.launch_app()' command. This will initiate a local Phoenix server in the notebook environment. Remember that by default, Phoenix in the notebook does not persist your data.\n",
            "\n",
            "Question: What is the Data retention policy?\n",
            "Answer: The data retention policy allows users to persist data in the notebook by setting the use_temp_dir flag to false in px.launch_app, which will store the data in SQLite on the disk at the PHOENIX_WORKING_DIR. Alternatively, users can deploy a Phoenix instance and point to it via PHOENIX_COLLECTOR_ENDPOINT.\n",
            "\n",
            "Question: Will hosted Phoenix be on the latest version of Phoenix?\n",
            "Answer: Hosted Phoenix will always be on the latest version of Phoenix.\n",
            "\n",
            "Question: Is Hosted Phoenix free?\n",
            "Answer: Hosted Phoenix is free for all developers, with plans to introduce a paid tier in the future that will offer increased data retention and additional storage access.\n",
            "\n",
            "Question: Can I persist data in the notebook?\n",
            "Answer: Yes, you can persist data in the notebook by either setting the `use_temp_dir` flag to false in `px.launch_app`, which will persist your data in SQLite on your disk at the `PHOENIX_WORKING_DIR`. Alternatively, you can deploy a Phoenix instance and point to it via `PHOENIX_COLLECTOR_ENDPOINT`.\n",
            "\n",
            "Question: Can I use gRPC for trace collection?\n",
            "Answer: Phoenix does natively support gRPC for trace collection post 4.0 release.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pheonix Evals"
      ],
      "metadata": {
        "id": "Jd6tXZk-59VT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6iwW7y2Bco8H",
        "outputId": "49df3b47-4999-4a52-b4e6-d46da4e1654f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    context.trace_id  \\\n",
              "context.span_id  document_position                                     \n",
              "9f030a063826726e 0                  c7592c02a4f76318adde85b4febe2f62   \n",
              "                 1                  c7592c02a4f76318adde85b4febe2f62   \n",
              "                 2                  c7592c02a4f76318adde85b4febe2f62   \n",
              "                 3                  c7592c02a4f76318adde85b4febe2f62   \n",
              "                 4                  c7592c02a4f76318adde85b4febe2f62   \n",
              "...                                                              ...   \n",
              "fc02f9e9d95f7f85 0                  9af3cfbb6cc446d32032feb06ca32a45   \n",
              "                 1                  9af3cfbb6cc446d32032feb06ca32a45   \n",
              "                 2                  9af3cfbb6cc446d32032feb06ca32a45   \n",
              "                 3                  9af3cfbb6cc446d32032feb06ca32a45   \n",
              "                 4                  9af3cfbb6cc446d32032feb06ca32a45   \n",
              "\n",
              "                                                                   input  \\\n",
              "context.span_id  document_position                                         \n",
              "9f030a063826726e 0                      How do I send traces to Phoenix?   \n",
              "                 1                      How do I send traces to Phoenix?   \n",
              "                 2                      How do I send traces to Phoenix?   \n",
              "                 3                      How do I send traces to Phoenix?   \n",
              "                 4                      How do I send traces to Phoenix?   \n",
              "...                                                                  ...   \n",
              "fc02f9e9d95f7f85 0                  Can I use gRPC for trace collection?   \n",
              "                 1                  Can I use gRPC for trace collection?   \n",
              "                 2                  Can I use gRPC for trace collection?   \n",
              "                 3                  Can I use gRPC for trace collection?   \n",
              "                 4                  Can I use gRPC for trace collection?   \n",
              "\n",
              "                                                                            reference  \\\n",
              "context.span_id  document_position                                                      \n",
              "9f030a063826726e 0                  Tracing Core Concepts\\nHow to log traces\\nTo l...   \n",
              "                 1                  How does Tracing Work?\\nThe components behind ...   \n",
              "                 2                  Quickstart: Tracing\\nInspect the inner-working...   \n",
              "                 3                  Save and Load Traces\\nHow to manually save and...   \n",
              "                 4                  Trace a Deployed App\\nOnce you are done iterat...   \n",
              "...                                                                               ...   \n",
              "fc02f9e9d95f7f85 0                  Use Cases: Tracing\\nThe following. guides serv...   \n",
              "                 1                  Overview: Tracing\\nTracing the execution of LL...   \n",
              "                 2                  How does Tracing Work?\\nThe components behind ...   \n",
              "                 3                  os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...   \n",
              "                 4                  tracer_provider \\n=\\n trace_sdk\\n.\\nTracerProv...   \n",
              "\n",
              "                                    document_score  \n",
              "context.span_id  document_position                  \n",
              "9f030a063826726e 0                        0.841724  \n",
              "                 1                        0.840770  \n",
              "                 2                        0.831993  \n",
              "                 3                        0.821851  \n",
              "                 4                        0.821648  \n",
              "...                                            ...  \n",
              "fc02f9e9d95f7f85 0                        0.773752  \n",
              "                 1                        0.771979  \n",
              "                 2                        0.767665  \n",
              "                 3                        0.767380  \n",
              "                 4                        0.765412  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0007d4b-ac9d-4fcf-ae45-1945839d5008\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>context.trace_id</th>\n",
              "      <th>input</th>\n",
              "      <th>reference</th>\n",
              "      <th>document_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context.span_id</th>\n",
              "      <th>document_position</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">9f030a063826726e</th>\n",
              "      <th>0</th>\n",
              "      <td>c7592c02a4f76318adde85b4febe2f62</td>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "      <td>Tracing Core Concepts\\nHow to log traces\\nTo l...</td>\n",
              "      <td>0.841724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c7592c02a4f76318adde85b4febe2f62</td>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "      <td>How does Tracing Work?\\nThe components behind ...</td>\n",
              "      <td>0.840770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c7592c02a4f76318adde85b4febe2f62</td>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "      <td>Quickstart: Tracing\\nInspect the inner-working...</td>\n",
              "      <td>0.831993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c7592c02a4f76318adde85b4febe2f62</td>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "      <td>Save and Load Traces\\nHow to manually save and...</td>\n",
              "      <td>0.821851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c7592c02a4f76318adde85b4febe2f62</td>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "      <td>Trace a Deployed App\\nOnce you are done iterat...</td>\n",
              "      <td>0.821648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">fc02f9e9d95f7f85</th>\n",
              "      <th>0</th>\n",
              "      <td>9af3cfbb6cc446d32032feb06ca32a45</td>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "      <td>Use Cases: Tracing\\nThe following. guides serv...</td>\n",
              "      <td>0.773752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9af3cfbb6cc446d32032feb06ca32a45</td>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "      <td>Overview: Tracing\\nTracing the execution of LL...</td>\n",
              "      <td>0.771979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9af3cfbb6cc446d32032feb06ca32a45</td>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "      <td>How does Tracing Work?\\nThe components behind ...</td>\n",
              "      <td>0.767665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9af3cfbb6cc446d32032feb06ca32a45</td>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "      <td>os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...</td>\n",
              "      <td>0.767380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9af3cfbb6cc446d32032feb06ca32a45</td>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "      <td>tracer_provider \\n=\\n trace_sdk\\n.\\nTracerProv...</td>\n",
              "      <td>0.765412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0007d4b-ac9d-4fcf-ae45-1945839d5008')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0007d4b-ac9d-4fcf-ae45-1945839d5008 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0007d4b-ac9d-4fcf-ae45-1945839d5008');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22e5b732-e72a-4f3f-ab99-11f4ec8feb90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22e5b732-e72a-4f3f-ab99-11f4ec8feb90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22e5b732-e72a-4f3f-ab99-11f4ec8feb90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_639c9a30-550f-4acb-95a7-166f2955e1a5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('retrieved_documents_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_639c9a30-550f-4acb-95a7-166f2955e1a5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('retrieved_documents_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "retrieved_documents_df",
              "summary": "{\n  \"name\": \"retrieved_documents_df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"context.trace_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"4d6e9230f68b1c497ccc315928aaacaa\",\n          \"0d40009b0dd9a14e41fcb0e70a02dd57\",\n          \"0989af61124a95e0c1a81041c044087a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"What are the benefits of using OpenTelemetry with Arize Phoenix?\",\n          \"If I am using both llamaindex and langchain in the same application, can I set up instrumentation for both of them?\",\n          \"What formats are supported for exporting inference data?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 122,\n        \"samples\": [\n          \"VertexAI\\nInstrument LLM calls made using VertexAI's SDK via the VertexAIInstrumentor\\nThe VertexAI SDK can be instrumented using the \\nopeninference-instrumentation-vertexai\\n package.\\nLaunch Phoenix\\nNotebook\\nCommand Line\\nDocker\\napp.phoenix.arize.com\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\narize-phoenix\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nLaunch Phoenix:\\nCopy\\nimport\\n phoenix \\nas\\n px\\n\\n\\npx\\n.\\nlaunch_app\\n()\\nConnect your notebook to Phoenix:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nBy default, notebook instances do not have persistent storage, so your traces will disappear after the notebook is closed. See \\nPersistence\\n or use one of the other deployment options to retain traces.\\nLaunch your local Phoenix instance:\\nCopy\\npython3\\n \\n-m\\n \\nphoenix.server.main\\n \\nserve\\nFor details on customizing a local terminal deployment, see \\nTerminal Setup\\n.\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nSee \\nQuickstart: Deployment\\n for more details\\nPull latest Phoenix image from \\nDocker Hub\\n:\\nCopy\\ndocker\\n \\npull\\n \\narizephoenix/phoenix:latest\\nRun your containerized instance:\\nCopy\\ndocker\\n \\nrun\\n \\n-p\\n \\n6006:6006\\n \\narizephoenix/phoenix:latest\\nThis will expose the Phoenix on \\nlocalhost:6006\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nFor more info on using Phoenix with Docker, see \\nDocker\\nIf you don't want to host an instance of Phoenix yourself or use a notebook instance, you can use a persistent instance provided on our site. Sign up for an Arize Phoenix account at\\nhttps://app.phoenix.arize.com/login\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your cloud instance:\\nCopy\\nimport\\n os\\n\\n\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\nresources \\nimport\\n Resource\",\n          \"Instrumenting Prompt Templates and Prompt Variables\\nInstrumenting prompt templates and variables allows you to track and visualize prompt changes. These can also be combined with \\nExperiments\\n to measure the performance changes driven by each of your prompts.\\nPython\\nWe provide a \\nusing_prompt_template\\n context manager to add a prompt template (including its version and variables) to the current OpenTelemetry Context. OpenInference \\nauto-instrumentors\\n will read this Context and pass the prompt template fields as span attributes, following the OpenInference \\nsemantic conventions\\n. Its inputs must be of the following type:\\nTemplate: non-empty string.\\nVersion: non-empty string.\\nVariables: a dictionary with string keys. This dictionary will be serialized to JSON when saved to the OTEL Context and remain a JSON string when sent as a span attribute.\\nCopy\\nfrom\\n openinference\\n.\\ninstrumentation \\nimport\\n using_prompt_template\\n\\n\\n\\n\\nprompt_template \\n=\\n \\n\\\"Please describe the weather forecast for \\n{city}\\n on \\n{date}\\n\\\"\\n\\n\\nprompt_template_variables \\n=\\n \\n{\\n\\\"city\\\"\\n:\\n \\n\\\"Johannesburg\\\"\\n,\\n \\n\\\"date\\\"\\n:\\n\\\"July 11\\\"\\n}\\n\\n\\nwith\\n \\nusing_prompt_template\\n(\\n\\n\\n    template\\n=\\nprompt_template,\\n\\n\\n    variables\\n=\\nprompt_template_variables,\\n\\n\\n    version\\n=\\n\\\"v1.0\\\"\\n,\\n\\n\\n    ):\\n\\n\\n    \\n# Commonly preceeds a chat completion to append templates to auto instrumentation\\n\\n\\n    \\n# response = client.chat.completions.create()\\n\\n\\n    \\n# Calls within this block will generate spans with the attributes:\\n\\n\\n    \\n# \\\"llm.prompt_template.template\\\" = \\\"Please describe the weather forecast for {city} on {date}\\\"\\n\\n\\n    \\n# \\\"llm.prompt_template.version\\\" = \\\"v1.0\\\"\\n\\n\\n    \\n# \\\"llm.prompt_template.variables\\\" = \\\"{\\\\\\\"city\\\\\\\": \\\\\\\"Johannesburg\\\\\\\", \\\\\\\"date\\\\\\\": \\\\\\\"July 11\\\\\\\"}\\\" # JSON serialized\\n\\n\\n    ...\\nIt can also be used as a decorator:\\nCopy\\n@using_prompt_template\\n(\\n\\n\\n    template\\n=\\nprompt_template,\\n\\n\\n    variables\\n=\\nprompt_template_variables,\\n\\n\\n    version\\n=\\n\\\"v1.0\\\"\\n,\\n\\n\\n)\\n\\n\\ndef\\n \\ncall_fn\\n(\\n*\\nargs\\n,\\n \\n**\\nkwargs\\n):\\n\\n\\n    \\n# Calls within this function will generate spans with the attributes:\\n\\n\\n    \\n# \\\"llm.prompt_template.template\\\" = \\\"Please describe the weather forecast for {city} on {date}\\\"\\n\\n\\n    \\n# \\\"llm.prompt_template.version\\\" = \\\"v1.0\\\"\\n\\n\\n    \\n# \\\"llm.prompt_template.variables\\\" = \\\"{\\\\\\\"city\\\\\\\": \\\\\\\"Johannesburg\\\\\\\", \\\\\\\"date\\\\\\\": \\\\\\\"July 11\\\\\\\"}\\\" # JSON serialized\\n\\n\\n    ...\\nPrevious\\nCustomize Spans\\nNext\\nAuto Instrumentation\\nLast updated \\n8 days ago\",\n          \"Prompt flow\\nCreate flows using Microsoft PromptFlow and send their traces to Phoenix\\nThis integration will allow you to trace \\nMicrosoft PromptFlow\\n flows and send their traces into\\narize-phoenix\\n.\\nLaunch Phoenix\\nNotebook\\nCommand Line\\nDocker\\napp.phoenix.arize.com\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\narize-phoenix\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nLaunch Phoenix:\\nCopy\\nimport\\n phoenix \\nas\\n px\\n\\n\\npx\\n.\\nlaunch_app\\n()\\nConnect your notebook to Phoenix:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nBy default, notebook instances do not have persistent storage, so your traces will disappear after the notebook is closed. See \\nPersistence\\n or use one of the other deployment options to retain traces.\\nLaunch your local Phoenix instance:\\nCopy\\npython3\\n \\n-m\\n \\nphoenix.server.main\\n \\nserve\\nFor details on customizing a local terminal deployment, see \\nTerminal Setup\\n.\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nSee \\nQuickstart: Deployment\\n for more details\\nPull latest Phoenix image from \\nDocker Hub\\n:\\nCopy\\ndocker\\n \\npull\\n \\narizephoenix/phoenix:latest\\nRun your containerized instance:\\nCopy\\ndocker\\n \\nrun\\n \\n-p\\n \\n6006:6006\\n \\narizephoenix/phoenix:latest\\nThis will expose the Phoenix on \\nlocalhost:6006\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nFor more info on using Phoenix with Docker, see \\nDocker\\nIf you don't want to host an instance of Phoenix yourself or use a notebook instance, you can use a persistent instance provided on our site. Sign up for an Arize Phoenix account at\\nhttps://app.phoenix.arize.com/login\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your cloud instance:\\nCopy\\nimport\\n os\\n\\n\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\nresources \\nimport\\n Resource\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.035202050177541064,\n        \"min\": 0.7127852871704106,\n        \"max\": 0.9000367065858801,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          0.8240083591448667,\n          0.8132033037857554,\n          0.8316631141434646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from phoenix.session.evaluation import get_retrieved_documents\n",
        "\n",
        "retrieved_documents_df = get_retrieved_documents(px.Client())\n",
        "retrieved_documents_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phoenix.session.evaluation import get_qa_with_reference\n",
        "\n",
        "queries_df = get_qa_with_reference(px.active_session())\n",
        "queries_df"
      ],
      "metadata": {
        "id": "QzKMthtAxzsU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "a65f625e-b1c5-4e51-ac9c-00ff0f3efbb9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              input  \\\n",
              "context.span_id                                                       \n",
              "54cdf11c954ecc3f                   How do I send traces to Phoenix?   \n",
              "5c89706b00c67ba9     What happens if I send the same traces twice?    \n",
              "3ef54d0c9aee79ee  Which frameworks and LLM providers are support...   \n",
              "9c0f677d46d73b9d  How can users create and manage datasets for p...   \n",
              "b7b06e01d71b7fef          How does Arize Phoenix use OpenTelemetry?   \n",
              "...                                                             ...   \n",
              "aa5c48651130d333                 What is the Data retention policy?   \n",
              "789bd79b491d47c9  Will hosted Phoenix be on the latest version o...   \n",
              "630103d91a7d81e1                            Is Hosted Phoenix free?   \n",
              "26b493baf6346e37                Can I persist data in the notebook?   \n",
              "93d67c391c0535d6               Can I use gRPC for trace collection?   \n",
              "\n",
              "                                                             output  \\\n",
              "context.span_id                                                       \n",
              "54cdf11c954ecc3f  You can send traces to Phoenix by instrumentin...   \n",
              "5c89706b00c67ba9  Tracing records the paths taken by requests as...   \n",
              "3ef54d0c9aee79ee  Arize Phoenix supports a variety of frameworks...   \n",
              "9c0f677d46d73b9d  Users can create and manage datasets for promp...   \n",
              "b7b06e01d71b7fef  Arize Phoenix uses OpenTelemetry for instrumen...   \n",
              "...                                                             ...   \n",
              "aa5c48651130d333  The data retention policy allows users to pers...   \n",
              "789bd79b491d47c9  Hosted Phoenix will always be on the latest ve...   \n",
              "630103d91a7d81e1  Hosted Phoenix is free for all developers, wit...   \n",
              "26b493baf6346e37  Yes, you can persist data in the notebook by e...   \n",
              "93d67c391c0535d6  Phoenix does natively support gRPC for trace c...   \n",
              "\n",
              "                                                          reference  \n",
              "context.span_id                                                      \n",
              "54cdf11c954ecc3f  Tracing Core Concepts\\nHow to log traces\\nTo l...  \n",
              "5c89706b00c67ba9  The reply half may be formatted for response p...  \n",
              "3ef54d0c9aee79ee  Arize\\nPhoenix works hand-in-hand with Arize, ...  \n",
              "9c0f677d46d73b9d  Arize\\nPhoenix works hand-in-hand with Arize, ...  \n",
              "b7b06e01d71b7fef  Arize Phoenix\\nAI Observability and Evaluation...  \n",
              "...                                                             ...  \n",
              "aa5c48651130d333  Email Extraction\\nComing soon\\nPrevious\\nSumma...  \n",
              "789bd79b491d47c9  Deployment\\nHow to self-host a phoenix instanc...  \n",
              "630103d91a7d81e1  Hosted Phoenix\\nWe now offer a hosted version ...  \n",
              "26b493baf6346e37  os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...  \n",
              "93d67c391c0535d6  Use Cases: Tracing\\nThe following. guides serv...  \n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-397782d1-9399-4b83-bd7c-c029dd6f5601\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context.span_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54cdf11c954ecc3f</th>\n",
              "      <td>How do I send traces to Phoenix?</td>\n",
              "      <td>You can send traces to Phoenix by instrumentin...</td>\n",
              "      <td>Tracing Core Concepts\\nHow to log traces\\nTo l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5c89706b00c67ba9</th>\n",
              "      <td>What happens if I send the same traces twice?</td>\n",
              "      <td>Tracing records the paths taken by requests as...</td>\n",
              "      <td>The reply half may be formatted for response p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3ef54d0c9aee79ee</th>\n",
              "      <td>Which frameworks and LLM providers are support...</td>\n",
              "      <td>Arize Phoenix supports a variety of frameworks...</td>\n",
              "      <td>Arize\\nPhoenix works hand-in-hand with Arize, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9c0f677d46d73b9d</th>\n",
              "      <td>How can users create and manage datasets for p...</td>\n",
              "      <td>Users can create and manage datasets for promp...</td>\n",
              "      <td>Arize\\nPhoenix works hand-in-hand with Arize, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b7b06e01d71b7fef</th>\n",
              "      <td>How does Arize Phoenix use OpenTelemetry?</td>\n",
              "      <td>Arize Phoenix uses OpenTelemetry for instrumen...</td>\n",
              "      <td>Arize Phoenix\\nAI Observability and Evaluation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aa5c48651130d333</th>\n",
              "      <td>What is the Data retention policy?</td>\n",
              "      <td>The data retention policy allows users to pers...</td>\n",
              "      <td>Email Extraction\\nComing soon\\nPrevious\\nSumma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789bd79b491d47c9</th>\n",
              "      <td>Will hosted Phoenix be on the latest version o...</td>\n",
              "      <td>Hosted Phoenix will always be on the latest ve...</td>\n",
              "      <td>Deployment\\nHow to self-host a phoenix instanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630103d91a7d81e1</th>\n",
              "      <td>Is Hosted Phoenix free?</td>\n",
              "      <td>Hosted Phoenix is free for all developers, wit...</td>\n",
              "      <td>Hosted Phoenix\\nWe now offer a hosted version ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26b493baf6346e37</th>\n",
              "      <td>Can I persist data in the notebook?</td>\n",
              "      <td>Yes, you can persist data in the notebook by e...</td>\n",
              "      <td>os\\n.\\nenviron\\n[\\n\"PHOENIX_NOTEBOOK_ENV\"\\n]\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93d67c391c0535d6</th>\n",
              "      <td>Can I use gRPC for trace collection?</td>\n",
              "      <td>Phoenix does natively support gRPC for trace c...</td>\n",
              "      <td>Use Cases: Tracing\\nThe following. guides serv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-397782d1-9399-4b83-bd7c-c029dd6f5601')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-397782d1-9399-4b83-bd7c-c029dd6f5601 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-397782d1-9399-4b83-bd7c-c029dd6f5601');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28754c00-af41-4cbb-b764-171d13585be1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28754c00-af41-4cbb-b764-171d13585be1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28754c00-af41-4cbb-b764-171d13585be1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ebd98560-2926-465f-a437-88ddb2f8386c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('queries_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ebd98560-2926-465f-a437-88ddb2f8386c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('queries_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "queries_df",
              "summary": "{\n  \"name\": \"queries_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"context.span_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"1d1278e7d05ef1dc\",\n          \"84ee64033b82d183\",\n          \"c76d67a1a42f3daf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"What are the benefits of using OpenTelemetry with Arize Phoenix?\",\n          \"If I am using both llamaindex and langchain in the same application, can I set up instrumentation for both of them?\",\n          \"What formats are supported for exporting inference data?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Using OpenTelemetry with Arize Phoenix allows for seamless integration and instrumentation with a variety of frameworks and SDKs across Python and JavaScript. This integration enables easy monitoring, evaluation, and troubleshooting of AI models, providing AI Engineers and Data Scientists with the ability to visualize data, evaluate performance, track down issues, and export data for improvement.\",\n          \"Yes, you can set up instrumentation for both LlamaIndex and LangChain in the same application. Each module provides instructions on how to instrument them within your application, allowing you to collect and display traces from both LlamaIndex and LangChain in Arize Phoenix.\",\n          \"Your data can be exported as a Parquet file or as a dataframe.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Arize\\nPhoenix works hand-in-hand with Arize, it's enterprise counterpart\\nShare Embeddings Data with Arize\\nEasily share data when you discover interesting insights so your data science team can perform further investigation or kickoff retraining workflows.\\nPrevious\\nModels\\nNext\\nExport Data from Arize to Phoenix\\nLast updated \\n4 months ago\\n\\nArize Phoenix\\nAI Observability and Evaluation\\nPhoenix is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows AI Engineers and Data Scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\\n\\nPhoenix is built by \\nArize AI\\n, the company behind the the industry-leading AI observability platform,  and a set of core contributors.\\nInstall Phoenix\\nUsing pip\\nUsing conda\\nContainer\\nIn your Jupyter or Colab environment, run the following command to install.\\nCopy\\npip\\n \\ninstall\\n \\narize-phoenix\\nFor full details on how to run phoenix in various environments such as Databricks, consult our \\nenvironments guide.\\nCopy\\nconda\\n \\ninstall\\n \\n-c\\n \\nconda-forge\\n \\narize-phoenix[evals]\\nPhoenix can also run via a container. The image can be found at:\\nCheckout the \\nenvironments section\\n and \\ndeployment guide\\n for details.\\nPhoenix works with OpenTelemetry and \\nOpenInference\\n instrumentation. If you are looking to deploy phoenix as a service rather than a library, see \\nDeployment\\nQuickstarts\\nRunning Phoenix for the first time? Select a quickstart below. \\nDemo\\nNext Steps\\nTry our Tutorials\\nCheck out a comprehensive list of example notebooks for LLM Traces, Evals, RAG Analysis, and more.  \\nCommunity\\nJoin the Phoenix Slack community to ask questions, share findings, provide feedback, and connect with other developers. \\nNext\\nQuickstart\\nLast updated \\n4 days ago\\n\\nUser Guide\\nLLM observability is complete visibility into every layer of an LLM-based software system: the application, the prompt, and the response.\\nPhoenix is a comprehensive platform designed to enable observability across every layer of an LLM-based system, empowering teams to build, optimize, and maintain high-quality applications efficiently.\\n\\ud83d\\udee0\\ufe0f Develop\\nDuring the development phase, Phoenix offers essential tools for debugging, experimentation, evaluation, prompt tracking, and search and retrieval.\\nTraces for Debugging\\nPhoenix's tracing and span analysis capabilities are invaluable during the prototyping and debugging stages. By instrumenting application code with Phoenix, teams gain detailed insights into the execution flow, making it easier to identify and resolve issues. Developers can drill down into specific spans, analyze performance metrics, and access relevant logs and metadata to streamline debugging efforts.\\nQuickstart: Tracing\\nExperimentation\\nLeverage experiments to measure prompt and model performance. Typically during this early stage, you'll focus on gather a robust set of test cases and evaluation metrics to test initial iterations of your application. Experiments at this stage may resemble unit tests, as they're geared towards ensure your application performs correctly.\\nRun Experiments\\nEvaluation\\nEither as a part of experiments or a standalone feature, evaluations help you understand how your app is performing at a granular level. Typical evaluations might be correctness evals compared against a ground truth data set, or LLM-as-a-judge evals to detect hallucinations or relevant RAG output.\\nQuickstart: Evals\\nPrompt Tracking\\nInstrument prompt and prompt variable collection to associate iterations of your app with the performance measured through evals and experiments. Phoenix tracks prompt templates, variables, and versions during execution to help you identify improvements and degradations.\\nInstrumenting Prompt Templates and Prompt Variables\\nSearch & Retrieval Embeddings Visualizer\\nPhoenix's search and retrieval optimization tools include an embeddings visualizer that helps teams understand how their data is being represented and clustered. This visual insight can guide decisions on indexing strategies, similarity measures, and data organization to improve the relevance and efficiency of search results.\\nQuickstart: Inferences\\n\\ud83e\\uddea Testing/Staging\\nIn the testing and staging environment, Phoenix supports comprehensive evaluation, benchmarking, and data curation. Traces, experimentation, prompt tracking, and embedding visualizer remain important in the testing and staging phase, helping teams identify and resolve issues before deployment.\\nIterate via Experiments\\nWith a stable set of test cases and evaluations defined, you can now easily iterate on your application and view performance changes in Phoenix right away. Swap out models, prompts, or pipeline logic, and run your experiment to immediately see the impact on performance.\\nRun Experiments\\nEvals Testing\\nPhoenix's flexible evaluation framework supports thorough testing of LLM outputs. Teams can define custom metrics, collect user feedback, and leverage separate LLMs for automated assessment. Phoenix offers tools for analyzing evaluation results, identifying trends, and tracking improvements over time.\\nQuickstart: Evals\\nCurate Data\\nPhoenix assists in curating high-quality data for testing and fine-tuning. It provides tools for data exploration, cleaning, and labeling, enabling teams to curate representative data that covers a wide range of use cases and edge conditions.\\nQuickstart: Datasets\\nGuardrails\\nAdd guardrails to your application to prevent malicious and erroneous inputs and outputs. Guardrails will be visualized in Phoenix, and can be attached to spans and traces in the same fashion as evaluation metrics.\\nGuardrails AI\\n\\ud83d\\ude80 Production\\nIn production, Phoenix works hand-in-hand with Arize, which focuses on the production side of the LLM lifecycle. The integration ensures a smooth transition from development to production, with consistent tooling and metrics across both platforms.\\nTraces in Production\\nPhoenix and Arize use the same collector frameworks in development and production. This allows teams to monitor latency, token usage, and other performance metrics, setting up alerts when thresholds are exceeded. \\nEvals for Production\\nPhoenix's evaluation framework can be used to generate ongoing assessments of LLM performance in production. Arize complements this with online evaluations, enabling teams to set up alerts if evaluation metrics, such as hallucination rates, go beyond acceptable thresholds.\\nFine-tuning\\nPhoenix and Arize together help teams identify data points for fine-tuning based on production performance and user feedback. This targeted approach ensures that fine-tuning efforts are directed towards the most impactful areas, maximizing the return on investment.\\nPhoenix, in collaboration with Arize, empowers teams to build, optimize, and maintain high-quality LLM applications throughout the entire lifecycle. By providing a comprehensive observability platform and seamless integration with production monitoring tools, Phoenix and Arize enable teams to deliver exceptional LLM-driven experiences with confidence and efficiency.\\nPrevious\\nHosted Phoenix\\nNext\\nExamples\\nLast updated \\n1 day ago\\n\\nIntegrations: Tracing\\nPhoenix natively works with a variety of frameworks and SDKs across Python and JavaScript via OpenTelemetry\\n auto-instrumentation\\n.\\nPython\\nLibrary\\nInstrumentation Package\\nLlamaIndex\\n\\n\\nopeninference-instrumentation-llama-index\\nLangChain\\n\\n\\nopeninference-instrumentation-langchain\\nOpenAI\\n\\n\\nopeninference-instrumentation-openai\\nMistralAI\\n\\n\\nopeninference-instrumentation-mistralai\\nVertexAI\\n\\n\\nopeninference-instrumentation-vertexai\\nDSPy\\n\\n\\nopeninference-instrumentation-dspy\\nAWS Bedrock\\n\\n\\nopeninference-instrumentation-bedrock\\nopeninference-instrumentation-guardrails\\nHaystack\\n\\n\\nopeninference-instrumentation-haystack\\nCrewAI\\n\\n\\nopeninference-instrumentation-crewai\\nJavascript\\nLibrary\\nInstrumentation\\n@arizeai/openinference-instrumentation-openai\\n@arizeai/openinference-instrumentation-langchain\\nPrevious\\nQuickstart: Tracing\\nNext\\nOpenAI\\nLast updated \\n1 day ago\\n\\nVertexAI\\nInstrument LLM calls made using VertexAI's SDK via the VertexAIInstrumentor\\nThe VertexAI SDK can be instrumented using the \\nopeninference-instrumentation-vertexai\\n package.\\nLaunch Phoenix\\nNotebook\\nCommand Line\\nDocker\\napp.phoenix.arize.com\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\narize-phoenix\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nLaunch Phoenix:\\nCopy\\nimport\\n phoenix \\nas\\n px\\n\\n\\npx\\n.\\nlaunch_app\\n()\\nConnect your notebook to Phoenix:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nBy default, notebook instances do not have persistent storage, so your traces will disappear after the notebook is closed. See \\nPersistence\\n or use one of the other deployment options to retain traces.\\nLaunch your local Phoenix instance:\\nCopy\\npython3\\n \\n-m\\n \\nphoenix.server.main\\n \\nserve\\nFor details on customizing a local terminal deployment, see \\nTerminal Setup\\n.\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nSee \\nQuickstart: Deployment\\n for more details\\nPull latest Phoenix image from \\nDocker Hub\\n:\\nCopy\\ndocker\\n \\npull\\n \\narizephoenix/phoenix:latest\\nRun your containerized instance:\\nCopy\\ndocker\\n \\nrun\\n \\n-p\\n \\n6006:6006\\n \\narizephoenix/phoenix:latest\\nThis will expose the Phoenix on \\nlocalhost:6006\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nFor more info on using Phoenix with Docker, see \\nDocker\\nIf you don't want to host an instance of Phoenix yourself or use a notebook instance, you can use a persistent instance provided on our site. Sign up for an Arize Phoenix account at\\nhttps://app.phoenix.arize.com/login\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your cloud instance:\\nCopy\\nimport\\n os\\n\\n\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\nresources \\nimport\\n Resource\",\n          \"LangChain.js\\nThis module provides automatic instrumentation for LangChain.js, more specifically, the @langchain/core module. which may be used in conjunction with @opentelemetry/sdk-trace-node.\\nInstall\\nCopy\\nnpm\\n \\ninstall\\n \\n--save\\n \\n@arizeai/openinference-instrumentation-langchain\\nSetup\\nTo load the LangChain instrumentation, manually instrument the \\n@langchain/core/callbacks/manager\\n module. The callbacks manager must be manually instrumented due to the non-traditional module structure in \\n@langchain/core\\n. Additional instrumentations can be registered as usual in the registerInstrumentations function.\\nCopy\\nimport\\n { NodeTracerProvider } \\nfrom\\n \\n\\\"@opentelemetry/sdk-trace-node\\\"\\n;\\n\\n\\nimport\\n { \\n\\n\\n  LangChainInstrumentation \\n\\n\\n} \\nfrom\\n \\n\\\"@arizeai/openinference-instrumentation-langchain\\\"\\n;\\n\\n\\nimport\\n \\n*\\n \\nas\\n CallbackManagerModule \\nfrom\\n \\n\\\"@langchain/core/callbacks/manager\\\"\\n;\\n\\n\\n\\n\\nconst\\n \\nprovider\\n \\n=\\n \\nnew\\n \\nNodeTracerProvider\\n();\\n\\n\\nprovider\\n.register\\n();\\n\\n\\n\\n\\nconst\\n \\nlcInstrumentation\\n \\n=\\n \\nnew\\n \\nLangChainInstrumentation\\n();\\n\\n\\n// LangChain must be manually instrumented as it doesn't have \\n\\n\\n// a traditional module structure\\n\\n\\nlcInstrumentation\\n.manuallyInstrument\\n(CallbackManagerModule);\\n\\n\\nResources\\nExample project\\nOpenInference package\\nPrevious\\nOpenAI Node SDK\\nNext\\nConcepts: Tracing\\nLast updated \\n6 days ago\\n\\nLlamaIndex\\nHow to use the python LlamaIndexInstrumentor to trace LlamaIndex\\nLlamaIndex\\n is a data framework for your LLM application. It's a powerful framework by which you can build an application that leverages RAG (retrieval-augmented generation) to super-charge an LLM with your own data. RAG is an extremely powerful LLM application model because it lets you harness the power of LLMs such as OpenAI's GPT but tuned to your data and use-case.\\nFor LlamaIndex, tracing instrumentation is added via an OpenTelemetry instrumentor aptly named the \\nLlamaIndexInstrumentor\\n . This callback is what is used to create spans and send them to the Phoenix collector.\\nInstrumentation (>=0.10.43)\\nLegacy One-Click (<0.10.43)\\nLegacy (<v0.10)\\nPhoenix supports LlamaIndex's latest \\ninstrumentation\\n paradigm.\\nTo get started, pip install the following.\\nCopy\\npip install \\\"llama-index-core>=0.10.43\\\" \\\"openinference-instrumentation-llama-index>=2\\\" \\\"opentelemetry-proto>=1.12.0\\\" opentelemetry-exporter-otlp opentelemetry-sdk\\nUse the following code snippet to activate the instrumentation.\\nNote that the \\nendpoint\\n variable below should the address of the Phoenix receiver.\\nCopy\\nfrom\\n openinference\\n.\\ninstrumentation\\n.\\nllama_index \\nimport\\n LlamaIndexInstrumentor\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\nendpoint \\n=\\n \\n\\\"http://127.0.0.1:6006/v1/traces\\\"\\n  \\n# Phoenix receiver address\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(\\nSimpleSpanProcessor\\n(\\nOTLPSpanExporter\\n(endpoint)))\\n\\n\\n\\n\\nLlamaIndexInstrumentor\\n().\\ninstrument\\n(tracer_provider\\n=\\ntracer_provider)\\nNote that the legacy One-Click system of spans can still be used instead by setting \\nuse_legacy_callback_handler=True\\n as shown below.\\nCopy\\nLlamaIndexInstrumentor\\n().\\ninstrument\\n(\\n\\n\\n    tracer_provider\\n=\\ntracer_provider,\\n\\n\\n    use_legacy_callback_handler\\n=\\nTrue\\n,\\n\\n\\n)\\nUsing phoenix as a callback requires an install of `llama-index-callbacks-arize-phoenix>0.1.3'\\nllama-index 0.10 introduced modular sub-packages. To use llama-index's one click,  you must install the small integration first:\\nCopy\\npip\\n \\ninstall\\n \\n'llama-index-callbacks-arize-phoenix>0.1.3'\\nCopy\\n# Phoenix can display in real time the traces automatically\\n\\n\\n# collected from your LlamaIndex application.\\n\\n\\nimport\\n phoenix \\nas\\n px\\n\\n\\n# Look for a URL in the output to open the App in a browser.\\n\\n\\npx\\n.\\nlaunch_app\\n()\\n\\n\\n# The App is initially empty, but as you proceed with the steps below,\\n\\n\\n# traces will appear automatically as your LlamaIndex application runs.\\n\\n\\n\\n\\nfrom\\n llama_index\\n.\\ncore \\nimport\\n set_global_handler\\n\\n\\n\\n\\nset_global_handler\\n(\\n\\\"arize_phoenix\\\"\\n)\\n\\n\\n\\n\\n# Run all of your LlamaIndex applications as usual and traces\\n\\n\\n# will be collected and displayed in Phoenix.\\nIf you are using an older version of llamaIndex (pre-0.10), you can still use phoenix. You will have to be using \\narize-phoenix>3.0.0\\n and downgrade \\nopeninference-instrumentation-llama-index<1.0.0\\nCopy\\n# Phoenix can display in real time the traces automatically\\n\\n\\n# collected from your LlamaIndex application.\\n\\n\\nimport\\n phoenix \\nas\\n px\\n\\n\\n# Look for a URL in the output to open the App in a browser.\\n\\n\\npx\\n.\\nlaunch_app\\n()\\n\\n\\n# The App is initially empty, but as you proceed with the steps below,\\n\\n\\n# traces will appear automatically as your LlamaIndex application runs.\\n\\n\\n\\n\\nimport\\n llama_index\\n\\n\\nllama_index\\n.\\nset_global_handler\\n(\\n\\\"arize_phoenix\\\"\\n)\\n\\n\\n\\n\\n# Run all of your LlamaIndex applications as usual and traces\\n\\nLangChain\\nHow to use the python LangChainInstrumentor to trace LangChain and LangGraph\\nPhoenix has first-class support for \\nLangChain\\n applications.\\nLaunch Phoenix\\nNotebook\\nCommand Line\\nDocker\\napp.phoenix.arize.com\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\narize-phoenix\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nLaunch Phoenix:\\nCopy\\nimport\\n phoenix \\nas\\n px\\n\\n\\npx\\n.\\nlaunch_app\\n()\\nConnect your notebook to Phoenix:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nBy default, notebook instances do not have persistent storage, so your traces will disappear after the notebook is closed. See \\nPersistence\\n or use one of the other deployment options to retain traces.\\nLaunch your local Phoenix instance:\\nCopy\\npython3\\n \\n-m\\n \\nphoenix.server.main\\n \\nserve\\nFor details on customizing a local terminal deployment, see \\nTerminal Setup\\n.\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nSee \\nQuickstart: Deployment\\n for more details\\nPull latest Phoenix image from \\nDocker Hub\\n:\\nCopy\\ndocker\\n \\npull\\n \\narizephoenix/phoenix:latest\\nRun your containerized instance:\\nCopy\\ndocker\\n \\nrun\\n \\n-p\\n \\n6006:6006\\n \\narizephoenix/phoenix:latest\\nThis will expose the Phoenix on \\nlocalhost:6006\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your instance using:\\nCopy\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nexporter\\n.\\notlp\\n.\\nproto\\n.\\nhttp\\n.\\ntrace_exporter \\nimport\\n OTLPSpanExporter\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\n\\n\\n\\ntracer_provider \\n=\\n trace_sdk\\n.\\nTracerProvider\\n()\\n\\n\\nspan_exporter \\n=\\n \\nOTLPSpanExporter\\n(\\n\\\"http://localhost:6006/v1/traces\\\"\\n)\\n\\n\\nspan_processor \\n=\\n \\nSimpleSpanProcessor\\n(span_exporter)\\n\\n\\ntracer_provider\\n.\\nadd_span_processor\\n(span_processor)\\n\\n\\ntrace_api\\n.\\nset_tracer_provider\\n(tracer_provider)\\nFor more info on using Phoenix with Docker, see \\nDocker\\nIf you don't want to host an instance of Phoenix yourself or use a notebook instance, you can use a persistent instance provided on our site. Sign up for an Arize Phoenix account at\\nhttps://app.phoenix.arize.com/login\\nInstall packages:\\nCopy\\npip\\n \\ninstall\\n \\nopentelemetry-sdk\\n \\nopentelemetry-exporter-otlp\\nConnect your application to your cloud instance:\\nCopy\\nimport\\n os\\n\\n\\nfrom\\n opentelemetry \\nimport\\n trace \\nas\\n trace_api\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk \\nimport\\n trace \\nas\\n trace_sdk\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\nresources \\nimport\\n Resource\\n\\n\\nfrom\\n opentelemetry\\n.\\nsdk\\n.\\ntrace\\n.\\nexport \\nimport\\n SimpleSpanProcessor\\n\\nfrom\\n llama_index\\n.\\ncore \\nimport\\n set_global_handler\\n\\n\\n\\n\\nset_global_handler\\n(\\n\\\"arize_phoenix\\\"\\n)\\n\\n\\n\\n\\n# Run all of your LlamaIndex applications as usual and traces\\n\\n\\n# will be collected and displayed in Phoenix.\\nIf you are using an older version of llamaIndex (pre-0.10), you can still use phoenix. You will have to be using \\narize-phoenix>3.0.0\\n and downgrade \\nopeninference-instrumentation-llama-index<1.0.0\\nCopy\\n# Phoenix can display in real time the traces automatically\\n\\n\\n# collected from your LlamaIndex application.\\n\\n\\nimport\\n phoenix \\nas\\n px\\n\\n\\n# Look for a URL in the output to open the App in a browser.\\n\\n\\npx\\n.\\nlaunch_app\\n()\\n\\n\\n# The App is initially empty, but as you proceed with the steps below,\\n\\n\\n# traces will appear automatically as your LlamaIndex application runs.\\n\\n\\n\\n\\nimport\\n llama_index\\n\\n\\nllama_index\\n.\\nset_global_handler\\n(\\n\\\"arize_phoenix\\\"\\n)\\n\\n\\n\\n\\n# Run all of your LlamaIndex applications as usual and traces\\n\\n\\n# will be collected and displayed in Phoenix.\\nBy adding the callback to the callback manager of LlamaIndex, we've created a one-way data connection between your LLM application and Phoenix Server.\\nTo view the traces in Phoenix, simply open the UI in your browser.\\nCopy\\npx\\n.\\nactive_session\\n().\\nurl\\nFor a fully working example of tracing with LlamaIndex, checkout our colab notebook.\\nPrevious\\nOpenAI\\nNext\\nLangChain\\nLast updated \\n13 days ago\\n\\nOverview: Tracing\\nTracing the execution of LLM applications using Telemetry\\nTracing is a powerful tool for understanding how your LLM application works. Phoenix has best-class tracing capabilities and is not tied to any LLM vendor or framework. Phoenix accepts traces over the OpenTelemetry protocol (OTLP) and supports first-class instrumentation for a variety of frameworks ( \\nLlamaIndex\\n, \\nLangChain\\n,\\n DSPy\\n),  SDKs (\\nOpenAI\\n, \\nBedrock\\n, \\nMistral\\n, \\nVertex\\n), and Languages. (Python, Javascript, etc.)\\nTracing can help you track down issues like:\\nApplication latency\\n - highlighting slow invocations of LLMs, Retrievers, etc.\\nToken Usage\\n - Displays the breakdown of token usage with LLMs to surface up your most expensive LLM calls\\nRuntime Exceptions\\n - Critical runtime exceptions such as rate-limiting are captured as exception events.\\nRetrieved Documents\\n - view all the documents retrieved during a retriever call and the score and order in which they were returned\\nEmbeddings\\n - view the embedding text used for retrieval and the underlying embedding model\\nLLM Parameters\\n - view the parameters used when calling out to an LLM to debug things like temperature and the system prompts\\nPrompt Templates\\n - Figure out what prompt template is used during the prompting step and what variables were used.\\nTool Descriptions -\\n view the description and function signature of the tools your LLM has been given access to\\nLLM Function Calls\\n - if using OpenAI or other a model with function calls, you can view the function selection and function messages in the input messages to the LLM.\\nTo get started, check out the \\nQuickstart guide\\nAfter that, read through the \\nConcepts Section\\n to get and understanding of the different components.\\nIf you want to learn how to accomplish a particular task, check out the \\nHow-To Guides.\\n\\n\\nPrevious\\nFAQs: Deployment\\nNext\\nQuickstart: Tracing\\nLast updated \\n13 days ago\",\n          \"How-to: Inferences\\nImport your data\\nImport Inference data (CV, NLP)\\nImport Prompt and Response (LLM) data\\nImport Retrieval data\\nImport Corpus (Vector Store) data\\nManage the App\\nDefine your dataset(s)\\nHow to launch the app\\nHow to view the UI\\nHow to close the app\\nHow to export data\\nHow to export your data for labeling, evaluation, or fine-tuning\\nHow to export embeddings\\nHow to export a cluster\\nHow to export all clusters\\nHow to generate embeddings\\n\\n\\nPrevious\\nQuickstart: Inferences\\nNext\\nImport Your Data\\nLast updated \\n3 months ago\\n\\nExporting Datasets\\nExporting for Fine-Tuning\\nFine-tuning lets you get more out of the models available by providing:\\nHigher quality results than prompting\\nAbility to train on more examples than can fit in a prompt\\nToken savings due to shorter prompts\\nLower latency requests\\nFine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt, letting you achieve better results on a wide number of tasks. \\nOnce a model has been fine-tuned, you won't need to provide as many examples in the prompt.\\n This saves costs and enables lower-latency requests.\\n\\nPhoenix natively exports OpenAI Fine-Tuning JSONL as long as the dataset contains compatible inputs  and outputs.\\nExporting OpenAI Evals\\nEvals provide a framework for evaluating large language models (LLMs) or systems built using LLMs. OpenAI Evals offer an existing registry of evals to test different dimensions of OpenAI models and the ability to write your own custom evals for use cases you care about. You can also use your data to build private evals. Phoenix can natively export the OpenAI Evals format as JSONL so you can use it with OpenAI Evals. See \\nhttps://github.com/openai/evals\\n for details.\\nPrevious\\nCreating Datasets\\nNext\\nHow-to: Experiments\\nLast updated \\n1 month ago\\n\\nOpenInference\\nOpenInference is an open standard that encompasses model inference and LLM application tracing.\\nFor a in-depth specification of the OpenInference specification, please consult the spec \\nhttps://github.com/Arize-ai/openinference\\nOpenInference is a set of specifications for model inferences and LLM traces\\nOpenInference is a specification that encompass two data models:\\nTracing\\ncapture the execution of an application that results in invocations of an LLM.\\n\\nInferences\\ndesigned to capture inference logs from a variety of model types and use-cases\\nPrevious\\nFrequently Asked Questions\\nNext\\nContribute to Phoenix\\nLast updated \\n23 days ago\\n\\nExport Data\\nHow to export your data for labeling, evaluation, or fine-tuning\\nExporting Embeddings\\nEmbeddings can be extremely useful for fine-tuning. There are two ways to export your embeddings from the Phoenix UI.\\nExport Selected Clusters\\nTo export a cluster (either selected via the lasso tool or via a the cluster list on the right hand panel), click on the export button on the top left of the bottom slide-out.\\nExport All Clusters\\nTo export all clusters of embeddings as a single dataframe (labeled by cluster), click the \\n...\\n icon on the top right of the screen and click export. Your data will be available either as a Parquet file or is available back in your notebook via your \\nsession\\n as a dataframe.\\nCopy\\nsession \\n=\\n px\\n.\\nactive_session\\n()\\n\\n\\nsession\\n.\\nexports\\n[\\n-\\n1\\n].\\ndataframe\\nPrevious\\nCorpus Data\\nNext\\nGenerate Embeddings\\nLast updated \\n3 months ago\\n\\nQuickstart: Inferences\\nObservability for all model types (LLM, NLP, CV, Tabular)\\nOverview\\nPhoenix Inferences allows you to observe the performance of your model through visualizing all the model\\u2019s inferences in one interactive UMAP view.\\nThis powerful visualization can be leveraged during EDA to understand model drift, find low performing clusters, uncover retrieval issues, and export data for retraining / fine tuning.\\nQuickstart\\nThe following Quickstart can be executed in a Jupyter notebook or Google Colab.\\nWe will begin by logging just a training set. Then proceed to add a production set for comparison.\\nStep 1: Install and load dependencies\\nUse \\npip\\n or \\nconda\\nto install \\narize-phoenix\\n.\\nCopy\\n!pip install arize\\n-\\nphoenix\\n\\n\\n\\n\\nimport\\n phoenix \\nas\\n px\\nStep 2: Prepare model data\\nPhoenix visualizes data taken from pandas dataframe, where each row of the dataframe compasses all the information about each inference (including feature values, prediction, metadata, etc.)\\nFor this Quickstart, we will show an example of visualizing the inferences from a computer vision model. See example notebooks for all model types \\nhere\\n.\\nLet\\u2019s begin by working with the training set for this model.\\nDownload the dataset and load it into a Pandas dataframe.\\nCopy\\nimport\\n pandas \\nas\\n pd\\n\\n\\n\\n\\ntrain_df \\n=\\n pd\\n.\\nread_parquet\\n(\\n\\n\\n    \\\"http://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_training.parquet\\\"\\n\\n\\n)\\nPreview the dataframe with \\ntrain_df.head()\\n and note that each row contains all the data specific to this CV model for each inference.\\nCopy\\ntrain_df.head()\\nStep 3: Define a Schema\\nBefore we can log these inferences, we need to define a Schema object to describe them.\\nThe Schema object informs Phoenix of the fields that the columns of the dataframe should map to.\\nHere we define a Schema to describe our particular CV training set:\\nCopy\\n# Define Schema to indicate which columns in train_df should map to each field\\n\\n\\ntrain_schema \\n=\\n px\\n.\\nSchema\\n(\\n\\n\\n    timestamp_column_name\\n=\\n\\\"prediction_ts\\\"\\n,\\n\\n\\n    prediction_label_column_name\\n=\\n\\\"predicted_action\\\"\\n,\\n\\n\\n    actual_label_column_name\\n=\\n\\\"actual_action\\\"\\n,\\n\\n\\n    embedding_feature_column_names\\n=\\n{\\n\\n\\n        \\n\\\"image_embedding\\\"\\n: px.\\nEmbeddingColumnNames\\n(\\n\\n\\n            vector_column_name\\n=\\n\\\"image_vector\\\"\\n,\\n\\n\\n            link_to_data_column_name\\n=\\n\\\"url\\\"\\n,\\n\\n\\n        ),\\n\\n\\n    },\\n\\n\\n)\\nImportant\\n:\\n The fields used in a Schema will \\nvary\\n depending on the model type that you are working with.\\nFor examples on how Schema are defined for other model types (NLP, tabular, LLM-based applications), see example notebooks under \\nEmbedding Analysis\\n and \\nStructured Data Analysis\\n.\\nStep 4: Wrap into Inference object\\nWrap your \\ntrain_df\\n and schema \\ntrain_schema\\n into a Phoenix \\ninference\\n object:\\nCopy\\ntrain_ds \\n=\\n \\nInference\\n(dataframe\\n=\\ntrain_df, schema\\n=\\ntrain_schema, name\\n=\\n\\\"training\\\"\\n)\\nStep 5: Launch Phoenix!\\nWe are now ready to launch Phoenix with our Inferences!\\nHere, we are passing \\ntrain_ds\\n as the \\nprimary\\n inferences, as we are only visualizing one inference set (see Step 6 for adding additional inference sets).\\nCopy\\nsession \\n=\\n px\\n.\\nlaunch_app\\n(primary\\n=\\ntrain_ds)\\nRunning this will fire up a Phoenix visualization. Follow in the instructions in the output to view Phoenix in a browser, or in-line in your notebook:\\nCopy\\n\\ud83c\\udf0d To view the Phoenix app in your browser, visit https://x0u0hsyy843-496ff2e9c6d22116-6060-colab.googleusercontent.com/\\n\\n\\n\\ud83d\\udcfa To view the Phoenix app in a notebook, run `px.active_session().view()`\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFECnz04co8H"
      },
      "source": [
        "Let's now use Phoenix's LLM Evals to evaluate the relevance of the retrieved documents with regards to the query. Note, we've turned on `explanations` which prompts the LLM to explain it's reasoning. This can be useful for debugging and for figuring out potential corrective actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hq4sr_zIco8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8648201ffcab4023a1a54dde1b964b8b",
            "df7e8713256a48c2992f3dce61c702d1",
            "d9af102cb64142b3ac7ea6a75027e6a7",
            "59a894868a0344789e8458549f8aa894",
            "2c6eb911b6354343a46fca08b0b85f03",
            "88978e8ddc704d8e9d4048095047615a",
            "44f75a3f6c48404990251849a9be33ca",
            "ae22d487bb1b442cad9018897a53e623",
            "c6aab3035f8247b6a3e276b2e86fe79b",
            "99e5a5eeb1ef41d68f41bbd3cb98d544",
            "d946d51d35344047add12d14c8445f46"
          ]
        },
        "outputId": "176a349e-727e-4a4c-c305-176fc34ae23a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "run_evals |          | 0/500 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8648201ffcab4023a1a54dde1b964b8b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from phoenix.evals import (\n",
        "    OpenAIModel,\n",
        "    RelevanceEvaluator,\n",
        "    HallucinationEvaluator,\n",
        "    QAEvaluator,\n",
        "    run_evals,\n",
        ")\n",
        "\n",
        "eval_model = OpenAIModel(model=\"gpt-4\")\n",
        "relevance_evaluator = RelevanceEvaluator(eval_model)\n",
        "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
        "qa_evaluator = QAEvaluator(eval_model)\n",
        "\n",
        "retrieved_documents_relevance_df = run_evals(\n",
        "    evaluators=[relevance_evaluator],\n",
        "    dataframe=retrieved_documents_df,\n",
        "    provide_explanation=True,\n",
        "    concurrency=20,\n",
        ")[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hallucination_eval_df, qa_eval_df = run_evals(\n",
        "    dataframe=queries_df,\n",
        "    evaluators=[hallucination_evaluator, qa_evaluator],\n",
        "    provide_explanation=True,\n",
        "    concurrency=20,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "Pe9J4-zYwuCl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3363dcebe07847be99e7b41b3840d042",
            "90412f8febda4ab1bb22fe56e2392274",
            "f7654cf0da3f47da801c21b947fda6da",
            "82e8f507e44841f88be5c66c91b27f48",
            "8aeca790868b44babe415849afba77db",
            "5f8024635af64b0a99855ae3adef558d",
            "aed1f2822d114ce4be7dcddfbc2dfc20",
            "aea78f53909e44b195de5886df74fad1",
            "fcf5b6ce6ca94b48b80ed2aa8ced55d5",
            "d10322222cb3435fafdbbdc4d98e5059",
            "d1d54e8e26a54881b1380b02159203ad"
          ]
        },
        "outputId": "b3424ecb-9536-4230-92ce-debaf19e690b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "run_evals |          | 0/200 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3363dcebe07847be99e7b41b3840d042"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RaZwCSFico8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "14ef12b7-af63-4ab1-ec14-c9b7d198ed54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  document_position      label  score  \\\n",
              "context.span_id                                         \n",
              "9f030a063826726e                  0   relevant      1   \n",
              "9f030a063826726e                  1   relevant      1   \n",
              "9f030a063826726e                  2   relevant      1   \n",
              "9f030a063826726e                  3  unrelated      0   \n",
              "9f030a063826726e                  4   relevant      1   \n",
              "...                             ...        ...    ...   \n",
              "fc02f9e9d95f7f85                  0  unrelated      0   \n",
              "fc02f9e9d95f7f85                  1  unrelated      0   \n",
              "fc02f9e9d95f7f85                  2  unrelated      0   \n",
              "fc02f9e9d95f7f85                  3   relevant      1   \n",
              "fc02f9e9d95f7f85                  4   relevant      1   \n",
              "\n",
              "                                                        explanation  \n",
              "context.span_id                                                      \n",
              "9f030a063826726e  The question asks about how to send traces to ...  \n",
              "9f030a063826726e  The question asks about how to send traces to ...  \n",
              "9f030a063826726e  The question asks about how to send traces to ...  \n",
              "9f030a063826726e  The question asks about how to send traces to ...  \n",
              "9f030a063826726e  The question asks about how to send traces to ...  \n",
              "...                                                             ...  \n",
              "fc02f9e9d95f7f85  The question asks about the possibility of usi...  \n",
              "fc02f9e9d95f7f85  The question asks about the possibility of usi...  \n",
              "fc02f9e9d95f7f85  The question is asking about the possibility o...  \n",
              "fc02f9e9d95f7f85  The question asks if gRPC can be used for trac...  \n",
              "fc02f9e9d95f7f85  The question asks if gRPC can be used for trac...  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-179bfe15-ef8d-4555-a877-66c92a87f61d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_position</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "      <th>explanation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context.span_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9f030a063826726e</th>\n",
              "      <td>0</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>The question asks about how to send traces to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9f030a063826726e</th>\n",
              "      <td>1</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>The question asks about how to send traces to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9f030a063826726e</th>\n",
              "      <td>2</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>The question asks about how to send traces to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9f030a063826726e</th>\n",
              "      <td>3</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "      <td>The question asks about how to send traces to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9f030a063826726e</th>\n",
              "      <td>4</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>The question asks about how to send traces to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc02f9e9d95f7f85</th>\n",
              "      <td>0</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "      <td>The question asks about the possibility of usi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc02f9e9d95f7f85</th>\n",
              "      <td>1</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "      <td>The question asks about the possibility of usi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc02f9e9d95f7f85</th>\n",
              "      <td>2</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "      <td>The question is asking about the possibility o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc02f9e9d95f7f85</th>\n",
              "      <td>3</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>The question asks if gRPC can be used for trac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc02f9e9d95f7f85</th>\n",
              "      <td>4</td>\n",
              "      <td>relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>The question asks if gRPC can be used for trac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-179bfe15-ef8d-4555-a877-66c92a87f61d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-179bfe15-ef8d-4555-a877-66c92a87f61d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-179bfe15-ef8d-4555-a877-66c92a87f61d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e493801b-e503-4769-ad0f-a2f7ebf6f5bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e493801b-e503-4769-ad0f-a2f7ebf6f5bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e493801b-e503-4769-ad0f-a2f7ebf6f5bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e4e890fd-cf9c-42f4-8c95-a96edd6d042c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('retrieved_documents_relevance_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e4e890fd-cf9c-42f4-8c95-a96edd6d042c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('retrieved_documents_relevance_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "retrieved_documents_relevance_df",
              "summary": "{\n  \"name\": \"retrieved_documents_relevance_df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"context.span_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"deae2ff376061d00\",\n          \"121ae2811425f408\",\n          \"a22066efd8156cd1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document_position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"unrelated\",\n          \"relevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"explanation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"The question asks about how to create a new session in Arize Phoenix. The reference text provides a detailed overview of the Phoenix platform, its features, and its use in different stages of application development. However, it does not provide any information on how to create a new session in Arize Phoenix. Therefore, the reference text does not contain information that can help answer the question.\",\n          \"The question asks about how to run an evaluation. The reference text provides information on how to run experiments, how to configure evaluators, and how to use evaluators. However, it does not provide specific information on how to run an evaluation. Therefore, while the reference text contains related information, it does not directly answer the question.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "retrieved_documents_relevance_df = retrieved_documents_relevance_df.reset_index().set_index('context.span_id')\n",
        "retrieved_documents_relevance_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hallucination_eval_df.head()"
      ],
      "metadata": {
        "id": "cCPWGtd0zPIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cc6e820f-7b58-4f84-dd9e-2a926f48b163"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         label  score  \\\n",
              "context.span_id                         \n",
              "54cdf11c954ecc3f       factual    0.0   \n",
              "5c89706b00c67ba9  hallucinated    1.0   \n",
              "3ef54d0c9aee79ee       factual    0.0   \n",
              "9c0f677d46d73b9d       factual    0.0   \n",
              "b7b06e01d71b7fef       factual    0.0   \n",
              "\n",
              "                                                        explanation  \n",
              "context.span_id                                                      \n",
              "54cdf11c954ecc3f  The query asks about how to send traces to Pho...  \n",
              "5c89706b00c67ba9  The query asks what happens if the same traces...  \n",
              "3ef54d0c9aee79ee  The query asks about the frameworks and LLM pr...  \n",
              "9c0f677d46d73b9d  The reference text provides information on how...  \n",
              "b7b06e01d71b7fef  The query asks about how Arize Phoenix uses Op...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eee160d7-9ab1-4e5e-a4a7-08a79dd9f7bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "      <th>explanation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context.span_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54cdf11c954ecc3f</th>\n",
              "      <td>factual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The query asks about how to send traces to Pho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5c89706b00c67ba9</th>\n",
              "      <td>hallucinated</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The query asks what happens if the same traces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3ef54d0c9aee79ee</th>\n",
              "      <td>factual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The query asks about the frameworks and LLM pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9c0f677d46d73b9d</th>\n",
              "      <td>factual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The reference text provides information on how...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b7b06e01d71b7fef</th>\n",
              "      <td>factual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The query asks about how Arize Phoenix uses Op...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eee160d7-9ab1-4e5e-a4a7-08a79dd9f7bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eee160d7-9ab1-4e5e-a4a7-08a79dd9f7bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eee160d7-9ab1-4e5e-a4a7-08a79dd9f7bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7aa38800-fcef-4da1-8fce-886dfa6ca5af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aa38800-fcef-4da1-8fce-886dfa6ca5af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7aa38800-fcef-4da1-8fce-886dfa6ca5af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "hallucination_eval_df",
              "summary": "{\n  \"name\": \"hallucination_eval_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"context.span_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"1d1278e7d05ef1dc\",\n          \"84ee64033b82d183\",\n          \"c76d67a1a42f3daf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"factual\",\n          \"hallucinated\",\n          \"NOT_PARSABLE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40201512610368484,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"explanation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"The query asks why Arize Phoenix is vendor-agnostic. The answer provided states that Arize Phoenix is vendor-agnostic because it works with OpenTelemetry and OpenInference instrumentation, allowing it to be compatible with a variety of different environments and services without being tied to any specific vendor or platform. However, the reference text does not provide any information to support this claim. The reference text mentions that Arize Phoenix works with a variety of models and provides a comprehensive platform for observability across every layer of an LLM-based system, but it does not mention anything about OpenTelemetry or OpenInference instrumentation. Therefore, the answer is not based on the reference text and is a hallucination of facts.\",\n          \"The query asks about the deployment options for Phoenix. The reference text provides information about different ways Phoenix can be deployed, including running it as a container using different image tags. The answer lists these image tags as deployment options, which is consistent with the information provided in the reference text. Therefore, the answer is based on the reference text and does not contain made up information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log the Evals into Phoenix"
      ],
      "metadata": {
        "id": "zbH5A6cS6fd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from phoenix.trace import SpanEvaluations\n",
        "\n",
        "px.Client().log_evaluations(\n",
        "    SpanEvaluations(eval_name=\"Hallucination\", dataframe=hallucination_eval_df),\n",
        "    SpanEvaluations(eval_name=\"QA Correctness\", dataframe=qa_eval_df),\n",
        "    SpanEvaluations(eval_name=\"Retrieval Relevance\", dataframe=retrieved_documents_relevance_df)\n",
        ")"
      ],
      "metadata": {
        "id": "Xbs-D5W-zkDZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session.view()"
      ],
      "metadata": {
        "id": "O2-3FxRc4ukO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1193ef27-1de3-400c-ed40-901784b879d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📺 Opening a view to the Phoenix app. The app is running at https://9zpo69ffpri13-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7b63f87616c0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"1000\"\n",
              "            src=\"https://9zpo69ffpri13-496ff2e9c6d22116-6006-colab.googleusercontent.com/\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sGN54AoM3hyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UtMkdRoK3jD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Trace"
      ],
      "metadata": {
        "id": "I5IS5dvf6lkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify and Create the Directory for Trace Dataset\n",
        "directory = 'my_saved_traces'\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Save the Trace Dataset\n",
        "trace_id = px.Client().get_trace_dataset().save(directory=directory)"
      ],
      "metadata": {
        "id": "qG-RDMTsY5a9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7RhNlyaI9b0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}