{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/9e6101d95936f4bd4d390efc9ce646dc6937fb2d/images/socal/github-large-banner-phoenix.jpg\" width=\"1000\"/>\n",
    "        <br>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically find the bad LLM responses in your LLM Evals with Cleanlab\n",
    "\n",
    "This guide will walk you through the process of evaluating LLM responses captured in Phoenix with Cleanlab's Trustworthy Language Models (TLM).\n",
    "\n",
    "TLM boosts the reliability of any LLM application by indicating when the model’s response is untrustworthy.\n",
    "\n",
    "This guide requires a Cleanlab TLM API key. If you don't have one, you can sign up for a free trial [here](https://tlm.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies & Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q \"arize-phoenix>=4.29.0\"\n",
    "pip install -q 'httpx<0.28'\n",
    "pip install -q openai cleanlab_tlm openinference-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sign up for a free trial of Cleanlab TLM and get an API key [here](https://tlm.cleanlab.ai/).\n",
    "if not (cleanlab_tlm_api_key := os.getenv(\"CLEANLAB_TLM_API_KEY\")):\n",
    "    cleanlab_tlm_api_key = getpass(\"🔑 Enter your Cleanlab TLM API key: \")\n",
    "\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = cleanlab_tlm_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll use Phoenix as our destination. You could instead add any other exporters you'd like in this approach.\n",
    "\n",
    "If you need to set up an API key for Phoenix, you can do so [here](https://app.phoenix.arize.com/).\n",
    "\n",
    "The code below will connect you to a Phoenix Cloud instance. You can also connect to [a self-hosted Phoenix instance](https://docs.arize.com/phoenix/deployment) if you'd prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Phoenix API Key for tracing\n",
    "if not (PHOENIX_API_KEY := os.getenv(\"PHOENIX_CLIENT_HEADERS\")):\n",
    "    PHOENIX_API_KEY = getpass(\"🔑 Enter your Phoenix API Key: \")\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have Phoenix configured, we can register that instance with OpenTelemetry, which will allow us to collect traces from our application here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔭 OpenTelemetry Tracing Details 🔭\n",
      "|  Phoenix Project: evaluating_traces_TLM\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
      "|  Transport: HTTP\n",
      "|  Transport Headers: {'api_key': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(project_name=\"evaluating_traces_TLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare trace dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of making this guide fully runnable, we'll briefly generate some traces and track them in Phoenix. Typically, you would have already captured traces in Phoenix and would skip to \"Download trace dataset from Phoenix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the 3rd month of the year in alphabetical order?\n",
      "Answer 1:\n",
      "The 3rd month of the year in alphabetical order is March.\n",
      "\n",
      "Question 2: What is the capital of France?\n",
      "Answer 2:\n",
      "The capital of France is Paris.\n",
      "\n",
      "Question 3: How many seconds are in 100 years?\n",
      "Answer 3:\n",
      "There are 3,153,600,000 seconds in 100 years.\n",
      "\n",
      "Question 4: Alice, Bob, and Charlie went to a café. Alice paid twice as much as Bob, and Bob paid three times as much as Charlie. If the total bill was $72, how much did each person pay?\n",
      "Answer 4:\n",
      "Let's represent the amounts paid by Alice, Bob, and Charlie as A, B, and C, respectively.\n",
      "\n",
      "From the given information:\n",
      "1. A = 2B\n",
      "2. B = 3C\n",
      "3. A + B + C = 72\n",
      "\n",
      "Substitute the values of A and B from equations 1 and 2 into equation 3:\n",
      "2B + B + B/3 = 72\n",
      "6B + 3B + B = 216\n",
      "10B = 216\n",
      "B = 21.6\n",
      "\n",
      "Now, find the values of A and C:\n",
      "A = 2B\n",
      "A = 2 * 21.6\n",
      "A = 43.2\n",
      "\n",
      "C = B/3\n",
      "C = 21.6/3\n",
      "C = 7.2\n",
      "\n",
      "Therefore, Alice paid $43.20, Bob paid $21.60, and Charlie paid $7.20.\n",
      "\n",
      "Question 5: When was the Declaration of Independence signed?\n",
      "Answer 5:\n",
      "The Declaration of Independence was adopted on July 4, 1776, but it was actually signed by most delegates on August 2, 1776.\n",
      "\n",
      "Generated 5 answers and tracked them in Phoenix.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Function to generate an answer\n",
    "def generate_answers(trivia_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a trivia master.\"},\n",
    "            {\"role\": \"user\", \"content\": trivia_question},\n",
    "        ],\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "\n",
    "trivia_questions = [\n",
    "    \"What is the 3rd month of the year in alphabetical order?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"How many seconds are in 100 years?\",\n",
    "    \"Alice, Bob, and Charlie went to a café. Alice paid twice as much as Bob, and Bob paid three times as much as Charlie. If the total bill was $72, how much did each person pay?\",\n",
    "    \"When was the Declaration of Independence signed?\",\n",
    "]\n",
    "\n",
    "# Generate answers\n",
    "answers = []\n",
    "for i in range(len(trivia_questions)):\n",
    "    answer = generate_answers(trivia_questions[i])\n",
    "    answers.append(answer)\n",
    "    print(f\"Question {i+1}: {trivia_questions[i]}\")\n",
    "    print(f\"Answer {i+1}:\\n{answer}\\n\")\n",
    "\n",
    "print(f\"Generated {len(answers)} answers and tracked them in Phoenix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download trace dataset from Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/phoenix/utilities/client.py:45: UserWarning: ⚠️⚠️ The Phoenix server (8.14.1) and client (7.6.0) versions are severely mismatched. Upgrade  either the client or server to ensure API compatibility ⚠️⚠️\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>status_code</th>\n",
       "      <th>status_message</th>\n",
       "      <th>events</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>...</th>\n",
       "      <th>attributes.llm.provider</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>attributes.llm.system</th>\n",
       "      <th>attributes.llm.input_messages</th>\n",
       "      <th>attributes.llm.invocation_parameters</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>attributes.llm.model_name</th>\n",
       "      <th>attributes.output.mime_type</th>\n",
       "      <th>attributes.llm.output_messages</th>\n",
       "      <th>attributes.input.mime_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f8327c0feaa9104b</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-19 20:12:42.856189+00:00</td>\n",
       "      <td>2025-03-19 20:12:43.540837+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>f8327c0feaa9104b</td>\n",
       "      <td>0a8e43385a7a347dfc1ab0fe452d81f1</td>\n",
       "      <td>...</td>\n",
       "      <td>openai</td>\n",
       "      <td>LLM</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'message.content': 'You are a trivia master....</td>\n",
       "      <td>{\"model\": \"gpt-3.5-turbo\"}</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4J12RYILvdhbjKbN92vWwLtY1B\"...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.content': 'March', 'message.role': ...</td>\n",
       "      <td>application/json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e500f55a0965355</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-19 20:12:43.815089+00:00</td>\n",
       "      <td>2025-03-19 20:12:44.412861+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1e500f55a0965355</td>\n",
       "      <td>0238e2633f4109b1663eb5da545e8d96</td>\n",
       "      <td>...</td>\n",
       "      <td>openai</td>\n",
       "      <td>LLM</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'message.content': 'You are a trivia master....</td>\n",
       "      <td>{\"model\": \"gpt-3.5-turbo\"}</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4KTZj9cEsfa2B9m5xJwXoI2Zh3\"...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.content': 'The capital of France is...</td>\n",
       "      <td>application/json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7fd714b0743e678</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-19 20:12:44.487955+00:00</td>\n",
       "      <td>2025-03-19 20:12:45.375315+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>f7fd714b0743e678</td>\n",
       "      <td>6352391d98cfc603aed2366207b7c8d6</td>\n",
       "      <td>...</td>\n",
       "      <td>openai</td>\n",
       "      <td>LLM</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'message.content': 'You are a trivia master....</td>\n",
       "      <td>{\"model\": \"gpt-3.5-turbo\"}</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4KY4rV3fYoqGmKBzyxZMx1NlVy\"...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.content': 'There are 31,536,000 sec...</td>\n",
       "      <td>application/json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11abc1a7eb12cb32</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-19 20:12:45.511824+00:00</td>\n",
       "      <td>2025-03-19 20:12:48.043642+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>11abc1a7eb12cb32</td>\n",
       "      <td>ba5065ff79d70a980b4f53cda31d3f63</td>\n",
       "      <td>...</td>\n",
       "      <td>openai</td>\n",
       "      <td>LLM</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'message.content': 'You are a trivia master....</td>\n",
       "      <td>{\"model\": \"gpt-3.5-turbo\"}</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4LhMA2nOcsWzjHsWdkg3CPX2F1\"...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.content': 'Let's denote the amount ...</td>\n",
       "      <td>application/json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bec3a1555fa392ff</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-19 20:12:48.157944+00:00</td>\n",
       "      <td>2025-03-19 20:12:48.956120+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>bec3a1555fa392ff</td>\n",
       "      <td>dd9ccd53426bf28fa5c13bb918918388</td>\n",
       "      <td>...</td>\n",
       "      <td>openai</td>\n",
       "      <td>LLM</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'message.content': 'You are a trivia master....</td>\n",
       "      <td>{\"model\": \"gpt-3.5-turbo\"}</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4OnVYN1uY5ZAH1Te2AG0T38I1K\"...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.content': 'The Declaration of Indep...</td>\n",
       "      <td>application/json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name span_kind parent_id  \\\n",
       "context.span_id                                        \n",
       "f8327c0feaa9104b  ChatCompletion       LLM      None   \n",
       "1e500f55a0965355  ChatCompletion       LLM      None   \n",
       "f7fd714b0743e678  ChatCompletion       LLM      None   \n",
       "11abc1a7eb12cb32  ChatCompletion       LLM      None   \n",
       "bec3a1555fa392ff  ChatCompletion       LLM      None   \n",
       "\n",
       "                                       start_time  \\\n",
       "context.span_id                                     \n",
       "f8327c0feaa9104b 2025-03-19 20:12:42.856189+00:00   \n",
       "1e500f55a0965355 2025-03-19 20:12:43.815089+00:00   \n",
       "f7fd714b0743e678 2025-03-19 20:12:44.487955+00:00   \n",
       "11abc1a7eb12cb32 2025-03-19 20:12:45.511824+00:00   \n",
       "bec3a1555fa392ff 2025-03-19 20:12:48.157944+00:00   \n",
       "\n",
       "                                         end_time status_code status_message  \\\n",
       "context.span_id                                                                \n",
       "f8327c0feaa9104b 2025-03-19 20:12:43.540837+00:00          OK                  \n",
       "1e500f55a0965355 2025-03-19 20:12:44.412861+00:00          OK                  \n",
       "f7fd714b0743e678 2025-03-19 20:12:45.375315+00:00          OK                  \n",
       "11abc1a7eb12cb32 2025-03-19 20:12:48.043642+00:00          OK                  \n",
       "bec3a1555fa392ff 2025-03-19 20:12:48.956120+00:00          OK                  \n",
       "\n",
       "                 events   context.span_id                  context.trace_id  \\\n",
       "context.span_id                                                               \n",
       "f8327c0feaa9104b     []  f8327c0feaa9104b  0a8e43385a7a347dfc1ab0fe452d81f1   \n",
       "1e500f55a0965355     []  1e500f55a0965355  0238e2633f4109b1663eb5da545e8d96   \n",
       "f7fd714b0743e678     []  f7fd714b0743e678  6352391d98cfc603aed2366207b7c8d6   \n",
       "11abc1a7eb12cb32     []  11abc1a7eb12cb32  ba5065ff79d70a980b4f53cda31d3f63   \n",
       "bec3a1555fa392ff     []  bec3a1555fa392ff  dd9ccd53426bf28fa5c13bb918918388   \n",
       "\n",
       "                  ...  attributes.llm.provider  \\\n",
       "context.span_id   ...                            \n",
       "f8327c0feaa9104b  ...                   openai   \n",
       "1e500f55a0965355  ...                   openai   \n",
       "f7fd714b0743e678  ...                   openai   \n",
       "11abc1a7eb12cb32  ...                   openai   \n",
       "bec3a1555fa392ff  ...                   openai   \n",
       "\n",
       "                  attributes.openinference.span.kind attributes.llm.system  \\\n",
       "context.span_id                                                              \n",
       "f8327c0feaa9104b                                 LLM                openai   \n",
       "1e500f55a0965355                                 LLM                openai   \n",
       "f7fd714b0743e678                                 LLM                openai   \n",
       "11abc1a7eb12cb32                                 LLM                openai   \n",
       "bec3a1555fa392ff                                 LLM                openai   \n",
       "\n",
       "                                      attributes.llm.input_messages  \\\n",
       "context.span_id                                                       \n",
       "f8327c0feaa9104b  [{'message.content': 'You are a trivia master....   \n",
       "1e500f55a0965355  [{'message.content': 'You are a trivia master....   \n",
       "f7fd714b0743e678  [{'message.content': 'You are a trivia master....   \n",
       "11abc1a7eb12cb32  [{'message.content': 'You are a trivia master....   \n",
       "bec3a1555fa392ff  [{'message.content': 'You are a trivia master....   \n",
       "\n",
       "                 attributes.llm.invocation_parameters  \\\n",
       "context.span_id                                         \n",
       "f8327c0feaa9104b           {\"model\": \"gpt-3.5-turbo\"}   \n",
       "1e500f55a0965355           {\"model\": \"gpt-3.5-turbo\"}   \n",
       "f7fd714b0743e678           {\"model\": \"gpt-3.5-turbo\"}   \n",
       "11abc1a7eb12cb32           {\"model\": \"gpt-3.5-turbo\"}   \n",
       "bec3a1555fa392ff           {\"model\": \"gpt-3.5-turbo\"}   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "context.span_id                                                       \n",
       "f8327c0feaa9104b  {\"id\":\"chatcmpl-BCu4J12RYILvdhbjKbN92vWwLtY1B\"...   \n",
       "1e500f55a0965355  {\"id\":\"chatcmpl-BCu4KTZj9cEsfa2B9m5xJwXoI2Zh3\"...   \n",
       "f7fd714b0743e678  {\"id\":\"chatcmpl-BCu4KY4rV3fYoqGmKBzyxZMx1NlVy\"...   \n",
       "11abc1a7eb12cb32  {\"id\":\"chatcmpl-BCu4LhMA2nOcsWzjHsWdkg3CPX2F1\"...   \n",
       "bec3a1555fa392ff  {\"id\":\"chatcmpl-BCu4OnVYN1uY5ZAH1Te2AG0T38I1K\"...   \n",
       "\n",
       "                 attributes.llm.model_name attributes.output.mime_type  \\\n",
       "context.span_id                                                          \n",
       "f8327c0feaa9104b        gpt-3.5-turbo-0125            application/json   \n",
       "1e500f55a0965355        gpt-3.5-turbo-0125            application/json   \n",
       "f7fd714b0743e678        gpt-3.5-turbo-0125            application/json   \n",
       "11abc1a7eb12cb32        gpt-3.5-turbo-0125            application/json   \n",
       "bec3a1555fa392ff        gpt-3.5-turbo-0125            application/json   \n",
       "\n",
       "                                     attributes.llm.output_messages  \\\n",
       "context.span_id                                                       \n",
       "f8327c0feaa9104b  [{'message.content': 'March', 'message.role': ...   \n",
       "1e500f55a0965355  [{'message.content': 'The capital of France is...   \n",
       "f7fd714b0743e678  [{'message.content': 'There are 31,536,000 sec...   \n",
       "11abc1a7eb12cb32  [{'message.content': 'Let's denote the amount ...   \n",
       "bec3a1555fa392ff  [{'message.content': 'The Declaration of Indep...   \n",
       "\n",
       "                 attributes.input.mime_type  \n",
       "context.span_id                              \n",
       "f8327c0feaa9104b           application/json  \n",
       "1e500f55a0965355           application/json  \n",
       "f7fd714b0743e678           application/json  \n",
       "11abc1a7eb12cb32           application/json  \n",
       "bec3a1555fa392ff           application/json  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phoenix as px\n",
    "\n",
    "spans_df = px.Client().get_spans_dataframe(project_name=\"evaluating_traces_TLM\")\n",
    "spans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate evaluations with TLM\n",
    "\n",
    "Now that we have our trace dataset, we can generate evaluations for each trace using TLM. Ultimately, we want to end up with a trustworthiness score and explaination for each prompt, response pair in the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_tlm import TLM\n",
    "\n",
    "tlm = TLM(options={\"log\": [\"explanation\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to extract the prompts and responses from the individual traces. `TLM.get_trustworthiness_score()` will take a list of prompts and responses and return trustworthiness scores and explanations.\n",
    "\n",
    "**IMPORTANT:** It is essential to always include any system prompts, context, or other information that was originally provided to the LLM to generate the response. You should construct the prompt input to `get_trustworthiness_score()` in a way that is as similar as possible to the original prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with input and output columns\n",
    "eval_df = spans_df[[\"context.span_id\", \"attributes.input.value\", \"attributes.output.value\"]].copy()\n",
    "eval_df.set_index(\"context.span_id\", inplace=True)\n",
    "\n",
    "\n",
    "# Combine system and user prompts from the traces\n",
    "def get_prompt(input_value):\n",
    "    if isinstance(input_value, str):\n",
    "        input_value = json.loads(input_value)\n",
    "    system_prompt = input_value[\"messages\"][0][\"content\"]\n",
    "    user_prompt = input_value[\"messages\"][1][\"content\"]\n",
    "    return system_prompt + \"\\n\" + user_prompt\n",
    "\n",
    "\n",
    "# Get the responses from the traces\n",
    "def get_response(output_value):\n",
    "    if isinstance(output_value, str):\n",
    "        output_value = json.loads(output_value)\n",
    "    return output_value[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Create a list of prompts and associated responses\n",
    "prompts = [get_prompt(input_value) for input_value in eval_df[\"attributes.input.value\"]]\n",
    "responses = [get_response(output_value) for output_value in eval_df[\"attributes.output.value\"]]\n",
    "\n",
    "eval_df[\"prompt\"] = prompts\n",
    "eval_df[\"response\"] = responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the prompts and responses, we can evaluate each pair using TLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying TLM... 100%|██████████|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f8327c0feaa9104b</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4J12RYILvdhbjKbN92vWwLtY1B\"...</td>\n",
       "      <td>You are a trivia master.\\nWhat is the 3rd mont...</td>\n",
       "      <td>March</td>\n",
       "      <td>0.037318</td>\n",
       "      <td>The user is asking for the third month of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e500f55a0965355</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4KTZj9cEsfa2B9m5xJwXoI2Zh3\"...</td>\n",
       "      <td>You are a trivia master.\\nWhat is the capital ...</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>Did not find a reason to doubt trustworthiness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7fd714b0743e678</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4KY4rV3fYoqGmKBzyxZMx1NlVy\"...</td>\n",
       "      <td>You are a trivia master.\\nHow many seconds are...</td>\n",
       "      <td>There are 31,536,000 seconds in a year (60 sec...</td>\n",
       "      <td>0.260966</td>\n",
       "      <td>The proposed response calculates the number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11abc1a7eb12cb32</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4LhMA2nOcsWzjHsWdkg3CPX2F1\"...</td>\n",
       "      <td>You are a trivia master.\\nAlice, Bob, and Char...</td>\n",
       "      <td>Let's denote the amount Charlie paid as C. \\n\\...</td>\n",
       "      <td>0.380158</td>\n",
       "      <td>This response is untrustworthy due to lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bec3a1555fa392ff</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4OnVYN1uY5ZAH1Te2AG0T38I1K\"...</td>\n",
       "      <td>You are a trivia master.\\nWhen was the Declara...</td>\n",
       "      <td>The Declaration of Independence was approved b...</td>\n",
       "      <td>0.945734</td>\n",
       "      <td>Did not find a reason to doubt trustworthiness.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             attributes.input.value  \\\n",
       "context.span_id                                                       \n",
       "f8327c0feaa9104b  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "1e500f55a0965355  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "f7fd714b0743e678  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "11abc1a7eb12cb32  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "bec3a1555fa392ff  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "context.span_id                                                       \n",
       "f8327c0feaa9104b  {\"id\":\"chatcmpl-BCu4J12RYILvdhbjKbN92vWwLtY1B\"...   \n",
       "1e500f55a0965355  {\"id\":\"chatcmpl-BCu4KTZj9cEsfa2B9m5xJwXoI2Zh3\"...   \n",
       "f7fd714b0743e678  {\"id\":\"chatcmpl-BCu4KY4rV3fYoqGmKBzyxZMx1NlVy\"...   \n",
       "11abc1a7eb12cb32  {\"id\":\"chatcmpl-BCu4LhMA2nOcsWzjHsWdkg3CPX2F1\"...   \n",
       "bec3a1555fa392ff  {\"id\":\"chatcmpl-BCu4OnVYN1uY5ZAH1Te2AG0T38I1K\"...   \n",
       "\n",
       "                                                             prompt  \\\n",
       "context.span_id                                                       \n",
       "f8327c0feaa9104b  You are a trivia master.\\nWhat is the 3rd mont...   \n",
       "1e500f55a0965355  You are a trivia master.\\nWhat is the capital ...   \n",
       "f7fd714b0743e678  You are a trivia master.\\nHow many seconds are...   \n",
       "11abc1a7eb12cb32  You are a trivia master.\\nAlice, Bob, and Char...   \n",
       "bec3a1555fa392ff  You are a trivia master.\\nWhen was the Declara...   \n",
       "\n",
       "                                                           response     score  \\\n",
       "context.span_id                                                                 \n",
       "f8327c0feaa9104b                                              March  0.037318   \n",
       "1e500f55a0965355                    The capital of France is Paris.  0.987430   \n",
       "f7fd714b0743e678  There are 31,536,000 seconds in a year (60 sec...  0.260966   \n",
       "11abc1a7eb12cb32  Let's denote the amount Charlie paid as C. \\n\\...  0.380158   \n",
       "bec3a1555fa392ff  The Declaration of Independence was approved b...  0.945734   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "f8327c0feaa9104b  The user is asking for the third month of the ...  \n",
       "1e500f55a0965355    Did not find a reason to doubt trustworthiness.  \n",
       "f7fd714b0743e678  The proposed response calculates the number of...  \n",
       "11abc1a7eb12cb32  This response is untrustworthy due to lack of ...  \n",
       "bec3a1555fa392ff    Did not find a reason to doubt trustworthiness.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate each of the prompt, response pairs using TLM\n",
    "evaluations = tlm.get_trustworthiness_score(prompts, responses)\n",
    "\n",
    "# Extract the trustworthiness scores and explanations from the evaluations\n",
    "trust_scores = [entry[\"trustworthiness_score\"] for entry in evaluations]\n",
    "explanations = [entry[\"log\"][\"explanation\"] for entry in evaluations]\n",
    "\n",
    "# Add the trust scores and explanations to the DataFrame\n",
    "eval_df[\"score\"] = trust_scores\n",
    "eval_df[\"explanation\"] = explanations\n",
    "\n",
    "# Display the new DataFrame\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a DataFrame with added colums:\n",
    "- `prompt`: the combined system and user prompt from the trace\n",
    "- `response`: the LLM response from the trace\n",
    "- `score`: the trustworthiness score from TLM\n",
    "- `explanation`: the explanation from TLM\n",
    "\n",
    "Let's sort our traces by the `score` column to quickly find untrustworthy LLM responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a133162d3623131d</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu68UEJaw63CvUtbwRWLbrkxDQ2V\"...</td>\n",
       "      <td>You are a trivia master.\\nWhat is the 3rd mont...</td>\n",
       "      <td>The 3rd month of the year in alphabetical orde...</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>The proposed response states that the 3rd mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8327c0feaa9104b</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4J12RYILvdhbjKbN92vWwLtY1B\"...</td>\n",
       "      <td>You are a trivia master.\\nWhat is the 3rd mont...</td>\n",
       "      <td>March</td>\n",
       "      <td>0.037318</td>\n",
       "      <td>The user is asking for the third month of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7fd714b0743e678</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4KY4rV3fYoqGmKBzyxZMx1NlVy\"...</td>\n",
       "      <td>You are a trivia master.\\nHow many seconds are...</td>\n",
       "      <td>There are 31,536,000 seconds in a year (60 sec...</td>\n",
       "      <td>0.260966</td>\n",
       "      <td>The proposed response calculates the number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be3d0fe1e5d52a2b</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu699koonzGxFxqmSPKhQRQi31hf\"...</td>\n",
       "      <td>You are a trivia master.\\nHow many seconds are...</td>\n",
       "      <td>There are 3,153,600,000 seconds in 100 years.</td>\n",
       "      <td>0.359335</td>\n",
       "      <td>To calculate the number of seconds in 100 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11abc1a7eb12cb32</th>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>{\"id\":\"chatcmpl-BCu4LhMA2nOcsWzjHsWdkg3CPX2F1\"...</td>\n",
       "      <td>You are a trivia master.\\nAlice, Bob, and Char...</td>\n",
       "      <td>Let's denote the amount Charlie paid as C. \\n\\...</td>\n",
       "      <td>0.380158</td>\n",
       "      <td>This response is untrustworthy due to lack of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             attributes.input.value  \\\n",
       "context.span_id                                                       \n",
       "a133162d3623131d  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "f8327c0feaa9104b  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "f7fd714b0743e678  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "be3d0fe1e5d52a2b  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "11abc1a7eb12cb32  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "context.span_id                                                       \n",
       "a133162d3623131d  {\"id\":\"chatcmpl-BCu68UEJaw63CvUtbwRWLbrkxDQ2V\"...   \n",
       "f8327c0feaa9104b  {\"id\":\"chatcmpl-BCu4J12RYILvdhbjKbN92vWwLtY1B\"...   \n",
       "f7fd714b0743e678  {\"id\":\"chatcmpl-BCu4KY4rV3fYoqGmKBzyxZMx1NlVy\"...   \n",
       "be3d0fe1e5d52a2b  {\"id\":\"chatcmpl-BCu699koonzGxFxqmSPKhQRQi31hf\"...   \n",
       "11abc1a7eb12cb32  {\"id\":\"chatcmpl-BCu4LhMA2nOcsWzjHsWdkg3CPX2F1\"...   \n",
       "\n",
       "                                                             prompt  \\\n",
       "context.span_id                                                       \n",
       "a133162d3623131d  You are a trivia master.\\nWhat is the 3rd mont...   \n",
       "f8327c0feaa9104b  You are a trivia master.\\nWhat is the 3rd mont...   \n",
       "f7fd714b0743e678  You are a trivia master.\\nHow many seconds are...   \n",
       "be3d0fe1e5d52a2b  You are a trivia master.\\nHow many seconds are...   \n",
       "11abc1a7eb12cb32  You are a trivia master.\\nAlice, Bob, and Char...   \n",
       "\n",
       "                                                           response     score  \\\n",
       "context.span_id                                                                 \n",
       "a133162d3623131d  The 3rd month of the year in alphabetical orde...  0.034957   \n",
       "f8327c0feaa9104b                                              March  0.037318   \n",
       "f7fd714b0743e678  There are 31,536,000 seconds in a year (60 sec...  0.260966   \n",
       "be3d0fe1e5d52a2b      There are 3,153,600,000 seconds in 100 years.  0.359335   \n",
       "11abc1a7eb12cb32  Let's denote the amount Charlie paid as C. \\n\\...  0.380158   \n",
       "\n",
       "                                                        explanation  \n",
       "context.span_id                                                      \n",
       "a133162d3623131d  The proposed response states that the 3rd mont...  \n",
       "f8327c0feaa9104b  The user is asking for the third month of the ...  \n",
       "f7fd714b0743e678  The proposed response calculates the number of...  \n",
       "be3d0fe1e5d52a2b  To calculate the number of seconds in 100 year...  \n",
       "11abc1a7eb12cb32  This response is untrustworthy due to lack of ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = eval_df.sort_values(by=\"score\", ascending=True).head()\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  You are a trivia master.\n",
      "What is the 3rd month of the year in alphabetical order? \n",
      "\n",
      "OpenAI Response:  The 3rd month of the year in alphabetical order is March. \n",
      "\n",
      "TLM Trust Score:  0.03495703165124102 \n",
      "\n",
      "TLM Explanation:  The proposed response states that the 3rd month of the year in alphabetical order is March. To determine if this is correct, we first need to list the months of the year in alphabetical order: \n",
      "\n",
      "1. April\n",
      "2. August\n",
      "3. December\n",
      "4. February\n",
      "5. January\n",
      "6. July\n",
      "7. June\n",
      "8. March\n",
      "9. May\n",
      "10. November\n",
      "11. October\n",
      "12. September\n",
      "\n",
      "When we look at this list, we can see that March is actually the 8th month in alphabetical order, not the 3rd. The 3rd month in alphabetical order is December. Therefore, the proposed response is incorrect. \n",
      "This response is untrustworthy due to lack of consistency in possible responses from the model. Here's one inconsistent alternate response that the model considered (which may not be accurate either): \n",
      "December.\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the least trustworthy trace.\n",
    "print(\"Prompt: \", sorted_df.iloc[0][\"prompt\"], \"\\n\")\n",
    "print(\"OpenAI Response: \", sorted_df.iloc[0][\"response\"], \"\\n\")\n",
    "print(\"TLM Trust Score: \", sorted_df.iloc[0][\"score\"], \"\\n\")\n",
    "print(\"TLM Explanation: \", sorted_df.iloc[0][\"explanation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awesome! TLM was able to identify multiple traces that contained incorrect answers from OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload the `score` and `explanation` columns to Phoenix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload evaluations to Phoenix\n",
    "\n",
    "Our evals_df has a column for the span_id and a column for the evaluation result. The span_id is what allows us to connect the evaluation to the correct trace in Phoenix. Phoenix will also automatically look for columns named \"score\" and \"evaluation\" to display in the UI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"score\"] = eval_df[\"score\"].astype(float)\n",
    "eval_df[\"explanation\"] = eval_df[\"explanation\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/phoenix/utilities/client.py:45: UserWarning: ⚠️⚠️ The Phoenix server (8.14.1) and client (7.6.0) versions are severely mismatched. Upgrade  either the client or server to ensure API compatibility ⚠️⚠️\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/phoenix/utilities/client.py:45: UserWarning: ⚠️⚠️ The Phoenix server (8.14.1) and client (7.6.0) versions are severely mismatched. Upgrade  either the client or server to ensure API compatibility ⚠️⚠️\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(SpanEvaluations(eval_name=\"Trustworthiness\", dataframe=eval_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see evaluations in the Phoenix UI!\n",
    "\n",
    "From here you can continue collecting and evaluating traces!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
