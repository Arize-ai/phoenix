{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmwwTi0KUa1F"
   },
   "source": [
    "<center> <img src=\"https://storage.cloud.google.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"300\"/> </center>\n",
    "\n",
    "# <center>Getting Started with Hosted Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4-cym_JUfow"
   },
   "source": [
    "This guide demonstrates how to use hosted phoenix, our solution for AI developers to trace and evaluate their LLM applications without setting up infrastructure. Read more about Phoenix [here](https://docs.arize.com/phoenix/).\n",
    "\n",
    "ℹ️ This notebook requires an OpenAI API key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEFoI3zIUwt1"
   },
   "source": [
    "## Step 1: Install Dependencies 📚\n",
    "Let's get the notebook setup with dependencies. It does NOT require installing arize-phoenix to log traces, as we are compliant with OpenTelemetry tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q \"arize-phoenix>=4.29.0\" openinference-instrumentation-openai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "PHOENIX_API_KEY = \"usertest:usertest\"\n",
    "# if not (PHOENIX_API_KEY := os.getenv(\"PHOENIX_API_KEY\")):\n",
    "#     PHOENIX_API_KEY = getpass(\"🔑 Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_API_KEY\"] = PHOENIX_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGTKOk-oU18k"
   },
   "source": [
    "## Step 2: Setup Tracing\n",
    "Let's send a trace to Hosted Phoenix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-e git+ssh://git@github.com/Arize-ai/phoenix.git@8c24822d8445cb3877bb95277524ea8d06bb7b07#egg=arize_phoenix\n",
      "arize-phoenix-evals==0.15.0\n",
      "-e git+ssh://git@github.com/Arize-ai/phoenix.git@8c24822d8445cb3877bb95277524ea8d06bb7b07#egg=arize_phoenix_otel&subdirectory=packages/phoenix-otel\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:phoenix.config:📋 Ensuring phoenix working directory: /Users/kikocastillo/.phoenix\n",
      "INFO:phoenix.inferences.inferences:Dataset: phoenix_inferences_cddd9534-1b11-4de6-8058-ce9ee12bf70e initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO KIKO\n",
      "🔭 OpenTelemetry Tracing Details 🔭\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'api_key': 'usertest:usertest', 'authorization': 'Bearer usertest:usertest', 'user-agent': 'OTel-OTLP-Exporter-Python/1.26.0'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ['OTEL_EXPORTER_OTLP_TRACES_INSECURE']='true' \n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"http://localhost:4041\"\n",
    "\n",
    "# Setup OTEL tracing for hosted Phoenix. The register function will automatically detect the endpoint and headers from your environment variables.\n",
    "tracer_provider = register()\n",
    "\n",
    "# Turn on instrumentation for OpenAI\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider, skip_dep_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COGJEi8HoOaB"
   },
   "source": [
    "Send query to Hosted Phoenix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:opentelemetry.exporter.otlp.proto.grpc.exporter:Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1s.\n",
      "WARNING:opentelemetry.exporter.otlp.proto.grpc.exporter:Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 2s.\n",
      "WARNING:opentelemetry.exporter.otlp.proto.grpc.exporter:Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4s.\n",
      "WARNING:opentelemetry.exporter.otlp.proto.grpc.exporter:Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 8s.\n",
      "WARNING:opentelemetry.exporter.otlp.proto.grpc.exporter:Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 16s.\n",
      "WARNING:opentelemetry.exporter.otlp.proto.grpc.exporter:Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 32s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nature whispers soft\n",
      "Leaves rustle in the gentle breeze\n",
      "Peaceful serenade\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai_client = openai.OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a haiku.\"}],\n",
    "    max_tokens=20,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9dDee9_9ywx"
   },
   "source": [
    "## Step 3: Access Phoenix Instance\n",
    "\n",
    "From here, you can access your Phoenix instance to power evaluations, experiments, upload datasets, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:4041/arize_phoenix_version \"HTTP/1.1 200 OK\"\n",
      "/Users/kikocastillo/Documents/Arize/phoenix/src/phoenix/utilities/client.py:25: UserWarning: The Phoenix server has an unknown version and may have compatibility issues.\n",
      "  warnings.warn(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:4041/v1/spans?project_name=default&project-name=default \"HTTP/1.1 200 OK\"\n",
      "/Users/kikocastillo/Documents/Arize/phoenix/src/phoenix/utilities/client.py:45: UserWarning: The Phoenix server (4.32.0) and client (4.35.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Invalid IPC stream: negative continuation token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get spans to exclude the last 24 hours\u001b[39;00m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m phoenix_df \u001b[38;5;241m=\u001b[39m \u001b[43mpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_spans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(phoenix_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/Documents/Arize/phoenix/src/phoenix/session/client.py:195\u001b[0m, in \u001b[0;36mClient.query_spans\u001b[0;34m(self, start_time, end_time, limit, root_spans_only, project_name, stop_time, timeout, *queries)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mipc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[1;32m    196\u001b[0m             results\u001b[38;5;241m.\u001b[39mappend(reader\u001b[38;5;241m.\u001b[39mread_pandas())\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ArrowInvalid:\n",
      "File \u001b[0;32m~/anaconda3/envs/phoenix-dev/lib/python3.11/site-packages/pyarrow/ipc.py:190\u001b[0m, in \u001b[0;36mopen_stream\u001b[0;34m(source, options, memory_pool)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_stream\u001b[39m(source, \u001b[38;5;241m*\u001b[39m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    Create reader for Arrow streaming format.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        A reader for the given source\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRecordBatchStreamReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmemory_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_pool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/phoenix-dev/lib/python3.11/site-packages/pyarrow/ipc.py:52\u001b[0m, in \u001b[0;36mRecordBatchStreamReader.__init__\u001b[0;34m(self, source, options, memory_pool)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, \u001b[38;5;241m*\u001b[39m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m     options \u001b[38;5;241m=\u001b[39m _ensure_default_ipc_read_options(options)\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_pool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/phoenix-dev/lib/python3.11/site-packages/pyarrow/ipc.pxi:1006\u001b[0m, in \u001b[0;36mpyarrow.lib._RecordBatchStreamReader._open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/phoenix-dev/lib/python3.11/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/phoenix-dev/lib/python3.11/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Invalid IPC stream: negative continuation token"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "# Initiate Phoenix client\n",
    "px_client = px.Client()\n",
    "\n",
    "# Get spans from the last 7 days only\n",
    "start = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Get spans to exclude the last 24 hours\n",
    "end = datetime.now() - timedelta(days=0)\n",
    "\n",
    "phoenix_df = px_client.query_spans(start_time=start, end_time=end)\n",
    "print(phoenix_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBcnGURRDIE5"
   },
   "source": [
    "Use our latest and greatest features around datasets on the latest Phoenix version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"question\": \"What is Paul Graham known for?\",\n",
    "            \"answer\": \"Co-founding Y Combinator and writing on startups and techology.\",\n",
    "            \"metadata\": {\"topic\": \"tech\"},\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "phoenix_client = px.Client()\n",
    "dataset = phoenix_client.upload_dataset(\n",
    "    dataframe=df,\n",
    "    dataset_name=\"test-dataset-2\",\n",
    "    input_keys=[\"question\"],\n",
    "    output_keys=[\"answer\"],\n",
    "    metadata_keys=[\"metadata\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
