{
  "name": "mock-llm-server",
  "version": "1.0.0",
  "description": "Mock LLM API server (OpenAI + Anthropic + Gemini) with real-time monitoring dashboard",
  "type": "module",
  "scripts": {
    "dev": "tsx watch src/server.ts",
    "start": "tsx src/server.ts",
    "build": "tsc",
    "build:dashboard": "cd dashboard && pnpm run build",
    "build:all": "pnpm run build && pnpm run build:dashboard",
    "typecheck": "tsc --noEmit",
    "lint": "eslint src tests",
    "lint:fix": "eslint src tests --fix",
    "test": "vitest run",
    "test:watch": "vitest watch"
  },
  "dependencies": {
    "@faker-js/faker": "^10.2.0",
    "express": "^4.21.0",
    "ws": "^8.19.0"
  },
  "devDependencies": {
    "@anthropic-ai/sdk": "^0.39.0",
    "@eslint/js": "^9.0.0",
    "@google/genai": "^1.0.0",
    "@types/express": "^4.17.21",
    "@types/node": "^20.17.22",
    "@types/ws": "^8.18.1",
    "eslint": "^9.0.0",
    "json-schema-faker": "^0.5.9",
    "openai": "^4.77.0",
    "tsx": "^4.19.3",
    "typescript": "^5.8.2",
    "typescript-eslint": "^8.0.0",
    "vitest": "^2.1.0"
  },
  "engines": {
    "node": ">=22"
  }
}