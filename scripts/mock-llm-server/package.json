{
  "name": "mock-llm-server",
  "version": "1.0.0",
  "description": "Mock LLM API server (OpenAI + Anthropic + Gemini) with real-time monitoring dashboard",
  "type": "module",
  "scripts": {
    "dev": "tsx watch src/server.ts",
    "start": "tsx src/server.ts",
    "build": "tsc",
    "build:dashboard": "cd dashboard && pnpm run build",
    "build:all": "pnpm run build && pnpm run build:dashboard",
    "typecheck": "tsc --noEmit",
    "lint": "eslint src tests",
    "lint:fix": "eslint src tests --fix",
    "test": "vitest run",
    "test:watch": "vitest watch"
  },
  "dependencies": {
    "@faker-js/faker": "^10.3.0",
    "express": "^5.2.1",
    "ws": "^8.19.0"
  },
  "devDependencies": {
    "@anthropic-ai/sdk": "^0.78.0",
    "@eslint/js": "^10.0.1",
    "@google/genai": "^1.43.0",
    "@types/express": "^5.0.6",
    "@types/node": "^25.3.1",
    "@types/ws": "^8.18.1",
    "eslint": "^10.0.2",
    "json-schema-faker": "^0.6.0",
    "openai": "^6.25.0",
    "tsx": "^4.21.0",
    "typescript": "^5.9.3",
    "typescript-eslint": "^8.56.1",
    "vitest": "^4.0.18"
  },
  "engines": {
    "node": ">=22"
  }
}