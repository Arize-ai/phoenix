{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"arize llama-index logos\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/docs/notebooks/llama-index-knowledge-base-tutorial/arize_llamaindex.png\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex Chunk Size, Retrieval Method and K Eval Suite\n",
    "\n",
    "This colab provides a suite of retrieval performance tests that helps teams understand\n",
    "how to setup the retrieval system. It makes use of the Phoenix Eval options for \n",
    "Q&A (overall did it answer the question) and retrieval (did the right chunks get returned).\n",
    "\n",
    "There is a sweep of parameters that is stored in experiment_data/results_no_zero_remove, \n",
    "check that directory for results. \n",
    "\n",
    "The goal is to help teams choose a Chunk size, retireval method, K for return chunks\n",
    "\n",
    "This colab downloads the script (py) files. Those files can be run without this colab directly,\n",
    "in a code only environment (VS code for example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Eval\n",
    "\n",
    "This Eval evaluates whether a retrieved chunk contains an answer to the query. Its extremely useful for evaluating retrieval systems.\n",
    "\n",
    "https://docs.arize.com/phoenix/concepts/llm-evals/retrieval-rag-relevance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A EVal\n",
    "This Eval evaluates whether a question was correctly answered by the system based on the retrieved data. In contrast to retrieval Evals that are checks on chunks of data returned, this check is a system level check of a correct Q&A.\n",
    "\n",
    "https://docs.arize.com/phoenix/concepts/llm-evals/q-and-a-on-retrieved-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/chunking.png\" />\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge in setting up a retrieval system is having solid performance metrics that allow you to evaluate your different strategies:\n",
    "- Chunk Size\n",
    "- Retrieval Method\n",
    "- K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Donwload scripts\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Arize-ai/phoenix/main/scripts/rag/llama_index_w_eavls_and_qa.py\"\n",
    "response = requests.get(url)\n",
    "with open(\"example.py\", \"w\") as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Arize-ai/phoenix/main/scripts/rag/plotresults.py\"\n",
    "response = requests.get(url)\n",
    "with open(\"example.py\", \"w\") as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Arize-ai/phoenix/main/scripts/rag/config.py\"\n",
    "response = requests.get(url)\n",
    "with open(\"example.py\", \"w\") as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN AI KEY and Cohere Key\n",
    "\n",
    "Open the config.py and add your keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRABBING DOCUMENTS\n",
      "LOADING DOCUMENTS FROM FILE\n",
      "Opening raw_documents.pkl\n",
      "['How do I use the SDK to upload a ranking model?', 'What drift metrics are supported in Arize?', 'Does Arize support batch models?', 'Does Arize support training data?', 'How do I configure a threshold if my data has seasonality trends?', 'How are clusters in the UMAP calculated? When are the clusters refreshed?', 'How does Arize calculate AUC?', 'Can I send truth labels to Arize separately?', 'How do I send embeddings to Arize?', 'Can I copy a dashboard?', 'Can I copy a dashboard to a new space?', 'How do I configure permissions for GBQ?', 'How often does Arize query the table for table import jobs?', 'Can you configure the query interval for table import jobs?', 'Do you need to have a prediction label for classification models?', 'Do you need a prediction ID for the training set?', 'How do you set up PagerDuty alerts?', 'Does the ingestion job for GBQ tables detect changes in the table schema?', 'How do I send in extra metadata with each record?', 'What is the current retention period of the data in Arize (if any), and can we customize this? (e.g. could we choose to set a specific retention period of, say 90-days, so that all data older than 90 days is deleted from Arize systems?)', 'Does Arize store the individual records (rows) somewhere, or does it only store the aggregations calculated from the data?', 'What happens if I upload actuals twice?', 'What format should the prediction timestamp be?', 'How often do the monitors run and evaluate?', 'Do we have the ability to resolve a monitor?', 'Does Arize support Microsoft Teams alerting?', 'What should I do if I sent in duplicate prediction IDs?', 'Why does Arize use UMAP over t-SNE?', 'Can I export a dashboard as PDF?', \"How does Arize's surrogate explainability model work?\", 'Can I update my predictions or features on Arize?', 'What happens if my model schema changes after I deploy a new version of the model?', 'How does Arize integrate with SageMaker?', 'Does the ingestion job for GBQ tables detect changes in schema?', 'Can I configure the Arize data sampling policy?', 'About how long should it take for delayed actuals to link to predictions in the UI?', 'Can I change strings to numeric in Arize?', 'What is the definition of a model or a prediction in Arize?', 'How do I pass in delayed ground truth?', 'Can I pass in my own metrics within Arize?', 'How large should my file sizes be when uploading data?', 'How long does it take to ingest my data?', 'How do I edit the frequency that my table import job runs?', 'What permissions are needed to import my files from cloud storage?', 'How do I grant permissions to import my GBQ table?', 'Does Arize ingest null values?', 'Which file or dataframe columns can be null?', 'What file types are supported for cloud storage uploads?', 'Is prediction_id required?', 'How do I need to format timestamps?', 'Why do I need a timestamp?', 'What time unit is a timestamp?', 'Does Arize support timestamps that are pandas format?', 'Can I create any string format that is a timestamp?', 'Can I send latent ground truth for ranking models?', 'Does Arize count duplicate prediction IDs as a single prediction?', 'Does Arize sample the data on ingestion of files?', 'When connecting to a table, is the data copied into Arize or does Arize just run off of the table?', 'Is the entire data set copied when connecting to data in files?', 'How long does it take for data to show up in the platform?', 'Does Arize support PSI as a drift metric?', 'Arize help', 'Dataset not showing up', 'Is it possible for me to change the threshold for PSI for the drift tab, as in what I can configure for each monitor?', \"I don't have actuals\", \"I see data in the data ingestion tab but none of the charts are showing data. What's going wrong?\", \"My monitor's latest status is green even though the chart shows the threshold is crossed. What does this mean?\", 'What is a managed monitor?', 'What is Euclidean distance? I thought it is the distance between points. What does it mean on the page?', 'Can I deploy Arize on my own Kubernetes cluster?', 'How are the records sent to Arize secured? How does Arize handle sensitive data?', 'Data ingestion page does not show the correct number of records', 'How do I link my actuals to predictions?', 'Can I create one FileImporter job with both predictions and latent actuals?', 'Why is my FileImport job failing on uploading actuals?', 'What is a score categorical model?', \"I am sending images with my embeddings but the images don't load. What's going wrong?\", \"I am sending videos in link_to_data but they don't show up. Why?\", 'Does Arize support timeseries data?', 'Where can I find HIPAA reporting?', 'How do I get feature importance on data I upload in the File Importer?', 'How can I move a model from one space to another?', 'How do I get an Arize API key?', 'What is a space key?', 'How do I rotate my credentials?', \"I can't recover my password, how do I do that?\", \"What is Arize's retention policy?\", 'How do I delete a space?', 'How do I delete a space and organization?', 'How do I change my email address?', 'I sent the wrong records to Arize. How do I delete them?', 'I sent 8000 records but I only see 1000 in the UI. Why?', \"I can't find my feature in any of the dropdowns.\", 'How do I use custom metrics on monitors?', 'How do I unsubscribe from a monitor?', 'Do predictions from deleted models count against my plan usage?', 'How do I change current SAML auth to remove the email and only authorize using the first name and last name?', 'What counts against my plan usage?', \"What happens if I go over my plan's allocated volume?\", 'What is the change_timestamp on table import?', 'Do I need to upload timestamps?', 'How do I load private images into Arize?', 'What do I do if I sent in a feature whose type changed?', \"What's the difference between Arize's Pro and Enterprise plans?\", 'How to share customized dashboard?', 'How to create custom metric for ROI?', 'Where do I find the API and Space keys?', 'How can I run Arize on my own hardware?', 'Is my prediction data shared with any services except for Arize?', 'How do I change fields on a prediction?', 'Can I create monitors with an API?', 'Can I create dashboards with an API?', 'How do I delete data?', \"I can't see the points in the UMAP. How do I make the points bigger?\", 'I want to cancel my account. How do I do that?', 'I want to delete my data. Help.', 'How do I update my predictions?', 'The File Importer job failed. How do I restart it?', 'Does Arize support Snowflake?', 'How do I ingest CSV data?', 'How do I get access to my embeddings?', \"I don't see errors in the SDK, but my records don't show up. How do I troubleshoot?\", 'Can I download my data?', 'How can I change the threshold of my metric?', 'How do I duplicate a dashboard?', 'My monitor is noisy. How do I fix?', 'How do I download my data?', 'I got a 200 from my SDK request, but my data never showed up', 'Is there a way to automatically infer which columns serve which purpose during the ingestion process?', 'How much does the Arize platform cost and how do you charge?', 'What is the price of the Arize platform?', 'How much does Arize charge and how do you price, is it per model?', 'What would Arize cost annually and what is the likely ROI? I assume it is quite high ROI', 'Do you have a pricing calculator that can help me understand the price of Arize relative to the various deployment options?', 'What is the cost of the Arize platform?', 'Is there cost for Arize beyond an annual subscription price?', 'What is the price per model or per volume and how much does the price discount as the volume goes up?', 'What is the annual cost of a VPC deployment option? How does that price scale?', 'How expensive is the Arize platform and how do you charge?', 'Does Arize support object segmentation use cases?', 'If I am using an object segmentation model, should I apply my own segmentation mask to the image before uploading the image, or will the platform do that for me?', 'Can you give me an example schema I could use for uploading inference data from an image segmentation model?', \"What's the difference between image segmentation and object detection?\", 'How do you recommend I create embeddings for an object segmentation model?', 'Is it possible to upload multiple masks for the same image in a segmentation use case?', 'What evaluation metrics are supported for image segmentation use cases?', 'Do you have an example image segmentation notebook?', 'How many classes are supported for image segmentation?', 'Do you support IoU for image segmentation?', 'This is a test question?', '?', 'This is a question?', 'My service is a hosting service designed for hosting your website. You can put your website on our service and host it with accelerated CDN delivery, tracking of usage data for running your website. Our service is one of the best on the internet in terms of delivery and experience.', 'What is a timestamp?', 'What is a prediction ID?', 'What are actuals?', 'Can I log single events?', 'Can I log batches of data?', \"What happens if I don't have ground truths?\", 'Can Arize be deployed inside my own cloud environment?', 'What data do I need to send to Arize?', \"What if I don't have a timestamp?\", \"Do I need to send in input features along with my ground truth, if I'm sending my ground truth data later?\", \"What if I don't have my prediction label or prediction score for my training data?\", 'How do I send training data vs production data?', 'How do I connect Arize to data that exists somewhere else?', 'What is the validation environment used for?', 'Can I set permissions for my users?', 'Can I set up monitors programmatically, or am I only able to set them up through the UI?', 'How can I get feature importance values?', 'Do you only support SHAP for feature importance?']\n",
      "PARSING WITH CHUNK SIZE 100\n",
      "EXISTING INDEX FOUND, LOADING...\n",
      "--------------------------------------------------\n",
      "0\n",
      "How do I use the SDK to upload a ranking model?\n",
      "QUERY 1:  How do I use the SDK to upload a ranking model?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 4\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  2.582997 seconds\n",
      "      |_retrieve ->  0.68079 seconds\n",
      "      |_synthesize ->  1.901939 seconds\n",
      "        |_templating ->  4.7e-05 seconds\n",
      "        |_llm ->  1.896255 seconds\n",
      "**********\n",
      "RESPONSE:  The context does not provide specific information on how to use the SDK to upload a ranking model. \n",
      "\n",
      "LATENCY: 2.59 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1\n",
      "What drift metrics are supported in Arize?\n",
      "QUERY 2:  What drift metrics are supported in Arize?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 4\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  8.335998 seconds\n",
      "      |_retrieve ->  0.50222 seconds\n",
      "      |_synthesize ->  7.833368 seconds\n",
      "        |_templating ->  4.5e-05 seconds\n",
      "        |_llm ->  7.829969 seconds\n",
      "**********\n",
      "RESPONSE:  Arize supports various distributional drift metrics. Each of these metrics is tailored to a specific use case. For instance, one of the metrics they offer is PSI, which is less influenced by sample size and offers fewer false positives compared to the Kolmogorov-Smirnov test or Earth Mover's Distance. This makes it suitable for datasets with expected fluctuations. Arize's system also provides drift over time widgets with your chosen metric to determine if drift is contributing to performance degradation. \n",
      "\n",
      "LATENCY: 8.34 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2\n",
      "Does Arize support batch models?\n",
      "QUERY 3:  Does Arize support batch models?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 4\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  2.663326 seconds\n",
      "      |_retrieve ->  0.554565 seconds\n",
      "      |_synthesize ->  2.108391 seconds\n",
      "        |_templating ->  4.4e-05 seconds\n",
      "        |_llm ->  2.104613 seconds\n",
      "**********\n",
      "RESPONSE:  The context does not provide information on whether Arize supports batch models. \n",
      "\n",
      "LATENCY: 2.67 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "0\n",
      "How do I use the SDK to upload a ranking model?\n",
      "QUERY 1:  How do I use the SDK to upload a ranking model?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 4\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  The context information provided does not contain specific instructions on how to use the SDK to upload a ranking model. \n",
      "\n",
      "LATENCY: 9.14 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1\n",
      "What drift metrics are supported in Arize?\n",
      "QUERY 2:  What drift metrics are supported in Arize?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 4\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  The context doesn't provide specific information on what drift metrics are supported in Arize. \n",
      "\n",
      "LATENCY: 7.79 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2\n",
      "Does Arize support batch models?\n",
      "QUERY 3:  Does Arize support batch models?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 4\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  The information at hand does not specify whether Arize supports batch models. \n",
      "\n",
      "LATENCY: 6.89 \n",
      "\n",
      "--------------------------------------------------\n",
      "RUNNING EVALS\n",
      "\n",
      "RUNNING EVALS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL LATENCY: 11.56 \n",
      "\n",
      "RUNNING EVALS\n",
      "\n",
      "RUNNING EVALS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL LATENCY: 10.09 \n",
      "\n",
      "--------------------------------------------------\n",
      "0\n",
      "How do I use the SDK to upload a ranking model?\n",
      "QUERY 1:  How do I use the SDK to upload a ranking model?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 6\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  3.249376 seconds\n",
      "      |_retrieve ->  0.609155 seconds\n",
      "      |_synthesize ->  2.639993 seconds\n",
      "        |_templating ->  4.8e-05 seconds\n",
      "        |_llm ->  2.634044 seconds\n",
      "**********\n",
      "RESPONSE:  The context does not provide specific steps on how to use the SDK to upload a ranking model. \n",
      "\n",
      "LATENCY: 3.26 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1\n",
      "What drift metrics are supported in Arize?\n",
      "QUERY 2:  What drift metrics are supported in Arize?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 6\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  5.902544 seconds\n",
      "      |_retrieve ->  0.557798 seconds\n",
      "      |_synthesize ->  5.344504 seconds\n",
      "        |_templating ->  4.4e-05 seconds\n",
      "        |_llm ->  5.338366 seconds\n",
      "**********\n",
      "RESPONSE:  Arize supports various distributional drift metrics. Each metric is tailored to a specific use case. One example is the PSI metric, which is less influenced by sample size and offers fewer false positives compared to the Kolmogorov-Smirnov test or Earth Mover's Distance. This makes it suitable for datasets with expected fluctuations. \n",
      "\n",
      "LATENCY: 5.91 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2\n",
      "Does Arize support batch models?\n",
      "QUERY 3:  Does Arize support batch models?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 6\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  2.004639 seconds\n",
      "      |_retrieve ->  0.481565 seconds\n",
      "      |_synthesize ->  1.522627 seconds\n",
      "        |_templating ->  4.4e-05 seconds\n",
      "        |_llm ->  1.516933 seconds\n",
      "**********\n",
      "RESPONSE:  The context does not provide specific information about Arize supporting batch models. \n",
      "\n",
      "LATENCY: 2.01 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "0\n",
      "How do I use the SDK to upload a ranking model?\n",
      "QUERY 1:  How do I use the SDK to upload a ranking model?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 6\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  The context does not provide specific instructions on how to use the SDK to upload a ranking model. \n",
      "\n",
      "LATENCY: 12.47 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1\n",
      "What drift metrics are supported in Arize?\n",
      "QUERY 2:  What drift metrics are supported in Arize?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 6\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  Arize supports a variety of drift metrics, including the Population Stability Index, KL Divergence, KS Statistic, and JS Distance. \n",
      "\n",
      "LATENCY: 14.63 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2\n",
      "Does Arize support batch models?\n",
      "QUERY 3:  Does Arize support batch models?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 6\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  Yes, Arize does provide support for batch models. The batch name of your model can be specified at the point of export. This feature is specifically designed for use in the Validation environment. \n",
      "\n",
      "LATENCY: 21.17 \n",
      "\n",
      "--------------------------------------------------\n",
      "RUNNING EVALS\n",
      "\n",
      "RUNNING EVALS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "100%|██████████| 18/18 [00:11<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL LATENCY: 13.50 \n",
      "\n",
      "RUNNING EVALS\n",
      "\n",
      "RUNNING EVALS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "100%|██████████| 18/18 [00:12<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL LATENCY: 14.31 \n",
      "\n",
      "--------------------------------------------------\n",
      "0\n",
      "How do I use the SDK to upload a ranking model?\n",
      "QUERY 1:  How do I use the SDK to upload a ranking model?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 10\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  7.363115 seconds\n",
      "      |_retrieve ->  0.491579 seconds\n",
      "      |_synthesize ->  6.871206 seconds\n",
      "        |_templating ->  4.8e-05 seconds\n",
      "        |_llm ->  6.862448 seconds\n",
      "**********\n",
      "RESPONSE:  You can upload a ranking model using various data connectors such as Google Cloud Storage (GCS), AWS S3, Azure Blob Storage, Google BigQuery, Databricks, and Snowflake. You can also use Python Pandas SDK or the UI Drag & Drop method for uploading. However, ensure that your data represents unique ranks for a given prediction group to avoid visualization issues on the platform. \n",
      "\n",
      "LATENCY: 7.37 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1\n",
      "What drift metrics are supported in Arize?\n",
      "QUERY 2:  What drift metrics are supported in Arize?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 10\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  4.059356 seconds\n",
      "      |_retrieve ->  0.475859 seconds\n",
      "      |_synthesize ->  3.583091 seconds\n",
      "        |_templating ->  4.2e-05 seconds\n",
      "        |_llm ->  3.576142 seconds\n",
      "**********\n",
      "RESPONSE:  Arize supports various drift metrics including the Population Stability Index, KL Divergence, KS Statistic, and JS Distance. The choice of metric can be tailored to specific use cases. \n",
      "\n",
      "LATENCY: 4.07 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2\n",
      "Does Arize support batch models?\n",
      "QUERY 3:  Does Arize support batch models?\n",
      "----------\n",
      "TRANSFORMATION: original\n",
      "CHUNK SIZE: 100\n",
      "K : 10\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  1.641641 seconds\n",
      "      |_retrieve ->  0.495983 seconds\n",
      "      |_synthesize ->  1.14541 seconds\n",
      "        |_templating ->  4.2e-05 seconds\n",
      "        |_llm ->  1.138063 seconds\n",
      "**********\n",
      "RESPONSE:  Yes, Arize does support batch models. \n",
      "\n",
      "LATENCY: 1.65 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "0\n",
      "How do I use the SDK to upload a ranking model?\n",
      "QUERY 1:  How do I use the SDK to upload a ranking model?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 10\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  The context does not provide specific steps on how to use the SDK to upload a ranking model. \n",
      "\n",
      "LATENCY: 21.09 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1\n",
      "What drift metrics are supported in Arize?\n",
      "QUERY 2:  What drift metrics are supported in Arize?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 10\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  Arize supports several drift metrics such as the Population Stability Index, KL Divergence, KS Statistic, and JS Distance. \n",
      "\n",
      "LATENCY: 22.91 \n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2\n",
      "Does Arize support batch models?\n",
      "QUERY 3:  Does Arize support batch models?\n",
      "----------\n",
      "TRANSFORMATION: original_rerank\n",
      "CHUNK SIZE: 100\n",
      "K : 10\n",
      "LAMAINDEX MODEL : gpt-4\n",
      "RESPONSE:  Absolutely, Arize provides support for batch models. When exporting, you have the option to name the specific batch model you wish to use. Keep in mind that batch models are directly associated with the Validation environment. \n",
      "\n",
      "LATENCY: 37.19 \n",
      "\n",
      "--------------------------------------------------\n",
      "RUNNING EVALS\n",
      "\n",
      "RUNNING EVALS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL LATENCY: 25.23 \n",
      "\n",
      "RUNNING EVALS\n",
      "\n",
      "RUNNING EVALS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL LATENCY: 23.55 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import phoenix.experimental.evals.templates.default_templates as templates\n",
    "import datetime\n",
    "from llama_index_w_eavls_and_qa import get_urls, read_strings_from_csv, run_experiments, plot_graphs\n",
    "import pickle\n",
    "import config\n",
    "from llama_index import download_loader\n",
    "import openai\n",
    "import cohere\n",
    "\n",
    "name = \"BeautifulSoupWebReader\"\n",
    "BeautifulSoupWebReader = download_loader(name)\n",
    "now = datetime.datetime.now()\n",
    "run_name = now.strftime('%Y%m%d_%H%M')\n",
    "# Directory parameter for saving data!\n",
    "openai.api_key = (\n",
    "    config.open_ai_key\n",
    ")  # replace with the string containing the API key if needed\n",
    "cohere.api_key = config.cohere_key\n",
    "#Used by Arize Evals\n",
    "os.environ['OPENAI_API_KEY'] =  config.open_ai_key\n",
    "\n",
    "# if loading from scratch, change these below\n",
    "web_title = \"arize\"  # nickname for this website, used for saving purposes\n",
    "base_url = \"https://docs.arize.com/arize\"\n",
    "#Local files\n",
    "file_name = 'raw_documents.pkl'\n",
    "save_base = f\"./experiment_data/\" \n",
    "save_dir = save_base + run_name + \"/\"\n",
    "\n",
    "# Read strings from CSV\n",
    "questions = read_strings_from_csv(\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/constants.csv\")\n",
    "\n",
    "if not os.path.exists(save_base + file_name):\n",
    "    print(f\"'{save_base}{file_name}' does not exists.\")\n",
    "    urls = get_urls(base_url) #you need to - pip install lxml\n",
    "    print(f\"LOADED {len(urls)} URLS\")\n",
    "\n",
    "print(\"GRABBING DOCUMENTS\")\n",
    "# two options here, either get the documents from scratch or load one from disk\n",
    "if not os.path.exists(save_base + file_name):\n",
    "    print(\"LOADING DOCUMENTS FROM URLS\")\n",
    "    #You need to 'pip install lxml'\n",
    "    loader = BeautifulSoupWebReader()\n",
    "    documents = loader.load_data(urls=urls)  # may take some time\n",
    "    with open(save_base + file_name, \"wb\") as file:\n",
    "        pickle.dump(documents, file)\n",
    "    print(\"Documents saved to raw_documents.pkl\")\n",
    "else:\n",
    "    print(\"LOADING DOCUMENTS FROM FILE\")\n",
    "    print(\"Opening raw_documents.pkl\")\n",
    "    with open(save_base + file_name, \"rb\") as file:\n",
    "        documents = pickle.load(file)\n",
    "chunk_sizes = [\n",
    "    100,\n",
    "    #300,\n",
    "    #500,\n",
    "    #1000,\n",
    "    #2000,\n",
    "]  # change this, perhaps experiment from 500 to 3000 in increments of 500\n",
    "\n",
    "k = [4, 6, 10]\n",
    "#k = [10]  # num documents to retrieve\n",
    "\n",
    "#transformations = [\"original\", \"original_rerank\",\"hyde\", \"hyde_rerank\"]\n",
    "transformations = [\"original\", \"original_rerank\"]\n",
    "\n",
    "lama_index_model = \"gpt-4\"\n",
    "#lama_index_model = \"gpt-3.5-turbo\"\n",
    "eval_model = \"gpt-4\"\n",
    "\n",
    "qa_templ = templates.QA_PROMPT_TEMPLATE_STR \n",
    "#Uncomment when testing, 3 questions are easy to run through quickly \n",
    "#questions = questions[0:3]\n",
    "all_data = run_experiments(\n",
    "    documents,\n",
    "    questions,\n",
    "    chunk_sizes,\n",
    "    transformations,\n",
    "    k,\n",
    "    web_title,\n",
    "    save_dir,\n",
    "    lama_index_model,\n",
    "    eval_model,\n",
    "    qa_templ\n",
    ")\n",
    "\n",
    "\n",
    "with open(f\"{save_dir}{web_title}_all_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_data, f)\n",
    "\n",
    "#The retrievals with 0 relevant context really can't be optimized, removing gives a diff view\n",
    "plot_graphs(all_data, k, save_dir +  \"/results_zero_removed/\", show=False)\n",
    "plot_graphs(all_data, k, save_dir + \"/results_no_zero_remove/\", show=False, remove_zero=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results Q&A Evals (actual results in experiment_data)\n",
    "\n",
    "The Q&A Eval runs at the highest level of did you get the question answer correct  based on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix data\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/percentage_incorrect_plot.png\" />\n",
    "    </p>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results Retrieval Eval  (actual results in experiment_data)\n",
    "\n",
    "The retrieval analysis example is below, iterates through the chunk sizes, K (4/6/10), retrieval method\n",
    "The eval checks whether the retrieved chunk is relevant and has a chance to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix data\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/all_mean_precisions.png\" />\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results Latency  (actual results in experiment_data)\n",
    "\n",
    "The latency can highly varied based on retrieval approaches, below are latency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix data\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/median_latency_all.png\" />\n",
    "    </p>\n",
    "</center>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix-lib-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
