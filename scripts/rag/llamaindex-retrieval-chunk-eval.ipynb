{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex Chunk Size, Retrieval Method and K Eval Suite\n",
    "\n",
    "This colab provides a suite of retrieval performance tests that helps teams understand\n",
    "how to setup the retrieval system. It makes use of the Phoenix Eval options for \n",
    "Q&A (overall did it answer the question) and retrieval (did the right chunks get returned).\n",
    "\n",
    "There is a sweep of parameters that is stored in experiment_data/results_no_zero_remove, \n",
    "check that directory for results. \n",
    "\n",
    "The goal is to help teams choose a Chunk size, retireval method, K for return chunks\n",
    "\n",
    "This colab downloads the script (py) files. Those files can be run without this colab directly,\n",
    "in a code only environment (VS code for example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Eval\n",
    "\n",
    "This Eval evaluates whether a retrieved chunk contains an answer to the query. Its extremely useful for evaluating retrieval systems.\n",
    "\n",
    "https://docs.arize.com/phoenix/concepts/llm-evals/retrieval-rag-relevance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A EVal\n",
    "This Eval evaluates whether a question was correctly answered by the system based on the retrieved data. In contrast to retrieval Evals that are checks on chunks of data returned, this check is a system level check of a correct Q&A.\n",
    "\n",
    "https://docs.arize.com/phoenix/concepts/llm-evals/q-and-a-on-retrieved-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/chunking.png\" />\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge in setting up a retrieval system is having solid performance metrics that allow you to evaluate your different strategies:\n",
    "- Chunk Size\n",
    "- Retrieval Method\n",
    "- K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Donwload scripts\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Arize-ai/phoenix/main/scripts/rag/llama_index_w_eavls_and_qa.py\"\n",
    "response = requests.get(url)\n",
    "with open(\"example.py\", \"w\") as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Arize-ai/phoenix/main/scripts/rag/plotresults.py\"\n",
    "response = requests.get(url)\n",
    "with open(\"example.py\", \"w\") as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Arize-ai/phoenix/main/scripts/rag/config.py\"\n",
    "response = requests.get(url)\n",
    "with open(\"example.py\", \"w\") as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN AI KEY and Cohere Key\n",
    "\n",
    "Open the config.py and add your keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRABBING DOCUMENTS\n",
      "LOADING DOCUMENTS FROM FILE\n",
      "Opening raw_documents.pkl\n",
      "PARSING WITH CHUNK SIZE 100\n",
      "EXISTING INDEX FOUND, LOADING...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m eval_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m#Uncomment when testing\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m#questions = questions[0:3]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m all_data \u001b[39m=\u001b[39m run_experiments(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     documents,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     questions,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     chunk_sizes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     transformations,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     k,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     web_title,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     save_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     lama_index_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     eval_model\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msave_dir\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mweb_title\u001b[39m}\u001b[39;00m\u001b[39m_all_data.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonlopatecki/vs_projects/lang_human/llamaindex-retrieval-chunk-eval.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(all_data, f)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/llama_index_w_eavls_and_qa.py:180\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(documents, queries, chunk_sizes, query_transformations, k_values, web_title, save_dir, lama_index_model, eval_model, all_data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEXISTING INDEX FOUND, LOADING...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[39m# Rebuild storage context\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m storage_context \u001b[39m=\u001b[39m StorageContext\u001b[39m.\u001b[39;49mfrom_defaults(persist_dir\u001b[39m=\u001b[39;49mpersist_dir)\n\u001b[1;32m    182\u001b[0m \u001b[39m# Load index from the storage context\u001b[39;00m\n\u001b[1;32m    183\u001b[0m index \u001b[39m=\u001b[39m load_index_from_storage(storage_context)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/llama_index/storage/storage_context.py:81\u001b[0m, in \u001b[0;36mStorageContext.from_defaults\u001b[0;34m(cls, docstore, index_store, vector_store, graph_store, persist_dir, fs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     docstore \u001b[39m=\u001b[39m docstore \u001b[39mor\u001b[39;00m SimpleDocumentStore\u001b[39m.\u001b[39mfrom_persist_dir(\n\u001b[1;32m     76\u001b[0m         persist_dir, fs\u001b[39m=\u001b[39mfs\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m     index_store \u001b[39m=\u001b[39m index_store \u001b[39mor\u001b[39;00m SimpleIndexStore\u001b[39m.\u001b[39mfrom_persist_dir(\n\u001b[1;32m     79\u001b[0m         persist_dir, fs\u001b[39m=\u001b[39mfs\n\u001b[1;32m     80\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m     vector_store \u001b[39m=\u001b[39m vector_store \u001b[39mor\u001b[39;00m SimpleVectorStore\u001b[39m.\u001b[39;49mfrom_persist_dir(\n\u001b[1;32m     82\u001b[0m         persist_dir, fs\u001b[39m=\u001b[39;49mfs\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     84\u001b[0m     graph_store \u001b[39m=\u001b[39m graph_store \u001b[39mor\u001b[39;00m SimpleGraphStore\u001b[39m.\u001b[39mfrom_persist_dir(\n\u001b[1;32m     85\u001b[0m         persist_dir, fs\u001b[39m=\u001b[39mfs\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(docstore, index_store, vector_store, graph_store)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/llama_index/vector_stores/simple.py:88\u001b[0m, in \u001b[0;36mSimpleVectorStore.from_persist_dir\u001b[0;34m(cls, persist_dir, fs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     persist_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(persist_dir, DEFAULT_PERSIST_FNAME)\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_persist_path(persist_path, fs\u001b[39m=\u001b[39;49mfs)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/llama_index/vector_stores/simple.py:207\u001b[0m, in \u001b[0;36mSimpleVectorStore.from_persist_path\u001b[0;34m(cls, persist_path, fs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39mopen(persist_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    206\u001b[0m     data_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m--> 207\u001b[0m     data \u001b[39m=\u001b[39m SimpleVectorStoreData\u001b[39m.\u001b[39;49mfrom_dict(data_dict)\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(data)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/api.py:70\u001b[0m, in \u001b[0;36mDataClassJsonMixin.from_dict\u001b[0;34m(cls, kvs, infer_missing)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_dict\u001b[39m(\u001b[39mcls\u001b[39m: Type[A],\n\u001b[1;32m     67\u001b[0m               kvs: Json,\n\u001b[1;32m     68\u001b[0m               \u001b[39m*\u001b[39m,\n\u001b[1;32m     69\u001b[0m               infer_missing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m A:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m _decode_dataclass(\u001b[39mcls\u001b[39;49m, kvs, infer_missing)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:219\u001b[0m, in \u001b[0;36m_decode_dataclass\u001b[0;34m(cls, kvs, infer_missing)\u001b[0m\n\u001b[1;32m    217\u001b[0m     init_kwargs[field\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m value\n\u001b[1;32m    218\u001b[0m \u001b[39melif\u001b[39;00m _is_supported_generic(field_type) \u001b[39mand\u001b[39;00m field_type \u001b[39m!=\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m     init_kwargs[field\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m _decode_generic(field_type,\n\u001b[1;32m    220\u001b[0m                                               field_value,\n\u001b[1;32m    221\u001b[0m                                               infer_missing)\n\u001b[1;32m    222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     init_kwargs[field\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m _support_extended_types(field_type,\n\u001b[1;32m    224\u001b[0m                                                       field_value)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:279\u001b[0m, in \u001b[0;36m_decode_generic\u001b[0;34m(type_, value, infer_missing)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[39m# a mapping type has `.keys()` and `.values()`\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[39m# (see collections.abc)\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     ks \u001b[39m=\u001b[39m _decode_dict_keys(k_type, value\u001b[39m.\u001b[39mkeys(), infer_missing)\n\u001b[0;32m--> 279\u001b[0m     vs \u001b[39m=\u001b[39m _decode_items(v_type, value\u001b[39m.\u001b[39;49mvalues(), infer_missing)\n\u001b[1;32m    280\u001b[0m     xs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(ks, vs)\n\u001b[1;32m    281\u001b[0m \u001b[39melif\u001b[39;00m _is_tuple(type_):\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:362\u001b[0m, in \u001b[0;36m_decode_items\u001b[0;34m(type_args, xs, infer_missing)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m _isinstance_safe(type_args, Collection) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _issubclass_safe(type_args, Enum):\n\u001b[1;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_decode_item(type_arg, x) \u001b[39mfor\u001b[39;00m type_arg, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(type_args, xs))\n\u001b[0;32m--> 362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(_decode_item(type_args, x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m xs)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:362\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m _isinstance_safe(type_args, Collection) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _issubclass_safe(type_args, Enum):\n\u001b[1;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_decode_item(type_arg, x) \u001b[39mfor\u001b[39;00m type_arg, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(type_args, xs))\n\u001b[0;32m--> 362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_decode_item(type_args, x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:357\u001b[0m, in \u001b[0;36m_decode_items.<locals>._decode_item\u001b[0;34m(type_arg, x)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m _decode_dataclass(type_arg, x, infer_missing)\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m _is_supported_generic(type_arg):\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _decode_generic(type_arg, x, infer_missing)\n\u001b[1;32m    358\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:288\u001b[0m, in \u001b[0;36m_decode_generic\u001b[0;34m(type_, value, infer_missing)\u001b[0m\n\u001b[1;32m    286\u001b[0m         xs \u001b[39m=\u001b[39m _decode_items(_get_type_args(type_) \u001b[39mor\u001b[39;00m _NO_ARGS, value, infer_missing)\n\u001b[1;32m    287\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     xs \u001b[39m=\u001b[39m _decode_items(_get_type_arg_param(type_, \u001b[39m0\u001b[39;49m), value, infer_missing)\n\u001b[1;32m    290\u001b[0m \u001b[39m# get the constructor if using corresponding generic type in `typing`\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# otherwise fallback on constructing using type_ itself\u001b[39;00m\n\u001b[1;32m    292\u001b[0m materialize_type \u001b[39m=\u001b[39m type_\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:362\u001b[0m, in \u001b[0;36m_decode_items\u001b[0;34m(type_args, xs, infer_missing)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m _isinstance_safe(type_args, Collection) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _issubclass_safe(type_args, Enum):\n\u001b[1;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_decode_item(type_arg, x) \u001b[39mfor\u001b[39;00m type_arg, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(type_args, xs))\n\u001b[0;32m--> 362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(_decode_item(type_args, x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m xs)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:362\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m _isinstance_safe(type_args, Collection) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _issubclass_safe(type_args, Enum):\n\u001b[1;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_decode_item(type_arg, x) \u001b[39mfor\u001b[39;00m type_arg, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(type_args, xs))\n\u001b[0;32m--> 362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_decode_item(type_args, x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs)\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/dataclasses_json/core.py:354\u001b[0m, in \u001b[0;36m_decode_items.<locals>._decode_item\u001b[0;34m(type_arg, x)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decode_item\u001b[39m(type_arg, x):\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mif\u001b[39;00m is_dataclass(type_arg) \u001b[39mor\u001b[39;00m is_dataclass(xs):\n\u001b[1;32m    355\u001b[0m         \u001b[39mreturn\u001b[39;00m _decode_dataclass(type_arg, x, infer_missing)\n\u001b[1;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m _is_supported_generic(type_arg):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/dataclasses.py:1045\u001b[0m, in \u001b[0;36mis_dataclass\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns True if obj is an instance of a dataclass.\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(obj), _FIELDS)\n\u001b[0;32m-> 1045\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_dataclass\u001b[39m(obj):\n\u001b[1;32m   1046\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns True if obj is a dataclass or an instance of a\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[39m    dataclass.\"\"\"\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m obj \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtype\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mtype\u001b[39m(obj)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1758\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/vs_projects/lang_human/phoenix-lib-tests/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      6\u001b[0m _temp \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread()\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_is_stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 3.x has this\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mis_thread_alive\u001b[39m(t):\n\u001b[1;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39m_is_stopped\n\u001b[1;32m     12\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_Thread__stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 2.x has this\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from llama_index_w_eavls_and_qa import get_urls, read_strings_from_csv, run_experiments, plot_graphs\n",
    "import pickle\n",
    "import config\n",
    "from llama_index import download_loader\n",
    "import openai\n",
    "import cohere\n",
    "\n",
    "name = \"BeautifulSoupWebReader\"\n",
    "BeautifulSoupWebReader = download_loader(name)\n",
    "now = datetime.datetime.now()\n",
    "run_name = now.strftime('%Y%m%d_%H%M')\n",
    "# Directory parameter for saving data!\n",
    "openai.api_key = (\n",
    "    config.open_ai_key\n",
    ")  # replace with the string containing the API key if needed\n",
    "cohere.api_key = config.cohere_key\n",
    "#Used by Arize Evals\n",
    "os.environ['OPENAI_API_KEY'] =  config.open_ai_key\n",
    "\n",
    "# if loading from scratch, change these below\n",
    "web_title = \"arize\"  # nickname for this website, used for saving purposes\n",
    "base_url = \"https://docs.arize.com/arize\"\n",
    "#Local files\n",
    "file_name = 'raw_documents.pkl'\n",
    "save_base = f\"./experiment_data/\" \n",
    "save_dir = save_base + run_name + \"/\"\n",
    "\n",
    "# Read strings from CSV\n",
    "questions = read_strings_from_csv(\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/constants.csv\")\n",
    "\n",
    "if not os.path.exists(save_base + file_name):\n",
    "    print(f\"'{save_base}{file_name}' does not exists.\")\n",
    "    urls = get_urls(base_url) #you need to - pip install lxml\n",
    "    print(f\"LOADED {len(urls)} URLS\")\n",
    "\n",
    "print(\"GRABBING DOCUMENTS\")\n",
    "# two options here, either get the documents from scratch or load one from disk\n",
    "if not os.path.exists(save_base + file_name):\n",
    "    print(\"LOADING DOCUMENTS FROM URLS\")\n",
    "    #You need to 'pip install lxml'\n",
    "    loader = BeautifulSoupWebReader()\n",
    "    documents = loader.load_data(urls=urls)  # may take some time\n",
    "    with open(save_base + file_name, \"wb\") as file:\n",
    "        pickle.dump(documents, file)\n",
    "    print(\"Documents saved to raw_documents.pkl\")\n",
    "else:\n",
    "    print(\"LOADING DOCUMENTS FROM FILE\")\n",
    "    print(\"Opening raw_documents.pkl\")\n",
    "    with open(save_base + file_name, \"rb\") as file:\n",
    "        documents = pickle.load(file)\n",
    "chunk_sizes = [\n",
    "    100,\n",
    "    #300,\n",
    "    #500,\n",
    "    #1000,\n",
    "    #2000,\n",
    "]  # change this, perhaps experiment from 500 to 3000 in increments of 500\n",
    "\n",
    "k = [4, 6, 10]\n",
    "#k = [10]  # num documents to retrieve\n",
    "\n",
    "#transformations = [\"original\", \"original_rerank\",\"hyde\", \"hyde_rerank\"]\n",
    "transformations = [\"original\", \"original_rerank\"]\n",
    "\n",
    "lama_index_model = \"gpt-4\"\n",
    "#lama_index_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "eval_model = \"gpt-4\"\n",
    "\n",
    "#Uncomment when testing\n",
    "#questions = questions[0:3]\n",
    "all_data = run_experiments(\n",
    "    documents,\n",
    "    questions,\n",
    "    chunk_sizes,\n",
    "    transformations,\n",
    "    k,\n",
    "    web_title,\n",
    "    save_dir,\n",
    "    lama_index_model,\n",
    "    eval_model\n",
    ")\n",
    "\n",
    "\n",
    "with open(f\"{save_dir}{web_title}_all_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_data, f)\n",
    "\n",
    "#The retrievals with 0 relevant context really can't be optimized, removing gives a diff view\n",
    "plot_graphs(all_data, k, save_dir +  \"/results_zero_removed/\", show=False)\n",
    "plot_graphs(all_data, k, save_dir + \"/results_no_zero_remove/\", show=False, remove_zero=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results Q&A Evals (actual results in experiment_data)\n",
    "\n",
    "The Q&A Eval runs at the highest level of did you get the question answer correct  based on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix data\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/percentage_incorrect_plot.png\" />\n",
    "    </p>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results Retrieval Eval  (actual results in experiment_data)\n",
    "\n",
    "The retrieval analysis example is below, iterates through the chunk sizes, K (4/6/10), retrieval method\n",
    "The eval checks whether the retrieved chunk is relevant and has a chance to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix data\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/all_mean_precisions.png\" />\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results Latency  (actual results in experiment_data)\n",
    "\n",
    "The latency can highly varied based on retrieval approaches, below are latency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix data\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/median_latency_all.png\" />\n",
    "    </p>\n",
    "</center>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix-lib-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
