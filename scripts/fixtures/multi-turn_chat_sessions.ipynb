{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uqqq datasets openinference-instrumentation-openai openai-responses openai tiktoken langchain langchain-openai llama-index llama-index-llms-openai faker mdgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b788701385cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "from random import randint, random, shuffle\n",
    "\n",
    "import openai\n",
    "from datasets import load_dataset\n",
    "from faker import Faker\n",
    "from mdgen import MarkdownPostProvider\n",
    "from openai_responses import OpenAIMock\n",
    "from openinference.instrumentation import using_session, using_user\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import SpanLimits, TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter\n",
    "from tiktoken import encoding_for_model\n",
    "\n",
    "fake = Faker()\n",
    "fake.add_provider(MarkdownPostProvider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e29a5",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"GitBag/ultrainteract_multiturn_1_iter_processed_harvard\")[\"train\"].to_pandas()\n",
    "convo = df.loc[df.chosen.apply(len) == 10, \"chosen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62ce0f",
   "metadata": {},
   "source": [
    "# Tracer Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e76da34fee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_provider = TracerProvider(span_limits=SpanLimits(max_attributes=1_000_000))\n",
    "in_memory_span_exporter = InMemorySpanExporter()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(in_memory_span_exporter))\n",
    "endpoint = \"http://127.0.0.1:4317\"\n",
    "otlp_span_exporter = OTLPSpanExporter(endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1cf375",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_session_id():\n",
    "    p = random()\n",
    "    if p < 0.1:\n",
    "        return \":\" * randint(1, 5)\n",
    "    if p < 0.9:\n",
    "        return Faker([\"ja_JP\", \"vi_VN\", \"ko_KR\", \"zh_CN\"]).address()\n",
    "    return int(abs(random()) * 1_000_000_000)\n",
    "\n",
    "\n",
    "def gen_user_id():\n",
    "    p = random()\n",
    "    if p < 0.1:\n",
    "        return \":\" * randint(1, 5)\n",
    "    if p < 0.9:\n",
    "        return Faker([\"ja_JP\", \"vi_VN\", \"ko_KR\", \"zh_CN\"]).name()\n",
    "    return int(abs(random()) * 1_000_000_000)\n",
    "\n",
    "\n",
    "def export_spans():\n",
    "    \"\"\"Export spans in random order for receiver testing\"\"\"\n",
    "    spans = list(in_memory_span_exporter.get_finished_spans())\n",
    "    shuffle(spans)\n",
    "    for span in spans:\n",
    "        otlp_span_exporter.export([span])\n",
    "    in_memory_span_exporter.clear()\n",
    "    session_count = len({id_ for span in spans if (id_ := span.attributes.get(\"session.id\"))})\n",
    "    trace_count = len({span.context.trace_id for span in spans})\n",
    "    print(f\"Exported {session_count} sessions, {trace_count} traces, {len(spans)} spans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2ac17",
   "metadata": {},
   "source": [
    "# Text Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc6b1f",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedf0f3bc9b454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_count = randint(10, 20)\n",
    "\n",
    "\n",
    "def simulate_openai(messages):\n",
    "    user_id = gen_user_id() if random() < 0.9 else \" \"\n",
    "    session_id = gen_session_id()\n",
    "    client = openai.Client(api_key=\"sk-\")\n",
    "    model = \"gpt-4o-mini\"\n",
    "    encoding = encoding_for_model(model)\n",
    "    counts = [len(encoding.encode(m[\"content\"])) for m in messages]\n",
    "    multiplier = randint(1, 10)\n",
    "    messages = list(messages) * multiplier\n",
    "    counts = counts * multiplier\n",
    "    openai_mock = OpenAIMock()\n",
    "    tracer = tracer_provider.get_tracer(__name__)\n",
    "    with openai_mock.router:\n",
    "        for i in range(1, len(messages), 2):\n",
    "            openai_mock.chat.completions.create.response = dict(\n",
    "                choices=[dict(index=0, finish_reason=\"stop\", message=messages[i])],\n",
    "                usage=dict(\n",
    "                    prompt_tokens=sum(counts[:i]),\n",
    "                    completion_tokens=counts[i],\n",
    "                    total_tokens=sum(counts[: i + 1]),\n",
    "                ),\n",
    "            )\n",
    "            with ExitStack() as stack:\n",
    "                attributes = {\n",
    "                    \"input.value\": messages[i - 1][\"content\"],\n",
    "                    \"output.value\": messages[i][\"content\"],\n",
    "                }\n",
    "                if random() < 0.5:\n",
    "                    attributes[\"session.id\"] = session_id\n",
    "                    attributes[\"user.id\"] = user_id\n",
    "                else:\n",
    "                    stack.enter_context(using_session(session_id))\n",
    "                    stack.enter_context(using_user(user_id))\n",
    "                stack.enter_context(tracer.start_as_current_span(\"root\", attributes=attributes))\n",
    "                client.chat.completions.create(model=model, messages=messages[:i])\n",
    "\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "convo.sample(session_count).apply(simulate_openai)\n",
    "OpenAIInstrumentor().uninstrument()\n",
    "export_spans()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
