[project]
name = "arize-phoenix"
description = "AI Observability and Evaluation"
readme = "README.md"
requires-python = ">=3.8, <3.13"
license = {text="Elastic-2.0"}
license-files = { paths = ["LICENSE", "IP_NOTICE"] }
keywords = [
  "Observability",
  "Monitoring",
  "Explainability",
]
authors = [
  { name = "Arize AI", email = "phoenix-devs@arize.com" },
]
classifiers = [
  "Programming Language :: Python",
  "Programming Language :: Python :: 3.8",
  "Programming Language :: Python :: 3.9",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
]
dependencies = [
  "scikit-learn",
  "numpy<2",  # https://github.com/scikit-learn-contrib/hdbscan/issues/642
  "pandas>=1.0",
  "jinja2",
  "umap-learn",
  "hdbscan>=0.8.33",
  "starlette",
  "uvicorn",
  "psutil",
  "strawberry-graphql==0.236.0",  # need to pin version because we're monkey-patching
  "pyarrow",
  "typing-extensions>=4.5; python_version<'3.12'",
  # A minimum version of typing-extensions==4.6.0 is needed to avoid this issue on Python 3.12: https://github.com/Azure/azure-sdk-for-python/issues/33442#issuecomment-1847886784
  "typing-extensions>=4.6; python_version>='3.12'",
  "scipy",
  "wrapt",
  "protobuf>=3.20, <6.0",
  "grpcio",
  "tqdm",
  "httpx",
  "opentelemetry-sdk",
  "opentelemetry-proto>=1.12.0",  # needed to avoid this issue: https://github.com/Arize-ai/phoenix/issues/2695
  "opentelemetry-exporter-otlp",
  "opentelemetry-semantic-conventions",
  "openinference-semantic-conventions>=0.1.9",
  "openinference-instrumentation",
  "openinference-instrumentation-langchain>=0.1.12",
  "openinference-instrumentation-llama-index>=1.2.0",
  "openinference-instrumentation-openai>=0.1.4",
  "sqlalchemy[asyncio]>=2.0.4, <3",
  "alembic>=1.3.0, <2",
  "aiosqlite",
  "aioitertools",
  "sqlean.py>=3.45.1",
  "cachetools",
  "python-multipart",  # see https://www.starlette.io/#dependencies
  "arize-phoenix-evals>=0.13.1",
  "fastapi",
  "pydantic>=1.0,!=2.0.*,<3,", # exclude 2.0.* since it does not support the `json_encoders` configuration setting
]
dynamic = ["version"]

[project.optional-dependencies]
dev = [
  "gcsfs",
  "hatch",
  "jupyter",
  "nbqa",
  "ruff==0.5.4",
  "mypy==1.11.0",
  "pandas>=1.0",
  "tabulate",  # used by DataFrame.to_markdown()
  "types-tabulate",
  "pandas-stubs==2.2.2.240603; python_version>='3.9'",
  "pandas-stubs==2.0.3.230814; python_version<'3.9'",
  "pytest==8.3.1",
  "pytest-asyncio",
  "pytest-cov",
  "pytest-postgresql",
  "asyncpg",
  "psycopg[binary]",
  "strawberry-graphql[debug-server,opentelemetry]==0.236.0",  # need to pin version because we're monkey-patching
  "pre-commit",
  "arize[AutoEmbeddings, LLM_Evaluation]",
  "llama-index>=0.10.3",
  "langchain>=0.0.334",
  "litellm>=1.0.3",
  "google-cloud-aiplatform>=1.3",
  "anthropic",
  "prometheus_client",
  "asgi-lifespan",
  "Faker>=26.0.0",
]
evals = []
experimental = []
llama-index = [
  "llama-index==0.10.51",  # always pin to a version that keeps our notebooks working
  "llama-index-readers-file==0.1.25",
  "llama-index-llms-openai==0.1.24",
  "llama-index-embeddings-openai==0.1.10",
  "llama-index-agent-openai==0.2.7",
]
pg = [
  "asyncpg",
]
container = [
  "prometheus-client",
  "opentelemetry-sdk",
  "opentelemetry-proto>=1.12.0",
  "opentelemetry-exporter-otlp",
  "opentelemetry-semantic-conventions",
  "opentelemetry-instrumentation-fastapi",
  "opentelemetry-instrumentation-sqlalchemy",
  "opentelemetry-instrumentation-grpc",
  "py-grpc-prometheus",
  "strawberry-graphql[opentelemetry]==0.236.0",  # need to pin version because we're monkey-patching
  "uvloop; platform_system != 'Windows'",
]

[project.urls]
Documentation = "https://docs.arize.com/phoenix/"
Issues = "https://github.com/Arize-ai/phoenix/issues"
Source = "https://github.com/Arize-ai/phoenix"

[tool.hatch.version]
path = "src/phoenix/version.py"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/phoenix"]
exclude = ["src/phoenix/evals/"]
artifacts = ["src/phoenix/server/static", "src/phoenix/db/migrations"]

[tool.hatch.build]
only-packages = true

[tool.hatch.build.targets.sdist]
exclude = ["src/phoenix/evals/", "packages/"]
artifacts = ["src/phoenix/server/static", "src/phoenix/db/migrations"]

[tool.hatch.envs.default]
dependencies = [
  "numpy",
  "pandas==2.2.2; python_version>='3.9'",
  "pandas==1.4.0; python_version<'3.9'",
  "pytest==8.3.1",
  "pytest-asyncio",
  "pytest-cov",
  "pytest-postgresql",
  "asyncpg",
  "psycopg[binary]",
  "arize",
  "litellm>=1.0.3",
  "openai>=1.0.0",
  "tenacity",
  "protobuf==3.20",  # version minimum (for tests)
  "responses",
  "tiktoken",
  "typing-extensions==4.5.0; python_version=='3.8'",
  "typing-extensions==4.6.0; python_version=='3.9'",
  "pydantic==1.9.0; python_version<='3.9'",  # minimum version of pydantic compatible with openai
  "pydantic==2.8.2; python_version=='3.12'",
  "httpx", # For OpenAI testing
  "respx", # For OpenAI testing
  "nest-asyncio", # for executor testing
  "astunparse; python_version<'3.9'",  # `ast.unparse(...)` is only available starting with Python 3.9
  "asgi-lifespan",
  "Faker>=26.0.0",
]

[tool.hatch.envs.type]
dependencies = [
  "mypy==1.11.0",
  "tenacity",
  "pandas>=1.0",
  "pandas-stubs==2.0.3.230814",
  "types-tabulate",
  "types-psutil",
  "types-tqdm",
  "types-protobuf",
  "types-setuptools",
  "types-cachetools",
  "openai>=1.0.0",
  "litellm>=1.0.3",
  "prometheus_client",
  "grpcio",
  "opentelemetry-sdk",
  "opentelemetry-proto>=1.12.0",
  "opentelemetry-exporter-otlp",
  "opentelemetry-semantic-conventions",
  "opentelemetry-instrumentation-fastapi",
  "opentelemetry-instrumentation-sqlalchemy",
  "opentelemetry-instrumentation-grpc",
  "py-grpc-prometheus",
  "strawberry-graphql[opentelemetry]==0.236.0",  # need to pin version because we're monkey-patching
  "requests",  # this is needed to type-check third-party packages
  "pydantic==1.10.17; python_version=='3.8'",  # lower minor versions of pydantic break strawberry mypy plugin
  "pydantic==1.10.17; python_version=='3.9'",  # lower minor versions of pydantic break strawberry mypy plugin
  "pydantic==2.8.2; python_version=='3.12'",
]

[[tool.hatch.envs.type.matrix]]
python = ["3.8", "3.9", "3.12"]

[tool.hatch.envs.style]
detached = true
dependencies = [
  "ruff==0.5.4",
]

[[tool.hatch.envs.style.matrix]]
python = ["3.8", "3.9", "3.12"]

[tool.hatch.envs.notebooks]
detached = true
dependencies = [
  "jupyter",
]

[tool.hatch.envs.docs]
detached = true
dependencies = [
  "pyment",
  "interrogate",
]

[tool.hatch.envs.default.scripts]
tests = "pytest {args}"
coverage = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/phoenix --cov=tests {args}"

[[tool.hatch.envs.test.matrix]]
python = ["3.8", "3.12"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
addopts = [
  "-rA",
  "--import-mode=importlib",
  "--doctest-modules",
]
testpaths = [
  "tests",
]

[tool.coverage.run]
branch = true
parallel = true
omit = [
  "**/__init__.py",
]

[tool.coverage.report]
fail_under=30
show_missing=true
sort="cover"
exclude_lines = [
  "no cov",
  "if __name__ == .__main__.:",
  "if TYPE_CHECKING:",
]

[tool.hatch.envs.type.scripts]
check = [
  "mypy .",
]

[tool.hatch.envs.style.scripts]
check = [
  "ruff format --check --diff .",
  "ruff check .",
]
fix = [
  "ruff format .",
  "ruff check --fix .",
]

[tool.hatch.envs.notebooks.scripts]
clean = [
  "jupyter nbconvert --ClearOutputPreprocessor.enabled=True --ClearMetadataPreprocessor.enabled=True --inplace **/*.ipynb **/internal/*.ipynb **/tracing/*.ipynb **/dolly-pythia-fine-tuned/*.ipynb",
]

[tool.hatch.envs.publish]
dependencies = [
  "check-wheel-contents",
  "twine",
]

[tool.hatch.envs.publish.scripts]
testpypi = [
  "check-wheel-contents dist/",
  "twine upload  --verbose --repository testpypi dist/*",
]
pypi = [
  "check-wheel-contents dist/",
  "twine upload --verbose dist/*",
]

[tool.hatch.envs.docs.scripts]
check = [
  "interrogate -vv src/",
]

[tool.hatch.envs.gql]
dependencies = [
  "strawberry-graphql[cli]==0.236.0",  # need to pin version because we're monkey-patching
  "requests",
]

[tool.hatch.envs.gql.scripts]
build = 'strawberry export-schema phoenix.server.api.schema:schema > app/schema.graphql'

[tool.hatch.envs.openapi]
dependencies = [
  "pydantic==2.8.2",
  "fastapi==0.111.0",
]

[tool.hatch.envs.openapi.scripts]
build = "python -m phoenix.server.api.openapi.main > schemas/openapi.json"

[tool.hatch.envs.proto]
detached = true
dependencies = [
  "grpcio-tools==1.54.3",
  "mypy-protobuf==3.5.0",
]

[tool.hatch.envs.proto.scripts]
recompile = """
python -m grpc_tools.protoc -I src/phoenix/proto --python_out=src/phoenix --mypy_out=src/phoenix src/phoenix/proto/trace/v1/evaluation.proto
"""

[tool.interrogate]
fail-under = 0
# generate-badge = "badges/"
omit-covered-files = true
ignore-init-method = true
ignore-init-module = true
ignore-magic = false
ignore-semiprivate = false
ignore-private = false
ignore-property-decorators = false
ignore-module = false
ignore-nested-functions = false
ignore-nested-classes = false
ignore-setters = false

[tool.mypy]
plugins = ["strawberry.ext.mypy_plugin", "pydantic.mypy"]
disallow_untyped_calls = true
disallow_untyped_defs = true
disallow_incomplete_defs  = true
strict = true
exclude = [
  "api_reference",
  "packages/",
  "src/phoenix/evals/",
  "dist/",
  "scripts/data/",
  "sdist/",
  "tests/",
  "tutorials/",
  "examples/manually-instrumented-chatbot/"
]

[[tool.mypy.overrides]]
module = [
  "hdbscan",
  "umap",
  "numba.*",
  "scipy.*",
  "sklearn.*",
  "arize.*",
  "wrapt",
  "langchain.*",
  "litellm",
  "litellm.*",
  "nest_asyncio",
  "opentelemetry.*",
  "pyarrow",
  "sqlean",
  "grpc.*",
  "py_grpc_prometheus.*",
  "orjson",  # suppress fastapi internal type errors
]
ignore_missing_imports = true

[tool.ruff]
exclude = [
  "api_reference",
  "packages",
  "src/phoenix/evals/",
  "dist/",
  ".git",
  "__pycache__",
  "*_pb2.py*",
  "*.pyi",
  "docs/",
]
extend-include = ["*.ipynb"]
line-length = 100
target-version = "py38"

[tool.ruff.lint.per-file-ignores]
"*.ipynb" = ["E402", "E501"]

[tool.ruff.lint]
select = ["E", "F", "W", "I", "NPY201"]

[tool.ruff.lint.isort]
force-single-line = false

[tool.ruff.format]
line-ending = "lf"
